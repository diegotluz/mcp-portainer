Directory structure:
└── portainer-portainer-docs/
    ├── README.md
    ├── privacy.md
    ├── SUMMARY.md
    ├── whats-new.md
    ├── admin/
    │   ├── licenses.md
    │   ├── notifications.md
    │   ├── environments/
    │   │   ├── README.md
    │   │   ├── access-groups.md
    │   │   ├── access.md
    │   │   ├── aeec.md
    │   │   ├── environments.md
    │   │   ├── groups.md
    │   │   ├── tags.md
    │   │   ├── update.md
    │   │   └── add/
    │   │       ├── README.md
    │   │       ├── aci.md
    │   │       ├── api.md
    │   │       ├── local.md
    │   │       ├── nomad.md
    │   │       ├── docker/
    │   │       │   ├── README.md
    │   │       │   ├── agent.md
    │   │       │   ├── api.md
    │   │       │   ├── edge-async.md
    │   │       │   ├── edge.md
    │   │       │   └── socket.md
    │   │       ├── kaas/
    │   │       │   ├── README.md
    │   │       │   ├── aks.md
    │   │       │   ├── civo.md
    │   │       │   ├── digitalocean.md
    │   │       │   ├── eks.md
    │   │       │   ├── gke.md
    │   │       │   └── linode.md
    │   │       ├── kube-create/
    │   │       │   ├── README.md
    │   │       │   ├── omni.md
    │   │       │   └── microk8s/
    │   │       │       ├── README.md
    │   │       │       └── offline.md
    │   │       ├── kubernetes/
    │   │       │   ├── README.md
    │   │       │   ├── agent.md
    │   │       │   ├── edge-async.md
    │   │       │   ├── edge.md
    │   │       │   └── import.md
    │   │       ├── podman/
    │   │       │   ├── README.md
    │   │       │   ├── agent.md
    │   │       │   ├── edge-async.md
    │   │       │   ├── edge.md
    │   │       │   └── socket.md
    │   │       └── swarm/
    │   │           ├── README.md
    │   │           ├── agent.md
    │   │           ├── api.md
    │   │           ├── edge-async.md
    │   │           ├── edge.md
    │   │           └── socket.md
    │   ├── logs/
    │   │   ├── README.md
    │   │   ├── activity.md
    │   │   └── authentication.md
    │   ├── registries/
    │   │   ├── README.md
    │   │   ├── browse.md
    │   │   ├── manage.md
    │   │   └── add/
    │   │       ├── README.md
    │   │       ├── azure.md
    │   │       ├── custom.md
    │   │       ├── dockerhub.md
    │   │       ├── ecr.md
    │   │       ├── ghcr.md
    │   │       ├── gitlab.md
    │   │       ├── proget.md
    │   │       └── quay.md
    │   ├── settings/
    │   │   ├── README.md
    │   │   ├── edge.md
    │   │   ├── general.md
    │   │   ├── authentication/
    │   │   │   ├── README.md
    │   │   │   ├── active-directory.md
    │   │   │   ├── ldap.md
    │   │   │   └── oauth.md
    │   │   └── credentials/
    │   │       ├── README.md
    │   │       ├── aks.md
    │   │       ├── civo.md
    │   │       ├── digitalocean.md
    │   │       ├── eks.md
    │   │       ├── gke.md
    │   │       ├── linode.md
    │   │       ├── omni.md
    │   │       └── ssh.md
    │   └── user/
    │       ├── README.md
    │       ├── add.md
    │       ├── password.md
    │       ├── promote.md
    │       ├── roles.md
    │       ├── users.md
    │       └── teams/
    │           ├── README.md
    │           ├── add-user.md
    │           └── add.md
    ├── advanced/
    │   ├── access-control.md
    │   ├── cli.md
    │   ├── db-encryption.md
    │   ├── deprecated.md
    │   ├── docker-roles-and-permissions.md
    │   ├── edge-agent.md
    │   ├── helm-chart-configuration-options.md
    │   ├── kubernetes-roles-and-bindings.md
    │   ├── mtls.md
    │   ├── relative-paths.md
    │   ├── reset-admin.md
    │   ├── security.md
    │   ├── siem.md
    │   ├── ssl.md
    │   ├── app-templates/
    │   │   ├── README.md
    │   │   ├── build.md
    │   │   └── format.md
    │   └── reverse-proxy/
    │       ├── README.md
    │       ├── nginx.md
    │       └── traefik.md
    ├── api/
    │   ├── access.md
    │   ├── docs.md
    │   └── examples.md
    ├── contribute/
    │   └── contribute.md
    ├── faq/
    │   ├── concepts.md
    │   ├── contributing.md
    │   ├── installing.md
    │   ├── troubleshooting.md
    │   └── upgrading.md
    ├── start/
    │   ├── agent.md
    │   ├── architecture.md
    │   ├── intro.md
    │   ├── lifecycle.md
    │   ├── requirements-and-prerequisites.md
    │   ├── install/
    │   │   ├── README.md
    │   │   └── server/
    │   │       ├── README.md
    │   │       ├── setup.md
    │   │       ├── docker/
    │   │       │   ├── README.md
    │   │       │   ├── linux.md
    │   │       │   ├── wcs.md
    │   │       │   └── wsl.md
    │   │       ├── kubernetes/
    │   │       │   ├── README.md
    │   │       │   ├── baremetal.md
    │   │       │   └── wsl.md
    │   │       ├── podman/
    │   │       │   ├── README.md
    │   │       │   └── linux.md
    │   │       └── swarm/
    │   │           ├── README.md
    │   │           ├── linux.md
    │   │           ├── wcs.md
    │   │           └── wsl.md
    │   ├── install-ce/
    │   │   ├── README.md
    │   │   └── server/
    │   │       ├── README.md
    │   │       ├── setup.md
    │   │       ├── docker/
    │   │       │   ├── README.md
    │   │       │   ├── linux.md
    │   │       │   ├── wcs.md
    │   │       │   └── wsl.md
    │   │       ├── kubernetes/
    │   │       │   ├── README.md
    │   │       │   ├── baremetal.md
    │   │       │   └── wsl.md
    │   │       ├── podman/
    │   │       │   ├── README.md
    │   │       │   └── linux.md
    │   │       └── swarm/
    │   │           ├── README.md
    │   │           ├── linux.md
    │   │           ├── wcs.md
    │   │           └── wsl.md
    │   └── upgrade/
    │       ├── README.md
    │       ├── docker.md
    │       ├── edge.md
    │       ├── from-1.x.md
    │       ├── kubernetes.md
    │       ├── nomad.md
    │       ├── podman.md
    │       ├── swarm.md
    │       └── tobe/
    │           ├── README.md
    │           ├── agent.md
    │           ├── docker.md
    │           ├── inapp.md
    │           ├── kubernetes.md
    │           ├── podman.md
    │           └── swarm.md
    └── user/
        ├── account-settings.md
        ├── nomad.md
        ├── aci/
        │   ├── README.md
        │   ├── dashboard.md
        │   └── containers/
        │       ├── README.md
        │       ├── add.md
        │       ├── details.md
        │       └── remove.md
        ├── docker/
        │   ├── README.md
        │   ├── dashboard.md
        │   ├── events.md
        │   ├── configs/
        │   │   ├── README.md
        │   │   ├── add.md
        │   │   └── remove.md
        │   ├── containers/
        │   │   ├── README.md
        │   │   ├── add.md
        │   │   ├── advanced.md
        │   │   ├── attach-volume.md
        │   │   ├── console.md
        │   │   ├── edit.md
        │   │   ├── inspect.md
        │   │   ├── logs.md
        │   │   ├── ownership.md
        │   │   ├── remove.md
        │   │   ├── stats.md
        │   │   ├── view.md
        │   │   └── webhooks.md
        │   ├── host/
        │   │   ├── README.md
        │   │   ├── details.md
        │   │   ├── registries.md
        │   │   └── setup.md
        │   ├── images/
        │   │   ├── README.md
        │   │   ├── build.md
        │   │   ├── export.md
        │   │   ├── import.md
        │   │   └── pull.md
        │   ├── networks/
        │   │   ├── README.md
        │   │   ├── add.md
        │   │   └── remove.md
        │   ├── secrets/
        │   │   ├── README.md
        │   │   ├── add.md
        │   │   └── remove.md
        │   ├── services/
        │   │   ├── README.md
        │   │   ├── add.md
        │   │   ├── configure.md
        │   │   ├── logs.md
        │   │   ├── rollback.md
        │   │   ├── scale.md
        │   │   ├── tasks.md
        │   │   └── webhooks.md
        │   ├── stacks/
        │   │   ├── README.md
        │   │   ├── add.md
        │   │   ├── edit.md
        │   │   ├── migrate.md
        │   │   ├── remove.md
        │   │   ├── template.md
        │   │   └── webhooks.md
        │   ├── swarm/
        │   │   ├── README.md
        │   │   ├── cluster-visualizer.md
        │   │   ├── details.md
        │   │   ├── registries.md
        │   │   └── setup.md
        │   ├── templates/
        │   │   ├── README.md
        │   │   ├── application.md
        │   │   ├── custom.md
        │   │   ├── deploy-container.md
        │   │   └── deploy-stack.md
        │   └── volumes/
        │       ├── README.md
        │       ├── add.md
        │       ├── browse.md
        │       └── remove.md
        ├── edge/
        │   ├── README.md
        │   ├── configurations.md
        │   ├── groups.md
        │   ├── jobs.md
        │   ├── waiting-room.md
        │   ├── stacks/
        │   │   ├── README.md
        │   │   └── add.md
        │   └── templates/
        │       ├── README.md
        │       ├── application.md
        │       └── custom.md
        ├── home/
        │   ├── README.md
        │   ├── openamt.md
        │   └── snapshot.md
        └── kubernetes/
            ├── README.md
            ├── dashboard.md
            ├── helm.md
            ├── kubeconfig.md
            ├── kubectl.md
            ├── applications/
            │   ├── README.md
            │   ├── add.md
            │   ├── detach-volume.md
            │   ├── edit.md
            │   ├── inspect-helm.md
            │   ├── inspect.md
            │   ├── manifest.md
            │   ├── remove.md
            │   └── webhooks.md
            ├── cluster/
            │   ├── README.md
            │   ├── details.md
            │   ├── node.md
            │   ├── registries.md
            │   ├── security.md
            │   └── setup.md
            ├── configurations/
            │   ├── README.md
            │   ├── add-1.md
            │   └── add.md
            ├── more-resources/
            │   ├── README.md
            │   ├── cluster-roles.md
            │   ├── jobs.md
            │   ├── namespace-roles.md
            │   └── service-accounts.md
            ├── namespaces/
            │   ├── README.md
            │   ├── access.md
            │   ├── add.md
            │   ├── manage.md
            │   └── remove.md
            ├── networking/
            │   ├── README.md
            │   ├── services.md
            │   └── ingresses/
            │       ├── README.md
            │       ├── add.md
            │       ├── manifest.md
            │       └── remove-an-ingress.md
            ├── templates/
            │   ├── README.md
            │   ├── add.md
            │   ├── edit.md
            │   └── remove.md
            └── volumes/
                ├── README.md
                ├── inspect.md
                └── remove.md

================================================
FILE: README.md
================================================
# Welcome

Welcome to Portainer's official documentation site.

## About Portainer

**Portainer Community Edition (CE)** is our foundation. With over half a million regular users, CE is a powerful, open source toolset that allows you to easily build and manage containers in Docker, Docker Swarm, Kubernetes and Azure ACI.

**Portainer Business Edition (BE)** is our commercial offering. With features geared towards businesses and larger organizations such as [Role-Based Access Control](admin/user/roles.md), [registry management](admin/registries/browse.md), and [dedicated support](./#getting-support), Portainer BE is a powerful toolset that allows you to easily build and manage containers in Docker, Docker Swarm, Kubernetes, Podman and Azure ACI.

{% hint style="info" %}
Portainer Business Edition requires a license key to install and use. If you don't currently have a license key, you can [request three nodes free](https://www.portainer.io/get-a-license) of Portainer Business Edition or [purchase a license](https://www.portainer.io/pricing).
{% endhint %}

Portainer hides the complexity of managing containers behind an easy-to-use UI. By removing the need to use the CLI, write YAML or understand manifests, Portainer makes deploying apps and troubleshooting problems so easy that anyone can do it.

Our team is here to help you on your journey. Community and five/three nodes free users can get assistance through our [community support channels](./#community-edition), and paid Business customers through our [business support channels](./#business-edition).

## Documentation

We're working hard to ensure that our documentation keeps up with our ever-growing Portainer community. If you have a question we encourage you to start with the documentation (right here!). If you can't find what you're looking for, please visit our [Knowledge Base](https://portal.portainer.io/knowledge) or one of our support channels.&#x20;

For more detailed step-by-step guides to Portainer, we're building out the [Portainer Academy](https://academy.portainer.io) with more courses regularly.

{% hint style="info" %}
As an open source product we rely on users in our community to support one another by asking questions, engaging in discussions and sharing knowledge. Together with the documentation found on this site and our [YouTube channel](https://www.youtube.com/channel/UC7diMJcrULjDseq5yhSUZgg), we cover a lot of ground but there may be gaps.
{% endhint %}

## Getting support

### Community Edition, Five/Three Node Free and Home & Student Users

Community Edition, five/three nodes free and Home & Student users can get support through the following channels:

* **Ask our AI bot** by clicking the **Ask AI** button in the bottom right of this documentation site. Our AI chatbot pulls from a number of sources and is a great place to start when looking for help.
* **Ask questions** either in our [GitHub Discussions](https://github.com/orgs/portainer/discussions/categories/help) forum or the [community Slack channel](https://join.slack.com/t/portainer/shared_invite/zt-21zpww5ab-mG_lA7UXbWL3HW3sPqjqEA). Other platforms exist (Reddit, Discord, Stack Overflow) but we are less active in those spaces.
* **Log bugs** in [GitHub Issues](https://github.com/portainer/portainer/issues) so they can be properly managed.
* **Flag vulnerabilities** by emailing [security@portainer.io](mailto:security@portainer.io) so we can deal with them immediately.
* **Flag documentation issues** via our [GitHub documentation channel](https://github.com/portainer/portainer-docs/issues) (or start [contributing](contribute/contribute.md) and make our documentation better!).

### Business Edition Customers

If you are a Professional or Enterprise tier Portainer Business Edition customer, you can log tickets directly with our team via [email](mailto:businesssupport@portainer.io) or filling out the [Request Support form](https://www.portainer.io/portainer-business-support). You can report a bug, ask a question, tell us about an issue with documentation, or request a feature. Tickets are checked and resolved by Portainer staff within the SLA.



================================================
FILE: privacy.md
================================================
# Privacy Policy

You can find our privacy policy [on our website](https://www.portainer.io/legal/privacy-policy).



================================================
FILE: SUMMARY.md
================================================
# Table of contents

* [Welcome](README.md)
* [What's new in version 2.27](whats-new.md)
* [Release Notes](release-notes.md)

## Getting Started <a href="#start" id="start"></a>

* [Introduction](start/intro.md)
* [Portainer architecture](start/architecture.md)
* [Lifecycle policy](start/lifecycle.md)
* [Requirements and prerequisites](start/requirements-and-prerequisites.md)
* [Install Portainer BE](start/install/README.md)
  * [Set up a new Portainer BE Server installation](start/install/server/README.md)
    * [Docker Standalone](start/install/server/docker/README.md)
      * [Install Portainer BE with Docker on Linux](start/install/server/docker/linux.md)
      * [Install Portainer BE with Docker on WSL / Docker Desktop](start/install/server/docker/wsl.md)
      * [Install Portainer BE with Docker on Windows Container Service](start/install/server/docker/wcs.md)
    * [Docker Swarm](start/install/server/swarm/README.md)
      * [Install Portainer BE with Docker Swarm on Linux](start/install/server/swarm/linux.md)
      * [Install Portainer BE with Docker Swarm on WSL / Docker Desktop](start/install/server/swarm/wsl.md)
      * [Install Portainer BE with Docker Swarm on Windows Container Service](start/install/server/swarm/wcs.md)
    * [Podman](start/install/server/podman/README.md)
      * [Install Portainer BE with Podman on Linux](start/install/server/podman/linux.md)
    * [Kubernetes](start/install/server/kubernetes/README.md)
      * [Install Portainer BE on your Kubernetes environment](start/install/server/kubernetes/baremetal.md)
      * [Install Portainer BE with Kubernetes on WSL / Docker Desktop](start/install/server/kubernetes/wsl.md)
    * [Initial setup](start/install/server/setup.md)
* [Install Portainer CE](start/install-ce/README.md)
  * [Set up a new Portainer CE Server installation](start/install-ce/server/README.md)
    * [Docker Standalone](start/install-ce/server/docker/README.md)
      * [Install Portainer CE with Docker on Linux](start/install-ce/server/docker/linux.md)
      * [Install Portainer CE with Docker on WSL / Docker Desktop](start/install-ce/server/docker/wsl.md)
      * [Install Portainer CE with Docker on Windows Container Service](start/install-ce/server/docker/wcs.md)
    * [Docker Swarm](start/install-ce/server/swarm/README.md)
      * [Install Portainer CE with Docker Swarm on Linux](start/install-ce/server/swarm/linux.md)
      * [Install Portainer CE with Docker Swarm on WSL / Docker Desktop](start/install-ce/server/swarm/wsl.md)
      * [Install Portainer CE with Docker Swarm on Windows Container Service](start/install-ce/server/swarm/wcs.md)
    * [Podman](start/install-ce/server/podman/README.md)
      * [Install Portainer CE with Podman on Linux](start/install-ce/server/podman/linux.md)
    * [Kubernetes](start/install-ce/server/kubernetes/README.md)
      * [Install Portainer CE on your Kubernetes environment](start/install-ce/server/kubernetes/baremetal.md)
      * [Install Portainer CE with Kubernetes on WSL / Docker Desktop](start/install-ce/server/kubernetes/wsl.md)
    * [Initial setup](start/install-ce/server/setup.md)
* [Add an environment to an existing installation](start/agent.md)
* [Updating Portainer](start/upgrade/README.md)
  * [Updating on Docker Standalone](start/upgrade/docker.md)
  * [Updating on Docker Swarm](start/upgrade/swarm.md)
  * [Updating on Podman](start/upgrade/podman.md)
  * [Updating on Kubernetes](start/upgrade/kubernetes.md)
  * [Updating on Nomad](start/upgrade/nomad.md)
  * [Updating the Edge Agent](start/upgrade/edge.md)
  * [Updating from Portainer 1.x](start/upgrade/from-1.x.md)
  * [Switching to Portainer Business Edition](start/upgrade/tobe/README.md)
    * [Upgrade to Business Edition from within Portainer Community Edition](start/upgrade/tobe/inapp.md)
    * [Docker Standalone](start/upgrade/tobe/docker.md)
    * [Docker Swarm](start/upgrade/tobe/swarm.md)
    * [Podman](start/upgrade/tobe/podman.md)
    * [Kubernetes](start/upgrade/tobe/kubernetes.md)
    * [Upgrading Agent-only deployments](start/upgrade/tobe/agent.md)

## Using Portainer <a href="#user" id="user"></a>

* [Home](user/home/README.md)
  * [Snapshot browsing](user/home/snapshot.md)
  * [OpenAMT](user/home/openamt.md)
* [Docker/Swarm/Podman](user/docker/README.md)
  * [Dashboard](user/docker/dashboard.md)
  * [Templates](user/docker/templates/README.md)
    * [Application](user/docker/templates/application.md)
    * [Custom templates](user/docker/templates/custom.md)
    * [Deploy a stack](user/docker/templates/deploy-stack.md)
    * [Deploy a container](user/docker/templates/deploy-container.md)
  * [Stacks](user/docker/stacks/README.md)
    * [Add a new stack](user/docker/stacks/add.md)
    * [Inspect or edit a stack](user/docker/stacks/edit.md)
    * [Create a template from a deployed stack](user/docker/stacks/template.md)
    * [Webhooks](user/docker/stacks/webhooks.md)
    * [Migrate or duplicate a stack](user/docker/stacks/migrate.md)
    * [Remove a stack](user/docker/stacks/remove.md)
  * [Services](user/docker/services/README.md)
    * [Add a new service](user/docker/services/add.md)
    * [Configure service options](user/docker/services/configure.md)
    * [Scale a service](user/docker/services/scale.md)
    * [View the status of a service task](user/docker/services/tasks.md)
    * [View service logs](user/docker/services/logs.md)
    * [Roll back a service](user/docker/services/rollback.md)
    * [Webhooks](user/docker/services/webhooks.md)
  * [Containers](user/docker/containers/README.md)
    * [Add a new container](user/docker/containers/add.md)
    * [View a container's details](user/docker/containers/view.md)
    * [Inspect a container](user/docker/containers/inspect.md)
    * [Edit or duplicate a container](user/docker/containers/edit.md)
    * [Advanced container settings](user/docker/containers/advanced.md)
    * [Webhooks](user/docker/containers/webhooks.md)
    * [Attach a volume to a container](user/docker/containers/attach-volume.md)
    * [View container logs](user/docker/containers/logs.md)
    * [View container statistics](user/docker/containers/stats.md)
    * [Access a container's console](user/docker/containers/console.md)
    * [Change container ownership](user/docker/containers/ownership.md)
    * [Remove a container](user/docker/containers/remove.md)
  * [Images](user/docker/images/README.md)
    * [Pull an image](user/docker/images/pull.md)
    * [Build a new image](user/docker/images/build.md)
    * [Import an image](user/docker/images/import.md)
    * [Export an image](user/docker/images/export.md)
  * [Networks](user/docker/networks/README.md)
    * [Add a new network](user/docker/networks/add.md)
    * [Remove a network](user/docker/networks/remove.md)
  * [Volumes](user/docker/volumes/README.md)
    * [Add a new volume](user/docker/volumes/add.md)
    * [Browse a volume](user/docker/volumes/browse.md)
    * [Remove a volume](user/docker/volumes/remove.md)
  * [Configs](user/docker/configs/README.md)
    * [Add a new config](user/docker/configs/add.md)
    * [Remove a config](user/docker/configs/remove.md)
  * [Secrets](user/docker/secrets/README.md)
    * [Add a new secret](user/docker/secrets/add.md)
    * [Remove a secret](user/docker/secrets/remove.md)
  * [Events](user/docker/events.md)
  * [Host](user/docker/host/README.md)
    * [Details](user/docker/host/details.md)
    * [Setup](user/docker/host/setup.md)
    * [Registries](user/docker/host/registries.md)
  * [Swarm](user/docker/swarm/README.md)
    * [Details](user/docker/swarm/details.md)
    * [Cluster visualizer](user/docker/swarm/cluster-visualizer.md)
    * [Setup](user/docker/swarm/setup.md)
    * [Registries](user/docker/swarm/registries.md)
* [Kubernetes](user/kubernetes/README.md)
  * [Dashboard](user/kubernetes/dashboard.md)
  * [kubectl shell](user/kubernetes/kubectl.md)
  * [Kubeconfig](user/kubernetes/kubeconfig.md)
  * [Custom Templates](user/kubernetes/templates/README.md)
    * [Add a new custom template](user/kubernetes/templates/add.md)
    * [Edit a custom template](user/kubernetes/templates/edit.md)
    * [Remove a custom template](user/kubernetes/templates/remove.md)
  * [Namespaces](user/kubernetes/namespaces/README.md)
    * [Add a new namespace](user/kubernetes/namespaces/add.md)
    * [Manage a namespace](user/kubernetes/namespaces/manage.md)
    * [Manage access to a namespace](user/kubernetes/namespaces/access.md)
    * [Remove a namespace](user/kubernetes/namespaces/remove.md)
  * [Helm](user/kubernetes/helm.md)
  * [Applications](user/kubernetes/applications/README.md)
    * [Add a new application using a form](user/kubernetes/applications/add.md)
    * [Add a new application using code](user/kubernetes/applications/manifest.md)
    * [Inspect an application](user/kubernetes/applications/inspect.md)
    * [Inspect a Helm application](user/kubernetes/applications/inspect-helm.md)
    * [Edit an application](user/kubernetes/applications/edit.md)
    * [Webhooks](user/kubernetes/applications/webhooks.md)
    * [Detach a volume from an application](user/kubernetes/applications/detach-volume.md)
    * [Remove an application](user/kubernetes/applications/remove.md)
  * [Networking](user/kubernetes/networking/README.md)
    * [Services](user/kubernetes/networking/services.md)
    * [Ingresses](user/kubernetes/networking/ingresses/README.md)
      * [Add an Ingress manually](user/kubernetes/networking/ingresses/add.md)
      * [Add an Ingress using a manifest](user/kubernetes/networking/ingresses/manifest.md)
      * [Remove an Ingress](user/kubernetes/networking/ingresses/remove-an-ingress.md)
  * [ConfigMaps & Secrets](user/kubernetes/configurations/README.md)
    * [Add a ConfigMap](user/kubernetes/configurations/add.md)
    * [Add a Secret](user/kubernetes/configurations/add-1.md)
  * [Volumes](user/kubernetes/volumes/README.md)
    * [Inspect a volume](user/kubernetes/volumes/inspect.md)
    * [Remove a volume](user/kubernetes/volumes/remove.md)
  * [More Resources](user/kubernetes/more-resources/README.md)
    * [Cron Jobs & Jobs](user/kubernetes/more-resources/jobs.md)
    * [Service Accounts](user/kubernetes/more-resources/service-accounts.md)
    * [Cluster Roles](user/kubernetes/more-resources/cluster-roles.md)
    * [Roles](user/kubernetes/more-resources/namespace-roles.md)
  * [Cluster](user/kubernetes/cluster/README.md)
    * [Details](user/kubernetes/cluster/details.md)
    * [Inspect a node](user/kubernetes/cluster/node.md)
    * [Setup](user/kubernetes/cluster/setup.md)
    * [Security constraints](user/kubernetes/cluster/security.md)
    * [Registries](user/kubernetes/cluster/registries.md)
* [Azure ACI](user/aci/README.md)
  * [Dashboard](user/aci/dashboard.md)
  * [Container instances](user/aci/containers/README.md)
    * [Add a new container](user/aci/containers/add.md)
    * [View container details](user/aci/containers/details.md)
    * [Remove a container](user/aci/containers/remove.md)
* [Nomad](user/nomad.md)
* [Edge Compute](user/edge/README.md)
  * [Edge Groups](user/edge/groups.md)
  * [Edge Stacks](user/edge/stacks/README.md)
    * [Add a new Edge Stack](user/edge/stacks/add.md)
  * [Edge Jobs](user/edge/jobs.md)
  * [Edge Configurations](user/edge/configurations.md)
  * [Waiting Room](user/edge/waiting-room.md)
  * [Edge Templates](user/edge/templates/README.md)
    * [Application](user/edge/templates/application.md)
    * [Custom](user/edge/templates/custom.md)
* [Account settings](user/account-settings.md)

## Administering Portainer <a href="#admin" id="admin"></a>

* [User-related](admin/user/README.md)
  * [Users](admin/user/users.md)
  * [Add a new user](admin/user/add.md)
  * [Turn a user into an administrator](admin/user/promote.md)
  * [Reset a user's password](admin/user/password.md)
  * [Teams](admin/user/teams/README.md)
    * [Add a new team](admin/user/teams/add.md)
    * [Add a user to a team](admin/user/teams/add-user.md)
  * [Roles](admin/user/roles.md)
* [Environment-related](admin/environments/README.md)
  * [Environments](admin/environments/environments.md)
  * [Add a new environment](admin/environments/add/README.md)
    * [Add a local environment](admin/environments/add/local.md)
    * [Add a Docker Standalone environment](admin/environments/add/docker/README.md)
      * [Install Portainer Agent on Docker Standalone](admin/environments/add/docker/agent.md)
      * [Connect to the Docker API](admin/environments/add/docker/api.md)
      * [Connect to the Docker Socket](admin/environments/add/docker/socket.md)
      * [Install Edge Agent Standard on Docker Standalone](admin/environments/add/docker/edge.md)
      * [Install Edge Agent Async on Docker Standalone](admin/environments/add/docker/edge-async.md)
    * [Add a Docker Swarm environment](admin/environments/add/swarm/README.md)
      * [Install Portainer Agent on Docker Swarm](admin/environments/add/swarm/agent.md)
      * [Connect to the Docker API](admin/environments/add/swarm/api.md)
      * [Connect to the Docker Socket](admin/environments/add/swarm/socket.md)
      * [Install Edge Agent Standard on Docker Swarm](admin/environments/add/swarm/edge.md)
      * [Install Edge Agent Async on Docker Swarm](admin/environments/add/swarm/edge-async.md)
    * [Add a Podman environment](admin/environments/add/podman/README.md)
      * [Install Portainer Agent on Podman](admin/environments/add/podman/agent.md)
      * [Connect to the Podman Socket](admin/environments/add/podman/socket.md)
      * [Install Edge Agent Standard on Podman](admin/environments/add/podman/edge.md)
      * [Install Edge Agent Async on Podman](admin/environments/add/podman/edge-async.md)
    * [Add a Kubernetes environment](admin/environments/add/kubernetes/README.md)
      * [Install Portainer Agent on your Kubernetes environment](admin/environments/add/kubernetes/agent.md)
      * [Install Edge Agent Standard on Kubernetes](admin/environments/add/kubernetes/edge.md)
      * [Install Edge Agent Async on Kubernetes](admin/environments/add/kubernetes/edge-async.md)
      * [Import an existing Kubernetes environment](admin/environments/add/kubernetes/import.md)
    * [Add an ACI environment](admin/environments/add/aci.md)
    * [Add a Nomad environment](admin/environments/add/nomad.md)
    * [Provision KaaS Cluster](admin/environments/add/kaas/README.md)
      * [Civo](admin/environments/add/kaas/civo.md)
      * [Akamai Connected Cloud](admin/environments/add/kaas/linode.md)
      * [DigitalOcean](admin/environments/add/kaas/digitalocean.md)
      * [Google Cloud](admin/environments/add/kaas/gke.md)
      * [AWS](admin/environments/add/kaas/eks.md)
      * [Azure](admin/environments/add/kaas/aks.md)
    * [Create a Kubernetes cluster](admin/environments/add/kube-create/README.md)
      * [Talos Kubernetes](admin/environments/add/kube-create/omni.md)
      * [MicroK8s](admin/environments/add/kube-create/microk8s/README.md)
        * [Offline installation](admin/environments/add/kube-create/microk8s/offline.md)
    * [Add an environment via the Portainer API](admin/environments/add/api.md)
  * [Auto onboarding](admin/environments/aeec.md)
  * [Groups](admin/environments/groups.md)
  * [Tags](admin/environments/tags.md)
  * [Manage access to environments](admin/environments/access.md)
  * [Manage access to environment groups](admin/environments/access-groups.md)
  * [Update & Rollback](admin/environments/update.md)
* [Registries](admin/registries/README.md)
  * [Add a new registry](admin/registries/add/README.md)
    * [Add a DockerHub account](admin/registries/add/dockerhub.md)
    * [Add an AWS ECR registry](admin/registries/add/ecr.md)
    * [Add a Quay.io registry](admin/registries/add/quay.md)
    * [Add a ProGet registry](admin/registries/add/proget.md)
    * [Add an Azure registry](admin/registries/add/azure.md)
    * [Add a Gitlab registry](admin/registries/add/gitlab.md)
    * [Add a GitHub registry](admin/registries/add/ghcr.md)
    * [Add a custom registry](admin/registries/add/custom.md)
  * [Browse a registry](admin/registries/browse.md)
  * [Manage a registry](admin/registries/manage.md)
* [Licenses](admin/licenses.md)
* [Logs](admin/logs/README.md)
  * [Authentication](admin/logs/authentication.md)
  * [Activity](admin/logs/activity.md)
* [Notifications](admin/notifications.md)
* [Settings](admin/settings/README.md)
  * [General](admin/settings/general.md)
  * [Authentication](admin/settings/authentication/README.md)
    * [Authenticate via LDAP](admin/settings/authentication/ldap.md)
    * [Authenticate via Active Directory](admin/settings/authentication/active-directory.md)
    * [Authenticate via OAuth](admin/settings/authentication/oauth.md)
  * [Shared credentials](admin/settings/credentials/README.md)
    * [Add Sidero Omni credentials](admin/settings/credentials/omni.md)
    * [Add Civo credentials](admin/settings/credentials/civo.md)
    * [Add Akamai Connected Cloud credentials](admin/settings/credentials/linode.md)
    * [Add DigitalOcean credentials](admin/settings/credentials/digitalocean.md)
    * [Add Google Cloud credentials](admin/settings/credentials/gke.md)
    * [Add AWS credentials](admin/settings/credentials/eks.md)
    * [Add Azure credentials](admin/settings/credentials/aks.md)
    * [Add SSH credentials](admin/settings/credentials/ssh.md)
  * [Edge Compute](admin/settings/edge.md)

## Frequently Asked Questions <a href="#faq" id="faq"></a>

* [Portainer Concepts](faq/concepts.md)
* [Installing](faq/installing.md)
* [Upgrading](faq/upgrading.md)
* [Troubleshooting](faq/troubleshooting.md)
* [Contributing](faq/contributing.md)

## Advanced Topics <a href="#advanced" id="advanced"></a>

* [CLI configuration options](advanced/cli.md)
* [App templates](advanced/app-templates/README.md)
  * [Build and host your own app templates](advanced/app-templates/build.md)
  * [App template JSON format](advanced/app-templates/format.md)
* [The Portainer Edge Agent](advanced/edge-agent.md)
* [Access control](advanced/access-control.md)
* [Reset the admin user's password](advanced/reset-admin.md)
* [Security and compliance](advanced/security.md)
* [Encrypting the Portainer database](advanced/db-encryption.md)
* [Using your own SSL certificate with Portainer](advanced/ssl.md)
* [Using mTLS with Portainer](advanced/mtls.md)
* [Stream auth and activity logs to an external provider](advanced/siem.md)
* [Using Portainer with reverse proxies](advanced/reverse-proxy/README.md)
  * [Deploying Portainer behind Traefik Proxy](advanced/reverse-proxy/traefik.md)
  * [Deploying Portainer behind nginx reverse proxy](advanced/reverse-proxy/nginx.md)
* [How Relative Path Support works in Portainer](advanced/relative-paths.md)
* [Helm chart configuration options](advanced/helm-chart-configuration-options.md)
* [Docker roles and permissions](advanced/docker-roles-and-permissions.md)
* [Kubernetes roles and bindings](advanced/kubernetes-roles-and-bindings.md)
* [Deprecated and removed features](advanced/deprecated.md)

## API

* [Accessing the Portainer API](api/access.md)
* [API documentation](api/docs.md)
* [API usage examples](api/examples.md)

## Get More Help <a href="#help" id="help"></a>

* [Knowledge Base](https://portal.portainer.io/knowledge)
* [Portainer Academy](https://academy.portainer.io)
* [YouTube](https://www.youtube.com/channel/UC7diMJcrULjDseq5yhSUZgg/videos)
* [GitHub](https://github.com/orgs/portainer/discussions)
* [Slack](https://join.slack.com/t/portainer/shared_invite/zt-21zpww5ab-mG_lA7UXbWL3HW3sPqjqEA)
* [Discord](https://discord.com/invite/j8fVken)
* [Open a support request](https://www.portainer.io/portainer-business-support)

## Contribute to Portainer <a href="#contribute" id="contribute"></a>

* [Contribute](contribute/contribute.md)
* [Build instructions](contribute/build/README.md)
  * [Set up a macOS build environment](contribute/build/mac.md)
  * [Set up a Linux build environment](contribute/build/linux.md)

***

* [Privacy Policy](privacy.md)



================================================
FILE: whats-new.md
================================================
# What's new in version 2.27

Portainer version 2.27 includes a number of new fixes and updates. For a full list of changes, please refer to our [release notes](release-notes.md).

{% embed url="https://www.youtube.com/watch?v=6xjVN7pSp5E" %}

## Long Term Support (LTS)

2.27 is a Long Term Support, or "LTS", release of Portainer. LTS releases are intended to to be solid, tested, production-ready versions of Portainer, suitable for running in both testing and production environments. LTS releases generally do not have any additional features as compared to the previous STS release, but rather are a consolidation of all the new features and changes that have gone into the previous STS releases but with additional polishing and testing.

You can read more about our release principles in our [lifecycle policy](start/lifecycle.md).

As many users will be coming to this LTS release directly from the previous LTS release (2.21), the features listed below include those from previous STS releases.&#x20;

## New features

### Podman support ![](.gitbook/assets/button_be.png) ![](.gitbook/assets/button_ce.png)

This release brings official Podman support to Portainer. You can now [install Portainer Server on Podman environments](start/install/server/podman/) as well as [add Podman environments to an existing Portainer installation](admin/environments/add/podman/), just like Docker and Kubernetes environments through the environment wizard, and are managed in just the same way. You can deploy containers and stacks, pull images, inspect logs, and everything else you'd expect on your Podman environment.

At present, support is limited to rootful Podman 5 installations on CentOS 9. While other versions of Podman on other Linux distributions may work, we have not fully tested outside of the above options as of yet, and we hope to expand this in the future.

### Omni Integration ![](.gitbook/assets/button_be.png)&#x20;

We're excited to introduce our integration with Sidero's Omni platform in this release. With Omni, you can provision, configure and manage Talos Linux servers running Kubernetes environments right from the Portainer UI with [just a few clicks](admin/environments/add/kube-create/omni.md).

<figure><img src=".gitbook/assets/2.26-whatsnew-omni.png" alt=""><figcaption></figcaption></figure>

As our first release of this feature, there may be bugs or limitations with the implementation. We encourage you to provide constructive feedback so we can improve in future releases.

{% hint style="success" %}
The Portainer and Sidero teams will be running a live demo and workshop of this integration at KubeCon Europe in London on the 1st of April! Spaces are strictly limited, so if you're interested you can [sign up here](https://www.portainer.io/events-kubecon-europe-april-2025)!
{% endhint %}

### Manage Kubernetes Jobs and Cron Jobs ![](.gitbook/assets/button_be.png) ![](.gitbook/assets/button_ce.png)

Adding to our management of Kubernetes object types, you can now view and manage [Cron Jobs and Kubernetes Jobs](user/kubernetes/more-resources/jobs.md) within Portainer.

<figure><img src=".gitbook/assets/2.26-kubernetes-more-resources-jobs-cronjobs.png" alt=""><figcaption></figcaption></figure>

You will find this functionality under [More resources](user/kubernetes/more-resources/) on Kubernetes environments.

### New Kubernetes security options ![](.gitbook/assets/button_be.png)

There are some new Kubernetes security options available in this release, too. Administrators can now disable the Kubeconfig and Kube shell options on environments in Portainer, for situations where you might need to lock down access to that functionality.

### Ask the AI link ![](.gitbook/assets/button_be.png)

Getting help within Portainer is now even easier. We've included a link on the top right of every page to our popular AI-powered chatbot, letting you get quick answers to your Portainer questions.&#x20;

<figure><img src=".gitbook/assets/2.25.0-icons.png" alt=""><figcaption></figcaption></figure>

The chatbot has been trained on the Portainer documentation, knowledge base, blog posts and the Portainer Academy as well as our GitHub issues and discussions, so is an excellent source of Portainer knowledge.

### Portainer support bundle ![](.gitbook/assets/button_be.png)

If you do find yourself in a situation where the chatbot can't help and you need to reach out for help from our team, our new support bundle lets you submit your Portainer configuration data to the Portainer team for assistance. This feature strips out secure information like passwords before bundling so your information is kept safe.

<figure><img src=".gitbook/assets/2.25.0-settings-support-bundle.png" alt=""><figcaption></figcaption></figure>



## Enhancements and fixes

### Expanded ACI support ![](.gitbook/assets/button_be.png)

This release also sees a significant amount of improvement to our support for ACI environments. When creating a container in an ACI environment you can now select a private virtual network, add tags, volumes, and GPUs. We've also expanded the management capabilities for your ACI workloads by adding stopping and restarting of ACIs as well as viewing of events related to those ACIs.

### Performance optimizations ![](.gitbook/assets/button_be.png) ![](.gitbook/assets/button_ce.png)

With every release we try to make using Portainer more responsive and performant, and 2.27 continues that trend. You'll notice much faster loading of pages within the app, more responsive searching, more reliable webhooks, more standardized interfaces, and all around a better experience.

We've also focused specifically on improving the performance of our Kubernetes management in this release, and the hard work has paid off. We're seeing significant improvements to load times for our Kubernetes pages within the app, much better responsiveness and an all around greater experience when managing Kubernetes in Portainer.

### Smaller Git clones ![](.gitbook/assets/button_be.png) ![](.gitbook/assets/button_ce.png)

Along with the general performance improvements, we've focused specifically on improving how we clone Git repositories when deploying stacks or applications from Git. We now perform much smaller Git clones, significantly reducing the amount of bandwidth and storage used to deploy from Git and as a result, making deployments faster.

### Added conditions to Kubernetes nodes ![](.gitbook/assets/button_be.png) ![](.gitbook/assets/button_ce.png)

To give you a better idea of the status of your Kubernetes nodes, we've added the Conditions column to the Kubernetes node view in this release.&#x20;

<figure><img src=".gitbook/assets/2.27-kubernetes-details-nodes-list.png" alt=""><figcaption></figcaption></figure>

This column displays whether any of your nodes are affected by conditions, for example DiskPressure, MemoryPressure, PIDPressure or NetworkUnavailable.

### Edge Stacks: Staggered deployment improvements ![](.gitbook/assets/button_be.png)

This release sees improvements to the staggered deployment functionality for Edge Stacks. Timeout values now apply to the batch when performing parallel deployments, helping avoid issues where a failed environment in a batch could halt the entire deployment unexpectedly.

### Improved logging ![](.gitbook/assets/button_be.png) ![](.gitbook/assets/button_ce.png)&#x20;

We've also made significant changes in how we log within Portainer, in particular for OAuth authentication and for Edge devices. OAuth logs now have increased verbosity which should help with diagnosing issues with authentication timeouts. Edge API calls now give more information when they error, including the environment ID and name, which helps when dealing with lots of Edge environments.

### Additional option for session timeout ![](.gitbook/assets/button_be.png) ![](.gitbook/assets/button_ce.png)

In 2.27 we've expanded the [session timeout options](admin/settings/authentication/) for authentication to include a 30 minute option. This helps to meet with security requirements around session timeout as well as giving you more options to suit your particular needs.

### Updated third-party binaries and libraries ![](.gitbook/assets/button_be.png) ![](.gitbook/assets/button_ce.png)

As we do with every release, we’ve updated the versions of the third party binaries and libraries that we use within Portainer to newer versions. This resolves a number of reported CVEs as well as providing improved performance and functionality.

### Removal of included Docker Compose binary ![](.gitbook/assets/button_be.png) ![](.gitbook/assets/button_ce.png)

In our ongoing efforts to rely less on third-party systems, we've removed the Docker Compose binary that we used to embed with the Portainer image, and instead we're now using our own integrated system for stack and compose functionality. This lets us avoid any potential CVEs within the Docker Compose binary, resulting to a more secure image, and has also improved performance when dealing with stacks.



================================================
FILE: admin/licenses.md
================================================
# Licenses

Licensing in Portainer Business Edition is based on the [number of nodes](https://portal.portainer.io/knowledge/what-is-a-node-for-licensing-purposes) you are managing.

<figure><img src="../.gitbook/assets/2.25.0-licenses-info.png" alt=""><figcaption></figcaption></figure>

If you wish to renew your existing license you can do so by clicking the **Renew license** button.

You can also view a list of each license applied to your Portainer installation.

<figure><img src="../.gitbook/assets/2.25.0-licenses-list.png" alt=""><figcaption></figcaption></figure>

If you want to add more nodes to your environment than your license allows, you can [buy more nodes](https://portal.portainer.io/knowledge/how-do-i-add-more-nodes-to-my-license).

## Add a new license

Once you have obtained your new license key, to add it to Portainer click **Add license**, enter your license key then click **Submit**.

<figure><img src="../.gitbook/assets/2.20-licenses-add.png" alt=""><figcaption></figcaption></figure>

## Remove a license

To remove a license (for example when you want to remove an expired license), tick the box next to the license and click **Remove**. You will be asked to confirm the removal.

{% hint style="warning" %}
Ensure you have enough licenses to cover the number of nodes you are using before committing to the removal. For more on how nodes are calculated, refer to [this knowledge base article](https://portal.portainer.io/knowledge/what-is-a-node-for-licensing-purposes).
{% endhint %}

<figure><img src="../.gitbook/assets/2.19-licenses-remove.png" alt=""><figcaption></figcaption></figure>

To confirm, click **Remove**.



================================================
FILE: admin/notifications.md
================================================
# Notifications

The Notifications section contains a record of all the notification messages you have received in Portainer (the popup messages that appear in the top right of the interface). You can search through past notifications as well as remove specific notification records from the list.

{% hint style="info" %}
The 50 most recent notifications are also accessible by clicking the bell icon in the top right of any page in the Portainer UI.
{% endhint %}

<figure><img src="../.gitbook/assets/2.16-notifications.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: admin/environments/README.md
================================================
# Environment-related

In Portainer terms, an _environment_ is an instance that you want to manage through Portainer. Environments can be Docker, Docker Swarm, Kubernetes, ACI or a combination. One Portainer Server instance can manage multiple environments.

{% hint style="info" %}
Endpoints were renamed to Environments in version 2.10.
{% endhint %}

{% content-ref url="environments.md" %}
[environments.md](environments.md)
{% endcontent-ref %}

{% content-ref url="add/" %}
[add](add/)
{% endcontent-ref %}

Environments can be organized in groups and given tags.

{% content-ref url="groups.md" %}
[groups.md](groups.md)
{% endcontent-ref %}

{% content-ref url="tags.md" %}
[tags.md](tags.md)
{% endcontent-ref %}

Access to environments can then be managed on a per-environment or per-environment group basis.

{% content-ref url="access.md" %}
[access.md](access.md)
{% endcontent-ref %}

{% content-ref url="access-groups.md" %}
[access-groups.md](access-groups.md)
{% endcontent-ref %}

Automatic onboarding scripts can be generated for larger Edge Agent deployments.

{% content-ref url="aeec.md" %}
[aeec.md](aeec.md)
{% endcontent-ref %}

Edge Agent environments can be updated (and updates rolled back) directly from within Portainer.

{% content-ref url="update.md" %}
[update.md](update.md)
{% endcontent-ref %}



================================================
FILE: admin/environments/access-groups.md
================================================
# Manage access to environment groups

{% hint style="info" %}
Environments can be [grouped](groups.md) for organizational purposes. If an environment and an individual user are in the same group, users will be tagged with `inherited` on the **Manage access** page. This means that the user is inheriting their access from the group, not the environment.

If you manually assign a user to an environment, and they are already assigned to it via a group, they will be tagged with `override` on the **Manage access** page, indicating that their individual access will override that of the group for this one environment. You can then modify their access in this special case.
{% endhint %}

From the menu expand **Environment-related** then select **Groups**. Locate the environment group you want to give users access to then select **Manage access** at the end of the row.

<figure><img src="../../.gitbook/assets/2.20-environments-access-groups.gif" alt=""><figcaption></figcaption></figure>

Next, select the users or teams you want to add using the dropdown. Then use the **Role** dropdown to select the role you want this user or team to have.

<figure><img src="../../.gitbook/assets/2.20-environments-access-groups-create.png" alt=""><figcaption></figcaption></figure>

Once all have been selected, click **Create access**.



================================================
FILE: admin/environments/access.md
================================================
# Manage access to environments

{% hint style="info" %}
Environments can be [grouped](groups.md) for organizational purposes. If an environment and an individual user are in the same group, users will be tagged with `inherited` on the **Manage access** page. This means that the user is inheriting their access from the group, not the environment.

If you manually assign a user to an environment, and they are already assigned to it via a group, they will be tagged with `override` on the **Manage access** page, indicating that their individual access will override that of the group for this one environment. You can then modify their access in this special case.
{% endhint %}

From the menu expand **Environment-related** and select **Environments**. Locate the environment you want to give users access to then select **Manage access** at the end of the row.

<figure><img src="../../.gitbook/assets/2.20-environments-access.gif" alt=""><figcaption></figcaption></figure>

Next, select the users or teams you want to add using the dropdown. Then use the **Role** dropdown to select the role you want this user or team to have.

<figure><img src="../../.gitbook/assets/2.20-environments-access-create.png" alt=""><figcaption></figcaption></figure>

Once all have been selected, click **Create access**.



================================================
FILE: admin/environments/aeec.md
================================================
# Auto onboarding

This section allows you to create customized scripts to quickly onboard a number of Edge Agents automatically. Your selections will update the script provided at the bottom of the page which you can then run on your remote environments.

First, select the type of Edge Agent deployment: **Edge Agent Standard** or **Edge Agent Async**.

{% hint style="info" %}
The Portainer Edge Agent can be deployed in two different modes - **standard mode** and **async mode**. In standard mode, we provide the ability to connect to the remote Edge Agent through a tunnel that is established on-demand from the Edge Agent to the Portainer Server, letting you interact directly with the environment in real time.&#x20;

In async mode, this tunnel connectivity is not available. Instead, we provide the ability to browse snapshots of the remote environment, allowing you to see the state of the Edge Agent's environment based on a recent state capture sent through to the Portainer Server, as well as use this snapshot to perform actions on the remote environment.&#x20;

Async mode has been developed to use very small amounts of data and as such is suitable for environments that have limited or intermittent connectivity as well as connections with limited data caps, for example mobile networks.&#x20;
{% endhint %}

Your **Edge key** will also be shown here if you need to access it directly.

<figure><img src="../../.gitbook/assets/2.18-environments-autoonboarding-type.png" alt=""><figcaption></figcaption></figure>

Once you have made your type selection, configure the options and select the platform (Linux or Windows) to generate your Edge agent deployment scripts.

| Field/Option                    | Overview                                                                                                                                                       |
| ------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Portainer API server URL        | This field displays your Portainer API server URL. This can be adjusted in the Edge Compute settings.                                                          |
| Portainer tunnel server address | This field displays your Portainer tunnel server address. This can be adjusted in the Edge Compute settings, and is not used for Edge Agent Async deployments. |
| Group                           | Select a [group](groups.md) for your Edge Agent deployments.                                                                                                   |
| Edge Groups                     | Select one or more [Edge Groups](../../user/edge/groups.md) for your Edge Agent deployments.                                                                   |
| Tags                            | Select one or more [tags](tags.md) for your Edge Agent deployments.                                                                                            |
| Edge ID Generator               | Provide a one-line script that will be used to generate a unique ID for your Edge devices. For Linux, an example would be using the `uuidgen` command.         |
| Environment variables           | Define a comma separated list of environment variables that will be sourced from the Edge devices for use in Portainer.                                        |
| Allow self-signed certs         | Toggle this to permit the use of self-signed certificates for the communication between the Edge Agent and the Portainer server.                               |

<figure><img src="../../.gitbook/assets/2.18-environments-autoonboarding-config.png" alt=""><figcaption></figcaption></figure>

Select the environment of your deployment and click **Copy** to copy the script to your clipboard.

<figure><img src="../../.gitbook/assets/2.20-environments-aeec-script.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: admin/environments/environments.md
================================================
# Environments

The Environments page lists the environments that can be managed with your Portainer installation. Here you can add new environments either [manually](add/) or through [auto onboarding](aeec.md), as well as manage which users and groups have [access](access.md) to individual environments.

<figure><img src="../../.gitbook/assets/2.20-environments-list.png" alt=""><figcaption></figcaption></figure>

To see the details of an existing environment, click on the environment's name in the list. The below options are generic to all environment types, but some environment types will have additional information displayed as well.

| Field/Option              | Overview                                                                                                                                                                                                                                     |
| ------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                      | The name of the environment, and how it appears in the list of environments on the dashboard.                                                                                                                                                |
| Environment URL / Address | The URL or address of the environment that is used by Portainer to connect and manage the environment. This could be a Docker socket or API, or the address and port of a Portainer Agent. Edge Agent environments will not have this field. |
| Public IP                 | The URL or address where exposed containers will be reachable. This is an optional field and will default to the environment URL if not set.                                                                                                 |
| Group                     | Select a group to add the environment to. This field is optional.                                                                                                                                                                            |
| Tags                      | Select one or more tags to associate with this environment. This field is optional.                                                                                                                                                          |

<figure><img src="../../.gitbook/assets/2.20-environments-details.png" alt=""><figcaption></figcaption></figure>

To remove an environment, check the box next to the environment to remove and click the **Remove** button. You will be asked to confirm your action.

{% hint style="danger" %}
This action cannot be reversed, so proceed with caution!
{% endhint %}



================================================
FILE: admin/environments/groups.md
================================================
# Groups

Groups organize your environments in Portainer. As an example, you can create groups for development, staging and production to differentiate between environment roles. You can also use groups to define which environments are available to which users.

{% hint style="info" %}
Portainer Community Edition supports basic user and group assignments. For more complex user roles within groups, use Portainer Business Edition.
{% endhint %}

## Adding a group

From the menu expand **Environment-related**, select **Groups**, then click **Add group**.&#x20;

<figure><img src="../../.gitbook/assets/2.20-environments-groups-add.gif" alt=""><figcaption></figcaption></figure>

Define the properties of the group, using the table below as a guide.

| Field/Option            | Overview                                                |
| ----------------------- | ------------------------------------------------------- |
| Name                    | Give the group a descriptive name.                      |
| Description             | Optionally describe the group in more detail.           |
| Tags                    | Apply any tags to the group.                            |
| Associated environments | Select the environments to be categorized in the group. |

<figure><img src="../../.gitbook/assets/2.20-environments-groups-add-details.png" alt=""><figcaption></figcaption></figure>

When you're finished, click **Create the group**.

## Removing a group

When you no longer need a group, you can remove it by ticking the box next to the group then clicking **Remove**.

{% hint style="info" %}
Removing a group will not delete environments and users in that group. However, it may change the environments accessible to users who have their access assigned via a group.
{% endhint %}



================================================
FILE: admin/environments/tags.md
================================================
# Tags

Tags can be applied to environments and are useful for defining node or resource metadata. For example, you could use tags to define the physical location of nodes, departments or owners of resources, and much more.

## Creating a tag

From the menu expand **Environment-related** then select **Tags**.&#x20;

<figure><img src="../../.gitbook/assets/2.20-environments-tags.gif" alt=""><figcaption></figcaption></figure>

Enter a name for the tag then click **Create tag**. The tag appears in the list and can be assigned to environments.

## Tagging an environment

From the menu expand **Environment-related**, select **Environments** then select the environment you want to tag.

<figure><img src="../../.gitbook/assets/2.20-environments-details.gif" alt=""><figcaption></figcaption></figure>

From the **Tags** lookup select the tag then click **Update environment**.

{% hint style="info" %}
Environment tags will be visible on the Portainer home page. You can also search for environments based on their tags.
{% endhint %}



================================================
FILE: admin/environments/update.md
================================================
# Update & Rollback

This feature lets you upgrade your Edge Agent deployments directly from Portainer, without the need to log into the remote environments and manually update.

{% hint style="warning" %}
This feature is currently in beta, and is only currently available for Edge Agents running on Docker Standalone environments.
{% endhint %}

To view your currently scheduled updates or schedule a new update process, from the menu expand **Environment-related** then select **Update & Rollback**.

<figure><img src="../../.gitbook/assets/2.20-environments-update.gif" alt=""><figcaption></figcaption></figure>

Here you will see a list of your pending and completed updates and rollbacks.

## Schedule an update

To add a new update schedule, click the **Add update & rollback schedule** button, then fill out the form.

{% hint style="info" %}
To schedule an update, Portainer must have a snapshot of all the environments you wish to upgrade.
{% endhint %}

| Field/Option         | Overview                                                                                                                                                                                                      |
| -------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                 | Enter a name for the scheduled update.                                                                                                                                                                        |
| Groups               | Select the Edge Group(s) containing the Edge devices you want to update. You can configure these groups under [Edge Groups](../../user/edge/groups.md).                                                       |
| Version              | Ensure the **Update** tab is selected, then select the version you want to upgrade to from the dropdown.                                                                                                      |
| Schedule date & time | <p>Select a date and time to schedule the update.<br>When upgrading from a version prior to 2.17, this field will be unavailable and the upgrade will take place immediately on creation of the schedule.</p> |
| Registry             | If needed, you can select the registry to pull the updated Portainer Agent and portainer-updater images from. This functionality is useful if you are running in an airgapped environment.                    |
| Agent Image          | If you need to use a different name for the Portainer Agent image you can specify it here.                                                                                                                    |
| Updater Image        | If you need to use a different name for the portainer-updater image you can specify it here.                                                                                                                  |

<figure><img src="../../.gitbook/assets/2.25.0-environment-update-rollback-add.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Create Schedule** to schedule the update. You will be returned to the Update & Rollback page where you can check the status of your scheduled update.

<figure><img src="../../.gitbook/assets/2.25.0-environment-update-rollback-list.png" alt=""><figcaption></figcaption></figure>

## Schedule a rollback

To schedule the rollback of an update, click the **Add update & rollback schedule** button, then fill out the form.

{% hint style="info" %}
To schedule a rollback, Portainer must have a snapshot of all the environments you wish to roll back.
{% endhint %}

| Field/Option         | Overview                                                                                                                                                                                                           |
| -------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Name                 | Enter a name for the scheduled rollback.                                                                                                                                                                           |
| Group                | Select the Edge Group(s) containing the Edge devices you want to roll back. You can configure these groups under [Edge Groups](../../user/edge/groups.md).                                                         |
| Version              | <p>Ensure the <strong>Rollback</strong> tab is selected, then select the version you want to roll back to from the dropdown.<br>This dropdown is only available when multiple rollback versions are available.</p> |
| Schedule date & time | Select a date and time to schedule the rollback.                                                                                                                                                                   |
| Registry             | If needed, you can select the registry to pull the Portainer Agent and portainer-updater images from. This functionality is useful if you are running in an airgapped environment.                                 |
| Agent Image          | If you need to use a different name for the Portainer Agent image you can specify it here.                                                                                                                         |
| Updater Image        | If you need to use a different name for the portainer-updater image you can specify it here.                                                                                                                       |

<figure><img src="../../.gitbook/assets/2.25.0-environment-update-rollback-add-rollback.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Create Schedule** to schedule the rollback. You will be returned to the Update & Rollback page where you can check the status of your scheduled rollback.




================================================
FILE: admin/environments/add/README.md
================================================
# Add a new environment

Portainer can manage multiple environments in addition to the local environment on which it is installed.&#x20;

You can choose to connect to existing environments:

<table data-view="cards"><thead><tr><th></th><th></th><th></th><th data-hidden data-card-target data-type="content-ref"></th><th data-hidden data-card-cover data-type="files"></th></tr></thead><tbody><tr><td><strong>Docker Standalone</strong></td><td>Connect to Docker Standalone via URL/IP, API or Socket</td><td></td><td><a href="docker/">docker</a></td><td><a href="../../../.gitbook/assets/card-docker.png">card-docker.png</a></td></tr><tr><td><strong>Docker Swarm</strong></td><td>Connect to Docker Swarm via URL/IP, API or Socket</td><td></td><td><a href="swarm/">swarm</a></td><td><a href="../../../.gitbook/assets/card-docker.png">card-docker.png</a></td></tr><tr><td><strong>Podman</strong></td><td>Connect to Podman via URL/IP or Socket</td><td></td><td><a href="podman/">podman</a></td><td><a href="../../../.gitbook/assets/podman-logo-tile.png">podman-logo-tile.png</a></td></tr><tr><td><strong>Kubernetes</strong></td><td>Connect to a Kubernetes environment via URL/IP or via kubeconfig import</td><td></td><td><a href="kubernetes/">kubernetes</a></td><td><a href="../../../.gitbook/assets/card-kubernetes.png">card-kubernetes.png</a></td></tr><tr><td><strong>Azure ACI</strong></td><td>Connect to an Azure ACI environment via API</td><td></td><td><a href="aci.md">aci.md</a></td><td><a href="../../../.gitbook/assets/card-aci.png">card-aci.png</a></td></tr></tbody></table>

Or alternatively set up new environments:

<table data-card-size="large" data-view="cards"><thead><tr><th></th><th></th><th></th><th data-hidden data-card-target data-type="content-ref"></th><th data-hidden data-card-cover data-type="files"></th></tr></thead><tbody><tr><td><strong>Provision KaaS Cluster</strong></td><td>Provision a Kubernetes cluster via a cloud provider's Kubernetes as a Service</td><td></td><td><a href="kaas/">kaas</a></td><td><a href="../../../.gitbook/assets/card-kaas-large.png">card-kaas-large.png</a></td></tr><tr><td><strong>Create a Kubernetes cluster</strong></td><td>Create a Kubernetes cluster on existing infrastructure</td><td></td><td><a href="kube-create/">kube-create</a></td><td><a href="../../../.gitbook/assets/card-kube-create-large.png">card-kube-create-large.png</a></td></tr></tbody></table>

You can also add environments via the Portainer API.

{% content-ref url="api.md" %}
[api.md](api.md)
{% endcontent-ref %}




================================================
FILE: admin/environments/add/aci.md
================================================
# Add an ACI environment

Before connecting to your Azure subscription, you need to create an Azure AD application. For more information on this please refer to the [official Microsoft documentation](https://docs.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal).

{% hint style="info" %}
The following ACI features are not currently supported:

* ACI Persistent Storage
* Private networks
{% endhint %}

To add an ACI environment, from the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Select **ACI** as your environment type and click **Start Wizard**. Enter the **environment details** using the table below as a guide.

| Field              | Overview                                                                                                                                                |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name               | Enter a name for your environment.                                                                                                                      |
| Application ID     | Enter the application ID for the app you created in your Azure account. This can be found on the **Overview** page of your app within the Azure Portal. |
| Tenant ID          | Enter the tenant ID for your app. This can be found on the **Overview** page of your app within the Azure Portal.                                       |
| Authentication Key | Enter the client secret for your app. This can be created under **Certificates & secrets** within your application in the Azure Portal.                 |

<figure><img src="../../../.gitbook/assets/2.15-aci_env.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section and categorize the environment by adding it to a [group](../groups.md) or [tagging](../tags.md) it for better searchability.

<figure><img src="../../../.gitbook/assets/2.15-aci_more-settings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Connect**. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments.



================================================
FILE: admin/environments/add/api.md
================================================
# Add an environment via the Portainer API

Portainer's [API](../../../api/docs.md) lets you perform the same actions as via the Portainer UI, including adding new environments. This article explains how to add the following types of environments via the API:

* A local environment using Docker socket communication.
* A remote environment using TCP communication.
* A remote environment using TCP communication secured via TLS.

{% hint style="info" %}
The examples in this article use [httpie](https://httpie.io/) to make HTTP calls from the command line to the Portainer API. Feel free to replace httpie with your preferred method.
{% endhint %}

## Preparation

After deploying Portainer, you'll need to initialize your admin user. First, initialize the admin password:

```
http POST https://my-portainer-server:9443/api/users/admin/init Username="admin" Password="adminpassword"
```

Now, use the admin account to authenticate against the API. Generate an authorization token for your username. This token will provide you with the same permissions as the user who generated it.

```
http POST https://my-portainer-server:9443/api/auth Username="admin" Password="adminpassword"
```

The response is a JSON object containing the JWT token inside the `jwt` field. Make a note of this token. You'll use it in the authorization header when making API calls.

```
{
  "jwt":"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE"
}
```

The authorization header value must take the form `Bearer JWT_TOKEN`. Using the above token as an example, the value would look like this:

```
Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE
```

{% hint style="info" %}
The JWT token is valid for 8 hours after it is generated. Once it expires, you will need to generate a new token.
{% endhint %}

## Adding an environment

### Adding a local environment via the Docker socket <a href="#local-endpoint-via-the-docker-socket" id="local-endpoint-via-the-docker-socket"></a>

This query will create an environment called `test-local` and will use the Docker socket to communicate with your environment.

{% hint style="info" %}
This example requires you to bind-mount the Docker socket when running Portainer.
{% endhint %}

Run the following command:

```
http --form POST https://my-portainer-server:9443/api/endpoints \
    "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE" \
    Name="test-local" EndpointCreationType=1
```

The response is a JSON object representing the environment:

```
{
    "AuthorizedTeams": [], 
    "AuthorizedUsers": [], 
    "Extensions": [], 
    "GroupId": 1, 
    "Id": 1, 
    "Name": "test-local", 
    "PublicURL": "",
    "Type": 1,
    "TLSConfig": {
        "TLS": false, 
        "TLSSkipVerify": false
    }, 
    "Type": 1, 
    "URL": "unix:///var/run/docker.sock"
}
```

Make a note of the `Id` value. It will be used to execute queries against the Docker Engine for the endpoint.

### Adding a remote environment <a href="#remote-endpoint" id="remote-endpoint"></a>

This query will create an environment called `test-remote`. It will communicate with your environment over TCP using the IP address `10.0.7.10` and port `2375`. Make sure you replace the example values with your own IP address and port.

{% hint style="info" %}
The Docker API must be exposed on the provided IP address and port. To learn how to do this, refer to the Docker documentation.
{% endhint %}

Run the following command:

```
http --form POST https://my-portainer-server:9443/api/endpoints \
    "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE" \
    Name="test-remote" URL="tcp://10.0.7.10:2375" EndpointCreationType=1
```

The response is a JSON object representing the environment:

```
{
    "AuthorizedTeams": [], 
    "AuthorizedUsers": [], 
    "Extensions": [], 
    "GroupId": 1, 
    "Id": 1, 
    "Type": 1,
    "Name": "test-remote", 
    "PublicURL": "", 
    "TLSConfig": {
        "TLS": false, 
        "TLSSkipVerify": false
    }, 
    "Type": 1, 
    "URL": "tcp://10.0.7.10:2375"
}
```

Take a note of the `Id` value. It will be used to execute queries against the Docker Engine for the environment.

### Adding a remote environment with TLS <a href="#remote-endpoint-secured-using-tls" id="remote-endpoint-secured-using-tls"></a>

This query will create an environment called `test-remote-tls`. It will communicate with your environment over TCP (secured with TLS) using the IP address `10.0.7.10` and port `2376`. Make sure you replace the example values with your own IP address and port.

{% hint style="info" %}
The Docker API must be exposed on the provided IP address and port. To learn how to do this, refer to the Docker documentation.
{% endhint %}

Run the following command:

```
http --form POST https://my-portainer-server:9443/api/endpoints \
    "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE" \
    Name="test-remote-tls" URL="tcp://10.0.7.10:2376" EndpointCreationType=1 TLS="true" TLSCACertFile@/path/to/ca.pem TLSCertFile@/path/to/cert.pem TLSKeyFile@/path/to/key.pem
```

The response is a JSON object representing the environment:

```
{
    "AuthorizedTeams": [], 
    "AuthorizedUsers": [], 
    "Extensions": [], 
    "GroupId": 1, 
    "Id": 1, 
    "Type": 1,
    "Name": "test-remote-tls", 
    "PublicURL": "", 
    "TLSConfig": {
        "TLS": true, 
        "TLSCACert": "/data/tls/1/ca.pem", 
        "TLSCert": "/data/tls/1/cert.pem", 
        "TLSKey": "/data/tls/1/key.pem", 
        "TLSSkipVerify": false
    }, 
    "Type": 1, 
    "URL": "tcp://10.0.7.10:2376"
}
```

Make a note of the `Id` value. It will be used to execute queries against the Docker Engine for the environment.



================================================
FILE: admin/environments/add/local.md
================================================
# Add a local environment

You can only add a local environment when the Portainer Server container is being created. You cannot add a local environment after Portainer is deployed.

For more information about the installation process, visit the [Getting Started](../../../start/intro.md) section (in particular, the [installation steps](../../../start/install/)).



================================================
FILE: admin/environments/add/nomad.md
================================================
# Add a Nomad environment

As of Portainer version 2.20.0, Nomad is no longer a supported platform by Portainer.



================================================
FILE: admin/environments/add/docker/README.md
================================================
# Add a Docker Standalone environment

When connecting a Docker Standalone host to Portainer, there are a few different methods you can use depending on your particular requirements. You can install the Portainer Agent on the Docker Standalone host and connect via the agent, you can connect directly to the Docker API or the Docker socket, or you can deploy the Portainer Edge Agent in standard or async mode.

Regardless of the method you choose, there are some generic requirements you will need to meet. You will require:

* The latest version of Docker installed and working on your Docker Standalone host.
* sudo, root, or Administrator access on your Docker Standalone host.

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../../start/requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* Docker is running as root (for Linux) or an Administrator (for Windows). Portainer with rootless Docker has some limitations, and requires additional configuration.

<table data-view="cards"><thead><tr><th></th><th></th><th></th><th data-hidden data-card-target data-type="content-ref"></th><th data-hidden data-card-cover data-type="files"></th></tr></thead><tbody><tr><td><strong>Agent</strong></td><td></td><td></td><td><a href="agent.md">agent.md</a></td><td><a href="../../../../.gitbook/assets/card-agent-large.png">card-agent-large.png</a></td></tr><tr><td><strong>API</strong></td><td></td><td></td><td><a href="api.md">api.md</a></td><td><a href="../../../../.gitbook/assets/card-api-large.png">card-api-large.png</a></td></tr><tr><td><strong>Socket</strong></td><td></td><td></td><td><a href="socket.md">socket.md</a></td><td><a href="../../../../.gitbook/assets/card-socket-large.png">card-socket-large.png</a></td></tr><tr><td><strong>Edge Agent Standard</strong></td><td></td><td></td><td><a href="edge.md">edge.md</a></td><td><a href="../../../../.gitbook/assets/card-edgestd-large.png">card-edgestd-large.png</a></td></tr><tr><td><strong>Edge Agent Async</strong></td><td></td><td></td><td><a href="edge-async.md">edge-async.md</a></td><td><a href="../../../../.gitbook/assets/card-edgeasync-large.png">card-edgeasync-large.png</a></td></tr></tbody></table>



================================================
FILE: admin/environments/add/docker/agent.md
================================================
# Install Portainer Agent on Docker Standalone

Portainer uses the _Portainer Agent_ container to communicate with the _Portainer Server_ instance and provide access to the node's resources. This document will outline how to install the Portainer Agent on your node and how to connect to it from your Portainer Server instance. If you do not have a working Portainer Server instance yet, please refer to the [Portainer Server installation guide](../../../../start/install/server/docker/linux.md) first.

In addition to the generic requirements for Docker Standalone environments, you will need:

* Port `9001` accessible on this machine from the Portainer Server instance. If this is not available, we recommend using the [Edge Agent](edge.md) instead.
* If you are running Windows on your node, either:
  * Windows Subsystem for Linux (WSL) installed and a Linux distribution selected. For a new installation we recommend WSL2.
  * Windows Container Services (WCS) configured and running.

The Portainer Agent installation instructions also make the following additional assumptions about your environment:

* You are accessing Docker via Unix sockets (or a named pipe when using WCS). The Portainer Agent does not support connecting to the Docker engine via TCP.
* If running Linux, SELinux is disabled on the machine running Docker. If you require SELinux, you will need to pass the `--privileged` flag to Docker when deploying Portainer.
*   You have not set a custom `AGENT_SECRET` on your Portainer Server instance. If you have (by specifying an `AGENT_SECRET` environment variable when starting the Portainer Server container), you will need to provide that same secret to your agent in the same way (as an environment variable) when deploying, for example by adding the following to your `docker run` command:

    `-e AGENT_SECRET=yoursecret`

From the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Next, select **Docker Standalone** as the environment type then click **Start Wizard**. Select the **Agent** option, then your environment type. Copy the command for your environment type and run it on your Docker Standalone instance. For example, if you are deploying on a Linux machine or a Windows machine with WSL installed, use the **Linux & Windows WSL** command. If you are deploying on a Windows machine with WCS, use the **Windows WCS** command.

{% hint style="info" %}
If you want to use the [host management features](../../../../user/docker/host/setup.md#enable-host-management-features) of the Portainer Agent, you should add the necessary volume mount to the command that Portainer provides:

```
-v /:/host
```
{% endhint %}

{% hint style="info" %}
If Docker on the environment you're deploying the Agent to has the Docker volume path at a non-standard location (instead of `/var/lib/docker/volumes`) you will need to adjust the volume mount in the deployment command to suit.&#x20;

For example, if your volume path was `/srv/data/docker`, you would change the line in the command to:

```
- v /srv/data/docker:/var/lib/docker/volumes \
```

The right side of the mount should remain as `/var/lib/docker/volumes`, as that is what the Agent expects.
{% endhint %}

Once the Agent has been deployed, enter the environment details using the table below as a guide:

| Field/Option        | Overview                                                                                                                                                                                                                                                                      |
| ------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                | Give the environment a descriptive name.                                                                                                                                                                                                                                      |
| Environment address | Enter the DNS name or IP address to connect to the Portainer Agent along with the port (the default port is `9001`). Do not provide a protocol - communication with the Agent by the Server is performed over HTTPS with certificates generated by the Agent on installation. |

<figure><img src="../../../../.gitbook/assets/2.16-environments-add-docker-agent.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section to categorize the environment by adding it to a [group](../../groups.md) or [tagging](../../tags.md) it for better searchability.

{% hint style="info" %}
GPU configuration has been moved to [Host Setup](../../../../user/docker/host/setup.md#other) and can be configured once the environment has been set up.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-moresettings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Connect**. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments.



================================================
FILE: admin/environments/add/docker/api.md
================================================
# Connect to the Docker API

Before you begin, you will need to ensure that your Docker instance is configured to admit remote connections. To learn how to do this, refer to Docker's own documentation. Once Docker is configured, you will be able to connect either with or without TLS.

From the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Next, select **Docker Standalone** as the environment type then click **Start Wizard**. Select the **API** option and your platform, then enter the environment details using the table below as a guide:

<table><thead><tr><th width="280">Field/Option</th><th>Overview</th></tr></thead><tbody><tr><td>Name</td><td>Give the environment a descriptive name.</td></tr><tr><td>Docker API URL</td><td>Enter the DNS name or IP address to connect to the Docker host along with the port. When connecting without TLS, the default port is <code>2375</code>. When connecting with TLS, the default port is <code>2376</code>.</td></tr><tr><td>TLS</td><td>Toggle this option on if you wish to use TLS. Toggle it off if you don't want to use TLS.</td></tr><tr><td>Skip Certification Verification</td><td>Toggle this option on to skip the verification of the TLS certificate used by the Docker API. If this option is off, the below fields will not appear.</td></tr><tr><td>TLS CA certificate</td><td>Select your CA certificate.</td></tr><tr><td>TLS certificate</td><td>Select your certificate.</td></tr><tr><td>TLS key</td><td>Select the key that matches the certificate.</td></tr></tbody></table>

{% hint style="info" %}
Portainer expects TLS certificates and keys to be in PEM format.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-api-details.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section to categorize the environment by adding it to a [group](../../groups.md) or [tagging](../../tags.md) it for better searchability.

{% hint style="info" %}
GPU configuration has been moved to [Host Setup](../../../../user/docker/host/setup.md#other) and can be configured once the environment has been set up.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-moresettings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Connect**. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments.



================================================
FILE: admin/environments/add/docker/edge-async.md
================================================
# Install Edge Agent Async on Docker Standalone

When a remote environment is not directly accessible from the Portainer Server instance, we recommend deploying the Portainer _Edge Agent_ to the remote environment. This allows you to manage the remote environment from your Portainer Server instance without having to open any ports on the environment. Rather than the traditional approach of the server connecting to Agents, the Edge Agent instead polls the Portainer Server periodically to see if there are any pending jobs to perform, and acts appropriately.

{% hint style="info" %}
For a technical summary of how the Edge Agent works, refer to our [advanced documentation](../../../../advanced/edge-agent.md).
{% endhint %}

## Async mode vs Standard mode

The Portainer Edge Agent can be deployed in two different modes - standard mode and async mode. In standard mode, we provide the ability to connect to the remote Edge Agent through a tunnel that is established on-demand from the Edge Agent to the Portainer Server, letting you interact directly with the environment in real time.&#x20;

In async mode, this tunnel connectivity is not available. Instead, we provide the ability to browse snapshots of the remote environment, allowing you to see the state of the Edge Agent's environment based on a recent state capture sent through to the Portainer Server, as well as use this snapshot to perform actions on the remote environment.&#x20;

Async mode has been developed to use very small amounts of data and as such is suitable for environments that have limited or intermittent connectivity as well as connections with limited data caps, for example mobile networks.&#x20;

{% hint style="info" %}
Edge Agent Async mode is only available in Portainer Business Edition.
{% endhint %}

## Preparation

In async mode, the Edge Agent requires only the UI port (usually `9443` or `30779` on Kubernetes with NodePort) to be open on the Portainer server instance. The tunnel port is not required for async mode. Our installation instructions configure Portainer Server to listen on both ports by default, and you will need to ensure your firewalling provides external access to the UI port in order to proceed.

{% hint style="warning" %}
If your Portainer Server instance is deployed with TLS, the agent will use HTTPS for the connection it makes back to Portainer. However if your Portainer instance uses a self-signed certificate, the Edge Agent must be deployed with the `-e EDGE_INSECURE_POLL=1` flag. If you do not deploy the Edge Agent with this flag, then the agent will not be able to communicate with the Portainer Server instance.
{% endhint %}

In addition, our instructions assume your environment meets [our requirements](../../../../start/requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.

## Deploying

To add an async Edge Agent to a Docker Standalone environment, from the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Select **Docker Standalone** then click **Start Wizard**. Then select the **Edge Agent Async** option. Enter the environment details using the table below as a guide.

| Field                    | Overview                                                                                                                                                                         |
| ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                     | Enter a name for your environment.                                                                                                                                               |
| Portainer API server URL | Enter the URL and port of your Portainer Server instance as it will be seen from your Edge environment. If using a FQDN, ensure that DNS is properly configured to provide this. |

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-async-name (1).png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section and adjust the **Ping**, **Snapshot** and **Command** intervals for the environment - this defines how often this Edge Agent will check in with the Portainer Server for status updates, snapshot updates and to see if there are new pending commands to run, respectively. The default for each is once a minute, but the defaults can be adjusted in the [Edge Compute settings](../../../settings/edge.md#async-check-in-intervals).&#x20;

You can also categorize the environment by adding it to a [group](../../groups.md) or [tagging](../../tags.md) it for better searchability.

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-async-settings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Create**. If you are pre-staging your Edge Agent deployment, you can now retrieve the join token for use in your deployment.&#x20;

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-jointoken.png" alt=""><figcaption></figcaption></figure>

Otherwise, complete the new fields that have appeared using the table below as a guide.

| Field/Option            | Overview                                                                                                                                        |
| ----------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------- |
| Environment variables   | Enter a comma separated list of environment variables that will be sourced from the host where the agent is deployed and provided to the agent. |
| Allow self-signed certs | Toggle this on to allow self-signed certificates when the agent is connecting to Portainer via HTTPS.                                           |

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-envvars.png" alt=""><figcaption></figcaption></figure>

Choose your platform (**Linux** or **Windows**), copy the generated command and run the command on your Edge environment to complete the installation.

{% hint style="warning" %}
If you have set a custom `AGENT_SECRET` on your Portainer Server instance (by specifying an AGENT\_SECRET environment variable when starting the Portainer Server container) you **must** remember to explicitly provide the same secret to your Edge Agent in the same way (as an environment variable) when deploying your Edge Agent, for example by adding the following to your `docker run` command: \
`-e AGENT_SECRET=yoursecret`
{% endhint %}

{% hint style="info" %}
If Docker on the environment you're deploying the Edge Agent to has the Docker volume path at a non-standard location (instead of `/var/lib/docker/volumes`) you will need to adjust the volume mount in the deployment command to suit.&#x20;

For example, if your volume path was `/srv/data/docker`, you would change the line in the command to:

```
- v /srv/data/docker:/var/lib/docker/volumes \
```

The right side of the mount should remain as `/var/lib/docker/volumes`, as that is what the Edge Agent expects.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-async-command.png" alt=""><figcaption></figcaption></figure>

If you have another Edge async environment of the same type to deploy you can click **Add another environment** to do so. Otherwise if you have any other environments to configure click **Next** to proceed, or click **Close** to return to the list of environments.



================================================
FILE: admin/environments/add/docker/edge.md
================================================
# Install Edge Agent Standard on Docker Standalone

When a remote environment is not directly accessible from the Portainer Server instance, we recommend deploying the Portainer _Edge Agent_ to the remote environment. This allows you to manage the remote environment from your Portainer Server instance without having to open any ports on the environment. Rather than the traditional approach of the server connecting to Agents, the Edge Agent instead polls the Portainer Server periodically to see if there are any pending jobs to perform, and acts appropriately.

{% hint style="info" %}
For a technical summary of how the Edge Agent works, refer to our [advanced documentation](../../../../advanced/edge-agent.md).
{% endhint %}

## Preparation

The Edge Agent requires two ports be open on the Portainer Server instance: the UI port (usually `9443` or `30779` on Kubernetes with NodePort) and the tunnel port ( `8000` or `30776` when using Kubernetes with NodePort). The tunnel port is used to provide a secure TLS tunnel between the Portainer Edge Agent and the Portainer Server instance. Our installation instructions configure Portainer Server to listen on both ports by default, and you will need to ensure your firewalling provides external access to these ports in order to proceed.

{% hint style="warning" %}
If your Portainer Server instance is deployed with TLS, the agent will use HTTPS for the connection it makes back to Portainer. However if your Portainer instance uses a self-signed certificate, the Edge Agent must be deployed with the `-e EDGE_INSECURE_POLL=1` flag. If you do not deploy the Edge Agent with this flag, then the agent will not be able to communicate with the Portainer Server instance.
{% endhint %}

In addition, our instructions assume your environment meets [our requirements](../../../../start/requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.

## Deploying

To add a standard Edge Agent to a Docker Standalone environment, from the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Select **Docker Standalone** then click **Start Wizard**. Then select the **Edge Agent Standard** option. Enter the environment details using the table below as a guide.

| Field                           | Overview                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| ------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                            | Enter a name for your environment.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| Portainer API server URL        | Enter the URL and port of your Portainer Server instance as it will be seen from your Edge environment. If using a FQDN, ensure that DNS is properly configured to provide this.                                                                                                                                                                                                                                                                                                                                                              |
| Portainer tunnel server address | <p>Enter the address and port of your Portainer Server instance's tunnel server as it will be seen from your Edge environment. If using a FQDN, ensure that DNS is properly configured to provide this.<br>In most cases, this will be the same address as the Portainer API server URL, but without the protocol and on port <code>8000</code>.<br>This field is only available in Portainer Business Edition. For Community Edition users, refer to <a href="https://github.com/portainer/portainer/issues/6251">this GitHub issue</a>.</p> |

<figure><img src="../../../../.gitbook/assets/2.17-install-agent-edge-nameurl.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section and adjust the Poll frequency for the environment - this defines how often this Edge Agent will check the Portainer Server for new jobs. The default is every 5 seconds. You can also categorize the environment by adding it to a [group](../../groups.md) or [tagging](../../tags.md) it for better searchability.

<figure><img src="../../../../.gitbook/assets/2.15-edge_agent_more_settings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Create**. If you are pre-staging your Edge Agent deployment, you can now retrieve the join token for use in your deployment.&#x20;

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-jointoken.png" alt=""><figcaption></figcaption></figure>

Otherwise, complete the new fields that have appeared using the table below as a guide.

| Field/Option            | Overview                                                                                                                                        |
| ----------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------- |
| Environment variables   | Enter a comma separated list of environment variables that will be sourced from the host where the agent is deployed and provided to the agent. |
| Allow self-signed certs | Toggle this on to allow self-signed certificates when the agent is connecting to Portainer via HTTPS.                                           |

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-envvars.png" alt=""><figcaption></figcaption></figure>

Choose your platform (**Linux** or **Windows**), copy the generated command and run the command on your Edge environment to complete the installation.

{% hint style="warning" %}
If you have set a custom `AGENT_SECRET` on your Portainer Server instance (by specifying an AGENT\_SECRET environment variable when starting the Portainer Server container) you **must** remember to explicitly provide the same secret to your Edge Agent in the same way (as an environment variable) when deploying your Edge Agent, for example by adding the following to your `docker run` command: \
`-e AGENT_SECRET=yoursecret`
{% endhint %}

{% hint style="info" %}
If Docker on the environment you're deploying the Edge Agent to has the Docker volume path at a non-standard location (instead of `/var/lib/docker/volumes`) you will need to adjust the volume mount in the deployment command to suit.&#x20;

For example, if your volume path was `/srv/data/docker`, you would change the line in the command to:

```
- v /srv/data/docker:/var/lib/docker/volumes \
```

The right side of the mount should remain as `/var/lib/docker/volumes`, as that is what the Edge Agent expects.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-command.png" alt=""><figcaption></figcaption></figure>

If you have another Edge standard environment of the same type to deploy you can click **Add another environment** to do so. Otherwise if you have any other environments to configure click **Next** to proceed, or click **Close** to return to the list of environments.



================================================
FILE: admin/environments/add/docker/socket.md
================================================
# Connect to the Docker Socket

Connecting to the Docker socket directly can only be done from the local environment. Before you begin, ensure the user running the Portainer Server container has permissions to access the Docker socket.

From the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Next, select **Docker Standalone** as the environment type then click **Start Wizard**. Select the **Socket** option and your platform. You will be shown the required parameter to pass to the Portainer container as part of your `docker run` command.

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-socket-command.png" alt=""><figcaption></figcaption></figure>

Fill out the fields based on the table below.

<table><thead><tr><th width="280">Field/Option</th><th>Overview</th></tr></thead><tbody><tr><td>Name</td><td>Give the environment a descriptive name.</td></tr><tr><td>Override default socket path</td><td>Toggle this option on to override the default <code>/var/run/docker.sock</code> socket path.</td></tr><tr><td>Socket Path</td><td>If <strong>Override default socket path</strong> is enabled, enter the path to the Docker socket.</td></tr></tbody></table>

{% hint style="info" %}
Ensure that if you change the Socket Path, that you update the required bind mount parameter above to suit.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-socket-details.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section to categorize the environment by adding it to a [group](../../groups.md) or [tagging](../../tags.md) it for better searchability.

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-moresettings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Connect**. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments.



================================================
FILE: admin/environments/add/kaas/README.md
================================================
# Provision KaaS Cluster

Portainer supports the provisioning of new Kubernetes environments on select cloud providers directly from within the interface, allowing you to spin up a new cloud Kubernetes environment and deploy the Portainer Agent with a few clicks.

{% hint style="info" %}
This feature is only available in [Portainer Business Edition](https://www.portainer.io/business-upsell?from=kaas-provisioning).
{% endhint %}

To get started, from the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

From the wizard select the **Provision KaaS Cluster** option and click **Start Wizard**. Then, select your provider. We currently support the following providers:

<table data-view="cards"><thead><tr><th></th><th></th><th></th><th data-hidden data-card-cover data-type="files"></th><th data-hidden data-card-target data-type="content-ref"></th></tr></thead><tbody><tr><td><strong>Civo</strong></td><td>Civo Kubernetes</td><td></td><td><a href="../../../../.gitbook/assets/card-civo-large.png">card-civo-large.png</a></td><td><a href="civo.md">civo.md</a></td></tr><tr><td><strong>Akamai Connected Cloud</strong></td><td>Linode Kubernetes Engine (LKE)</td><td></td><td><a href="../../../../.gitbook/assets/akamai-logo-circle-tile.png">akamai-logo-circle-tile.png</a></td><td><a href="linode.md">linode.md</a></td></tr><tr><td><strong>DigitalOcean</strong></td><td>DigitalOcean Kubernetes (DOKS)</td><td></td><td><a href="../../../../.gitbook/assets/card-digitalocean-large.png">card-digitalocean-large.png</a></td><td><a href="digitalocean.md">digitalocean.md</a></td></tr><tr><td><strong>Google Cloud</strong></td><td>Google Kubernetes Engine (GKE)</td><td></td><td><a href="../../../../.gitbook/assets/card-googlecloud-large.png">card-googlecloud-large.png</a></td><td><a href="gke.md">gke.md</a></td></tr><tr><td><strong>Amazon Web Services (AWS)</strong></td><td>Elastic Kubernetes Service (EKS)</td><td></td><td><a href="../../../../.gitbook/assets/card-aws-large.png">card-aws-large.png</a></td><td><a href="eks.md">eks.md</a></td></tr><tr><td><strong>Microsoft Azure</strong></td><td>Azure Kubernetes Service (AKS)</td><td></td><td><a href="../../../../.gitbook/assets/card-azure-large.png">card-azure-large.png</a></td><td><a href="aks.md">aks.md</a></td></tr></tbody></table>



================================================
FILE: admin/environments/add/kaas/aks.md
================================================
# Azure

Select the **Azure** option from the list of providers. If you haven't already configured credentials for Azure you'll be asked to provide them now. Enter a **name** for your credentials then enter your **Subscription ID**, **Tenant ID**, **Client ID** and **Client Secret**. Once this is done, click **Save**.

{% hint style="info" %}
You can find more details on [setting up access to your Azure account](../../../settings/credentials/aks.md) in the [shared credentials documentation](../../../settings/credentials/).
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.21.2-kaas-create-azure-creds.png" alt=""><figcaption></figcaption></figure>

Once you have added your credentials (or if you already had them set up) select your cluster options from the fields below.

| Field/Option            | Overview                                                                                                                                                    |
| ----------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                    | Enter a name for your cluster.                                                                                                                              |
| Credentials             | Select the set of credentials to use for the provision.                                                                                                     |
| Region                  | Select the region to deploy your cluster in.                                                                                                                |
| Resource group          | Select an existing resource group or add a new resource group for your cluster.                                                                             |
| Node pool name          | Enter a name for your node pool.                                                                                                                            |
| Node size               | Select the size of the individual nodes in your cluster.                                                                                                    |
| Node count              | Enter the number of nodes to provision in your cluster.                                                                                                     |
| Availability zones      | Select the availability zones to use for your cluster.                                                                                                      |
| API server availability | Select the uptime SLA you require for your cluster.                                                                                                         |
| DNS name prefix         | Enter the DNS name prefix to use with your cluster. You will use this to connect to the Kubernetes API when managing containers after creating the cluster. |
| Kubernetes version      | Select the version of Kubernetes you want to deploy on your cluster                                                                                         |

{% hint style="info" %}
You can manually refresh the options available from Azure by clicking **Reload cluster details** under the **Actions** section.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.21.2-kaas-create-azure-cluster.png" alt=""><figcaption></figcaption></figure>

You can also expand the **More settings** section and set groups and tags for your environment now or you can do this later.

<figure><img src="../../../../.gitbook/assets/2.15-kaas-provision-moresettings.png" alt=""><figcaption></figcaption></figure>

Once you have made your selections, click **Provision environment** to begin the provision. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments where you will see the progress of your provision.



================================================
FILE: admin/environments/add/kaas/civo.md
================================================
# Civo

Select the **Civo** option from the list of providers. If you haven't already provided your Civo API token you'll be asked to provide credential details. Provide a **name** for your credentials and paste your Civo API token into the **API key** field and click **Add credentials**.

{% hint style="info" %}
You can find more details on [setting up access to your Civo account](../../../settings/credentials/civo.md) in the [shared credentials documentation](../../../settings/credentials/).
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.21.2-kaas-create-civo-creds.png" alt=""><figcaption></figcaption></figure>

Once you have added your credentials (or if you already had them set up) select your cluster options from the fields below.

| Field/Option       | Overview                                                             |
| ------------------ | -------------------------------------------------------------------- |
| Name               | Enter a name for your cluster.                                       |
| Credentials        | Select the set of credentials to use for the provision.              |
| Region             | Select the region to deploy your cluster in.                         |
| Node size          | Select the size of the individual nodes in your cluster.             |
| Node count         | Enter the number of nodes to provision in your cluster.              |
| Network ID         | Select the network to add your cluster to.                           |
| Kubernetes version | Select the version of Kubernetes you want to deploy on your cluster. |

{% hint style="info" %}
You can manually refresh the options available from Civo by clicking **Reload cluster details** in the **Actions** section.
{% endhint %}

### A note about Civo versions

Civo clusters using Kubernetes version 1.27 or above on a node size of Extra Small may fail to complete provisioning as the compute resources are too limited for required workloads. Versions prior to 1.27 do not have this resource requirement, so can be used with the Extra Small node size.

<figure><img src="../../../../.gitbook/assets/2.21.2-kaas-create-civo-cluster.png" alt=""><figcaption></figcaption></figure>

You can also expand the **More settings** section and set groups and tags for your environment now or you can do this later.

<figure><img src="../../../../.gitbook/assets/2.15-kaas-provision-moresettings.png" alt=""><figcaption></figcaption></figure>

Once you have made your selections, click **Provision environment** to begin the provision. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments where you will see the progress of your provision.



================================================
FILE: admin/environments/add/kaas/digitalocean.md
================================================
# DigitalOcean

Select the **DigitalOcean** option from the list of providers. If you haven't already provided your DigitalOcean API token you'll be asked to provide credentials. Provide a **name** for your credentials and paste your DigitalOcean API token into the **API key** field and click **Add credentials**.

{% hint style="info" %}
You can find more details on [setting up access to your DigitalOcean account](../../../settings/credentials/digitalocean.md) in the [shared credentials documentation](../../../settings/credentials/).
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.21.2-kaas-create-digitalocean-creds.png" alt=""><figcaption></figcaption></figure>

Once you have added your credentials (or if you already had them set up) select your cluster options from the fields below.

| Field/Option       | Overview                                                             |
| ------------------ | -------------------------------------------------------------------- |
| Name               | Enter a name for your cluster.                                       |
| Credentials        | Select the set of credentials to use for the provision.              |
| Region             | Select the region to deploy your cluster in.                         |
| Node size          | Select the size of the individual nodes in your cluster.             |
| Node count         | Enter the number of nodes to provision in your cluster.              |
| Kubernetes version | Select the version of Kubernetes you want to deploy on your cluster. |

{% hint style="info" %}
You can manually refresh the options available from DigitalOcean by clicking **Reload cluster details** under the **Actions** section.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.21.2-kaas-create-digitalocean-cluster.png" alt=""><figcaption></figcaption></figure>

You can also expand the **More settings** section and set groups and tags for your environment now or you can do this later.

<figure><img src="../../../../.gitbook/assets/2.15-kaas-provision-moresettings.png" alt=""><figcaption></figcaption></figure>

Once you have made your selections, click **Provision environment** to begin the provision. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments where you will see the progress of your provision.



================================================
FILE: admin/environments/add/kaas/eks.md
================================================
# AWS

Select the **AWS** option from the list of providers. If you haven't already configured credentials for AWS you'll be asked to provide them now. Enter a **name** for your credentials then enter your **Access key ID** and **Secret access key**. Once this is done, click **Save**.

{% hint style="info" %}
You can find more details on [setting up access to your AWS account](../../../settings/credentials/eks.md) in the [shared credentials documentation](../../../settings/credentials/).
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.21.2-kaas-create-aws-creds.png" alt=""><figcaption></figcaption></figure>

Once you have added your credentials (or if you already had them set up) select your cluster options from the fields below.

| Field/Option         | Overview                                                                                                                                                                       |
| -------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Name                 | Enter a name for your cluster.                                                                                                                                                 |
| Credentials          | Select the set of credentials to use for the provision.                                                                                                                        |
| Region               | Select the region to deploy your cluster in.                                                                                                                                   |
| AMI type             | Select the AMI type to use for your nodes.                                                                                                                                     |
| Instance type        | Select the instance type to use for your nodes. You will need to make sure that the instance type you choose is available in the region you choose or the provision will fail. |
| Node disk size (GiB) | Enter the amount of disk space to provision on each node.                                                                                                                      |
| Node count           | Enter the number of nodes to provision in your cluster.                                                                                                                        |
| Kubernetes version   | Select the version of Kubernetes you want to deploy on your cluster                                                                                                            |

{% hint style="info" %}
You can manually refresh the options available from AWS by clicking **Reload cluster details** under the **Actions** section.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.15-kaas-provision-eks.png" alt=""><figcaption></figcaption></figure>

You can also expand the **More settings** section and set groups and tags for your environment now or you can do this later.

<figure><img src="../../../../.gitbook/assets/2.15-kaas-provision-moresettings.png" alt=""><figcaption></figcaption></figure>

Once you have made your selections, click **Provision environment** to begin the provision. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments where you will see the progress of your provision.



================================================
FILE: admin/environments/add/kaas/gke.md
================================================
# Google Cloud

Select the **Google Cloud** option from the list of providers. If you haven't already configured credentials for Google Cloud you'll be asked to provide them now. Enter a **name** for your credentials then click **Upload file** and select your JSON private key. Once this is done, click **Save**.

{% hint style="info" %}
You can find more details on [setting up access to your Google Cloud account ](../../../settings/credentials/gke.md)in the [shared credentials documentation](../../../settings/credentials/).
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.21.2-kaas-create-googlecloud-creds.png" alt=""><figcaption></figcaption></figure>

Once you have added your credentials (or if you already had them set up) select your cluster options from the fields below.

| Field/Option         | Overview                                                            |
| -------------------- | ------------------------------------------------------------------- |
| Name                 | Enter a name for your cluster.                                      |
| Credentials          | Select the set of credentials to use for the provision.             |
| Region               | Select the region to deploy your cluster in.                        |
| Node size            | Select the size of the individual nodes in your cluster.            |
| Node disk space (GB) | Enter the amount of disk space to provision on each node.           |
| Node count           | Enter the number of nodes to provision in your cluster.             |
| Subnet               | Select the subnet to attach to the cluster.                         |
| Kubernetes version   | Select the version of Kubernetes you want to deploy on your cluster |

{% hint style="info" %}
You can manually refresh the options available from Google Cloud by clicking **Reload cluster details** under the **Actions** section.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.21.2-kaas-create-googlecloud-cluster.png" alt=""><figcaption></figcaption></figure>

You can also expand the **More settings** section and set groups and tags for your environment now or you can do this later.

<figure><img src="../../../../.gitbook/assets/2.15-kaas-provision-moresettings.png" alt=""><figcaption></figcaption></figure>

Once you have made your selections, click **Provision environment** to begin the provision. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments where you will see the progress of your provision.



================================================
FILE: admin/environments/add/kaas/linode.md
================================================
# Akamai Connected Cloud

Select the **Akamai Connected Cloud** option from the list of providers. If you haven't already provided your API token you'll be asked to provide credentials. Provide a **name** for your credentials and paste your API token into the **API key** field and click **Add credentials**.

{% hint style="info" %}
You can find more details on [setting up access to your Akamai account](../../../settings/credentials/linode.md) in the [shared credentials documentation](../../../settings/credentials/).
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.21.2-kaas-create-akamai-creds.png" alt=""><figcaption></figcaption></figure>

Once you have added your credentials (or if you already had them set up) select your cluster options from the fields below.

| Field/Option       | Overview                                                             |
| ------------------ | -------------------------------------------------------------------- |
| Name               | Enter a name for your cluster.                                       |
| Credentials        | Select the set of credentials to use for the provision.              |
| Region             | Select the region to deploy your cluster in.                         |
| Node size          | Select the size of the individual nodes in your cluster.             |
| Node count         | Enter the number of nodes to provision in your cluster.              |
| Kubernetes version | Select the version of Kubernetes you want to deploy on your cluster. |

{% hint style="info" %}
You can manually refresh the options available from Akamai by clicking **Reload cluster details** under the **Actions** section.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.21.2-kaas-create-akamai-cluster.png" alt=""><figcaption></figcaption></figure>

You can also expand the **More settings** section and set groups and tags for your environment now or you can do this later.

<figure><img src="../../../../.gitbook/assets/2.15-kaas-provision-moresettings.png" alt=""><figcaption></figcaption></figure>

Once you have made your selections, click **Provision environment** to begin the provision. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments where you will see the progress of your provision.



================================================
FILE: admin/environments/add/kube-create/README.md
================================================
# Create a Kubernetes cluster

With Portainer Business Edition you can create a Kubernetes cluster on your existing infrastructure directly from the Portainer UI.&#x20;

{% hint style="info" %}
Portainer connects to your infrastructure and deploy Kubernetes and the Portainer Agent. You can provide your credentials during the deployment or set them up ahead of time in [Shared credentials](../../../settings/credentials/).
{% endhint %}

At present, we support deploying Talos Kubernetes via Omni and MicroK8s via SSH:

{% content-ref url="omni.md" %}
[omni.md](omni.md)
{% endcontent-ref %}

{% content-ref url="microk8s/" %}
[microk8s](microk8s/)
{% endcontent-ref %}



================================================
FILE: admin/environments/add/kube-create/omni.md
================================================
# Talos Kubernetes

## Introduction

Portainer consists of two elements, the _Portainer Server_ and the _Portainer Agent_. Both elements run as lightweight containers on Kubernetes. This document will outline how to create a Talos Kubernetes cluster via Omni and install the Portainer Edge Agent. If you do not have a working Portainer Server instance yet, please refer to the [Portainer Server installation guide](../../../../start/install/server/kubernetes/baremetal.md) first.

## Prerequisites

In order to connect to Omni and deploy a Talos Kubernetes cluster and the Portainer Edge Agent, you will need:

* An installation of Omni. You can use the [SaaS option](https://www.siderolabs.com/platform/saas-for-kubernetes/) or alternatively [self-host](https://omni.siderolabs.com/how-to-guides/self_hosted) an Omni installation. Note that while we believe that self-hosted installations will work fine, we have not extensively tested them in this initial release of this feature.
* A service account on your Omni installation for Portainer to use. This service account should have Admin access. You can learn more about how to create a service account in our [credentials documentation](../../../settings/credentials/omni.md).
* Machines registered within your Omni installation to be used for your Talos cluster. Documentation on registering these machines can be found in [Sidero's documentation](https://omni.siderolabs.com/how-to-guides/registering-machines).
* The machines you intend to use for your Talos Kubernetes cluster must be able to communicate with the Portainer Server deployment on API port (by default `9443`) and the tunnel server port (by default `8000`). This is so that the Edge Agent that is deployed on the cluster can communicate with the Portainer server.

## Deployment

To create your Talos Kubernetes cluster and deploy the Portainer Edge Agent to your machines, from the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Select **Create a Kubernetes cluster** and click **Start wizard**, then ensure **Talos Kubernetes** is selected.

If you have not yet [configured a set of credentials for your Omni installation](../../../settings/credentials/omni.md), you will be asked to provide them now. If you already have a credential set configured, you can skip to [cluster configuration](omni.md#configure-your-cluster).

### Credential details

Fill in the fields based on the table below:

| Field/Option        | Overview                                                                                                                       |
| ------------------- | ------------------------------------------------------------------------------------------------------------------------------ |
| Credentials name    | Enter a name for this credential set. This is how it will be listed in Portainer.                                              |
| Endpoint URL        | Enter the endpoint URL of your Omni installation. This is generally the same URL you would be using to access the Omni web UI. |
| Service account key | Paste your service account key into this field.                                                                                |

{% hint style="info" %}
You can create a service account through the Omni web UI or using `omnictl`. You can find more information on how to do this in our [Omni credentials documentation](../../../settings/credentials/omni.md).
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.26-environments-add-kube-create-omni-creds.png" alt=""><figcaption></figcaption></figure>

Once you have entered your credentials click **Add credentials**. The credential set will be saved under the name you entered, and you will be taken to the cluster configuration.

### Configure your cluster

Once you have a set of credentials configured, you can proceed to configuring your cluster. Enter a **Name** for your cluster and fill out the rest of the fields based on the tables below.

#### Portainer server details

Here you can provide the details for Portainer so that the agent can be deployed once the cluster has been created. Note that the URLs here should be the URLs that Portainer is accessible on from the perspective of the machines in the cluster.

| Field/Option                    | Overview                                                                                                   |
| ------------------------------- | ---------------------------------------------------------------------------------------------------------- |
| Portainer API server URL        | The URL to your Portainer server. This should generally be pre-populated with the correct value.           |
| Portainer tunnel server address | The address to the Portainer tunnel server. This should generally be pre-populated with the correct value. |

<figure><img src="../../../../.gitbook/assets/2.26-environments-add-kube-create-omni-portainer.png" alt=""><figcaption></figcaption></figure>

#### Omni cluster summary

Here you can select the credentials to use to connect to Omni as well as the versions of Talos and Kubernetes to deploy.

| Field/Option       | Overview                                                                                                                                             |
| ------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------- |
| Credentials        | Select the set of Omni credentials to use from the dropdown.                                                                                         |
| Talos version      | Select the version of Talos to deploy on your cluster machines. The options here may be limited by the machines you select later in the process.     |
| Kubernetes version | Select the version of Kubernetes to install on your cluster machines. The options here may be restricted based on the version of Talos chosen above. |

<figure><img src="../../../../.gitbook/assets/2.26-environments-add-kube-create-omni-clustersummary.png" alt=""><figcaption></figcaption></figure>

#### Cluster machines

Here you can specify the machines to use for your cluster. The dropdowns will display the list of available machines alongside any labels on each machine to help with identification.&#x20;

| Field/Option     | Overview                                                                                                                                                 |
| ---------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Control Plane    | Select the machine(s) to use as your control plane nodes. You will need to choose at least one, and an odd number of control plane nodes is recommended. |
| Main worker pool | Select the machine(s) to use as your worker nodes.                                                                                                       |

<figure><img src="../../../../.gitbook/assets/2.26-environments-add-kube-create-omni-machines (1).png" alt=""><figcaption></figcaption></figure>

Once you have selected machines here you can tweak the networking configuration for each machine individually if necessary by clicking the cog icon next to the individual machine.

<figure><img src="../../../../.gitbook/assets/2.26-environments-add-kube-create-omni-machines-customconfig-form.png" alt=""><figcaption></figcaption></figure>

Machines that have had their networking configuration adjusted in this way will have an orange dot on the cog icon:

<figure><img src="../../../../.gitbook/assets/2.26-environments-add-kube-create-omni-machines-customconfig.png" alt=""><figcaption><p>talos-w1e-4a0 has a modified network configuration whereas talos-y3d-vuj does not.</p></figcaption></figure>



#### Cluster Configuration patch

This section allows you to apply a custom YAML configuration to your cluster if required. You can click **Cluster Configuration patch** to display the section and provide your YAML in the editor.

<figure><img src="../../../../.gitbook/assets/2.26-environments-add-kube-create-omni-clusterpatch.png" alt=""><figcaption></figcaption></figure>



#### More settings

As an optional step you can expand the More settings section to customize the deployment further.

| Field/Option       | Overview                                                                                                                     |
| ------------------ | ---------------------------------------------------------------------------------------------------------------------------- |
| Initial deployment | This section lets you select a custom template to deploy after cluster creation.                                             |
| Stack              | Optionally enter a stack name for your initial deployment.                                                                   |
| Custom template    | Select the template to deploy from the dropdown.                                                                             |
| Metadata           | This section lets you specify metadata for the environment for use within Portainer.                                         |
| Group              | Select the group to add the environment to.                                                                                  |
| Tags               | Select the tags to apply to your environment. These tags apply only to Portainer, and not to the cluster within Omni itself. |

<figure><img src="../../../../.gitbook/assets/2.26-environments-add-kube-create-omni-moresettings.png" alt=""><figcaption></figcaption></figure>

Once you have entered your cluster configuration details, click **Provision environment** to begin the provision. Portainer will start provisioning your cluster with the options you selected. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments.

### Provision progress

From the Environments page you will be able to see the progress of any running Kubernetes environment provisions. The status will be updated as the provision completes, and if the provision runs into problems an error will be displayed here. You can hover over the status or error for additional detail.

<figure><img src="../../../../.gitbook/assets/2.26-environments-add-kube-create-omni-progress.png" alt=""><figcaption></figcaption></figure>

Once the provision completes, you will be able to access the environment as you would any other Portainer-configured environment.




================================================
FILE: admin/environments/add/kube-create/microk8s/README.md
================================================
# MicroK8s

## Introduction

Portainer consists of two elements, the _Portainer Server_ and the _Portainer Agent_. Both elements run as lightweight containers on Kubernetes. This document will outline how to connect Portainer to your existing infrastructure to deploy MicroK8s and install the Portainer Agent. If you do not have a working Portainer Server instance yet, please refer to the [Portainer Server installation guide](../../../../../start/install/server/kubernetes/baremetal.md) first.

## Prerequisites

In order to connect to and deploy MicroK8s and the Portainer Agent on your existing infrastructure, you will need:

* One or more Linux-based machines on which MicroK8s will be deployed. We have primarily tested on Ubuntu 20.04 LTS but most comparable Linux distributions should work. These machines can be bare metal servers or virtual machines.
* Root or passwordless sudo SSH access to the above machines on port `22`. This is needed in order to install MicroK8s. Portainer supports both password-based and key-based authentication.
* The `snap` tool installed on the above machines. You can find installation instructions for most Linux distributions [at the Snapcraft website](https://snapcraft.io/docs/installing-snapd). The `snap` tool is used to install MicroK8s and any selected addons.
* Communication between the Portainer Server and the above machines, as well as communication between the individual machines in the cluster. This is to ensure the Portainer Server can reach the machines both for the initial installation and for communication with the Portainer Agent once the cluster is up and running, and so that the cluster nodes can communicate with each other.
* For the standard installation, internet access (specifically to Docker Hub and registry.k8s.io) from the machines where MicroK8s will be deployed. If internet access is not available you can perform an offline installation, though there are some [prerequisite steps](offline.md) that must be completed. In addition, operating offline may affect enabling of some addons.

## What to expect

By necessity, our MicroK8s deployment makes some configuration decisions for you.

* The Portainer Agent is deployed using NodePort, on port `30778`.&#x20;
* There may be some configuration differences between versions of MicroK8s deployed. One notable difference is from version 1.25, if the `ingress` addon is installed an additional ingress named `nginx` is configured. This does not occur on version 1.24. We recommend referring to the [MicroK8s release notes](https://microk8s.io/docs/release-notes) for further detail.
* The deployment does not configure any storage classes on your cluster (unless the `hostpath-storage` addon is installed, though this is not recommended for multiple node clusters). Due to the vast amount of potential storage class configurations, this is not something we currently provide automatically. We recommend configuring a storage class once provision completes.

## Deployment

To create and deploy MicroK8s and the Portainer Agent to your machines, from the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Select **Create a Kubernetes cluster** and click **Start wizard**, then select **MicroK8s**.

If you have not yet [configured a set of SSH credentials](../../../../settings/credentials/ssh.md), you will be asked to provide them now. If you already have a credential set configured, you can skip to [cluster configuration](./#configure-your-cluster).

### Add SSH credentials

Fill in the fields based on the table below:

| Field/Option               | Overview                                                                                                             |
| -------------------------- | -------------------------------------------------------------------------------------------------------------------- |
| Credentials name           | Enter a name for this credential set. This is how it will be listed in Portainer.                                    |
| SSH username               | Enter the username for your SSH account.                                                                             |
| SSH password               | Enter the password for your SSH account. You can leave this field blank if you intend to use SSH key authentication. |
| Use SSH key authentication | Enable this toggle to use SSH key authentication instead of password authentication.                                 |
| SSH private key passphrase | If your SSH private key is encrypted, provide the passphrase here.                                                   |
| SSH private key            | Paste your SSH private key in this field.                                                                            |

{% hint style="info" %}
You can also choose to generate a new SSH key pair by clicking the **Generate new RSA SSH key pair** button, or upload an existing private key by clicking the **Upload SSH private key** button. You can find more detailed instructions for generating a new SSH key in our [SSH credentials documentation](../../../../settings/credentials/ssh.md#generate-a-new-key-pair).
{% endhint %}

<figure><img src="../../../../../.gitbook/assets/2.26-environments-add-kube-create-microk8s-creds.png" alt=""><figcaption></figcaption></figure>

Once you have entered your credentials click **Add credentials**. The credential set will be saved under the name you entered, and you will be taken to the [cluster configuration](./#configure-your-cluster).

### Configure your cluster

Once you have a set of credentials configured, you can proceed to configuring your cluster. Fill out the fields based on the table below:

| Field/Option        | Overview                                                                                                                                                                                                   |
| ------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                | Enter a name for your environment. This is how the environment will appear in Portainer.                                                                                                                   |
| Credentials         | Select the set of SSH credentials to use from the dropdown.                                                                                                                                                |
| Control plane nodes | Enter a comma-separated or line-separated list of the IP addresses for the machines that will be the **control plane nodes** for your cluster. You can also specify a range of IP addresses with a hyphen. |
| Worker nodes        | Enter a comma-separated or line-separated list of the IP addresses for the machines that will be the **worker nodes** for your cluster. You can also specify a range of IP addresses with a hyphen.        |

<figure><img src="../../../../../.gitbook/assets/2.19-environments-create-microk8s-nodes.png" alt=""><figcaption></figcaption></figure>

Once you have selected a credential set and entered the node IPs, you can click **Test connections** to ensure the credentials work for all the IP addresses and that they are reachable from the Portainer Server instance. If there are any issues connecting to the nodes they will be displayed.

<figure><img src="../../../../../.gitbook/assets/2.19-environments-create-microk8s-test.png" alt=""><figcaption></figcaption></figure>

You can now proceed to configuring MicroK8s itself. Fill out the fields based on the table below:

| Field/Option       | Overview                                                                                                                                                                                                                            |
| ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Kubernetes version | Select the version of MicroK8s to deploy on your cluster. This field is disabled if **Offline install** is enabled.                                                                                                                 |
| Offline install    | Enable this toggle if you are performing an installation on an environment that has no internet access. You must complete [pre-configuration of your nodes](offline.md) for offline installation.                                   |
| Addons             | Optionally click the **Add addon** button to select one or more addons to deploy alongside the MicroK8s installation. You can also specify any arguments needed for each addon. This is disabled if **Offline install** is enabled. |

<figure><img src="../../../../../.gitbook/assets/2.20.3-environments-add-k8s-create-version.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section to customize the deployment further.

| Field/Option    | Overview                                                                                                                                                                                                                                                                                                                                                    |
| --------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Custom Template | Select a custom template to deploy on your cluster once the MicroK8s and Portainer Agent installations are complete. This is handy for pre-loading a new environment with your applications. The template will be deployed in the default namespace unless the template specifies a namespace to use. You can also set any variables the template requires. |
| Group           | Select a [group](../../../groups.md) to add the new environment to once provisioning completes.                                                                                                                                                                                                                                                             |
| Tags            | Select any [tags](../../../tags.md) to add to the environment.                                                                                                                                                                                                                                                                                              |

<figure><img src="../../../../../.gitbook/assets/2.19-environments-create-microk8s-moresettings.png" alt=""><figcaption></figcaption></figure>

Once you have entered your cluster configuration details, click **Provision environment** to begin the provision. Portainer will start provisioning your cluster with the options you selected. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments.

### Provision progress

From the Environments page you will be able to see the progress of any running Kubernetes environment provisions. The status will be updated as the provision completes, and if the provision runs into problems an error will be displayed here. You can hover over the status or error for additional detail.

<figure><img src="../../../../../.gitbook/assets/2.18-environments-add-k8sinstall-creating.png" alt=""><figcaption></figcaption></figure>

Once the provision completes, you will be able to access the environment as you would any other Portainer-configured environment.



================================================
FILE: admin/environments/add/kube-create/microk8s/offline.md
================================================
# Offline installation

To perform a MicroK8s environment creation when the target servers are offline or airgapped, some prerequisite configuration is required. This includes downloading the MicroK8s installation files for the version you wish to install, the related addon images, and the Portainer Agent image.

{% hint style="warning" %}
This is advanced functionality and assumes working knowledge of the Linux command line. If you do not explicitly need to perform offline or airgapped installs of MicroK8s environments we recommend following the [standard procedure](./).
{% endhint %}

## Preparation

As with a standard MicroK8s provision, Portainer requires root or passwordless sudo SSH access to the servers that are being provisioned. Within this SSH user's home directory, create a directory named `microk8s`, and within that a subdirectory named `images`. This is where Portainer expects the MicroK8s files to be for an offline installation. For example:

```
mkdir -p $HOME/microk8s
mkdir -p $HOME/microk8s/images
```

Once you have completed the below steps, ensure that the above directory (and files within) are owned by the SSH user that Portainer will connect with to perform the installation.

You will also want to ensure you have `snap` installed as this is required for the MicroK8s installation. Modern versions of Ubuntu should come with `snap` preinstalled, but you can refer to the [snap documentation](https://snapcraft.io/docs/installing-snap-on-ubuntu) if you need to install it separately.

## Download MicroK8s

Next you will need to download the MicroK8s installation files. The below example does so for version 1.27 - if you need to use a different version, adjust the command accordingly.

```
snap download microk8s --channel 1.27
snap download core20
```

This should result in 4 files being downloaded - an `.assert` file and a `.snap` file for both `microk8s` and `core20`. For example (your exact filenames may differ):

```
core20_2318.assert
core20_2318.snap
microk8s_6743.assert
microk8s_6743.snap
```

Move these downloaded files into the `microk8s` directory you created earlier, renaming them as you go to the filenames expected by Portainer:

```
mv microk8s_*.snap $HOME/microk8s/microk8s.snap
mv microk8s_*.assert $HOME/microk8s/microk8s.assert
mv core20_*.snap $HOME/microk8s/core20.snap
mv core20_*.assert $HOME/microk8s/core20.assert
```

## Download required images

To support the necessary addons for MicroK8s, you will need to pre-download the Docker images used to provision the addons. The exact addons and versions differ depending on the version of MicroK8s you are installing, and can be found at the following URL in the MicroK8s repository (adjust the version number to suit):

```
https://github.com/canonical/microk8s/blob/1.27/build-scripts/images.txt
```

For example, for 1.27 you will need the following:

```
docker.io/calico/cni:v3.25.0
docker.io/calico/kube-controllers:v3.25.0
docker.io/calico/node:v3.25.0
docker.io/cdkbot/hostpath-provisioner:1.4.2
docker.io/coredns/coredns:1.10.0
docker.io/library/busybox:1.28.4
registry.k8s.io/ingress-nginx/controller:v1.5.1
registry.k8s.io/metrics-server/metrics-server:v0.5.2
registry.k8s.io/pause:3.7
```

In addition, you will need the Portainer Agent image - replace `{PORTAINER_SERVER_VERSION}` with the version number that matches your Portainer Server installation (for example, `2.20.3`):

```
docker.io/portainer/agent:{PORTAINER_SERVER_VERSION}
```

You may also want to pre-download the `kubectl-shell` image if you wish to use the [kubectl shell](../../../../../user/kubernetes/kubectl.md) functionality within Portainer:

```
docker.io/portainer/kubectl-shell:latest
```

One way to pre-download these images is to use an installed version of Docker to pull the images and then save them in the path and filename that is expected. For example:

```
docker image pull docker.io/portainer/agent:2.20.3
docker image save docker.io/portainer/agent:2.20.3 -o "$HOME/microk8s/images/docker,io-portainer-agent_2.20.3.tar"
```

This will need to be done for each image needed. A simple bash script, once populated with the images in a list, could perform this:

```
imageList=("docker.io/calico/cni:v3.25.0" "docker.io/calico/kube-controllers:v3.25.0" "docker.io/calico/node:v3.25.0" "docker.io/cdkbot/hostpath-provisioner:1.4.2" "docker.io/coredns/coredns:1.10.0" "docker.io/library/busybox:1.28.4" "registry.k8s.io/ingress-nginx/controller:v1.5.1" "registry.k8s.io/metrics-server/metrics-server:v0.5.2" "registry.k8s.io/pause:3.7" "docker.io/portainer/agent:2.20.3" "docker.io/portainer/kubectl-shell:latest")

for image in ${imageList[@]}; do
  docker image pull $image && docker image save $image -o "$HOME/microk8s/images/$(echo $image | sed 's/\//-/g' | sed 's/:/_/g').tar"
done
```

## Copy the files to all nodes

If you are installing a multi-node cluster, the `$HOME/microk8s` directory and files within must be on all nodes in the cluster at the same path. While doing this, ensure that the directory and files have the correct owner (the SSH user that Portainer will use to connect to the nodes).

## Begin the installation

You are now ready to follow the [standard procedure](./) in Portainer for creating a MicroK8s cluster, but with the **Offline install** toggle enabled.

<figure><img src="../../../../../.gitbook/assets/2.20.3-environments-add-k8s-create-offline-toggle.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: admin/environments/add/kubernetes/README.md
================================================
# Add a Kubernetes environment

When connecting a Kubernetes environment to Portainer, there are a few different methods you can use depending on your particular requirements. You can install the Portainer Agent on the Kubernetes cluster and connect via the agent, you can deploy the Portainer Edge Agent in standard or async mode, or you can choose to import an existing Kubernetes environment with a kubeconfig file.

Regardless of the method you choose, there are some generic requirements you will need to meet. You will require:

* A working and up to date Kubernetes cluster.

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../../start/requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* You will be using the `portainer` namespace for Portainer.

<table data-card-size="large" data-view="cards"><thead><tr><th></th><th></th><th></th><th data-hidden data-card-cover data-type="files"></th><th data-hidden data-card-target data-type="content-ref"></th></tr></thead><tbody><tr><td><strong>Agent</strong></td><td></td><td></td><td><a href="../../../../.gitbook/assets/card-agent-large.png">card-agent-large.png</a></td><td><a href="agent.md">agent.md</a></td></tr><tr><td><strong>Edge Agent Standard</strong></td><td></td><td></td><td><a href="../../../../.gitbook/assets/card-edgestd-large.png">card-edgestd-large.png</a></td><td><a href="edge.md">edge.md</a></td></tr><tr><td><strong>Edge Agent Async</strong></td><td></td><td></td><td><a href="../../../../.gitbook/assets/card-edgeasync-large.png">card-edgeasync-large.png</a></td><td><a href="edge-async.md">edge-async.md</a></td></tr><tr><td><strong>Import</strong></td><td>Import an existing Kubernetes config</td><td></td><td><a href="../../../../.gitbook/assets/card-import-large.png">card-import-large.png</a></td><td><a href="import.md">import.md</a></td></tr></tbody></table>



================================================
FILE: admin/environments/add/kubernetes/agent.md
================================================
# Install Portainer Agent on your Kubernetes environment

Portainer consists of two elements, the _Portainer Server_ and the _Portainer Agent_. Both elements run as lightweight containers on Kubernetes. This document will outline how to install the Portainer Agent on your cluster and how to connect to it from your Portainer Server instance. If you do not have a working Portainer Server instance yet, please refer to the [Portainer Server installation guide](../../../../start/install/server/kubernetes/baremetal.md) first.

In addition to the generic requirements for Kubernetes environments, you will need:

* Access to run `kubectl` commands on your cluster.
* Cluster Admin rights on your Kubernetes cluster. This is so Portainer can create the necessary `ServiceAccount` and `ClusterRoleBinding` for it to access the Kubernetes cluster.

The installation instructions also make the following additional assumption about your environment:

*   If you have (by specifying an `AGENT_SECRET` environment variable when starting the Portainer Server container), you will need to provide that same secret to your agent in the same way (as an environment variable) by adding it to the YAML file within the agent deployment definition:

    `env:`

    &#x20; `- name: AGENT_SECRET`

    &#x20;   `value: yoursecret`

To deploy Portainer Agent within a Kubernetes cluster you can use our provided YAML manifests.

{% hint style="info" %}
Helm charts for agent-only deployments will be available soon.
{% endhint %}

From the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Select the **Kubernetes** option and click **Start Wizard**. Select the **Agent** option and choose the tab that matches your configuration (**Kubernetes via load balancer** or **Kubernetes via node port**). Copy the command, then run it on the control node of your Kubernetes cluster.

{% hint style="info" %}
Make sure you run this command on your Kubernetes node before continuing.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-k8s-agent-command.png" alt=""><figcaption></figcaption></figure>

The deployment command will return something similar to this:

```
namespace/portainer created
serviceaccount/portainer-sa-clusteradmin created
clusterrolebinding.rbac.authorization.k8s.io/portainer-crb-clusteradmin created
service/portainer-agent created
service/portainer-agent-headless created
deployment.apps/portainer-agent created
```

To validate that the agent is running, use this command:

```
 kubectl get pods --namespace=portainer
```

The result should look something like this:

```
NAME                               READY   STATUS    RESTARTS   AGE
portainer-agent-5988b5d966-bvm9m   1/1     Running   0          15m
```

Regardless of the method used, once the agent is running on the Kubernetes host, you must complete the appropriate environmental details.

{% hint style="warning" %}
Only do this **once** for your environment, regardless of how many nodes are in the cluster. You do **not** need to add each node as an individual environment in Portainer. Adding just one node will allow Portainer to manage the entire cluster.
{% endhint %}

| Field/Option        | Overview                                                                                                                                                                                                                                                                                                                                         |
| ------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Name                | Give the environment a descriptive name.                                                                                                                                                                                                                                                                                                         |
| Environment address | Define the IP address or name used to connect to the environment (the Kubernetes host) and specify the port if required (`30778` when using NodePort; `9001` when using Load Balancer). Do not provide a protocol - communication with the Agent by the Server is performed over HTTPS with certificates generated by the Agent on installation. |

<figure><img src="../../../../.gitbook/assets/2.15-k8s_env_url.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section to customize the deployment further.

| Field/Option    | Overview                                                                                                                                                                                                                                                                                   |
| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Custom Template | Select a custom template to deploy on your cluster. This is handy for pre-loading a new environment with your applications. The template will be deployed in the default namespace unless the template specifies a namespace to use. You can also set any variables the template requires. |
| Group           | Select a [group](../../groups.md) to add the new environment to once provisioning completes.                                                                                                                                                                                               |
| Tags            | Select any [tags](../../tags.md) to add to the environment.                                                                                                                                                                                                                                |

<figure><img src="../../../../.gitbook/assets/2.19-environments-create-microk8s-moresettings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Connect**. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments.



================================================
FILE: admin/environments/add/kubernetes/edge-async.md
================================================
# Install Edge Agent Async on Kubernetes

When a remote environment is not directly accessible from the Portainer Server instance, we recommend deploying the Portainer _Edge Agent_ to the remote environment. This allows you to manage the remote environment from your Portainer Server instance without having to open any ports on the environment. Rather than the traditional approach of the server connecting to Agents, the Edge Agent instead polls the Portainer Server periodically to see if there are any pending jobs to perform, and acts appropriately.

{% hint style="info" %}
For a technical summary of how the Edge Agent works, refer to our [advanced documentation](../../../../advanced/edge-agent.md).
{% endhint %}

## Async mode vs Standard mode

The Portainer Edge Agent can be deployed in two different modes - standard mode and async mode. In standard mode, we provide the ability to connect to the remote Edge Agent through a tunnel that is established on-demand from the Edge Agent to the Portainer Server, letting you interact directly with the environment in real time.&#x20;

In async mode, this tunnel connectivity is not available. Instead, we provide the ability to browse snapshots of the remote environment, allowing you to see the state of the Edge Agent's environment based on a recent state capture sent through to the Portainer Server, as well as use this snapshot to perform actions on the remote environment.&#x20;

Async mode has been developed to use very small amounts of data and as such is suitable for environments that have limited or intermittent connectivity as well as connections with limited data caps, for example mobile networks.&#x20;

{% hint style="info" %}
Edge Agent Async mode is only available in Portainer Business Edition.
{% endhint %}

## Preparation

In async mode, the Edge Agent requires only the UI port (usually `9443` or `30779` on Kubernetes with NodePort) to be open on the Portainer server instance. The tunnel port is not required for async mode. Our installation instructions configure Portainer Server to listen on both ports by default, and you will need to ensure your firewalling provides external access to the UI port in order to proceed.

{% hint style="warning" %}
If your Portainer Server instance is deployed with TLS, the agent will use HTTPS for the connection it makes back to Portainer. However if your Portainer instance uses a self-signed certificate, the Edge Agent must be deployed with the `-e EDGE_INSECURE_POLL=1` flag. If you do not deploy the Edge Agent with this flag, then the agent will not be able to communicate with the Portainer Server instance.
{% endhint %}

In addition, our instructions assume your environment meets [our requirements](../../../../start/requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.

## Deploying

To add an async Edge Agent to a Kubernetes environment, from the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Select **Kubernetes** then click **Start Wizard**. Then select the **Edge Agent Async** option. Enter the environment details using the table below as a guide.

| Field                    | Overview                                                                                                                                                                         |
| ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                     | Enter a name for your environment.                                                                                                                                               |
| Portainer API server URL | Enter the URL and port of your Portainer Server instance as it will be seen from your Edge environment. If using a FQDN, ensure that DNS is properly configured to provide this. |

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-async-name.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section and adjust the **Ping**, **Snapshot** and **Command** intervals for the environment - this defines how often this Edge Agent will check in with the Portainer Server for status updates, snapshot updates and to see if there are new pending commands to run, respectively. The default for each is once a minute, but the defaults can be adjusted in the [Edge Compute settings](../../../settings/edge.md#async-check-in-intervals).&#x20;

You can also categorize the environment by adding it to a [group](../../groups.md) or [tagging](../../tags.md) it for better searchability.

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-async-settings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Create**. If you are pre-staging your Edge Agent deployment, you can now retrieve the join token for use in your deployment.&#x20;

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-jointoken.png" alt=""><figcaption></figcaption></figure>

Otherwise, complete the new fields that have appeared using the table below as a guide.

| Field/Option            | Overview                                                                                                                                        |
| ----------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------- |
| Environment variables   | Enter a comma separated list of environment variables that will be sourced from the host where the agent is deployed and provided to the agent. |
| Allow self-signed certs | Toggle this on to allow self-signed certificates when the agent is connecting to Portainer via HTTPS.                                           |

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-envvars.png" alt=""><figcaption></figcaption></figure>

Copy the generated command and run the command on your Edge environment to complete the installation.

{% hint style="warning" %}
If you have set a custom `AGENT_SECRET` on your Portainer Server instance (by specifying an AGENT\_SECRET environment variable when starting the Portainer Server container) you **must** remember to explicitly provide the same secret to your Edge Agent in the same way (as an environment variable) when deploying your Edge Agent, within the agent deployment definition:

`env:`\
&#x20; `- name: AGENT_SECRET`\
&#x20;   `value: yoursecret`
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-k8s-edge-async-command.png" alt=""><figcaption></figcaption></figure>

If you have another Edge async environment of the same type to deploy you can click **Add another environment** to do so. Otherwise if you have any other environments to configure click **Next** to proceed, or click **Close** to return to the list of environments.



================================================
FILE: admin/environments/add/kubernetes/edge.md
================================================
# Install Edge Agent Standard on Kubernetes

When a remote environment is not directly accessible from the Portainer Server instance, we recommend deploying the Portainer _Edge Agent_ to the remote environment. This allows you to manage the remote environment from your Portainer Server instance without having to open any ports on the environment. Rather than the traditional approach of the server connecting to Agents, the Edge Agent instead polls the Portainer Server periodically to see if there are any pending jobs to perform, and acts appropriately.

{% hint style="info" %}
For a technical summary of how the Edge Agent works, refer to our [advanced documentation](../../../../advanced/edge-agent.md).
{% endhint %}

## Preparation

The Edge Agent requires two ports be open on the Portainer Server instance: the UI port (usually `9443` or `30779` on Kubernetes with NodePort) and the tunnel port ( `8000` or `30776` when using Kubernetes with NodePort). The tunnel port is used to provide a secure TLS tunnel between the Portainer Edge Agent and the Portainer Server instance. Our installation instructions configure Portainer Server to listen on both ports by default, and you will need to ensure your firewalling provides external access to these ports in order to proceed.

{% hint style="warning" %}
If your Portainer Server instance is deployed with TLS, the agent will use HTTPS for the connection it makes back to Portainer. However if your Portainer instance uses a self-signed certificate, the Edge Agent must be deployed with the `-e EDGE_INSECURE_POLL=1` flag. If you do not deploy the Edge Agent with this flag, then the agent will not be able to communicate with the Portainer Server instance.
{% endhint %}

In addition, our instructions assume your environment meets [our requirements](../../../../start/requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.

## Deploying

From the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Select **Kubernetes** then click **Start Wizard**. Then select the **Edge Agent Standard** option. Enter the environment details using the table below as a guide.

| Field                           | Overview                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| ------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                            | Enter a name for your environment.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| Portainer API server URL        | Enter the URL and port of your Portainer Server instance as it will be seen from your Edge environment. If using a FQDN, ensure that DNS is properly configured to provide this.                                                                                                                                                                                                                                                                                                                                                              |
| Portainer tunnel server address | <p>Enter the address and port of your Portainer Server instance's tunnel server as it will be seen from your Edge environment. If using a FQDN, ensure that DNS is properly configured to provide this.<br>In most cases, this will be the same address as the Portainer API server URL, but without the protocol and on port <code>8000</code>.<br>This field is only available in Portainer Business Edition. For Community Edition users, refer to <a href="https://github.com/portainer/portainer/issues/6251">this GitHub issue</a>.</p> |

<figure><img src="../../../../.gitbook/assets/2.17-install-agent-edge-nameurl.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section and adjust the Poll frequency for the environment - this defines how often this Edge Agent will check the Portainer Server for new jobs. The default is every 5 seconds. You can also categorize the environment by adding it to a [group](../../groups.md) or [tagging](../../tags.md) it for better searchability.

<figure><img src="../../../../.gitbook/assets/2.15-edge_agent_more_settings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Create**. If you are pre-staging your Edge Agent deployment, you can now retrieve the join token for use in your deployment.&#x20;

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-jointoken.png" alt=""><figcaption></figcaption></figure>

Otherwise, complete the new fields that have appeared using the table below as a guide.

| Field/Option            | Overview                                                                                                                                        |
| ----------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------- |
| Environment variables   | Enter a comma separated list of environment variables that will be sourced from the host where the agent is deployed and provided to the agent. |
| Allow self-signed certs | Toggle this on to allow self-signed certificates when the agent is connecting to Portainer via HTTPS.                                           |

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-envvars.png" alt=""><figcaption></figcaption></figure>

Copy the generated command and run the command on your Edge environment to complete the installation.

{% hint style="warning" %}
If you have set a custom `AGENT_SECRET` on your Portainer Server instance (by specifying an AGENT\_SECRET environment variable when starting the Portainer Server container) you **must** remember to explicitly provide the same secret to your Edge Agent in the same way (as an environment variable) when deploying your Edge Agent, within the agent deployment definition:

`env:`\
&#x20; `- name: AGENT_SECRET`\
&#x20;   `value: yoursecret`
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-k8s-edge-command.png" alt=""><figcaption></figcaption></figure>

If you have another Edge standard environment of the same type to deploy you can click **Add another environment** to do so. Otherwise if you have any other environments to configure click **Next** to proceed, or click **Close** to return to the list of environments.



================================================
FILE: admin/environments/add/kubernetes/import.md
================================================
# Import an existing Kubernetes environment

With Portainer you can import your existing Kubernetes environment through the use of a [kubeconfig](https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/) file. Portainer will use the information in the kubeconfig file to connect to your environment then deploy and configure the Portainer Agent for you.

{% hint style="info" %}
This feature is only available in [Portainer Business Edition](https://www.portainer.io/business-upsell?from=k8s-create-from-kubeconfig).
{% endhint %}

## Requirements

While we have tried to support as many configurations as possible, there are a few requirements in order to fully support the import process:

* Your cluster must have a load balancer configured and enabled.
* Your kubeconfig file must specify `current-context`.
* Your kubeconfig file must be self-contained (i.e., consist of only the one file with no external references).
* Your kubeconfig file must provide cluster admin level credentials, in order for Portainer to deploy the agent on your cluster.

## Generating a kubeconfig file for import

Depending on your environment, there may be different methods for creating a supported kubeconfig file. The following environment types are currently supported:

### On-premise clusters

For an on-premise cluster, you can use the following kubectl command to generate a supported kubeconfig file:

```
kubectl config view --flatten=true --minify=true > kubeconfig.yml
```

### Civo

To create a kubeconfig file from a Civo cluster, log into the Civo dashboard and go to **Kubernetes**. Select the cluster to import and click on **Click to Download** next to the **Kubeconfig** label.

### Linode

To create a kubeconfig file from a Linode cluster, log into the Linode dashboard and click on **Kubernetes** in the left hand menu. Select the cluster to import, and in the top right of the page select **Actions** then **Download Config**.

### DigitalOcean

To create a kubeconfig file from a DigitalOcean cluster, log into the DigitalOcean dashboard and in the left hand menu select **Manage** then **Kubernetes**. Alternatively, go to **Projects**, select the project containing your cluster, then look in the **Clusters** panel. Select the cluster to import, then click the **Kubeconfig** option to download the kubeconfig file.

### Microsoft Azure

To create a kubeconfig file from an Azure cluster, download and install the [Azure CLI](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli) from Microsoft. Start a shell session on Linux or an administrator PowerShell session on Windows, and run the following:

```
az login
```

This command can take a couple of minutes to complete the first time it is used, and involves a browser window opening in order to authenticate you with Azure.

Once this completes and you are authenticated, run the following command:

```
az aks get-credentials --resource-group [resource-group-name] --name [cluster-name] --file ./kubeconfig-azure.yml
```

Replace `[resource-group-name]` with the resource group containing your cluster. Replace `[cluster-name]` with your cluster.

## Importing your kubeconfig

Once you have your kubeconfig file created, from the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

&#x20;Select the **Kubernetes** option and click **Start Wizard**. Then select the **Import** option.

{% hint style="info" %}
The import option is only available in [Portainer Business Edition](https://www.portainer.io/business-upsell?from=k8s-create-from-kubeconfig).
{% endhint %}

Enter a **name** for cluster then click **Select a file** to browse for your kubeconfig file.&#x20;

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-k8s-import-setup.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section to customize the deployment further.

| Field/Option    | Overview                                                                                                                                                                                                                                                                                   |
| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Custom Template | Select a custom template to deploy on your cluster. This is handy for pre-loading a new environment with your applications. The template will be deployed in the default namespace unless the template specifies a namespace to use. You can also set any variables the template requires. |
| Group           | Select a [group](../../groups.md) to add the new environment to once provisioning completes.                                                                                                                                                                                               |
| Tags            | Select any [tags](../../tags.md) to add to the environment.                                                                                                                                                                                                                                |

<figure><img src="../../../../.gitbook/assets/2.19-environments-create-microk8s-moresettings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click the **Connect** button. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments where you will see the progress of your provision.



================================================
FILE: admin/environments/add/podman/README.md
================================================
# Add a Podman environment

When connecting a Podman host to Portainer, there are a few different methods you can use depending on your particular requirements. You can install the Portainer Agent on the Podman host and connect via the agent, you can connect directly to the Podman socket, or you can deploy the Portainer Edge Agent in standard or async mode.

Regardless of the method you choose, there are some generic requirements you will need to meet. You will require:

* CentOS 9 with the latest version of Podman 5.x installed and working on your Podman host. Other Podman versions and Linux distros may work but we currently only support the above. We recommend following the [official installation instructions](https://podman.io/docs/installation#installing-on-linux) for Podman.
* sudo or root access on your Podman host.

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../../start/requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* Podman is running as root. Portainer with rootless Podman may work but is currently not officially supported.

<table data-card-size="large" data-view="cards"><thead><tr><th></th><th></th><th></th><th data-hidden data-card-target data-type="content-ref"></th><th data-hidden data-card-cover data-type="files"></th></tr></thead><tbody><tr><td><strong>Agent</strong></td><td></td><td></td><td><a href="agent.md">agent.md</a></td><td><a href="../../../../.gitbook/assets/card-agent-large.png">card-agent-large.png</a></td></tr><tr><td><strong>Socket</strong></td><td></td><td></td><td><a href="socket.md">socket.md</a></td><td><a href="../../../../.gitbook/assets/card-socket-large.png">card-socket-large.png</a></td></tr><tr><td><strong>Edge Agent Standard</strong></td><td></td><td></td><td><a href="edge.md">edge.md</a></td><td><a href="../../../../.gitbook/assets/card-edgestd-large.png">card-edgestd-large.png</a></td></tr><tr><td><strong>Edge Agent Async</strong></td><td></td><td></td><td><a href="edge-async.md">edge-async.md</a></td><td><a href="../../../../.gitbook/assets/card-edgeasync-large.png">card-edgeasync-large.png</a></td></tr></tbody></table>



================================================
FILE: admin/environments/add/podman/agent.md
================================================
# Install Portainer Agent on Podman

Portainer uses the _Portainer Agent_ container to communicate with the _Portainer Server_ instance and provide access to the node's resources. This document will outline how to install the Portainer Agent on your node and how to connect to it from your Portainer Server instance. If you do not have a working Portainer Server instance yet, please refer to the [Portainer Server installation guide](../../../../start/install/server/docker/linux.md) first.

In addition to the generic requirements for Podman environments, you will need:

* Port `9001` accessible on this machine from the Portainer Server instance. If this is not available, we recommend using the [Edge Agent](../docker/edge.md) instead.

The Portainer Agent installation instructions also make the following additional assumptions about your environment:

* You are accessing Podman via Unix sockets. The Portainer Agent does not support connecting to the Podman engine via TCP.
*   You have not set a custom `AGENT_SECRET` on your Portainer Server instance. If you have (by specifying an `AGENT_SECRET` environment variable when starting the Portainer Server container), you will need to provide that same secret to your agent in the same way (as an environment variable) when deploying, for example by adding the following to your `podman run` command:

    `-e AGENT_SECRET=yoursecret`

From the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Next, select **Podman** as the environment type then click **Start Wizard**. Select the **Agent** option, then your environment type. Copy the commands and run them on your Podman instance.

{% hint style="info" %}
If you want to use the [host management features](../../../../user/docker/host/setup.md#enable-host-management-features) of the Portainer Agent, you should add the necessary volume mount to the command that Portainer provides:

```
-v /:/host
```
{% endhint %}

{% hint style="info" %}
If Podman on the environment you're deploying the Agent to has the Podman volume path at a non-standard location (instead of `/var/lib/containers/storage/volumes`) you will need to adjust the volume mount in the deployment command to suit.&#x20;

For example, if your volume path was `/srv/data/podman`, you would change the line in the command to:

```
- v /srv/data/podman:/var/lib/docker/volumes \
```

The right side of the mount should remain as `/var/lib/docker/volumes`, as that is what the Agent expects (even when using Podman).
{% endhint %}

Once the Agent has been deployed, enter the environment details using the table below as a guide:

| Field/Option        | Overview                                                                                                                                                                                                                                                                      |
| ------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                | Give the environment a descriptive name.                                                                                                                                                                                                                                      |
| Environment address | Enter the DNS name or IP address to connect to the Portainer Agent along with the port (the default port is `9001`). Do not provide a protocol - communication with the Agent by the Server is performed over HTTPS with certificates generated by the Agent on installation. |

<figure><img src="../../../../.gitbook/assets/2.22.0-environments-add-podman-agent.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section to categorize the environment by adding it to a [group](../../groups.md) or [tagging](../../tags.md) it for better searchability.

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-moresettings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Connect**. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments.



================================================
FILE: admin/environments/add/podman/edge-async.md
================================================
# Install Edge Agent Async on Podman

When a remote environment is not directly accessible from the Portainer Server instance, we recommend deploying the Portainer _Edge Agent_ to the remote environment. This allows you to manage the remote environment from your Portainer Server instance without having to open any ports on the environment. Rather than the traditional approach of the server connecting to Agents, the Edge Agent instead polls the Portainer Server periodically to see if there are any pending jobs to perform, and acts appropriately.

{% hint style="info" %}
For a technical summary of how the Edge Agent works, refer to our [advanced documentation](../../../../advanced/edge-agent.md).
{% endhint %}

## Async mode vs Standard mode

The Portainer Edge Agent can be deployed in two different modes - standard mode and async mode. In standard mode, we provide the ability to connect to the remote Edge Agent through a tunnel that is established on-demand from the Edge Agent to the Portainer Server, letting you interact directly with the environment in real time.&#x20;

In async mode, this tunnel connectivity is not available. Instead, we provide the ability to browse snapshots of the remote environment, allowing you to see the state of the Edge Agent's environment based on a recent state capture sent through to the Portainer Server, as well as use this snapshot to perform actions on the remote environment.&#x20;

Async mode has been developed to use very small amounts of data and as such is suitable for environments that have limited or intermittent connectivity as well as connections with limited data caps, for example mobile networks.&#x20;

{% hint style="info" %}
Edge Agent Async mode is only available in Portainer Business Edition.
{% endhint %}

## Preparation

In async mode, the Edge Agent requires only the UI port (usually `9443` or `30779` on Kubernetes with NodePort) to be open on the Portainer server instance. The tunnel port is not required for async mode. Our installation instructions configure Portainer Server to listen on both ports by default, and you will need to ensure your firewalling provides external access to the UI port in order to proceed.

{% hint style="warning" %}
If your Portainer Server instance is deployed with TLS, the agent will use HTTPS for the connection it makes back to Portainer. However if your Portainer instance uses a self-signed certificate, the Edge Agent must be deployed with the `-e EDGE_INSECURE_POLL=1` flag. If you do not deploy the Edge Agent with this flag, then the agent will not be able to communicate with the Portainer Server instance.
{% endhint %}

In addition, our instructions assume your environment meets [our requirements](../../../../start/requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.

## Deploying

To add an async Edge Agent to a Podman environment, from the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Select **Podman** then click **Start Wizard**. Then select the **Edge Agent Async** option. Enter the environment details using the table below as a guide.

| Field                    | Overview                                                                                                                                                                         |
| ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                     | Enter a name for your environment.                                                                                                                                               |
| Portainer API server URL | Enter the URL and port of your Portainer Server instance as it will be seen from your Edge environment. If using a FQDN, ensure that DNS is properly configured to provide this. |

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-async-name (1).png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section and adjust the **Ping**, **Snapshot** and **Command** intervals for the environment - this defines how often this Edge Agent will check in with the Portainer Server for status updates, snapshot updates and to see if there are new pending commands to run, respectively. The default for each is once a minute, but the defaults can be adjusted in the [Edge Compute settings](../../../settings/edge.md#async-check-in-intervals).&#x20;

You can also categorize the environment by adding it to a [group](../../groups.md) or [tagging](../../tags.md) it for better searchability.

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-async-settings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Create**. If you are pre-staging your Edge Agent deployment, you can now retrieve the join token for use in your deployment.&#x20;

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-jointoken.png" alt=""><figcaption></figcaption></figure>

Otherwise, complete the new fields that have appeared using the table below as a guide.

| Field/Option            | Overview                                                                                                                                        |
| ----------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------- |
| Environment variables   | Enter a comma separated list of environment variables that will be sourced from the host where the agent is deployed and provided to the agent. |
| Allow self-signed certs | Toggle this on to allow self-signed certificates when the agent is connecting to Portainer via HTTPS.                                           |

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-envvars.png" alt=""><figcaption></figcaption></figure>

Copy the generated command and run the command on your Edge environment to complete the installation.

{% hint style="warning" %}
If you have set a custom `AGENT_SECRET` on your Portainer Server instance (by specifying an AGENT\_SECRET environment variable when starting the Portainer Server container) you **must** remember to explicitly provide the same secret to your Edge Agent in the same way (as an environment variable) when deploying your Edge Agent, for example by adding the following to your `docker run` command: \
`-e AGENT_SECRET=yoursecret`
{% endhint %}

{% hint style="info" %}
If Podman on the environment you're deploying the Edge Agent to has the Podman volume path at a non-standard location (instead of `/var/lib/containers/storage/volumes`) you will need to adjust the volume mount in the deployment command to suit.&#x20;

For example, if your volume path was `/srv/data/podman`, you would change the line in the command to:

```
- v /srv/data/podman:/var/lib/docker/volumes \
```

The right side of the mount should remain as `/var/lib/docker/volumes`, as that is what the Edge Agent expects (even when using Podman).
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.22.0-environments-add-podman-edge-async-command.png" alt=""><figcaption></figcaption></figure>

If you have another Edge async environment of the same type to deploy you can click **Add another environment** to do so. Otherwise if you have any other environments to configure click **Next** to proceed, or click **Close** to return to the list of environments.



================================================
FILE: admin/environments/add/podman/edge.md
================================================
# Install Edge Agent Standard on Podman

When a remote environment is not directly accessible from the Portainer Server instance, we recommend deploying the Portainer _Edge Agent_ to the remote environment. This allows you to manage the remote environment from your Portainer Server instance without having to open any ports on the environment. Rather than the traditional approach of the server connecting to Agents, the Edge Agent instead polls the Portainer Server periodically to see if there are any pending jobs to perform, and acts appropriately.

{% hint style="info" %}
For a technical summary of how the Edge Agent works, refer to our [advanced documentation](../../../../advanced/edge-agent.md).
{% endhint %}

## Preparation

The Edge Agent requires two ports be open on the Portainer Server instance: the UI port (usually `9443` or `30779` on Kubernetes with NodePort) and the tunnel port ( `8000` or `30776` when using Kubernetes with NodePort). The tunnel port is used to provide a secure TLS tunnel between the Portainer Edge Agent and the Portainer Server instance. Our installation instructions configure Portainer Server to listen on both ports by default, and you will need to ensure your firewalling provides external access to these ports in order to proceed.

{% hint style="warning" %}
If your Portainer Server instance is deployed with TLS, the agent will use HTTPS for the connection it makes back to Portainer. However if your Portainer instance uses a self-signed certificate, the Edge Agent must be deployed with the `-e EDGE_INSECURE_POLL=1` flag. If you do not deploy the Edge Agent with this flag, then the agent will not be able to communicate with the Portainer Server instance.
{% endhint %}

In addition, our instructions assume your environment meets [our requirements](../../../../start/requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.

## Deploying

To add a standard Edge Agent to a Podman environment, from the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Select **Podman** then click **Start Wizard**. Then select the **Edge Agent Standard** option. Enter the environment details using the table below as a guide.

| Field                           | Overview                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| ------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                            | Enter a name for your environment.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| Portainer API server URL        | Enter the URL and port of your Portainer Server instance as it will be seen from your Edge environment. If using a FQDN, ensure that DNS is properly configured to provide this.                                                                                                                                                                                                                                                                                                                                                              |
| Portainer tunnel server address | <p>Enter the address and port of your Portainer Server instance's tunnel server as it will be seen from your Edge environment. If using a FQDN, ensure that DNS is properly configured to provide this.<br>In most cases, this will be the same address as the Portainer API server URL, but without the protocol and on port <code>8000</code>.<br>This field is only available in Portainer Business Edition. For Community Edition users, refer to <a href="https://github.com/portainer/portainer/issues/6251">this GitHub issue</a>.</p> |

<figure><img src="../../../../.gitbook/assets/2.17-install-agent-edge-nameurl.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section and adjust the Poll frequency for the environment - this defines how often this Edge Agent will check the Portainer Server for new jobs. The default is every 5 seconds. You can also categorize the environment by adding it to a [group](../../groups.md) or [tagging](../../tags.md) it for better searchability.

<figure><img src="../../../../.gitbook/assets/2.15-edge_agent_more_settings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Create**. If you are pre-staging your Edge Agent deployment, you can now retrieve the join token for use in your deployment.&#x20;

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-jointoken.png" alt=""><figcaption></figcaption></figure>

Otherwise, complete the new fields that have appeared using the table below as a guide.

| Field/Option            | Overview                                                                                                                                        |
| ----------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------- |
| Environment variables   | Enter a comma separated list of environment variables that will be sourced from the host where the agent is deployed and provided to the agent. |
| Allow self-signed certs | Toggle this on to allow self-signed certificates when the agent is connecting to Portainer via HTTPS.                                           |

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-envvars.png" alt=""><figcaption></figcaption></figure>

Copy the generated command and run the command on your Edge environment to complete the installation.

{% hint style="warning" %}
If you have set a custom `AGENT_SECRET` on your Portainer Server instance (by specifying an AGENT\_SECRET environment variable when starting the Portainer Server container) you **must** remember to explicitly provide the same secret to your Edge Agent in the same way (as an environment variable) when deploying your Edge Agent, for example by adding the following to your `podman run` command: \
`-e AGENT_SECRET=yoursecret`
{% endhint %}

{% hint style="info" %}
If Podman on the environment you're deploying the Edge Agent to has the Podman volume path at a non-standard location (instead of `/var/lib/containers/storage/volumes`) you will need to adjust the volume mount in the deployment command to suit.&#x20;

For example, if your volume path was `/srv/data/podman`, you would change the line in the command to:

```
- v /srv/data/podman:/var/lib/docker/volumes \
```

The right side of the mount should remain as `/var/lib/docker/volumes`, as that is what the Edge Agent expects (even when using Podman).
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.22.0-environments-add-podman-edge-std-command.png" alt=""><figcaption></figcaption></figure>

If you have another Edge standard environment of the same type to deploy you can click **Add another environment** to do so. Otherwise if you have any other environments to configure click **Next** to proceed, or click **Close** to return to the list of environments.



================================================
FILE: admin/environments/add/podman/socket.md
================================================
# Connect to the Podman Socket

Connecting to the Podman socket directly can only be done from the local environment. Before you begin, ensure the user running the Portainer Server container has permissions to access the Podman socket.

From the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Next, select **Podman** as the environment type then click **Start Wizard**. Select the **Socket** option and your platform. You will be shown the command required to ensure you have started the Podman socket.

<figure><img src="../../../../.gitbook/assets/2.22.0-environments-add-podman-socket.png" alt=""><figcaption></figcaption></figure>

Fill out the fields based on the table below.

<table><thead><tr><th width="280">Field/Option</th><th>Overview</th></tr></thead><tbody><tr><td>Name</td><td>Give the environment a descriptive name.</td></tr><tr><td>Override default socket path</td><td>Toggle this option on to override the default socket path.</td></tr><tr><td>Socket Path</td><td>If <strong>Override default socket path</strong> is enabled, enter the path to the Podman socket.</td></tr></tbody></table>

<figure><img src="../../../../.gitbook/assets/2.22.0-environments-add-podman-socket-2.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section to categorize the environment by adding it to a [group](../../groups.md) or [tagging](../../tags.md) it for better searchability.

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-moresettings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Connect**. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments.



================================================
FILE: admin/environments/add/swarm/README.md
================================================
# Add a Docker Swarm environment

When connecting a Docker Swarm environment to Portainer, there are a few different methods you can use depending on your particular requirements. You can install the Portainer Agent on the Docker Swarm cluster and connect via the agent, you can connect directly to the Docker API or the Docker socket, or you can deploy the Portainer Edge Agent in standard or async mode.

Regardless of the method you choose, there are some generic requirements you will need to meet. You will require:

* The latest version of Docker installed and working on your Docker Swarm nodes.
* Swarm mode enabled and working, including the overlay network for the swarm service communication.
* `sudo`, `root` or Administrator access on the manager node of your swarm cluster.

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../../start/requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* Docker is running as root (for Linux) or an Administrator (for Windows). Portainer with rootless Docker has some limitations, and requires additional configuration.
* If your nodes are using DNS records to communicate, that all records are resolvable across the cluster.

<table data-view="cards"><thead><tr><th></th><th></th><th></th><th data-hidden data-card-cover data-type="files"></th><th data-hidden data-card-target data-type="content-ref"></th></tr></thead><tbody><tr><td><strong>Agent</strong></td><td></td><td></td><td><a href="../../../../.gitbook/assets/card-agent-large.png">card-agent-large.png</a></td><td><a href="agent.md">agent.md</a></td></tr><tr><td><strong>API</strong></td><td></td><td></td><td><a href="../../../../.gitbook/assets/card-api-large.png">card-api-large.png</a></td><td><a href="api.md">api.md</a></td></tr><tr><td><strong>Socket</strong></td><td></td><td></td><td><a href="../../../../.gitbook/assets/card-socket-large.png">card-socket-large.png</a></td><td><a href="socket.md">socket.md</a></td></tr><tr><td><strong>Edge Agent Standard</strong></td><td></td><td></td><td><a href="../../../../.gitbook/assets/card-edgestd-large.png">card-edgestd-large.png</a></td><td><a href="edge.md">edge.md</a></td></tr><tr><td><strong>Edge Agent Async</strong></td><td></td><td></td><td><a href="../../../../.gitbook/assets/card-edgeasync-large.png">card-edgeasync-large.png</a></td><td><a href="edge-async.md">edge-async.md</a></td></tr></tbody></table>



================================================
FILE: admin/environments/add/swarm/agent.md
================================================
# Install Portainer Agent on Docker Swarm

Portainer uses the _Portainer Agent_ container to communicate with the _Portainer Server_ instance and provide access to the node's resources. This document will outline how to install the Portainer Agent on your environment and how to connect to it from your Portainer Server instance. If you do not have a working Portainer Server instance yet, please refer to the [Portainer Server installation guide](../../../../start/install/server/swarm/linux.md) first.

In addition to the generic requirements for Docker Swarm environments, you will need:

* The manager and worker nodes must be able to communicate with each other over port `9001`. In addition, the Portainer Server installation must be able to reach the nodes on port `9001`. If this is not possible, we advise looking at the [Edge Agent](edge.md) instead.
* If you are running Windows on your node, either:
  * Windows Subsystem for Linux (WSL) installed and a Linux distribution selected. For a new installation we recommend WSL2.
  * Windows Container Services (WCS) configured and running.

The Portainer Agent installation instructions also make the following additional assumptions about your environment:

* SELinux is disabled on the machines running Docker.
* You are accessing Docker via Unix sockets (or a named pipe when using WCS).
*   You have not set a custom `AGENT_SECRET` on your Portainer Server instance. If you have (by specifying an `AGENT_SECRET` environment variable when starting the Portainer Server container), you will need to provide that same secret to your agent in the same way (as an environment variable) when deploying by adding it to the stack file:

    `environment:`

    &#x20; `- AGENT_SECRET: yoursecret`

From the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

{% hint style="warning" %}
Only do this **once** for your environment, regardless of how many nodes are in the cluster. You do **not** need to add each node as an individual environment in Portainer. Adding just one node (we recommend the manager node) will allow Portainer to manage the entire cluster.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Next, select **Docker Swarm** as the environment type then click **Start Wizard**. Select the **Agent** option and your platform. Copy the command, then run it on the manager node of your Docker Swarm cluster. For example, if you are deploying on a Linux machine or a Windows machine with WSL installed, use the **Linux & Windows WSL** command. If you are deploying on a Windows machine with WCS, use the **Windows WCS** command.

{% hint style="info" %}
You must run the command on the Docker Swarm cluster before entering the environment details.
{% endhint %}

{% hint style="info" %}
If you want to use the [host management features](../../../../user/docker/swarm/setup.md#host-and-filesystem) of the Portainer Agent, you should add the necessary volume mount to the command that Portainer provides:

```
--mount type=bind,src=//,dst=/host
```
{% endhint %}

{% hint style="info" %}
If Docker on the environment you're deploying the Agent to has the Docker volume path at a non-standard location (instead of `/var/lib/docker/volumes`) you will need to adjust the volume mount in the deployment command to suit.&#x20;

For example, if your volume path was `/srv/data/docker`, you would change the line in the command to:

```
--mount type=bind,src=//srv/data/docker,dst=/var/lib/docker/volumes \
```

The `dst` value of the mount should remain as `/var/lib/docker/volumes`, as that is what the Agent expects.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.16-environments-add-swarm-agent.png" alt=""><figcaption></figcaption></figure>

The deployment command will return something similar to this:

```
Creating network portainer-agent_portainer_agent
Creating service portainer-agent_agent
```

To validate the agent is running,  run the following command:

```
 docker service ls
```

The result of which should look something like this:

```
ID                  NAME                    MODE                REPLICAS            IMAGE                    PORTS
tshb6ee2710s        portainer-agent_agent   global              1/1                 portainer/agent:latest
```

Once the agent is running on the Docker Swarm cluster, enter the environment details, using the table below as a guide.

{% hint style="warning" %}
Only do this **once** for your environment, regardless of how many nodes are in the cluster. You do **not** need to add each node as an individual environment in Portainer. Adding just one node (we recommend the manager node) will allow Portainer to manage the entire cluster.
{% endhint %}

<table><thead><tr><th width="238">Field</th><th>Overview</th></tr></thead><tbody><tr><td>Name</td><td>Give the environment a descriptive name.</td></tr><tr><td>Environment address</td><td>Enter the IP or DNS name at which the Portainer Server instance can reach the environment along with the port (<code>9001</code>). Do not provide a protocol - communication with the Agent by the Server is performed over HTTPS with certificates generated by the Agent on installation.</td></tr></tbody></table>

<figure><img src="../../../../.gitbook/assets/2.15-environments-add-swarm-agent-config.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section and categorize the environment by adding it to a [group](../../groups.md) or [tagging](../../tags.md) it for better searchability.

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-moresettings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Connect**. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments.



================================================
FILE: admin/environments/add/swarm/api.md
================================================
# Connect to the Docker API

Before you begin, you will need to ensure that your Docker instance is configured to admit remote connections. To learn how to do this, refer to Docker's own documentation. Once Docker is configured, you will be able to connect either with or without TLS.

From the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Next, select **Docker Swarm** as the environment type then click **Start Wizard**. Select the **API** option and your platform, then enter the environment details using the table below as a guide:

<table><thead><tr><th width="280">Field/Option</th><th>Overview</th></tr></thead><tbody><tr><td>Name</td><td>Give the environment a descriptive name.</td></tr><tr><td>Docker API URL</td><td>Enter the DNS name or IP address to connect to the Docker host along with the port. When connecting without TLS, the default port is <code>2375</code>. When connecting with TLS, the default port is <code>2376</code>.</td></tr><tr><td>TLS</td><td>Toggle this option on if you wish to use TLS. Toggle it off if you don't want to use TLS.</td></tr><tr><td>Skip Certification Verification</td><td>Toggle this option on to skip the verification of the TLS certificate used by the Docker API. If this option is off, the below fields will not appear.</td></tr><tr><td>TLS CA certificate</td><td>Select your CA certificate.</td></tr><tr><td>TLS certificate</td><td>Select your certificate.</td></tr><tr><td>TLS key</td><td>Select the key that matches the certificate.</td></tr></tbody></table>

{% hint style="info" %}
Portainer expects TLS certificates and keys to be in PEM format.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-swarm-api-details.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section to categorize the environment by adding it to a [group](../../groups.md) or [tagging](../../tags.md) it for better searchability.

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-moresettings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Connect**. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments.



================================================
FILE: admin/environments/add/swarm/edge-async.md
================================================
# Install Edge Agent Async on Docker Swarm

When a remote environment is not directly accessible from the Portainer Server instance, we recommend deploying the Portainer _Edge Agent_ to the remote environment. This allows you to manage the remote environment from your Portainer Server instance without having to open any ports on the environment. Rather than the traditional approach of the server connecting to Agents, the Edge Agent instead polls the Portainer Server periodically to see if there are any pending jobs to perform, and acts appropriately.

{% hint style="info" %}
For a technical summary of how the Edge Agent works, refer to our [advanced documentation](../../../../advanced/edge-agent.md).
{% endhint %}

## Async mode vs Standard mode

The Portainer Edge Agent can be deployed in two different modes - standard mode and async mode. In standard mode, we provide the ability to connect to the remote Edge Agent through a tunnel that is established on-demand from the Edge Agent to the Portainer Server, letting you interact directly with the environment in real time.&#x20;

In async mode, this tunnel connectivity is not available. Instead, we provide the ability to browse snapshots of the remote environment, allowing you to see the state of the Edge Agent's environment based on a recent state capture sent through to the Portainer Server, as well as use this snapshot to perform actions on the remote environment.&#x20;

Async mode has been developed to use very small amounts of data and as such is suitable for environments that have limited or intermittent connectivity as well as connections with limited data caps, for example mobile networks.&#x20;

{% hint style="info" %}
Edge Agent Async mode is only available in Portainer Business Edition.
{% endhint %}

## Preparation

In async mode, the Edge Agent requires only the UI port (usually `9443` or `30779` on Kubernetes with NodePort) to be open on the Portainer server instance. The tunnel port is not required for async mode. Our installation instructions configure Portainer Server to listen on both ports by default, and you will need to ensure your firewalling provides external access to the UI port in order to proceed.

{% hint style="warning" %}
If your Portainer Server instance is deployed with TLS, the agent will use HTTPS for the connection it makes back to Portainer. However if your Portainer instance uses a self-signed certificate, the Edge Agent must be deployed with the `-e EDGE_INSECURE_POLL=1` flag. If you do not deploy the Edge Agent with this flag, then the agent will not be able to communicate with the Portainer Server instance.
{% endhint %}

In addition, our instructions assume your environment meets [our requirements](../../../../start/requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.

## Deploying

To add an async Edge Agent to a Docker Swarm environment, from the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Select **Docker Swarm** then click **Start Wizard**. Then select the **Edge Agent Async** option. Enter the environment details using the table below as a guide.

| Field                    | Overview                                                                                                                                                                         |
| ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                     | Enter a name for your environment.                                                                                                                                               |
| Portainer API server URL | Enter the URL and port of your Portainer Server instance as it will be seen from your Edge environment. If using a FQDN, ensure that DNS is properly configured to provide this. |

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-async-name.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section and adjust the **Ping**, **Snapshot** and **Command** intervals for the environment - this defines how often this Edge Agent will check in with the Portainer Server for status updates, snapshot updates and to see if there are new pending commands to run, respectively. The default for each is once a minute, but the defaults can be adjusted in the [Edge Compute settings](../../../settings/edge.md#async-check-in-intervals).&#x20;

You can also categorize the environment by adding it to a [group](../../groups.md) or [tagging](../../tags.md) it for better searchability.

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-async-settings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Create**. If you are pre-staging your Edge Agent deployment, you can now retrieve the join token for use in your deployment.&#x20;

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-jointoken.png" alt=""><figcaption></figcaption></figure>

Otherwise, complete the new fields that have appeared using the table below as a guide.

| Field/Option            | Overview                                                                                                                                        |
| ----------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------- |
| Environment variables   | Enter a comma separated list of environment variables that will be sourced from the host where the agent is deployed and provided to the agent. |
| Allow self-signed certs | Toggle this on to allow self-signed certificates when the agent is connecting to Portainer via HTTPS.                                           |

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-envvars.png" alt=""><figcaption></figcaption></figure>

Choose your platform (**Linux** or **Windows**), copy the generated command and run the command on your Edge environment to complete the installation.

{% hint style="warning" %}
If you have set a custom `AGENT_SECRET` on your Portainer Server instance (by specifying an `AGENT_SECRET` environment variable when starting the Portainer Server container) you **must** remember to explicitly provide the same secret to your Edge Agent in the same way (as an environment variable) when deploying your Edge Agent by adding it to the stack file:

`environment:`\
&#x20; `- AGENT_SECRET: yoursecret`
{% endhint %}

{% hint style="info" %}
If Docker on the environment you're deploying the Edge Agent to has the Docker volume path at a non-standard location (instead of `/var/lib/docker/volumes`) you will need to adjust the volume mount in the deployment command to suit.&#x20;

For example, if your volume path was `/srv/data/docker`, you would change the line in the command to:

```
--mount type=bind,src=//srv/data/docker,dst=/var/lib/docker/volumes \
```

The `dst` value of the mount should remain as `/var/lib/docker/volumes`, as that is what the Edge Agent expects.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-swarm-edge-async-command.png" alt=""><figcaption></figcaption></figure>

If you have another Edge async environment of the same type to deploy you can click **Add another environment** to do so. Otherwise if you have any other environments to configure click **Next** to proceed, or click **Close** to return to the list of environments.



================================================
FILE: admin/environments/add/swarm/edge.md
================================================
# Install Edge Agent Standard on Docker Swarm

When a remote environment is not directly accessible from the Portainer Server instance, we recommend deploying the Portainer _Edge Agent_ to the remote environment. This allows you to manage the remote environment from your Portainer Server instance without having to open any ports on the environment. Rather than the traditional approach of the server connecting to Agents, the Edge Agent instead polls the Portainer Server periodically to see if there are any pending jobs to perform, and acts appropriately.

{% hint style="info" %}
For a technical summary of how the Edge Agent works, refer to our [advanced documentation](../../../../advanced/edge-agent.md).
{% endhint %}

## Preparation

The Edge Agent requires two ports be open on the Portainer Server instance: the UI port (usually `9443` or `30779` on Kubernetes with NodePort) and the tunnel port ( `8000` or `30776` when using Kubernetes with NodePort). The tunnel port is used to provide a secure TLS tunnel between the Portainer Edge Agent and the Portainer Server instance. Our installation instructions configure Portainer Server to listen on both ports by default, and you will need to ensure your firewalling provides external access to these ports in order to proceed.

{% hint style="warning" %}
If your Portainer Server instance is deployed with TLS, the agent will use HTTPS for the connection it makes back to Portainer. However if your Portainer instance uses a self-signed certificate, the Edge Agent must be deployed with the `-e EDGE_INSECURE_POLL=1` flag. If you do not deploy the Edge Agent with this flag, then the agent will not be able to communicate with the Portainer Server instance.
{% endhint %}

In addition, our instructions assume your environment meets [our requirements](../../../../start/requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.

## Deploying

To add a standard Edge Agent to a Docker Swarm environment, from the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Select **Docker Swarm** then click **Start Wizard**. Then select the **Edge Agent Standard** option. Enter the environment details using the table below as a guide.

| Field                           | Overview                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| ------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                            | Enter a name for your environment.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| Portainer API server URL        | Enter the URL and port of your Portainer Server instance as it will be seen from your Edge environment. If using a FQDN, ensure that DNS is properly configured to provide this.                                                                                                                                                                                                                                                                                                                                                              |
| Portainer tunnel server address | <p>Enter the address and port of your Portainer Server instance's tunnel server as it will be seen from your Edge environment. If using a FQDN, ensure that DNS is properly configured to provide this.<br>In most cases, this will be the same address as the Portainer API server URL, but without the protocol and on port <code>8000</code>.<br>This field is only available in Portainer Business Edition. For Community Edition users, refer to <a href="https://github.com/portainer/portainer/issues/6251">this GitHub issue</a>.</p> |

<figure><img src="../../../../.gitbook/assets/2.17-install-agent-edge-nameurl.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section and adjust the Poll frequency for the environment - this defines how often this Edge Agent will check the Portainer Server for new jobs. The default is every 5 seconds. You can also categorize the environment by adding it to a [group](../../groups.md) or [tagging](../../tags.md) it for better searchability.

<figure><img src="../../../../.gitbook/assets/2.15-edge_agent_more_settings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Create**. If you are pre-staging your Edge Agent deployment, you can now retrieve the join token for use in your deployment.&#x20;

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-jointoken.png" alt=""><figcaption></figcaption></figure>

Otherwise, complete the new fields that have appeared using the table below as a guide.

| Field/Option            | Overview                                                                                                                                        |
| ----------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------- |
| Environment variables   | Enter a comma separated list of environment variables that will be sourced from the host where the agent is deployed and provided to the agent. |
| Allow self-signed certs | Toggle this on to allow self-signed certificates when the agent is connecting to Portainer via HTTPS.                                           |

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-edge-envvars.png" alt=""><figcaption></figcaption></figure>

Choose your platform (**Linux** or **Windows**), copy the generated command and run the command on your Edge environment to complete the installation.

{% hint style="warning" %}
If you have set a custom `AGENT_SECRET` on your Portainer Server instance (by specifying an `AGENT_SECRET` environment variable when starting the Portainer Server container) you **must** remember to explicitly provide the same secret to your Edge Agent in the same way (as an environment variable) when deploying your Edge Agent by adding it to the stack file:

`environment:`\
&#x20; `- AGENT_SECRET: yoursecret`
{% endhint %}

{% hint style="info" %}
If Docker on the environment you're deploying the Edge Agent to has the Docker volume path at a non-standard location (instead of `/var/lib/docker/volumes`) you will need to adjust the volume mount in the deployment command to suit.&#x20;

For example, if your volume path was `/srv/data/docker`, you would change the line in the command to:

```
--mount type=bind,src=//srv/data/docker,dst=/var/lib/docker/volumes \
```

The `dst` value of the mount should remain as `/var/lib/docker/volumes`, as that is what the Edge Agent expects.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-swarm-edge-command.png" alt=""><figcaption></figcaption></figure>

If you have another Edge standard environment of the same type to deploy you can click **Add another environment** to do so. Otherwise if you have any other environments to configure click **Next** to proceed, or click **Close** to return to the list of environments.



================================================
FILE: admin/environments/add/swarm/socket.md
================================================
# Connect to the Docker Socket

{% hint style="info" %}
Connecting to the Docker socket on a Swarm environment is a legacy option and not recommended for new installs. We highly recommend using the [Portainer Agent](agent.md) instead.
{% endhint %}

Connecting to the Docker socket directly can only be done from the local environment. Before you begin, ensure the user running the Portainer Server container has permissions to access the Docker socket.

From the menu expand **Environment-related**, click **Environments**, then click **Add environment**.

<figure><img src="../../../../.gitbook/assets/2.22-environments-add.gif" alt=""><figcaption></figcaption></figure>

Next, select **Docker Swarm** as the environment type then click **Start Wizard**. Select the **Socket** option and your platform. You will be shown the required parameter to pass to the Portainer container as part of your Portainer Server deployment.

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-swarm-socket-command.png" alt=""><figcaption></figcaption></figure>

Fill out the fields based on the table below.

<table><thead><tr><th width="280">Field/Option</th><th>Overview</th></tr></thead><tbody><tr><td>Name</td><td>Give the environment a descriptive name.</td></tr><tr><td>Override default socket path</td><td>Toggle this option on to override the default <code>/var/run/docker.sock</code> socket path.</td></tr><tr><td>Socket Path</td><td>If <strong>Override default socket path</strong> is enabled, enter the path to the Docker socket.</td></tr></tbody></table>

{% hint style="info" %}
Ensure that if you change the Socket Path, that you update the required bind mount parameter above to suit.
{% endhint %}

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-socket-details.png" alt=""><figcaption></figcaption></figure>

As an optional step you can expand the **More settings** section to categorize the environment by adding it to a [group](../../groups.md) or [tagging](../../tags.md) it for better searchability.

<figure><img src="../../../../.gitbook/assets/2.18-environments-add-docker-moresettings.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Connect**. If you have other environments to configure click **Next** to proceed, otherwise click **Close** to return to the list of environments.



================================================
FILE: admin/logs/README.md
================================================
# Logs

Within the Portainer Business Edition UI you can view authentication and activity logs for your Portainer installation.

{% content-ref url="authentication.md" %}
[authentication.md](authentication.md)
{% endcontent-ref %}

{% content-ref url="activity.md" %}
[activity.md](activity.md)
{% endcontent-ref %}



================================================
FILE: admin/logs/activity.md
================================================
# Activity

Within the Portainer Business Edition UI you can view a log of all actions taken. The log is read-only and cannot be edited.

From the menu expand **Logs** then select **Activity**.

<figure><img src="../../.gitbook/assets/2.20-logs-activity.gif" alt=""><figcaption></figcaption></figure>

If you want to export logs, filter by date range then click **Export to CSV**.

<figure><img src="../../.gitbook/assets/2.15-settings-authlogs-activity-export.png" alt=""><figcaption></figcaption></figure>

Activity logs are searchable, and the date and time, user, endpoint, and action are provided for each.

<figure><img src="../../.gitbook/assets/2.15-settings-authlogs-activity-list.png" alt=""><figcaption></figcaption></figure>

You can also click **inspect** to inspect the activity's payload.

<figure><img src="../../.gitbook/assets/2.15-settings-authlogs-activity-inspect.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: admin/logs/authentication.md
================================================
# Authentication

Within the Portainer Business Edition UI you can view a log of all authentication actions. The log is read-only and cannot be edited.

{% hint style="info" %}
Portainer also provides the ability to view [detailed activity logs](activity.md).
{% endhint %}

From the menu expand **Logs** and select **Authentication**.

<figure><img src="../../.gitbook/assets/2.20-logs-authentication.gif" alt=""><figcaption></figcaption></figure>

If you want to export logs, filter by date range then click **Export to CSV**.

<figure><img src="../../.gitbook/assets/2.15-settings-authlogs-export.png" alt=""><figcaption></figcaption></figure>

Authentication events are searchable and filterable, and the date and time, origin IP address, context, user and result are provided for each.

<figure><img src="../../.gitbook/assets/2.15-settings-authlogs-list.png" alt=""><figcaption></figcaption></figure>




================================================
FILE: admin/registries/README.md
================================================
# Registries

A registry is a repository of container images that can be pulled and deployed on a containerized infrastructure. Portainer supports connecting registries to the Portainer Server instance, allowing you to use those registries when deploying containers.

<figure><img src="../../.gitbook/assets/2.15-admin-registries.png" alt=""><figcaption></figcaption></figure>

{% content-ref url="add/" %}
[add](add/)
{% endcontent-ref %}

{% content-ref url="add/custom.md" %}
[custom.md](add/custom.md)
{% endcontent-ref %}

With Portainer Business Edition you can also browse and manage your registries within Portainer itself.

{% content-ref url="browse.md" %}
[browse.md](browse.md)
{% endcontent-ref %}

{% content-ref url="manage.md" %}
[manage.md](manage.md)
{% endcontent-ref %}

## Hiding anonymous Docker Hub

By default the **Docker Hub (anonymous)** registry is available to all users. If you would prefer to hide this from the registry selection, you can click **Hide for all users**.

<figure><img src="../../.gitbook/assets/2.15-admin-registries-dockerhub-hide.png" alt=""><figcaption></figcaption></figure>

{% hint style="info" %}
As the anonymous Docker Hub access is built into Docker itself this does not fully disable access to this registry, but it does hide it from the dropdown list of registries in the Portainer UI. In addition, if no other registries are available to a user the Docker Hub (anonymous) option will be displayed regardless of this setting.
{% endhint %}



================================================
FILE: admin/registries/browse.md
================================================
# Browse a registry

The registry manager extends your container management experience by giving you the ability to browse defined registries and manipulate their content. By using this feature, container users enjoy the benefit of having a single interface to manage any Docker registry deployment, providing a consistent look and feel across any provider.

{% hint style="info" %}
Your registry must support Docker Registry API v2 in order to integrate with Portainer.
{% endhint %}

From the menu select **Registries** then select **Browse** next to the registry that you want to browse.

<figure><img src="../../.gitbook/assets/2.15-registries-browse.gif" alt=""><figcaption></figcaption></figure>

A list of the repositories within a registry, along with the number of tags for each repository appears. Select a repository to view its details.

<figure><img src="../../.gitbook/assets/2.15-registries-browse-repos.png" alt=""><figcaption></figcaption></figure>

The **Repository information** page provides the repository name, tag and image count, as well as a list of all tags. You can retag an image in order to promote it through the deployment lifecycle, or simply add or remove tags to annotate changes or usage.

This page also provides an option to clean up unused legacy images by safely deleting them. You can also remove the entire repository.

<figure><img src="../../.gitbook/assets/2.15-registries-browse-repo-detail.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: admin/registries/manage.md
================================================
# Manage a registry

The registry manager extends your container management experience by giving you the ability to browse defined registries and manipulate their content. By using this feature, container users enjoy the benefit of having a single interface to manage any Docker registry deployment, providing a consistent look and feel across any provider.

## Adding a tag

From the menu select **Registries**, select the registry you want to manage then click **browse**. From the list, select the repository you want to manage.

<figure><img src="../../.gitbook/assets/2.15-registries-manage.gif" alt=""><figcaption></figcaption></figure>

In the **Add tag** section at the top-right of the page, enter the name of your tag, select the image from the dropdown, then click the **Add tag** button.

<figure><img src="../../.gitbook/assets/2.15-registries-manage-addtag.png" alt=""><figcaption></figcaption></figure>

## Retagging

{% hint style="info" %}
If you host your own Docker registry, and you want the ability to retag images, you will need to add the following to your Docker registry's environment variables:

`REGISTRY_STORAGE_DELETE_ENABLED=TRUE`
{% endhint %}

From the menu select **Registries**, choose the registry you want to manage and click **browse**. From the list of repositories, select the repository you want to manage.

<figure><img src="../../.gitbook/assets/2.15-registries-manage.gif" alt=""><figcaption></figcaption></figure>

In the **Tags** section, locate the image you want to retag then click **Retag** to its right. Enter the new tag for the image then click the tick icon.

<figure><img src="../../.gitbook/assets/2.15-registries-manage-retag.png" alt=""><figcaption></figcaption></figure>

## Removing a tag

{% hint style="info" %}
If you host your own Docker registry, and want the ability to remove tags, you will need to add the following to your Docker registry's environment variables:

`REGISTRY_STORAGE_DELETE_ENABLED=TRUE`
{% endhint %}

From the menu select **Registries**, select the registry you want to manage then click **Browse**. From the list, select the repository you want to manage.

<figure><img src="../../.gitbook/assets/2.15-registries-manage.gif" alt=""><figcaption></figcaption></figure>

Tick the checkbox next to the tag you want to remove then click **Remove**.

<figure><img src="../../.gitbook/assets/2.15-registries-manage-removetag.gif" alt=""><figcaption></figcaption></figure>

When the confirmation message appears, if you're sure, click **Remove**.



================================================
FILE: admin/registries/add/README.md
================================================
# Add a new registry

From the menu select **Registries** then click **Add registry**.

<figure><img src="../../../.gitbook/assets/2.19-registries-add.gif" alt=""><figcaption></figcaption></figure>

From the **Registry provider** section select the type of registry you want to add. Portainer provides configuration support for a number of popular registry providers:

{% content-ref url="dockerhub.md" %}
[dockerhub.md](dockerhub.md)
{% endcontent-ref %}

{% content-ref url="ecr.md" %}
[ecr.md](ecr.md)
{% endcontent-ref %}

{% content-ref url="quay.md" %}
[quay.md](quay.md)
{% endcontent-ref %}

{% content-ref url="proget.md" %}
[proget.md](proget.md)
{% endcontent-ref %}

{% content-ref url="azure.md" %}
[azure.md](azure.md)
{% endcontent-ref %}

{% content-ref url="gitlab.md" %}
[gitlab.md](gitlab.md)
{% endcontent-ref %}

{% content-ref url="ghcr.md" %}
[ghcr.md](ghcr.md)
{% endcontent-ref %}

You can also add your own custom registry:

{% content-ref url="custom.md" %}
[custom.md](custom.md)
{% endcontent-ref %}



================================================
FILE: admin/registries/add/azure.md
================================================
# Add an Azure registry

From the menu select **Registries** then click **Add registry** and select **Azure** as the registry provider.

<figure><img src="../../../.gitbook/assets/2.15-settings-registries-add-azure.gif" alt=""><figcaption></figcaption></figure>

Complete the form, using the table below as a guide.

| Field/Option | Overview                                                         |
| ------------ | ---------------------------------------------------------------- |
| Name         | Enter the name you'd like to use in Portainer for your registry. |
| Registry URL | Enter the URL of your Azure registry.                            |
| Username     | Enter the username you use to log into your Azure registry.      |
| Password     | Enter the password that corresponds to the username above.       |

<figure><img src="../../../.gitbook/assets/2.15-settings-registries-add-azure-details.png" alt=""><figcaption></figcaption></figure>

When the form is complete, click **Add registry**.



================================================
FILE: admin/registries/add/custom.md
================================================
# Add a custom registry

From the menu select **Registries** then click **Add registry**. Ensure **Custom registry** is selected.

<figure><img src="../../../.gitbook/assets/2.15-settings-registries-add-custom.gif" alt=""><figcaption></figcaption></figure>

In the **Custom registry details** section, enter the registry name and URL (both mandatory). If authentication is required, toggle **Authentication** on and enter the username and password.&#x20;

<figure><img src="../../../.gitbook/assets/2.15-settings-registries-add-custom-details.png" alt=""><figcaption></figcaption></figure>

When you're finished, click **Add registry**.




================================================
FILE: admin/registries/add/dockerhub.md
================================================
# Add a DockerHub account

Portainer provides built-in support for anonymous Docker Hub access, but in some cases you may need to log into Docker Hub (for example, private images or to support pulling a large number of images).

From the menu select **Registries** then click **Add registry** and select **DockerHub** as the registry provider.

<figure><img src="../../../.gitbook/assets/2.15-settings-registries-add-dockerhub.gif" alt=""><figcaption></figcaption></figure>

Complete the form, using the table below as a guide.

| Field/Option           | Overview                                                                                                                                                                                                                                 |
| ---------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                   | Enter a name for the registry. This is how it will appear in the list of registries and when selecting a registry to pull from.                                                                                                          |
| DockerHub username     | Enter the username you use to connect to Docker Hub.                                                                                                                                                                                     |
| DockerHub access token | Enter a Docker Hub personal access token that corresponds to the username above. You can create an access token by logging into Docker Hub, clicking your username in the top right and going to Account Settings then the Security tab. |

<figure><img src="../../../.gitbook/assets/2.15-settings-registries-add-dockerhub-details.png" alt=""><figcaption></figcaption></figure>

When the form is complete, click **Add registry**.




================================================
FILE: admin/registries/add/ecr.md
================================================
# Add an AWS ECR registry

From the menu select **Registries** then click **Add registry** and select **AWS ECR** as the registry provider.

<figure><img src="../../../.gitbook/assets/2.19-registries-add-ecr.gif" alt=""><figcaption></figcaption></figure>

## Preparation

If your registry requires authentication to access, you must create an IAM user with access to the registry for Portainer to use. Instructions on creating an IAM user are available [from AWS](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html#id_users_create_console). When you have created the user, make note of the **Access key ID** and **Secret access key**, as you will need these below.

{% hint style="info" %}
At present we do not support IAM users with MFA enabled. We recommend creating a user specifically for Portainer to use with MFA disabled.
{% endhint %}

When creating the user you will need to attach one or more policies to provide registry access. For full registry management functionality within Portainer, we recommend the `AmazonEC2ContainerRegistryFullAccess` policy.

## Add your registry

Complete the form, using the table below as a guide.

| Field/Option          | Overview                                                                                                                                                            |
| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                  | Enter the name you'd like to use in Portainer for your registry.                                                                                                    |
| Registry URL          | Enter the URL of your AWS ECR registry, including the account ID and region. You can find this in the AWS console under Amazon Container Services, ECR, Registries. |
| Authentication        | Enable this option if your registry requires authentication to access.                                                                                              |
| AWS Access Key        | Enter the Access key ID for the IAM user that will access the AWS ECR registry.                                                                                     |
| AWS Secret Access Key | Enter the Secret access key for the above IAM user.                                                                                                                 |
| Region                | Enter the region your registry is in, for example `us-west-1`.                                                                                                      |

<figure><img src="../../../.gitbook/assets/2.19-registries-add-ecr.png" alt=""><figcaption></figcaption></figure>

When the form is complete, click **Add registry**.



================================================
FILE: admin/registries/add/ghcr.md
================================================
# Add a GitHub registry

{% hint style="info" %}
The GitHub registry option is only available in Portainer Business Edition.
{% endhint %}

From the menu select **Registries** then click **Add registry** and select **GitHub** as the registry provider.

<figure><img src="../../../.gitbook/assets/2.17-registries-add-github.gif" alt=""><figcaption></figcaption></figure>

Complete the form, using the table below as a guide.

| Field/Option              | Overview                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                      | Enter the name you'd like to use in Portainer for your registry.                                                                                                                                                                                                                                                                                                                                                                                                                                              |
| Username                  | Enter the username you use to log into your GitHub registry.                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| Personal Access Token     | <p>Enter the personal access token (classic) that corresponds to the username above. Your personal access token (classic) will need the <code>delete:packages</code>, <code>repo</code>, and <code>write:packages</code> scopes assigned.<br>GitHub <a href="https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry#authenticating-to-the-container-registry">does not currently support</a> the use of fine-grained tokens for registry access.</p> |
| Use organisation registry | Toggle this on if your registry is part of a Github organization.                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| Organisation name         | Enter the name of your GitHub organization.                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |

<figure><img src="../../../.gitbook/assets/2.17-registries-add-ghcr-details.png" alt=""><figcaption></figcaption></figure>

{% hint style="info" %}
For more information about creating a personal access token, see [GitHub's own documentation](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token).
{% endhint %}

When the form is complete, click **Add registry**.



================================================
FILE: admin/registries/add/gitlab.md
================================================
# Add a Gitlab registry

From the menu select **Registries** then click **Add registry** and select **Gitlab** as the registry provider.

<figure><img src="../../../.gitbook/assets/2.15-settings-registries-add-gitlab.gif" alt=""><figcaption></figcaption></figure>

Complete the form, using the table below as a guide.

| Field/Option                   | Overview                                                                                                                                                         |
| ------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Username                       | Enter the username you use to log into your Gitlab registry.                                                                                                     |
| Personal Access Token          | Enter the personal access token that corresponds to the username above. Your personal access token will need the `read_api` and `read_registry` scopes assigned. |
| Override default configuration | If you need to make changes to the Portainer defaults for Gitlab, you can do so here.                                                                            |

<figure><img src="../../../.gitbook/assets/2.15-settings-registries-add-gitlab-details.png" alt=""><figcaption></figcaption></figure>

{% hint style="info" %}
For more information about creating a personal access token, see [Gitlab's own documentation](https://docs.gitlab.com/ee/user/profile/personal_access_tokens.html).
{% endhint %}

When the form is complete, click **Add registry**.



================================================
FILE: admin/registries/add/proget.md
================================================
# Add a ProGet registry

From the menu select **Registries** then click **Add registry** and select **ProGet** as the registry provider.

<figure><img src="../../../.gitbook/assets/2.15-settings-registries-add-proget.gif" alt=""><figcaption></figcaption></figure>

Complete the form, using the table below as a guide.

| Field/Option | Overview                                                         |
| ------------ | ---------------------------------------------------------------- |
| Name         | Enter the name you'd like to use in Portainer for your registry. |
| Registry URL | Enter the URL of your ProGet registry, including the feed name.  |
| Base URL     | Enter the base URL of your ProGet registry.                      |
| Username     | Enter the username you use to log into your ProGet registry.     |
| Password     | Enter the password that corresponds to the username above.       |

<figure><img src="../../../.gitbook/assets/2.15-settings-registries-add-proget-details.png" alt=""><figcaption></figcaption></figure>

When the form is complete, click **Add registry**.



================================================
FILE: admin/registries/add/quay.md
================================================
# Add a Quay.io registry

From the menu select **Registries** then click **Add registry** and select **Quay.io** as the registry provider.

<figure><img src="../../../.gitbook/assets/2.15-settings-registries-add-quay.gif" alt=""><figcaption></figcaption></figure>

Complete the form, using the table below as a guide.

| Field/Option              | Overview                                                                                           |
| ------------------------- | -------------------------------------------------------------------------------------------------- |
| Username                  | Enter the username you use to connect to your Quay.io registry.                                    |
| Password                  | Enter the password that corresponds to the username above.                                         |
| Use organisation registry | Toggle on if you need to specify the organization to use when connecting to your Quay.io registry. |

<figure><img src="../../../.gitbook/assets/2.15-settings-registries-add-quay-details.png" alt=""><figcaption></figcaption></figure>

When the form is complete, click **Add registry**.



================================================
FILE: admin/settings/README.md
================================================
# Settings

This section provides access to Portainer settings that apply to Portainer in general. For environment-specific settings, check the [Host](../../user/docker/host/), [Swarm](../../user/docker/swarm/) or [Cluster](../../user/kubernetes/cluster/) sections in each environment depending on the environment type.

{% content-ref url="general.md" %}
[general.md](general.md)
{% endcontent-ref %}

{% content-ref url="authentication/" %}
[authentication](authentication/)
{% endcontent-ref %}

{% content-ref url="credentials/" %}
[credentials](credentials/)
{% endcontent-ref %}

{% content-ref url="edge.md" %}
[edge.md](edge.md)
{% endcontent-ref %}



================================================
FILE: admin/settings/edge.md
================================================
# Edge Compute

To enable and configure Edge Compute functionality in Portainer, select **Settings** from the menu then select **Edge Compute**.&#x20;

{% hint style="info" %}
To learn how to use our Edge Compute functionality, please refer to the [Edge Compute](../../user/edge/) section of this documentation.
{% endhint %}

<figure><img src="../../.gitbook/assets/2.15-settings-edgecompute.gif" alt=""><figcaption></figcaption></figure>

## Edge Compute settings

In this section you can use the following options to enable and configure Edge Compute functionality within Portainer.

| Field/Option                               | Overview                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| ------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Enable Edge Compute features               | Toggle this on to enable Edge Compute functionality including Edge Device features.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| Portainer API server URL                   | <p>Enter the default URL and port of your Portainer Server instance as it will be seen from your Edge environment. If using a FQDN, ensure that DNS is properly configured to provide this.<br>This value can be overridden when manually deploying an Edge Agent.<br>This feature is only available in Portainer Business Edition.</p>                                                                                                                                                                                                                                                                                        |
| Portainer tunnel server address            | <p>Enter the default address and port of your Portainer Server instance's tunnel server as it will be seen from your Edge environment. If using a FQDN, ensure that DNS is properly configured to provide this.<br>In most cases, this will be the same address as the Portainer API server URL, but without the protocol and on port <code>8000</code>.<br>This value can be overridden when manually deploying an Edge Agent.<br>This feature is only available in Portainer Business Edition. For Community Edition users, refer to <a href="https://github.com/portainer/portainer/issues/6251">this GitHub issue</a>.</p> |
| Use separate mTLS cert                     | <p>Enable this toggle to use a separate mTLS certificate for Edge Agent communication. With this option disabled, Edge Agents will use the same TLS certificate as the Portainer UI.<br>For more information on mTLS read our <a href="../../advanced/mtls.md">advanced documentation</a>.</p>                                                                                                                                                                                                                                                                                                                                 |
| TLS CA certificate                         | When **Use separate mTLS cert** is enabled, select and upload the CA certificate for use with mTLS.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| TLS certificate                            | When **Use separate mTLS cert** is enabled, select and upload the server certificate for use with mTLS.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| TLS key                                    | When **Use separate mTLS cert** is enabled, select and upload the key corresponding to the server certificate.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| Enforce use of Portainer generated Edge ID | Enable this option to require that the Edge ID used by an Edge Agent deployment exist within Portainer's database (in other words, have an environment with the matching ID already created) in order to connect.                                                                                                                                                                                                                                                                                                                                                                                                              |

<figure><img src="../../.gitbook/assets/2.20-settings-edge-edgecompute.png" alt=""><figcaption></figcaption></figure>

When you are done, click **Save Settings**.

{% hint style="warning" %}
If you add or change the mTLS CA certificate you will need to restart the Portainer Server in order for the change to apply. You should also ensure any Edge Agents that are using mTLS are also updated to use the new CA certificate.
{% endhint %}

## Deployment sync options

This section defines options that apply how Edge Agents sync with the Portainer Server instance.

### Check-in intervals

| Field/Option                      | Overview                                                                                   |
| --------------------------------- | ------------------------------------------------------------------------------------------ |
| Edge agent default poll frequency | Select how often Edge Agents in standard mode check in with the Portainer Server instance. |

<figure><img src="../../.gitbook/assets/2.18-settings-edge-checkin.png" alt=""><figcaption></figcaption></figure>

### Async Check-in intervals

The following options apply to Edge Agents deployed in async mode.

| Field/Option                          | Overview                                                                                                  |
| ------------------------------------- | --------------------------------------------------------------------------------------------------------- |
| Edge agent default ping frequency     | Select how often Edge Agents in async mode ping back to the Portainer Server instance.                    |
| Edge agent default snapshot frequency | Select how often Edge Agents in async mode update their snapshot with the Portainer Server instance.      |
| Edge agent default command frequency  | Select how often Edge Agents in async mode check with the Portainer Server instance for pending commands. |

<figure><img src="../../.gitbook/assets/2.17-settings-edge-asynccheckin.png" alt=""><figcaption></figcaption></figure>

## Edge Compute access

This section lets you configure access to your Edge Compute environments through the use of the **Edge Administrator** role. The Edge Administrator role gives a user comprehensive control over Edge resources within all Edge environments, but does not provide full administrative access to the rest of Portainer.

<figure><img src="../../.gitbook/assets/2.20-settings-edge-access.png" alt=""><figcaption></figcaption></figure>

To add a user as an Edge Administrator, select the username from the **Select user(s)** dropdown and click **Create access**.&#x20;

To remove a user from the Edge Administrator role, check the box next to their username in the Edge administrators list and click **Remove**.

## Automatic Edge Environment Creation

In this section you can configure how automatic Edge environment configuration functions.

| Field/Option                         | Overview                                                                                                                                                                                                                                                                           |
| ------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Enable Edge Environment Waiting Room | Toggle this on to enable the [waiting room](../../user/edge/waiting-room.md) feature for Edge devices. This will allow any Edge Device that connects to the Portainer instance to automatically associate with Portainer. We recommend leaving this on (the waiting room enabled). |

<figure><img src="../../.gitbook/assets/2.20-settings-edge-aeec.png" alt=""><figcaption></figcaption></figure>

## Intel OpenAMT

This section controls the configuration of the [Intel OpenAMT](../../user/home/openamt.md) functionality in Portainer.

| Field/Option                         | Overview                                                                                                                                                                                                                                          |
| ------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Enable OpenAMT                       | Toggle this option on to enable Portainer's OpenAMT functionality. This can only be enabled when **Enable Edge Compute features** is toggled on, and when on will reveal the below fields.                                                        |
| MPS Server                           | Enter the FQDN or IP address of your MPS server.                                                                                                                                                                                                  |
| MPS User                             | Enter the username used to connect to your MPS server.                                                                                                                                                                                            |
| MPS Password                         | Enter the password for the MPS User defined above. The password must be between 8 and 32 characters and include at least one upper case letter, at least one lower case letter, at least one base-10 digit and at least one special character.    |
| Domain Name                          | Enter the fully-qualified domain name associated with the provisioning certificate.                                                                                                                                                               |
| Provisioning Certificate File (.pfx) | <p>Click <strong>Upload file</strong> to upload your PFX-format certificate. The PFX must contain the private key. On AMT 15 based devices you must use SHA2.</p><p></p><p>Currently supported CAs are Comodo, DigiCert, Entrust and GoDaddy.</p> |
| Provisioning Certificate Password    | Enter the password for the provisioning certificate. The password must be between 8 and 32 characters and include at least one upper case letter, at least one lower case letter, at least one base-10 digit and at least one special character.  |

<figure><img src="../../.gitbook/assets/2.15-settings-edgecompute-openamt.png" alt=""><figcaption></figcaption></figure>

When you have finished making changes, click **Save Settings**.



================================================
FILE: admin/settings/general.md
================================================
# General

## Application settings

### Snapshot interval

Defines how often a data snapshot of environments is taken. A data snapshot consists of the information displayed on the home page for the environment as well as other basic information. The default is every 5 minutes.

### Edge agent default poll frequency

This setting defines the default interval used by Edge Agents when checking in with the Portainer instance.

### Use custom logo

Replaces our logo with your own. Toggle on and enter the URL to the logo. The recommended size is 155px by 55px.

### Allow the collection of anonymous statistics

We collect anonymized information about your Portainer installation to help with our product development. You can opt out during installation, or toggle this setting off at any time.&#x20;

<figure><img src="../../.gitbook/assets/2.20-settings-general-application.png" alt=""><figcaption></figcaption></figure>

### Login screen banner

This setting allows you to specify a custom text banner that will appear on the login screen for all users. This could be used to provide informational detail, a warning message, or whatever you need. To enable this, toggle the **Login screen banner** option on and enter your message in the **Details** box.

<figure><img src="../../.gitbook/assets/2.16-settings-login-screen-banner.png" alt=""><figcaption></figcaption></figure>

Your message will then be shown at the login screen.

<figure><img src="../../.gitbook/assets/2.16-settings-login-screen-banner-example.png" alt=""><figcaption></figcaption></figure>

### App Templates

You can deploy containers and services using Portainer's set of built-in app templates, or [replace them with your own](../../advanced/app-templates/build.md) set of templates. Once you have a JSON file containing the template definitions, you can provide the URL to it here.

<figure><img src="../../.gitbook/assets/2.15-settings-settings-2.png" alt=""><figcaption></figcaption></figure>

## Kubernetes settings

### Helm Repository

If you wish to use your own Helm repository in place of the Bitnami repository we include by default, you can enter the URL here.

<figure><img src="../../.gitbook/assets/2.15-settings-settings-3.png" alt=""><figcaption></figcaption></figure>

### Kubeconfig

Here you can select the expiry time for [exported kubeconfig files](../../user/kubernetes/kubeconfig.md) from this dropdown. The new expiry time will only apply to configurations created after this value was changed. Administrators are also able to disable Kubeconfig download for non-admin users here.

<figure><img src="../../.gitbook/assets/2.22.0-settings-kubernetes-kubeconfig.png" alt=""><figcaption></figcaption></figure>

{% hint style="warning" %}
Tokens used in `kubeconfig` files become invalid when Portainer restarts — irrespective of the value set for **Kubeconfig expiry**. In this case, you will need to re-download the `kubeconfig` file.
{% endhint %}

### KubeShell

This option lets administrators disable KubeShell access for non-admin users.

<figure><img src="../../.gitbook/assets/2.22.0-settings-kubernetes-kubeshell.png" alt=""><figcaption></figcaption></figure>

### Deployment options

In this section you can configure various Kubernetes-specific deployment options.

| Field/Option                                            | Overview                                                                                                                                                                                                           |
| ------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Enforce code-based deployment                           | Enable this option to hide the Add with form button when deploying applications and prevent the adding or editing of Kubernetes resources via forms.                                                               |
| Allow web editor and custom template use                | When code-based deployment is enforced, enable this to allow the use of the web editor and custom templates when deploying an application.                                                                         |
| Allow specifying of a manifest via a URL                | When code-based deployment is enforced, enable this allow the use of the URL option when deploying an application.                                                                                                 |
| Allow per-environment override                          | Enable this to allow the above enforcement options to be overridden on a per-environment basis.                                                                                                                    |
| Require a note on applications                          | Enable this to require that deployments have the Notes field completed in order to deploy. This setting currently only applies when deploying via a form.                                                          |
| Allow stacks functionality with Kubernetes environments | Enable this to allow grouping of Kubernetes deployments into "stacks", helping to organize and manage related workloads. Disabling this option will hide the stacks functionality on your Kubernetes environments. |

<figure><img src="../../.gitbook/assets/2.20-settings-general-kubernetes-deployment.png" alt=""><figcaption></figcaption></figure>

## Certificate Authority file for Kubernetes Helm repositories

This section lets you supply a certificate authority (CA) file for use with HTTPS connections to Helm repositories from Portainer. This is useful if the TLS certificate your Helm repository uses is signed by a custom CA, and applies to both the Helm Repository configured above and to Helm repositories configured per environment.

{% hint style="info" %}
This feature is only available in [Portainer Business Edition](https://www.portainer.io/business-upsell?from=ca-file).
{% endhint %}

<figure><img src="../../.gitbook/assets/2.18-settings-helmcafile.png" alt=""><figcaption></figcaption></figure>

## SSL certificate

During installation, Portainer by default creates a self-signed SSL certificate to encrypt traffic between the Portainer Server and the end user, as well as between the Portainer Server and the Portainer Agent. This certificate can be replaced with your own certificate.

{% hint style="info" %}
We recommend including the full chain in the certificate to ensure compatibility. If you do not have the full chain for your certificate, ask your certificate provider or use [What's My Chain Cert?](https://whatsmychaincert.com/) to generate it.
{% endhint %}

<figure><img src="../../.gitbook/assets/2.15-settings-settings-ssl-1.png" alt=""><figcaption></figcaption></figure>

### Force HTTPS only

If you have configured your Portainer Server instance to listen on `9443` (HTTPS) and `9000` (HTTP) you can toggle **Force HTTPS only** on to disable listening on port `9000`.

{% hint style="danger" %}
Make sure that your HTTPS configuration is working correctly **before** enabling this option. Failure to do so may result in you being [locked out of your Portainer installation](https://portal.portainer.io/knowledge/i-enabled-force-https-only-and-now-im-locked-out-of-portainer-how-do-i-get-back-in).
{% endhint %}

{% hint style="warning" %}
Ensure that any Edge agents have been correctly configured for HTTPS communication before enabling this. This setting does **not** affect Standard Agent deployments, as these use HTTPS certificates generated by the Agent on installation.
{% endhint %}

<figure><img src="../../.gitbook/assets/2.15-settings-settings-ssl-force.png" alt=""><figcaption></figcaption></figure>

After making changes to this section, click **Apply Changes**.

## Experimental features

This section allows you to enable experimental Portainer features for use in your deployment. These features are in early development and have gone through a limited set of testing, and are provided to users in order to gather feedback on the feature at an earlier stage of development.

{% hint style="danger" %}
Enabling experimental features on production deployments should be done cautiously and at your own risk.
{% endhint %}

| Field/Option              | Overview                                                                                                                                                                                     |
| ------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Enable OpenAI integration | Toggle this on to enable the OpenAI integration. When this is enabled, individual users will need to add their OpenAI key in their account settings for the feature to be available to them. |

<figure><img src="../../.gitbook/assets/2.18.3-settings-experimental.png" alt=""><figcaption></figcaption></figure>

## Hidden containers

Stops a container from appearing in the Portainer UI through the container label. Enter the name and value of the label, then click **Add filter**. Containers with matching labels will be hidden.

<figure><img src="../../.gitbook/assets/2.15-settings-settings-hiddencontainers.png" alt=""><figcaption></figcaption></figure>

## Back up Portainer

This setting contains all of the information that Portainer stores on the `/data` volume, archived in a `tar.gz` file, and is optionally encrypted with a password. This archive is all you need to restore Portainer.

{% hint style="warning" %}
This backup is **only** intended to back up the Portainer configuration. It does **not** back up what you have deployed on your environments (for example, containers, stacks, services, volumes, etc).&#x20;
{% endhint %}

### Backing up to a local disk <a href="#backup-to-local-disk" id="backup-to-local-disk"></a>

Log in as an admin user. From the menu select **Settings**, then scroll down to the **Back up Portainer** section.

<figure><img src="../../.gitbook/assets/2.20-settings-general-backup.gif" alt=""><figcaption></figcaption></figure>

**Download backup file** is the default option. As an optional step, toggle **Password protect** on and enter a password to encrypt the backup file. When you click **Download backup**, a `tar.gz` file will be downloaded via the browser.

### Backing up to S3

With Portainer Business Edition you have the option to store a backup of your configuration in an S3 bucket, either on demand or on a defined schedule.

To do this, log in as an admin user, select **Settings** from the menu, then scroll down to **Backup Portainer**.

<figure><img src="../../.gitbook/assets/2.20-settings-general-backup.gif" alt=""><figcaption></figcaption></figure>

Select **Store in S3** and fill in the options, using the below as a guide.

| Field/Option               | Overview                                                                                                                                                                                                                                                                                                      |
| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Schedule automatic backups | Enable this to schedule an automatic backup of your configuration to an S3 bucket.                                                                                                                                                                                                                            |
| Cron rule                  | <p>Define how often you want the backup to run using the <a href="https://en.wikipedia.org/wiki/Cron">cron</a> format.</p><p><code>[minute] [hour] [day of month] [month] [day of week]</code></p><p>For example, the following would run a backup at 3:41am every Tuesday:</p><p><code>41 3 * * 2</code></p> |
| Access Key ID              | Enter the access key ID for your S3 bucket.                                                                                                                                                                                                                                                                   |
| Secret Access Key          | Enter the secret key for your S3 bucket.                                                                                                                                                                                                                                                                      |
| Region                     | Enter the region where your bucket is located (for example, `us-west-1`).                                                                                                                                                                                                                                     |
| Bucket name                | Enter the name of your S3 bucket.                                                                                                                                                                                                                                                                             |
| S3 compatible host         | If you are using a non-AWS S3-compatible provider (such as MinIO), enter the URL (including the protocol and port if necessary) here. If you're using AWS S3, leave this blank.                                                                                                                               |
| Password protect           | Enable this to protect your backups with a password.                                                                                                                                                                                                                                                          |
| Password                   | Enter the password to set on your backups.                                                                                                                                                                                                                                                                    |

<figure><img src="../../.gitbook/assets/2.17-admin-settings-backup-s3.png" alt=""><figcaption></figcaption></figure>

### Restoring from a local file

Restoring a configuration is only possible on a fresh instance of Portainer during the initial installation. When you need to restore Portainer, deploy a fresh instance of Portainer with an empty data volume and choose the **Restore Portainer from backup** option during setup.

<figure><img src="../../.gitbook/assets/2.15-backup-restore-file.png" alt=""><figcaption></figcaption></figure>

On the initialization page, expand **Restore Portainer from backup**. Click **Select file** then browse to and select the `tar.gz` backup file. If the backup was originally encrypted, enter the password then click **Restore Portainer**.

The restore might take a few moments. When it has finished, you will be redirected to the login page. You can now log in with your previous credentials and your previous configuration will be restored.

### Restoring from S3

{% hint style="info" %}
This feature is only available in Portainer Business Edition.
{% endhint %}

Restoring a configuration is only possible on a fresh instance of Portainer during the initial installation. When you need to restore Portainer, deploy a fresh instance of Portainer with an empty data volume and choose the **Restore Portainer from backup** option during setup, making sure to select **Retrieve from S3**. Complete the fields using the table below as a guide.

| Field/Option       | Overview                                                                                                                                                                        |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Access key ID      | Enter the access key ID for your S3 bucket.                                                                                                                                     |
| Secret access key  | Enter the secret key for your S3 bucket.                                                                                                                                        |
| Region             | Enter the region where your bucket is located (for example, `us-west-1`).                                                                                                       |
| Bucket name        | Enter the name of your S3 bucket.                                                                                                                                               |
| S3 Compatible Host | If you are using a non-AWS S3-compatible provider (such as MinIO), enter the URL (including the protocol and port if necessary) here. If you're using AWS S3, leave this blank. |
| Filename           | Enter the filename of the backup you want to restore.                                                                                                                           |
| Password           | Enter the password set on your backup (if any).                                                                                                                                 |

<figure><img src="../../.gitbook/assets/2.17-admin-settings-backup-s3-restore.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Restore Portainer**. The restore might take a few moments. When it has finished, you will be redirected to the login page. You can now log in with your previous credentials and your previous configuration will be restored.

## Portainer support

In this section you will find settings related to troubleshooting your Portainer installation.

### Support bundle

This functionality allows you to collect information about your Portainer installation in a bundle that can then be provided to the Portainer support team to aid in troubleshooting issues. Personal information such as passwords and other sensitive credentials are removed from this bundle before being generated.

You can optionally choose to password protect the bundle by toggling on **Password Protect** and setting a password. If you do choose to set a password, ensure you provide the password to the Portainer support team when you supply the bundle.

<figure><img src="../../.gitbook/assets/2.25.0-settings-support-bundle.png" alt=""><figcaption></figcaption></figure>

Click **Download support bundle** to generate and download a .tar.gz file containing the bundle.

### Debug log

Toggle **Enable debug log** on to enable debug logging in the Portainer container logs. Debug logging can help with troubleshooting issues by providing a more verbose output.

<figure><img src="../../.gitbook/assets/2.25.0-settings-support-debug.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: admin/settings/authentication/README.md
================================================
# Authentication

Portainer provides its own internal authentication mechanism, encrypting user passwords and storing them in the local Portainer database. Alternatively, external authentication providers are available. In this section, we explain how to authenticate via LDAP, Active Directory and OAuth.

{% hint style="info" %}
For all authentication types you can adjust the session lifetime (the time before users are forced to reauthenticate). The default is 8 hours.
{% endhint %}

When using internal authentication, an administrator can set the minimum length for users' passwords. The default is 12 characters, but this can be adjusted using the slider. Any users with passwords that don't meet the requirements will be asked to update their passwords when they next log in.

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication.png" alt=""><figcaption></figcaption></figure>

{% content-ref url="ldap.md" %}
[ldap.md](ldap.md)
{% endcontent-ref %}

{% content-ref url="active-directory.md" %}
[active-directory.md](active-directory.md)
{% endcontent-ref %}

{% content-ref url="oauth.md" %}
[oauth.md](oauth.md)
{% endcontent-ref %}






================================================
FILE: admin/settings/authentication/active-directory.md
================================================
# Authenticate via Active Directory

Portainer Business Edition lets you connect to an existing Microsoft Active Directory service to manage your authentication settings in Portainer.

To set up Active Directory authentication, from the menu select **Settings** then select **Authentication**. Under the **Authentication method** section select **Microsoft Active Directory**.

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ad.gif" alt=""><figcaption></figcaption></figure>

A guide to all of the Active Directory configuration settings follows.

## Automatic user provisioning

Enabling this setting automatically creates users within Portainer once they are successfully authenticated by Active Directory (AD). If you do not enable this, you must [manually create users](ldap.md#manually-creating-ldap-users) with the same username as the corresponding AD user.

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ldap-auto.png" alt=""><figcaption></figcaption></figure>

## AD configuration

Configure your Active Directory details using the table below as a guide.

| Field/Option             | Overview                                                                                                                                                                                                                 |
| ------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| AD Controller            | Enter the FQDN or IP address of your domain controller. If you need to add more than one server, click **Add additional server**.                                                                                        |
| Service Account          | Enter the account name that is used to connect to Active Directory and search users.                                                                                                                                     |
| Service Account Password | Enter the password for the above service account.                                                                                                                                                                        |
| Connectivity check       | Perform a check to ensure there is connectivity and SSL handshaking between Portainer and your Active Directory server (if **Use StartTLS** or **Use TLS** are selected under the **AD Connectivity Security** section). |

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ad-config.png" alt=""><figcaption></figcaption></figure>

## AD Connectivity Security

Configure the security settings using the table below as a guide.

| Field/Option                            | Overview                                                                                                                                                  |
| --------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Use StartTLS                            | Enable this option if want to use StartTLS to secure the connection to the server. Enabling this will hide and ignore the **Use TLS** option.             |
| Use TLS                                 | Enable this option if you need to specify TLS certificates to connect to the LDAP server. Enabling this will hide and ignore the **Use StartTLS** option. |
| Skip verification of server certificate | Toggle this option on if you want to skip the verification of the server TLS certificate. Not recommended on unsecured networks.                          |
| TLS CA certificate                      | Lets you upload the CA certificate for your TLS certificate.                                                                                              |

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ad-security.png" alt=""><figcaption></figcaption></figure>

## User search configurations

Configure the user search configurations using the table below as a guide. Click **add user search configuration** to set up multiple configurations.

| Field/Option                | Overview                                                                                                                          |
| --------------------------- | --------------------------------------------------------------------------------------------------------------------------------- |
| Username Format             | Select the username format you want to use when logging into Portainer. Options are `username` and `username@domainname`.         |
| Root Domain                 | This will be filled with the domain of the domain controller.                                                                     |
| User Search Path (optional) | Click **add another entry** to define specific OUs or folders to search for users.                                                |
| Allowed Groups (optional)   | Click **add another group** to define specific groups to be allowed access to Portainer.                                          |
| User Filter                 | This will be filled based on the options you selected previously.                                                                 |
| Display Users               | Click this to use the settings provided to query the Active Directory server for a list of users matching the specified criteria. |

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ad-usersearch.png" alt=""><figcaption></figcaption></figure>

## Group search configurations

Configure the group search configurations using the table below as a guide. Click **add group search configuration** to set up multiple configurations.

| Field/Option                 | Overview                                                                                                                                                                     |
| ---------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Group Search Path (optional) | Click **add another entry** to define specific OUs or folders to search for groups.                                                                                          |
| Group Base DN                | Automatically updated based on previous selections.                                                                                                                          |
| Groups                       | Click **add another group** to define specific groups by OU or folder name.                                                                                                  |
| Group Filter                 | This will be filled based on options previously selected.                                                                                                                    |
| Display User/Group matching  | Click this to use the settings provided in Portainer to query the Active Directory server for a list of users matching the criteria specified, and how they match to groups. |

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ad-groupsearch.png" alt=""><figcaption></figcaption></figure>

## Auto-populate team admins

If desired, Portainer can configure specified AD groups of users to become Portainer administrators automatically.&#x20;

To configure this, first click **add group search configuration** and define the **Group Base DN**, **Groups** and **Group Filter** as required. Once done, click the **Fetch Admin Group(s)** button to retrieve the list of groups matching your search configuration.

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ad-autopop.png" alt=""><figcaption></figcaption></figure>

When you're happy with the group selection, enable this feature by toggling **Assign admin rights to group(s)** on.

## Test login

To test your settings are correct and that the right users and groups are configured for access, scroll down to **Test login**, enter a valid user and password then click **Test**. If everything is working as expected, a green tick will appear next to the button.

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ad-testlogin.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: admin/settings/authentication/ldap.md
================================================
# Authenticate via LDAP

## Introduction

Portainer can be configured to accept Lightweight Directory Access Protocol (LDAP) authentication if your organization has implemented LDAP authentication. When users attempt to log into Portainer, the application will authenticate them against your LDAP directory. If authentication is successful, the user is allowed to log into Portainer.

To configure Portainer LDAP authentication, you first need to add a user to your directory service for the purpose of authenticating from Portainer to read the LDAP. The user should be a service account that needs read-only access to LDAP.

## Enabling LDAP

Log into Portainer as an administrator. From the menu select **Settings**, select **Authentication** then select the **LDAP Authentication** option. Extra fields will appear, allowing you to configure LDAP.

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ldap.gif" alt=""><figcaption></figcaption></figure>

### Automatic user provisioning

Enabling this setting automatically creates users within Portainer once they are successfully authenticated by LDAP. If you do not enable this, you must [manually create users](ldap.md#manually-creating-ldap-users) with the same username as the corresponding LDAP directory.

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ldap-auto.png" alt=""><figcaption></figcaption></figure>

### Server Type

Here you can select a custom configuration or a preconfigured OpenLDAP template.

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ldap-type.png" alt=""><figcaption></figcaption></figure>

### LDAP configuration

Enter the IP address/FQDN and port number of your LDAP server. Opt to either connect anonymously (your LDAP server must support this) or enter a user account that has READ access to the directory. Click **Test connectivity** to validate that you can connect.

{% hint style="info" %}
For OpenLDAP, the Reader DN format should be set to `cn=user,dc=domain,dc=tld`. If your configuration differs you will need to adjust this to suit.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ldap-config.png" alt=""><figcaption></figcaption></figure>

If you want to add additional LDAP servers to provide for authentication fallback, click **Add additional server** and fill in the server details.

### LDAP security

Configure the remaining LDAP settings, using the table below as a guide:

| Field/Option                            | Overview                                                                                                                                                                                                                                                                                                                                   |
| --------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Use StartTLS                            | Changes the insecure connection to secure after the initial connection.                                                                                                                                                                                                                                                                    |
| Use TLS                                 | Initiates a connection to LDAP using TLS.                                                                                                                                                                                                                                                                                                  |
| Skip verification of server certificate | If you do not have access to the LDAP server certificate, skipping verification will enable encrypted communications. However, you must manually ensure that you are talking to the intended LDAP server that you specified in the URL. If that gets maliciously redirected, you could be talking to a different server. Use with caution. |

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ldap-security.png" alt=""><figcaption></figcaption></figure>

| Field/Option       | Overview                                                       |
| ------------------ | -------------------------------------------------------------- |
| TLS CA certificate | Lets you upload your CA certificate for the secure connection. |

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ldap-security-tls.png" alt=""><figcaption></figcaption></figure>

### User-search configurations

#### BaseDN

* Enter `dc=mydomain,dc=com` to search your entire directory for the username attempting to login.
* Enter `ou=myou,dc=mydomain,dc=com` to search for users only within the specified OU.
* Enter `cn=mycn,dc=mydomain,dc=com` if your users are only in a container.

If you have a large number of users in your domain, narrow the scope Portainer searches on by using OUs.

#### Username attribute

For LDAP, enter `uid` unless your configuration differs.

#### Filter

{% hint style="info" %}
These entries are case sensitive.
{% endhint %}

Enter filter criteria for the results returned from LDAP to Portainer. For example, to only allow users who are members of a group defined within an OU to login, set **Filter** to the following (the brackets are important, so copy the entire string):

```
(&(objectClass=user)(memberOf=cn=mycn,ou=myou,dc=mydomain,dc=com))
```

In the example below, the domain `portainer.local` has an OU called `Groups` and within that OU is a group called `PortainerDevUsers`. This search filter will only allow users who are members of the `PortainerDevUsers` LDAP group to log into Portainer.

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ldap-usersearch.png" alt=""><figcaption></figcaption></figure>

As an optional step, click **Add user search configuration** to define additional user-search configurations.

### Group-search configurations

In addition to user search, Portainer also gives you the option to set up group search. When configured, if an LDAP user is a member of an LDAP group, and that LDAP Group corresponds to an identically named Portainer [Team](../../user/teams/), then the LDAP user will automatically be placed into the Portainer Team based on their LDAP group membership. This is very useful for automatically granting access to Portainer environments via group membership.

#### Group Base DN

Enter either:

* Enter `dc=mydomain,dc=com` to search your entire directory for the list of groups.
* Enter `ou=myou,dc=mydomain,dc=com` to search for groups only within the specified OU.
* Enter `cn=mycn,dc=mydomain,dc=com` if your groups are only in a container.

If you have a large number of groups in your domain, narrow the scope Portainer searches on by using OUs.

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ldap-groupsearch.png" alt=""><figcaption></figcaption></figure>

#### Group Membership Attribute

Enter `member` as the attribute that determines if a user is a member of a group.

#### Group Filter

If you want to filter the list of groups to return only those that contain the string `Portainer` (for example: `PortainerDev`, `PortainerProd`, `PortainerUAT`), set up the filter like this:

```
(&(objectclass=group)(cn=*Portainer*))
```

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ldap-groupsearch-filter.png" alt=""><figcaption></figcaption></figure>

As an optional step, click **Add group search configuration** to define additional group-search configurations.

### Auto-populate team admins

If desired, Portainer can configure specified LDAP groups of users to become Portainer administrators automatically.&#x20;

To configure this, first click **add group search configuration** and define the **Group Base DN**, **Groups** and **Group Filter** as required. Once done, click the **Fetch Admin Group(s)** button to retrieve the list of groups matching your search configuration.

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ldap-autopop.png" alt=""><figcaption></figcaption></figure>

When you're happy with the group selection, enable this feature by toggling **Assign admin rights to group(s)** on.

### Test login

To test your configuration, you can enter a username and password and click the **Test** button.

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-ldap-testlogin.png" alt=""><figcaption></figcaption></figure>

## Manually creating LDAP users

{% hint style="info" %}
This is an optional step and is required only if you do not use automatic user provisioning.
{% endhint %}

Once LDAP has been enabled, from the menu select **Users**. Create a username that matches your LDAP source users with the format defined when you enabled LDAP (either `username` or `username@mydomain.com`).



================================================
FILE: admin/settings/authentication/oauth.md
================================================
# Authenticate via OAuth

## Configuring OAuth authentication in Portainer

From the menu select **Settings** then select **Authentication**. Under the **Authentication method** section click **OAuth**.

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-oauth.gif" alt=""><figcaption></figcaption></figure>

In the next screen, enter the credentials provided by your OAuth provider, using the table below as a guide.

| Field/Option                        | Overview                                                                                                                                                                                                                                                                                          |
| ----------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Use SSO                             | Enable SSO so that the OAuth provider won't be forced to ask for credentials when users are in a current logged-in session.                                                                                                                                                                       |
| Hide internal authentication prompt | Hide the ability to log in through internal authentication. Note that when external authentication is enabled, [only the initial admin user](https://portal.portainer.io/knowledge/can-i-use-internal-authentication-and-external-authentication-at-the-same-time) can log in with internal auth. |
| Automatic user provisioning         | If toggled on, users who exist at the OAuth provider's end will automatically be created in Portainer (you can define a default team to put those users in while this option is on). If toggled off, you'll need to [create users](../../user/add.md) in Portainer manually.                      |

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-oauth-sso.png" alt=""><figcaption></figcaption></figure>

If you toggle **Automatic team membership** on, you can choose to automatically add OAuth users to certain Portainer teams based on the **Claim name**. Claim names will be matched with teams or you can manually link a claim name (using regex) with Portainer teams under the **Statically assigned teams** option. You can also define a **Default team** for users who don't belong to any other team.

In addition, you can enable the automatic assignment of admin rights to specified groups if desired.

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-oauth-team.png" alt=""><figcaption></figcaption></figure>

When configuring Microsoft Entra ID (Azure AD) as the OAuth provider, you will need to [use the group's Object Id value](https://learn.microsoft.com/en-us/entra/fundamentals/how-to-manage-groups#edit-group-settings) for the claim value regex instead of the group name:

<figure><img src="../../../.gitbook/assets/2.20-settings-authentication-oauth-ad-teammembership-objectid.png" alt=""><figcaption></figcaption></figure>

## OAuth providers

Portainer provides pre-configured OAuth provider options or you can set up your own custom OAuth provider. Each of the pre-configured providers can have their configuration overridden if you need to make changes to the Portainer defaults.

### Microsoft

Configure your OAuth provider using the table below as a guide.

| Field/Option    | Overview                                                                                                          |
| --------------- | ----------------------------------------------------------------------------------------------------------------- |
| Tenant ID       | Enter the ID of the Azure Directory you wish to authenticate against. This is also known as the **Directory ID**. |
| Application ID  | Enter the public identifier of the OAuth application.                                                             |
| Application key | Enter the secret key for the OAuth application.                                                                   |

You can find these details using the following steps:

1.  Log in to your Azure Portal as an administrator.



    <figure><img src="../../../.gitbook/assets/authentication-oauth-ms-1.png" alt=""><figcaption></figcaption></figure>
2.  Click on **Azure Active Directory** and then click on **Overview**. Your **Tenant ID** can be found in the right pane. Use this as the **Tenant ID** in Portainer.



    <figure><img src="../../../.gitbook/assets/2.17-AzureOauth-AD.png" alt=""><figcaption></figcaption></figure>
3.  Still in Azure Active Directory, click on **App Registrations** then click **New registration**.



    Enter a friendly name for the Portainer instance. Choose appropriate option for Supported account types, Choose `Web` type for **Redirect URI** and enter the FQDN or IP address that your Portainer instance listens on `eg: https://portainer.example.com:9443`. Then click **Register**.



    <figure><img src="../../../.gitbook/assets/2.17-AzureOauth-NewReg-S1.png" alt=""><figcaption></figcaption></figure>

    <figure><img src="../../../.gitbook/assets/2.17-AzureOauth-NewReg.png" alt=""><figcaption></figcaption></figure>
4.  After creating the Registration, the screen below is displayed. Use the provided **Application ID** in the respective field in Portainer.



    <figure><img src="../../../.gitbook/assets/2.17-AzureOauth-NewReg-S2.png" alt=""><figcaption></figcaption></figure>
5.  Click on **Certificates & secrets** then click **Client secrets**, Click on **New client secret**. Add **Description** and choose Expiry date, then Click **Add.**



    The secret will then be generated for you. Use the Value as the **Application key** in the respective field in Portainer.



    <figure><img src="../../../.gitbook/assets/2.17-AzureOauth-NewReg-S4.png" alt=""><figcaption></figcaption></figure>

    <figure><img src="../../../.gitbook/assets/2.17-AzureOauth-NewReg-S3.png" alt=""><figcaption></figcaption></figure>
6.  Click on **API Permissions** and **Add a permission**. Select **Microsoft Graph** in the **Request API permissions screen**. Select **Delegated permissions** and add `email, openid, profile` permissions.

    <figure><img src="../../../.gitbook/assets/2.17-AzureOauth-NewReg-S5.gif" alt=""><figcaption></figcaption></figure>
7.  Make sure you Grant admin consent for Directory.

    <figure><img src="../../../.gitbook/assets/2.20-settings-authentication-oauth-ad-directory.png" alt=""><figcaption></figcaption></figure>
8.  Optionally, to use **Automatic Team Membership** ability in Portainer, you need create groups claim. Click on **Token Configuration** and **Add groups claim**. Select **Security Groups** and click **Add**.

    <figure><img src="../../../.gitbook/assets/2.17-AzureOauth-NewReg-S6.gif" alt=""><figcaption></figcaption></figure>

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-oauth-ms.png" alt=""><figcaption></figcaption></figure>

When you're finished, click **Save settings**.

### Google

Configure your OAuth provider using the table below as a guide.

| Field/Option  | Overview                                              |
| ------------- | ----------------------------------------------------- |
| Client ID     | Enter the public identifier of the OAuth application. |
| Client secret | Enter the secret key for the OAuth application.       |

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-oauth-google.png" alt=""><figcaption></figcaption></figure>

When you're finished, click **Save settings**.

### Github

Configure your OAuth provider using the table below as a guide.

| Field/Option  | Overview                                              |
| ------------- | ----------------------------------------------------- |
| Client ID     | Enter the public identifier of the OAuth application. |
| Client secret | Enter the secret key for the OAuth application.       |

<figure><img src="../../../.gitbook/assets/2.15-settings-authentication-oauth-github.png" alt=""><figcaption></figcaption></figure>

When you're finished, click **Save settings**.

### Custom

Complete the **OAuth Configuration** section based on the table below.

| Field/Option      | Overview                                                                                                                                                                                         |
| ----------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Client ID         | Enter the public identifier of the OAuth application.                                                                                                                                            |
| Client secret     | Enter the token access to the OAuth application.                                                                                                                                                 |
| Authorization URL | Enter the URL used to authenticate against the OAuth provider (will redirect users to the OAuth provider login screen).                                                                          |
| Access token URL  | Enter the URL used to exchange a valid OAuth authentication code for an access token.                                                                                                            |
| Resource URL      | Enter the URL used by Portainer to retrieve information about authenticated users.                                                                                                               |
| Redirect URL      | Enter the URL used by the OAuth provider to redirect users after they are successfully authenticated (also referred to as the callback URL). You should set this to your Portainer instance URL. |
| Logout URL        | Enter the URL used by the OAuth provider to log users out.                                                                                                                                       |
| User identifier   | Enter the identifier that Portainer will use to create accounts for authenticated users. Retrieved from the resource server specified in the **Resource URL** field.                             |
| Scopes            | Required by the OAuth provider to retrieve information about authenticated users. See your provider's own documentation for more information.                                                    |
| Auth Style        | Specify how to send the client ID and client secret to the OAuth provider.                                                                                                                       |

<figure><img src="../../../.gitbook/assets/2.21-settings-authentication-oauth-custom.png" alt=""><figcaption></figcaption></figure>

When you're finished, click **Save settings**.

## Giving environment access to OAuth teams and users

See [Managing user access to environments](../../environments/access.md).



================================================
FILE: admin/settings/credentials/README.md
================================================
# Shared credentials

In this section you can manage the credentials used with our [KaaS provisioning functionality](../../environments/add/kaas/) and our Kubernetes provisioning feature.

<figure><img src="../../../.gitbook/assets/2.18-settings-sharedcreds.png" alt=""><figcaption></figcaption></figure>

To add a new set of credentials, click the **Add credentials** button. Portainer currently supports the following credential types:

* [Sidero Omni](omni.md)
* [Civo](civo.md)
* [Akamai Connected Cloud](linode.md)
* [DigitalOcean](digitalocean.md)
* [Google Cloud](gke.md)
* [Amazon Web Services (AWS)](eks.md)
* [Microsoft Azure](aks.md)
* [SSH](ssh.md) (for use with Kubernetes cluster deployments)

To remove a set of credentials, check the box next to the credentials to remove and click **Remove**.



================================================
FILE: admin/settings/credentials/aks.md
================================================
# Add Azure credentials

Before you can add your Azure credentials to Portainer, you will need to retrieve your subscription ID, create an app and retrieve the related tenant ID and client ID, create a client secret and retrieve the value, and set the correct role or permissions on your resource group.

## Configuring your Azure account

Log in to the Azure portal. First, click **Subscriptions** and note down your **Subscription ID**.&#x20;

Then click the menu in the top left and select **Azure Active Directory**. Click **App registrations** in the left hand menu and select **New Registration**.

Enter a name for your registration that makes sense to you and leave the other fields as they are. Click **Register** to create the registration. In the app page that appears, note down the **Application (client) ID** and **Directory (tenant) ID**.

Next click on **Certificates & secrets** in the left hand menu. Click **New client secret** and enter a name for your secret. Select an expiry date for the secret and click **Add**. Copy the **Client Secret (value)** - you don't need the secret ID.

Now we need to set permissions. Click the menu in the top left, then **Resource Groups** and select your resource group. If you don't already have one, you can create a new one.&#x20;

Click on **Access control (IAM)** in the left hand menu then click **Add role assignment**. We recommend selecting the `Contributor` role, but if you want to specify the exact set of permissions they are as follows:

```
Microsoft.ContainerService/managedClusters/read
Microsoft.ContainerService/managedClusters/write
Microsoft.Resources/deployments/*
Microsoft.Resources/subscriptions/resourcegroups/read
Microsoft.Resources/subscriptions/resourcegroups/write
Microsoft.Resources/subscriptions/read
Microsoft.ContainerService/managedClusters/listClusterAdminCredential/action
```

Once you've chosen your permissions, click **Next**. Click **Select members** then search for the app you registered earlier. Click it, then click **Select** at the bottom of the page. Click **Review + assign**, then **Review + assign** again on the next page.

## Adding your credentials

To add credentials for an Azure account, from the [Cloud settings](./) page click **Add credentials**, then select the **Microsoft Azure** option. Enter a **name** for your credentials, then paste your **Subscription ID**, **Tenant ID**, **Client ID** and **Client Secret** into the fields.

<figure><img src="../../../.gitbook/assets/2.21.2-settings-cloud-credentials-azure.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Add credentials**. Your credentials will now be available to you when [provisioning a Kubernetes cluster on Azure](../../environments/add/kaas/aks.md).



================================================
FILE: admin/settings/credentials/civo.md
================================================
# Add Civo credentials

Before you can add your Civo credentials to Portainer, you will need to retrieve your API token from Civo.

## Retrieving your API token

Log into the Civo dashboard and expand the **Settings** menu. Select **Profile**, then the **Security** tab.

At the top of the page you should see your API key listed.

## Adding your credentials

To add credentials for a Civo account, from the [Shared credentials](./) page click **Add credentials**, then select the **Civo** option. Give your credential set a **name** and paste your **API key** into the box.

<figure><img src="../../../.gitbook/assets/2.21.2-settings-cloud-credentials-civo.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Add credentials**. Your credentials will now be available to you when [provisioning a Kubernetes cluster on Civo](../../environments/add/kaas/civo.md).



================================================
FILE: admin/settings/credentials/digitalocean.md
================================================
# Add DigitalOcean credentials

Before you can add your DigitalOcean credentials to Portainer, you will need to create an API token in your DigitalOcean account.

## Creating your API token

Log into the DigitalOcean dashboard and select **API** at the bottom left. Click **Generate New Token**, enter a token name and an expiration time, and ensure that both **Read** and **Write** scopes are ticked.

## Adding your credentials

To add credentials for a DigitalOcean account, from the [Shared credentials](./) page click **Add credentials**, then select the **DigitalOcean** option. Give your credential set a **name** and paste your **API key** into the box.

<figure><img src="../../../.gitbook/assets/2.21.2-settings-cloud-credentials-digitalocean.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Add credentials**. Your credentials will now be available to you when [provisioning a Kubernetes cluster on DigitalOcean](../../environments/add/kaas/digitalocean.md).



================================================
FILE: admin/settings/credentials/eks.md
================================================
# Add AWS credentials

Before you can add your AWS credentials to Portainer, you will need to configure your IAM account with the necessary access policies and create and retrieve an access key.

## Configuring access to AWS

While you can use an existing IAM user to communicate with Portainer, you may want to create a new user for just this purpose. The minimum IAM policies required for Portainer to provision are as follows:

* `AmazonEC2FullAccess`
* `AWSCloudFormationFullAccess`

In addition, we require two custom policies, which you should create and assign to your IAM user:

### EKSFullAccess

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": "eks:*",
            "Resource": "*"
        },
        {
            "Action": [
                "ssm:GetParameter",
                "ssm:GetParameters"
            ],
            "Resource": [
                "arn:aws:ssm:*:<account_id>:parameter/aws/*",
                "arn:aws:ssm:*::parameter/aws/*"
            ],
            "Effect": "Allow"
        },
        {
             "Action": [
               "kms:CreateGrant",
               "kms:DescribeKey"
             ],
             "Resource": "*",
             "Effect": "Allow"
        },
        {
             "Action": [
               "logs:PutRetentionPolicy"
             ],
             "Resource": "*",
             "Effect": "Allow"
        }        
    ]
}
```

### IAMLimitedAccess

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "iam:CreateInstanceProfile",
                "iam:DeleteInstanceProfile",
                "iam:GetInstanceProfile",
                "iam:RemoveRoleFromInstanceProfile",
                "iam:GetRole",
                "iam:CreateRole",
                "iam:DeleteRole",
                "iam:AttachRolePolicy",
                "iam:PutRolePolicy",
                "iam:ListInstanceProfiles",
                "iam:AddRoleToInstanceProfile",
                "iam:ListInstanceProfilesForRole",
                "iam:PassRole",
                "iam:DetachRolePolicy",
                "iam:DeleteRolePolicy",
                "iam:GetRolePolicy",
                "iam:GetOpenIDConnectProvider",
                "iam:CreateOpenIDConnectProvider",
                "iam:DeleteOpenIDConnectProvider",
                "iam:TagOpenIDConnectProvider",
                "iam:ListAttachedRolePolicies",
                "iam:TagRole",
                "iam:GetPolicy",
                "iam:CreatePolicy",
                "iam:DeletePolicy",
                "iam:ListPolicyVersions"
            ],
            "Resource": [
                "arn:aws:iam::<account_id>:instance-profile/eksctl-*",
                "arn:aws:iam::<account_id>:role/eksctl-*",
                "arn:aws:iam::<account_id>:policy/eksctl-*",
                "arn:aws:iam::<account_id>:oidc-provider/*",
                "arn:aws:iam::<account_id>:role/aws-service-role/eks-nodegroup.amazonaws.com/AWSServiceRoleForAmazonEKSNodegroup",
                "arn:aws:iam::<account_id>:role/eksctl-managed-*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "iam:GetRole"
            ],
            "Resource": [
                "arn:aws:iam::<account_id>:role/*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "iam:CreateServiceLinkedRole"
            ],
            "Resource": "*",
            "Condition": {
                "StringEquals": {
                    "iam:AWSServiceName": [
                        "eks.amazonaws.com",
                        "eks-nodegroup.amazonaws.com",
                        "eks-fargate.amazonaws.com"
                    ]
                }
            }
        }
    ]
}
```

Once you have your IAM user set up, log in to the AWS portal with the IAM user and in the top right menu - the user's name - select **Security Credentials**. Expand the **Access keys** section and click **Create New Access Key**.&#x20;

Copy the **Access key ID** and the **Secret access key** that are generated.

## Adding your credentials

To add credentials for an AWS account, from the [Shared credentials](./) page click **Add credentials**, then select the **Amazon Web Services (AWS)** option. Enter a **name** for your credentials, then paste your **access key ID** and and **secret access key** from AWS into the fields.

<figure><img src="../../../.gitbook/assets/2.21.2-settings-cloud-credentials-aws.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Add credentials**. Your credentials will now be available to you when [provisioning a Kubernetes cluster on AWS](../../environments/add/kaas/eks.md).



================================================
FILE: admin/settings/credentials/gke.md
================================================
# Add Google Cloud credentials

Before you can add your Google Cloud credentials to Portainer, you will need to configure your account for GKE, set up a service account, and retrieve the private key for that service account. Once this is complete, you can use the private key to set up access.

## Creating your private key

Log into the Google Cloud console and go to the dashboard for your project. To confirm GKE is enabled for your project, click on **Kubernetes Engine** in the left hand menu. If the section loads and displays the ability to create a cluster, you're set up already. Otherwise you'll be asked to **enable the Kubernetes Engine API**, which you should do.

Once this is confirmed, we need to create a service account. From the navigation menu, hover over **IAM & Admin** and click **Service Accounts**, then click **Create Service Account**. Fill in the service account details with a name, ID and description that makes sense to you and click **Create and Continue**. In the **Grant this service account access to project** section, add the`Compute Engine Service Agent` and `Kubernetes Engine Service Agent` roles to the service account and click **Continue**, then click **Done** to create the account.

Finally, we need to retrieve the private key for the service account. Click on the service account you just created, then select the **Keys** tab and click **Add Key** then **Create new key**. Select **JSON** as the type and click **Create**. This will download a file containing the private key for the service account.

## Adding your credentials

To add credentials for a Google Cloud account, from the [Shared credentials](./) page click **Add credentials**, then select the **Google Cloud** option. Give your credential set a **name** and upload the JSON private key for your service account.

<figure><img src="../../../.gitbook/assets/2.21.2-settings-cloud-credentials-googlecloud.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Add credentials**. Your credentials will now be available to you when [provisioning a Kubernetes cluster on Google Cloud](../../environments/add/kaas/gke.md).



================================================
FILE: admin/settings/credentials/linode.md
================================================
# Add Akamai Connected Cloud credentials

Before you can add your Akamai Connected Cloud credentials to Portainer, you will need to create an API token in your Akamai account.

## Creating your API token

Log into the Akamai dashboard and click your account name in the top right. Select **API Tokens**. Click **Create a Personal Access Token**, give it a label and set an expiry. The Portainer provisioning functionality only requires **Read/Write** for the **Kubernetes** option, so disable the rest.

## Adding your credentials

To add credentials for an Akamai account, from the [Shared credentials](./) page click **Add credentials**, then select the **Akamai Connected Cloud** option. Give your credential set a **name** and paste your **API key** into the box.

<figure><img src="../../../.gitbook/assets/2.21.2-settings-cloud-credentials-akamai.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Add credentials**. Your credentials will now be available to you when [provisioning a Kubernetes cluster on Akamai Connected Cloud](../../environments/add/kaas/linode.md).



================================================
FILE: admin/settings/credentials/omni.md
================================================
# Add Sidero Omni credentials

Before you can add your Sidero Omni credentials to Portainer, you will need to create a service account within Omni for Portainer to use. You can either do this via the Omni web UI, or via `omnictl`.

## Create a service account with the Omni web UI

To create a service account for Portainer through the Omni web UI, first log into the web UI with an administrator user. Once logged in, click on **Settings** then select the **Service Accounts** tab.

<figure><img src="../../../.gitbook/assets/2.26-settings-credentials-omni-service-webui-1.png" alt=""><figcaption></figcaption></figure>

Next click the **Create Service Account** button and complete the fields as per the table below:

| Field/Option    | Overview                                                                                                            |
| --------------- | ------------------------------------------------------------------------------------------------------------------- |
| ID              | Enter an ID for the service account. We suggest something like `portainer`.                                         |
| Expiration Days | Set the number of days you want the service account to be valid for.                                                |
| Role            | Select the `Admin` role from the dropdown. Portainer needs Admin privileges in order to create and manage clusters. |



<figure><img src="../../../.gitbook/assets/2.26-settings-credentials-omni-service-webui-2.png" alt=""><figcaption></figcaption></figure>

Once you have entered all the details click the **Create Service Account** button. The service account will be crated and you'll be shown the **Service account key**. Make a note of this key as it will not be shown again.

<figure><img src="../../../.gitbook/assets/2.26-settings-credentials-omni-service-webui-3.png" alt=""><figcaption></figcaption></figure>

You can now proceed to [add your credentials](omni.md#adding-your-credentials).

## Create a service account with omnictl

To create a service account for Portainer using `omnictl`, you will first need an environment where `omnictl` is installed and configured to connect to your Omni installation with an Admin user. You can learn more on how to do this from [Sidero Omni's documentation](https://omni.siderolabs.com/how-to-guides/install-and-configure-omnictl).

Once you have `omnictl` installed and configured, you can run the following command to create a service account:

```
onictl serviceaccount create portainer
```

This will create a service account named `portainer` with a lifetime of 1 year and with the same role as the user that created it. The command will output the `OMNI_ENDPOINT` and `OMNI_SERVICE_ACCOUNT_KEY` values - note both of these as you will need them in the next step.

You can now proceed to [add your credentials](omni.md#adding-your-credentials).

## Adding your credentials

To add credentials for an Omni account, from the [Shared credentials](./) page click **Add credentials**, then select the **Sidero Omni** option. Give your credential set a **name** and paste your **Endpoint URL** and **Service account key** into the respective boxes.

<figure><img src="../../../.gitbook/assets/2.26-settings-credentials-omni-add.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Add credentials**. Your credentials will now be available to you when [creating an Omni Talos cluster](../../environments/add/kube-create/omni.md).



================================================
FILE: admin/settings/credentials/ssh.md
================================================
# Add SSH credentials

SSH credentials are currently used by Portainer in our Kubernetes provisioning feature. Credentials created here will be usable by any admin-level user, though they will not be able to view the actual credentials directly.

## Setting up your SSH user

The exact method for configuring your SSH user will differ from platform to platform. For the Kubernetes provisioning feature, we assume the following for the user you create:

* The user has sudo privileges or is a root user - this is because Portainer needs this level of access in order to install Kubernetes.
* SSH is listening on port `22` on the server.

We generally recommend the use of a SSH key for authentication rather than password authentication, but Portainer supports both methods.

## Adding your credentials

To add your SSH credentials, from the [Shared credentials](./) page click **Add credentials**, then select the **SSH** option. Fill out the relevant fields as below.

| Field/Option               | Overview                                                                                                             |
| -------------------------- | -------------------------------------------------------------------------------------------------------------------- |
| Credentials name           | Enter a name you will use to identify your credential set in the Portainer application.                              |
| SSH username               | Enter the username for your SSH account.                                                                             |
| SSH password               | Enter the password for your SSH account. You can leave this field blank if you intend to use SSH key authentication. |
| Use SSH key authentication | Enable this toggle to use SSH key authentication instead of password authentication.                                 |
| SSH private key passphrase | If your SSH private key is encrypted, provide the passphrase here.                                                   |
| SSH private key            | Paste your SSH private key in this field.                                                                            |

<figure><img src="../../../.gitbook/assets/2.21.2-settings-cloud-credentials-ssh.png" alt=""><figcaption></figcaption></figure>

You can also choose to upload your private key by clicking **Upload SSH private key** and selecting the file to upload. This will replace anything in the SSH private key field with the contents of the uploaded file.

When you are ready, click **Add credentials** to complete the process.

### Generate a new key pair

If you would like to create a new key pair for your SSH credentials, you can do so by clicking **Generate new RSA SSH key pair**. You will first be prompted to enter an optional passphrase for your private key, then click the **Generate SSH key pair** button to proceed.

<figure><img src="../../../.gitbook/assets/2.18-settings-credentials-ssh-generate-1.png" alt=""><figcaption></figcaption></figure>

Portainer will then generate a new key pair for you and display the resulting private and public keys. You can copy the values to your clipboard with the Copy buttons, or download the individual files with the Download buttons.

{% hint style="warning" %}
Ensure you take a copy of both the public and private keys, as you will not be able to retrieve them.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.18-settings-credentials-ssh-generate-2.png" alt=""><figcaption></figcaption></figure>

Your newly generated public key should be added to the `authorized_keys` file for the SSH user you intend to use on your nodes for provisioning.

{% hint style="info" %}
Key pairs are generated with a key size of `4096` bits.
{% endhint %}

Once you have saved the public and private key files, click **Continue**. You will be returned to the previous screen and the SSH private key passphrase and SSH private key fields will be populated with your new key pair's passphrase and private key respectively.



================================================
FILE: admin/user/README.md
================================================
# User-related

Give access to individual users then manage them as their needs change over time.

{% content-ref url="users.md" %}
[users.md](users.md)
{% endcontent-ref %}

{% content-ref url="add.md" %}
[add.md](add.md)
{% endcontent-ref %}

{% content-ref url="promote.md" %}
[promote.md](promote.md)
{% endcontent-ref %}

{% content-ref url="password.md" %}
[password.md](password.md)
{% endcontent-ref %}

Add users to teams then assign them to roles (Business Edition).

{% content-ref url="teams/" %}
[teams](teams/)
{% endcontent-ref %}

{% content-ref url="roles.md" %}
[roles.md](roles.md)
{% endcontent-ref %}



================================================
FILE: admin/user/add.md
================================================
# Add a new user

From the menu expand **User-related** and select **Users**.&#x20;

<figure><img src="../../.gitbook/assets/2.20-users-users.gif" alt=""><figcaption></figcaption></figure>

Enter a username and a strong password (and confirm it). You can also set whether this user is an Administrator as well as add the user to any teams you have created.&#x20;

<figure><img src="../../.gitbook/assets/2.15-settings-users-add.png" alt=""><figcaption></figcaption></figure>

Once you're ready, click **Create user**.



================================================
FILE: admin/user/password.md
================================================
# Reset a user's password

From the menu expand **User-related** then select **Users**.&#x20;

<figure><img src="../../.gitbook/assets/2.20-users-users.gif" alt=""><figcaption></figcaption></figure>

Click the username of the user whose password you want to reset. In the **Change user password** section, enter a new strong password, re-enter the password to confirm it then click **Update password**.

<figure><img src="../../.gitbook/assets/2.15-settings-users-changepw.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: admin/user/promote.md
================================================
# Turn a user into an administrator

From the menu expand **User-related** then select **Users**.&#x20;

<figure><img src="../../.gitbook/assets/2.20-users-users.gif" alt=""><figcaption></figcaption></figure>

Click the username of the user you want to promote to administrator. Toggle **Administrator** on then click **Save**.

<figure><img src="../../.gitbook/assets/2.15-settings-users-promote.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: admin/user/roles.md
================================================
# Roles

Portainer Business Edition comes with Role-Based Access Control (RBAC) features that refine the access privileges available natively within Portainer. The RBAC feature allows you to create granular user access across all resources and all environments defined within Portainer.

## The basics

* A _role_ is a predefined set of privileges.
* _Privileges_ define the rights to perform actions.
* Users are assigned roles, and each role has specific privileges.
* To assign privileges, pair a user or team with a role then associate that pairing with an environment or environment group.
* A single user or team can have different roles for different environments in the Portainer inventory.

## Built-in roles

There are several types of roles:

* **Environment administrator** has full access within a given environment, but cannot make any changes to the infrastructure that underpins an environment (i.e. no host management), nor are they able to make changes to Portainer internal settings. Environment administrators are also unable to change ownership of resources.
* **Edge administrator** has full control over all resources in all Edge environments, and access to the Edge Compute features.
* **Operator** has operational control over the resources deployed within a given environment. Operator can update, re-deploy, start and stop containers/services, check logs and console into containers, but cannot create or delete any resources.
* **Helpdesk** has read-only access to the resources deployed within a given environment but cannot make changes to any resource, nor can they open a console to a container or make changes to a container’s volumes.
* **Standard User** has complete control over the resources that a user deploys, or if the user is a member of a team, has complete control over the resources that users of that team deploy.
* **Read-Only User** has read-only access to the resources they are entitled to see (resources created by members of their team, and public resources).

<figure><img src="../../.gitbook/assets/2.20-user-roles-list.png" alt=""><figcaption></figcaption></figure>

The **Administrator** role sits outside of the other roles and effectively acts as a 'Global Admin'. A user assigned to this role has complete control over Portainer settings, and all resources on every environment under Portainer's control.

{% hint style="info" %}
The **Team Leader** role (which can be defined when [adding a new team](teams/add.md)) is designed for setups that are using internal authentication only, and in a future version the role will be disabled when external authentication is enabled.
{% endhint %}

## Viewing user access

Portainer's **Effective access viewer** lets you see what access a user has. From the menu expand **User-related** then select **Roles**.

<figure><img src="../../.gitbook/assets/2.20-users-roles.gif" alt=""><figcaption></figcaption></figure>

Scroll down to the **Effective access viewer** section and select a user from the **User** dropdown. The user's roles and their access on your environments will display. Select **Manage access** on any row to be taken to the [environment's access configuration](../environments/access.md).

<figure><img src="../../.gitbook/assets/2.15-settings-users-roles-access.png" alt=""><figcaption></figcaption></figure>

## Docker vs Kubernetes

Because Docker does not natively provide role-based access control, we implement our own role management in order to provide this functionality. On a Kubernetes environment, we leverage the RBAC functionality built into Kubernetes alongside our own role management to provide security and flexibility to roles and access.

For more information on the permissions that each role has for Docker and Swarm environments, see our [Docker roles and permissions documentation](../../advanced/docker-roles-and-permissions.md). For more information about how we map Portainer roles to Kubernetes roles, see our [roles and bindings documentation](../../advanced/kubernetes-roles-and-bindings.md).



================================================
FILE: admin/user/users.md
================================================
# Users

The **Users** page lists the users configured to access Portainer and allows you to add new users and manage existing users.

{% hint style="info" %}
For management of user roles in Portainer Business Edition, refer to the [Roles](roles.md) section.
{% endhint %}

<figure><img src="../../.gitbook/assets/2.20-users.png" alt=""><figcaption></figcaption></figure>

{% content-ref url="add.md" %}
[add.md](add.md)
{% endcontent-ref %}



================================================
FILE: admin/user/teams/README.md
================================================
# Teams

Use teams to control user access to environments, container and service enablement, and volume control.

{% content-ref url="add.md" %}
[add.md](add.md)
{% endcontent-ref %}

{% content-ref url="add-user.md" %}
[add-user.md](add-user.md)
{% endcontent-ref %}




================================================
FILE: admin/user/teams/add-user.md
================================================
# Add a user to a team

From the menu expand **User-related** then select **Teams**.&#x20;

<figure><img src="../../../.gitbook/assets/2.20-users-teams.gif" alt=""><figcaption></figcaption></figure>

Select the team you want to add users to then click **Add** next to the user.

<figure><img src="../../../.gitbook/assets/2.15-settings-users-teams-adduser.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: admin/user/teams/add.md
================================================
# Add a new team

From the menu expand **User-related** then select **Teams**.&#x20;

<figure><img src="../../../.gitbook/assets/2.20-users-teams.gif" alt=""><figcaption></figcaption></figure>

Enter the name of the team and optionally select team leaders. Team leaders can add and remove existing users to and from their team, as well as promote existing team members to co-team leaders.

{% hint style="warning" %}
If your Portainer installation uses external authentication and teams are synced from your external authentication provider, the team leader role is disabled.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-settings-users-teams-add.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Create team**.



================================================
FILE: advanced/access-control.md
================================================
# Access control

All Docker and Docker Swarm resources (except images) deployed through Portainer have access control settings. You can set these when resources are deployed or at a later time. Resources deployed through a stack or a service will inherit the same access as the parent.

## Resources deployed through Portainer

### Access to administrators only

This is an example access control section, showing access control enabled. With these settings, only Portainer administrators will have access to the resource and any other resources created by it (for example, a stack that creates containers, services, volumes, networks and secrets).

<figure><img src="../.gitbook/assets/2.15-advanced-accesscontrol-admin.png" alt=""><figcaption></figcaption></figure>

### Access to all users

This is an example access control section showing access control disabled. All Portainer users will have access to the resource and any resources created by it.

<figure><img src="../.gitbook/assets/2.15-advanced-accesscontrol-public.png" alt=""><figcaption></figcaption></figure>

### Access restricted to specific groups or users

This is an example access control section showing access control enabled in **Restricted** mode. After you select the Restricted option, you can select more teams and users and give them access to the resource.

<figure><img src="../.gitbook/assets/2.15-advanced-accesscontrol-restricted.png" alt=""><figcaption></figcaption></figure>

## Resources deployed outside of Portainer

Any resources deployed to Docker or Docker Swarm outside of Portainer will be marked as `external` and you will have limited control over these resources. By default, these resources will have administrator-only access, but you can enable access control using these labels (examples used, swap out for your own parameters):

| Label                                       | Access Granted                                                                                                          |
| ------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------- |
| `io.portainer.accesscontrol.public`         | All Portainer users have access to the resource. Takes precedence over team/user assignments.                           |
| `io.portainer.accesscontrol.teams=dev,prod` | Access restricted to teams `dev` and `prod` only. Can be used in conjunction with `io.portainer.accesscontrol.users`    |
| `io.portainer.accesscontrol.users=bob,adam` | Access is restricted to users `bob` and `adam` only. Can be used in conjunction with `io.portainer.accesscontrol.teams` |

### Example 1 <a href="#examples" id="examples"></a>

Deploy a stack using Docker Compose and restrict access to teams `dev` and `prod`:

```
version: '3.2'
services:
    ltest:
        image: busybox:latest
        command: "ping localhost"
        labels:
            io.portainer.accesscontrol.teams: dev,prod
```

### Example 2

Deploy a stack using the Docker CLI and restrict access to team `testers` and users `bob` and `adam`:

```
version: '3.2'
services:
    ltest:
        image: busybox:latest
        command: "ping localhost"
        labels:
            io.portainer.accesscontrol.teams: testers
            io.portainer.accesscontrol.users: bob,adam
```

### Example 3

Deploy a container using the Docker CLI and make it accessible to all Portainer users:

```
docker run -d --label io.portainer.accesscontrol.public nginx:latest
```

### Example 4

Deploy a container using the Docker CLI and restrict access to teams `dev` and `prod` and users `bob`:

```
docker run -d --label io.portainer.accesscontrol.teams=dev,prod --label io.portainer.accesscontrol.users=bob nginx:latest
```



================================================
FILE: advanced/cli.md
================================================
# CLI configuration options

## Configuration flags available at the command line

| Flag                                                   | Description                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| ------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `--admin-password`                                     | Specifies a bcrypt hashed password for the admin user. This can only be used when first creating the admin user (such as during installation) and not to change the admin user's password after installation.                                                                                                                                                                                                                                |
| `--admin-password-file`                                | Specifies the path to the file containing the password for the admin user. This can only be used when first creating the admin user (such as during installation) and not to change the admin user's password after installation.                                                                                                                                                                                                            |
| `--base-url`                                           | <p>Specifies the path that Portainer is running under if you are running Portainer within a subpath behind a reverse proxy (for example use <code>--base-url /portainer</code> if you are running Portainer at <code>https://yourdomain/portainer</code>). Defaults to <code>/</code>.<br><strong>Note:</strong> when using this option you will still need to ensure your reverse proxy configuration will strip the specified subpath.</p> |
| <p><code>--bind</code></p><p><code>-p</code></p>       | Specifies the address and port from which to serve Portainer (default: `:9000`).                                                                                                                                                                                                                                                                                                                                                             |
| `--bind-https`                                         | Specifies the address and port from which to serve Portainer via HTTPS (default: `:9443`).                                                                                                                                                                                                                                                                                                                                                   |
| <p><code>--data</code></p><p><code>-d</code></p>       | Specifes the directory where Portainer data will be stored (default: `/data` on Linux, `C:\data` on Windows).                                                                                                                                                                                                                                                                                                                                |
| `--edge-compute`                                       | Automatically enables Edge Compute features.                                                                                                                                                                                                                                                                                                                                                                                                 |
| <p><code>--hide-label</code></p><p><code>-l</code></p> | Hides containers with a specific label in the UI.                                                                                                                                                                                                                                                                                                                                                                                            |
| `--http-disabled`                                      | Serve Portainer only on HTTPS. Overrides `--http-enabled`. Ensure your HTTPS configuration is fully working and any agents are configured for HTTPS before enabling this.                                                                                                                                                                                                                                                                    |
| `--http-enabled`                                       | Serve Portainer on HTTP. If used in combination with `--http-disabled`, this is ignored.                                                                                                                                                                                                                                                                                                                                                     |
| <p><code>--host</code></p><p><code>-H</code></p>       | Specifies the Docker daemon endpoint.                                                                                                                                                                                                                                                                                                                                                                                                        |
| `--license-key`                                        | Specifies the license key to use. Only applicable to Portainer Business Edition.                                                                                                                                                                                                                                                                                                                                                             |
| `--log-level`                                          | Set the log level of the Portainer application, for example `--log-level DEBUG`. This is useful when troubleshooting. Debug logging can also be enabled through [Settings](../admin/settings/).                                                                                                                                                                                                                                              |
| `--log-mode`                                           | Set the formatting for the Portainer log output, for example `--log-mode NOCOLOR`. Options are: `PRETTY` (default), `NOCOLOR` (disables color codes), `JSON` (JSON-formatted logs).                                                                                                                                                                                                                                                          |
| `--logo`                                               | Specifies the URL to the image to be displayed as a logo in the UI. If not specified, the Portainer logo is used instead.                                                                                                                                                                                                                                                                                                                    |
| `--mtlscacert`                                         | Specifies the path to the certificate authority (CA) certificate used for mTLS communication. (BE only)                                                                                                                                                                                                                                                                                                                                      |
| `--mtlscert`                                           | Specifies the path to the certificate used for mTLS communication. (BE only)                                                                                                                                                                                                                                                                                                                                                                 |
| `--mtlskey`                                            | Specifies the path to the certificate key used for mTLS communication. (BE only)                                                                                                                                                                                                                                                                                                                                                             |
| `--snapshot-interval`                                  | Specifies the time interval between two environment snapshot jobs expressed as a string. For example 30s, 5m, 1h… Supported by the `time.ParseDuration` method (default: 5m).                                                                                                                                                                                                                                                                |
| `--sslcacert`                                          | Specifies the path to the certificate authority (CA) certificate used to validate the Edge Agent certificate. (BE only, **deprecated**, use [mTLS](mtls.md) instead)                                                                                                                                                                                                                                                                         |
| `--sslcert`                                            | Specifies the path to the SSL certificate used to secure the Portainer instance (default: `/certs/portainer.crt` on Linux, `C:\certs\portainer.crt` on Windows).                                                                                                                                                                                                                                                                             |
| `--sslkey`                                             | Specifies the path to the SSL key used to secure the Portainer instance (default: `/certs/portainer.key` on Linux, `C:\certs\portainer.key` on Windows).                                                                                                                                                                                                                                                                                     |
| `--syslog-*`                                           | The `--syslog-*` options are used to configure auth and activity log streaming to an external Syslog-compatible provider. See the [SIEM documentation](siem.md) for more on this experimental feature.                                                                                                                                                                                                                                       |
| <p><code>--templates</code></p><p><code>-t</code></p>  | Specifies the URL to the templates (apps) definitions.                                                                                                                                                                                                                                                                                                                                                                                       |
| `--tlscacert`                                          | Specifies the path to the CA used for Docker daemon connections (default: `/certs/ca.pem` on Linux, `C:\certs\ca.pem` on Windows).                                                                                                                                                                                                                                                                                                           |
| `--tlscert`                                            | Specifies the path to the TLS certificate file used for Docker daemon connections (default: `/certs/cert.pem`, `C:\certs\cert.pem` on Windows).                                                                                                                                                                                                                                                                                              |
| `--tlskey`                                             | Specifies the path to the TLS key used for Docker daemon connections (default: `/certs/key.pem`, `C:\certs\key.pem` on Windows).                                                                                                                                                                                                                                                                                                             |
| `--tlsverify`                                          | TLS support (default: `false`).                                                                                                                                                                                                                                                                                                                                                                                                              |
| `--tlsskipverify`                                      | Disable TLS server verification.                                                                                                                                                                                                                                                                                                                                                                                                             |
| `--trusted-origins`                                    | Specify (in a comma-separated list) the domain(s) used to access Portainer when it is behind a reverse proxy. Use this option if Portainer is behind a reverse proxy and you are getting "Origin invalid" errors.                                                                                                                                                                                                                            |
| `--tunnel-addr`                                        | Specifies the tunnel address to listen on for use with the Edge Agent. Defaults to `0.0.0.0` (all interfaces).                                                                                                                                                                                                                                                                                                                               |
| `--tunnel-port`                                        | Specifies an alternate tunnel port to use with the Edge Agent. Use `--tunnel-port 8001` with `-p 8001:8001` to make the Edge Agent communicate on port `8001`.                                                                                                                                                                                                                                                                               |
| `--version`                                            | Display the version of Portainer.                                                                                                                                                                                                                                                                                                                                                                                                            |

## Creating an admin account and password

{% hint style="info" %}
The commands in this section will automatically create an administrator account called `admin` with the password you specify. This can only be used when first creating the admin user (such as during installation) and not to change the admin user's password after installation.
{% endhint %}

### Method 1: Creating the account from the command line

You can specify a bcrypt-encrypted password from the command line for the admin account. If you have installed the `apache2-utils` package, create the password using the following command:

```
htpasswd -nb -B admin "your-password" | cut -d ":" -f 2
```

If your system does not have that command, use a container to run the command instead:

```
docker run --rm httpd:2.4-alpine htpasswd -nbB admin "your-password" | cut -d ":" -f 2
```

Once the password has been created, specify the admin password from the command line by starting Portainer with the `--admin-password` flag:

{% tabs %}
{% tab title="Business Edition" %}
```
docker run -d -p 9443:9443 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ee:lts --admin-password='$2y$05$8oz75U8m5tI/xT4P0NbSHeE7WyRzOWKRBprfGotwDkhBOGP/u802u'
```
{% endtab %}

{% tab title="Community Edition" %}
```
docker run -d -p 9443:9443 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce:lts --admin-password='$2y$05$8oz75U8m5tI/xT4P0NbSHeE7WyRzOWKRBprfGotwDkhBOGP/u802u'
```
{% endtab %}
{% endtabs %}

### Method 2: Creating the account using a file

You can also store a plain text password inside a file and use the `--admin-password-file` flag. First, add the password to a file using the following example command as a guide:

```
echo -n mypassword > /tmp/portainer_password
```

Next, start the Portainer container:

{% tabs %}
{% tab title="Business Edition" %}
```
docker run -d -p 9443:9443 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock -v /tmp/portainer_password:/tmp/portainer_password portainer/portainer-ee:lts --admin-password-file /tmp/portainer_password
```
{% endtab %}

{% tab title="Community Edition" %}
```
docker run -d -p 9443:9443 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock -v /tmp/portainer_password:/tmp/portainer_password portainer/portainer-ce:lts --admin-password-file /tmp/portainer_password
```
{% endtab %}
{% endtabs %}

This also works well with Docker Swarm and Docker Secrets:

```
echo -n mypassword | docker secret create portainer-pass -
```

{% tabs %}
{% tab title="Business Edition" %}
```
docker service create \
    --name portainer \
    --secret portainer-pass \
    --publish 9443:9443 \
    --publish 8000:8000 \
    --replicas=1 \
    --constraint 'node.role == manager' \
    --mount type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \
    portainer/portainer-ee:lts \
    --admin-password-file '/run/secrets/portainer-pass' \
    -H unix:///var/run/docker.sock
```
{% endtab %}

{% tab title="Community Edition" %}
```
docker service create \
    --name portainer \
    --secret portainer-pass \
    --publish 9443:9443 \
    --publish 8000:8000 \
    --replicas=1 \
    --constraint 'node.role == manager' \
    --mount type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \
    portainer/portainer-ce:lts \
    --admin-password-file '/run/secrets/portainer-pass' \
    -H unix:///var/run/docker.sock
```
{% endtab %}
{% endtabs %}

## Hiding specific containers

Portainer lets you hide containers with a specific label by using the `-l` flag. Here's an example showing a container labeled `owner=acme`:

```
docker run -d --label owner=acme nginx
```

To hide this container, when starting Portainer add the `-l owner=acme` option on the CLI:

{% tabs %}
{% tab title="Business Edition" %}
```
docker run -d -p 9443:9443 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ee:lts -l owner=acme
```
{% endtab %}

{% tab title="Community Edition" %}
```
docker run -d -p 9443:9443 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce:lts -l owner=acme
```
{% endtab %}
{% endtabs %}

To hide multiple containers, repeat the `-l` flag:

{% tabs %}
{% tab title="Business Edition" %}
```
docker run -d -p 9443:9443 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ee:lts -l owner=acme -l service=secret
```
{% endtab %}

{% tab title="Community Edition" %}
```
docker run -d -p 9443:9443 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce:lts -l owner=acme -l service=secret
```
{% endtab %}
{% endtabs %}

## Using your own logo

{% hint style="info" %}
Images must be exactly 155px by 55px in size.
{% endhint %}

Replace our logo with your own using the `--logo` flag to specify the location of the image file:

{% tabs %}
{% tab title="Business Edition" %}
```
docker run -d -p 9443:9443 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ee:lts --logo "https://www.docker.com/sites/all/themes/docker/assets/images/brand-full.svg"
```
{% endtab %}

{% tab title="Community Edition" %}
```
docker run -d -p 9443:9443 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce:lts --logo "https://www.docker.com/sites/all/themes/docker/assets/images/brand-full.svg"
```
{% endtab %}
{% endtabs %}

You can also update the logo in the Portainer UI (**Settings** menu).

## Defining your own app templates

{% hint style="info" %}
We suggest hosting template files on [GitHub](https://www.github.com/) so Portainer can access them without authentication.
{% endhint %}

Portainer allows you to rapidly [deploy containers using app templates](../user/docker/templates/deploy-container.md). By default, Portainer templates will be used but you can also define your own.

Templates are loaded once when Portainer is first started. If you already deployed a Portainer instance then decide to use your own templates, you’ll need to clear the default templates either in the user interface or through the HTTP API. Use the `--templates` flag to specify a URL where the template file can be accessed via HTTP.

{% tabs %}
{% tab title="Business Edition" %}
```
docker run -d -p 9443:9443 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ee:lts --templates http://my-host.my-domain/templates.json
```
{% endtab %}

{% tab title="Community Edition" %}
```
docker run -d -p 9443:9443 -p 8000:8000 -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce:lts --templates http://my-host.my-domain/templates.json
```
{% endtab %}
{% endtabs %}



================================================
FILE: advanced/db-encryption.md
================================================
# Encrypting the Portainer database

Portainer uses a BoltDB database to store the configuration, kept in the `portainer_data` volume created during installation. This database can be encrypted for additional security through the use of a secret provided when the Portainer Server is started. Encryption can be added during the initial installation or at a later date.

{% hint style="warning" %}
At present, encryption of the database is not reversible.
{% endhint %}

## Docker Standalone

To enable encryption on Docker Standalone, you will first need to create a secret key, then modify your docker run command to mount the secret in the container.

### Create a secret

Create a text file on the system running Docker Standalone that is accessible to the Docker executable, yet somewhere secure. For this example, we'll assume the file is called `/root/secrets/portainer`. In this file enter a secret. This will be the key used to encrypt the Portainer database.

### Mount the secret

If Portainer is already running, you will need to stop and remove the Portainer container before continuing:

```
docker stop portainer
docker rm portainer
```

To encrypt the database, add a bind mount to the `docker run` command that mounts your secret in `/run/secrets/portainer`:

```
-v /root/secrets/portainer:/run/secrets/portainer
```

Your final `docker run` command may look like this:

```
docker run -d -p 8000:8000 -p 9443:9443 --name portainer \
    --restart=always \
    -v /var/run/docker.sock:/var/run/docker.sock \
    -v portainer_data:/data \
    -v /root/secrets/portainer:/run/secrets/portainer \
    portainer/portainer-ee:lts
```

When the Portainer container starts, it will encrypt any existing database, or for a fresh install will create a new encrypted database as part of the install process.

## Docker Swarm

To enable encryption on Docker Swarm, you will first need to create a secret. You will then either update the service to incorporate the new secret (if you have an existing Portainer installation) or edit the compose file used to create the stack to include the secret (if this is a fresh installation of Portainer).

### Create a secret

On a manager node, you can run the following command to create a secret:

```
echo "This is a secret" | docker secret create portainer -
```

Replace `This is a secret` with your secret. This will create a secret named `portainer`, which will be the key used to encrypt the Portainer database.

{% hint style="info" %}
You can also create a secret in Portainer if you are adding encryption to an existing installation.
{% endhint %}

### Existing installations: Update the service

To add encryption to an existing Portainer deployment on Docker Swarm, you can use the following command on a manager node:

```
docker service update \
    --secret-add src=portainer,target="/run/secrets/portainer" \
    portainer
```

The service will add the new secret and encrypt the database.

### New installations: Edit the compose file

To install Portainer on Docker Swarm with encryption, you will need to edit the compose file you downloaded as part of the installation process. Add a secrets section to the `portainer` service definition:

```
secrets:
  - portainer
```

This tells the service to use the `portainer` secret created earlier.

In addition, because we created it separately earlier we will need to specify it as `external` so that Docker knows not to create it when creating the stack. To do this we add a `secrets:` definition outside of the `services:` definition for the `portainer` secret:

```
secrets:
  portainer:
    external: true
```

With the secret added, your full Portainer stack file may look like this:

```
version: '3.2'

services:
  agent:
    image: portainer/agent:lts
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/lib/docker/volumes:/var/lib/docker/volumes
    networks:
      - agent_network
    deploy:
      mode: global
      placement:
        constraints: [node.platform.os == linux]

  portainer:
    image: portainer/portainer-ee:lts
    command: -H tcp://tasks.agent:9001 --tlsskipverify
    ports:
      - "9443:9443"
      - "9000:9000"
      - "8000:8000"
    volumes:
      - portainer_data:/data
    networks:
      - agent_network
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.role == manager]
    secrets:
      - portainer

networks:
  agent_network:
    driver: overlay
    attachable: true

volumes:
  portainer_data:
      
secrets:
  portainer:
    external: true
```

Save your changes, then use the compose file to deploy your Portainer installation as covered in the Swarm installation instructions. The database will be deployed encrypted as part of the installation process.

## Kubernetes

To enable encryption on Kubernetes you will first need to create a secret. You will then mount this secret as a volume in Portainer.

### Create a secret

From the command line on your Kubernetes cluster, you can run the following command to create your secret:

```
kubectl create secret generic portainer-key --from-literal=secret=IAmASecretKey --namespace portainer
```

Replace `IAmASecretKey` with your secret. This will create a secret named `portainer-key`, which will be the key used to encrypt the Portainer database.

### Modify the YAML file

Once the secret has been created, we need to modify the YAML file to mount the secret as a volume in Portainer. Download the YAML file for your particular deployment and locate the `container` definition for the `portainer` container. It should look something like this:

```
containers:
  - name: portainer
    image: "portainer/portainer-ee:lts"
    imagePullPolicy: Always
    args:          
    volumeMounts:
      - name: data
        mountPath: /data  
```

In the `volumeMounts` section, add a definition for the secret created earlier:

```
volumeMounts:
  - name: data
    mountPath: /data
  - name: portainer-key
    mountPath: /run/secrets/portainer
    subPath: portainer
```

We also need to add a definition to the `volumes` definition for the `spec`:

```
spec:
  containers:
    portainer:
    ...
  volumes:
    - name: portainer-key
      secret:
        secretName: portainer-key
        items:
          - key: secret
            path: portainer
      
```

Save the file, then apply it to your running configuration:

```
kubectl apply -f portainer.yaml
```

Replace `portainer.yaml` with the name of your modified YAML file.



================================================
FILE: advanced/deprecated.md
================================================
# Deprecated and removed features

This table lists deprecated and removed features and functionality that are no longer supported and should not be used. The **Deprecated** column shows the release in which the feature was tagged as deprecated. The **Remove** column shows the release in which the feature was or will be removed (TBD means 'to be decided').

| Feature                                                                          | Deprecated | Remove |
| -------------------------------------------------------------------------------- | ---------- | ------ |
| `PUT /kubernetes/{id}/namespaces` API endpoint                                   | 2.25.0     | TBD    |
| Nomad support                                                                    | 2.20.0     | 2.20.0 |
| Enabling SSL via `--ssl` (now enabled by default)                                | 2.9.0      | TBD    |
| Disabling analytics via `--no-analytics`                                         | 2.0        | TBD    |
| Kompose deployments                                                              | 2.15.0     | 2.17.0 |
| Specifying external environments in JSON via `--external-endpoints`              |            | 2.0    |
| Setting time between environment synchronization requests via `--sync-interval`  |            | 2.0    |
| Disabling Portainer internal authentication via `--no-auth`                      |            | 2.0    |
| Specifying a templates file to load on first run via `--templates-file`          |            | 2.0    |
| Preventing Portainer from running a snapshot of environments via `--no-snapshot` |            | 2.0    |



================================================
FILE: advanced/docker-roles-and-permissions.md
================================================
# Docker roles and permissions

This document describes the permission levels each [RBAC role](../admin/user/roles.md) has within the Portainer application for both Docker Standalone and Docker Swarm environments. Refer to the linked notes for further requirements on each operation.

{% hint style="info" %}
Role-Based Access Control is only available in Portainer Business Edition.
{% endhint %}

## Legend

<table><thead><tr><th width="145">Abbreviation</th><th>Role name</th></tr></thead><tbody><tr><td>EA</td><td>Environment Administrator</td></tr><tr><td>OP</td><td>Operator</td></tr><tr><td>HD</td><td>Helpdesk</td></tr><tr><td>ST</td><td>Standard user</td></tr><tr><td>RO</td><td>Read-only user</td></tr></tbody></table>

## Roles and permissions

### Templates

<table><thead><tr><th width="352">Operation</th><th width="62" data-type="checkbox">EA</th><th width="58" data-type="checkbox">OP</th><th width="58" data-type="checkbox">HD</th><th width="55" data-type="checkbox">ST</th><th width="58" data-type="checkbox">RO</th><th>Notes</th></tr></thead><tbody><tr><td>View app templates</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td></td></tr><tr><td>Deploy app templates</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td></td></tr><tr><td>View custom templates</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Create custom templates</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td></td></tr><tr><td>Deploy custom templates</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Edit custom templates</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Change custom template ownership</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Delete custom template</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr></tbody></table>

### Stacks

Access to these operations can be affected by the **Disable the use of Stacks for non-administrators** security setting ([Docker](../user/docker/host/setup.md#docker-security-settings), [Swarm](../user/docker/swarm/setup.md#docker-security-settings)).

<table><thead><tr><th width="352">Operation</th><th width="62" data-type="checkbox">EA</th><th width="58" data-type="checkbox">OP</th><th width="57" data-type="checkbox">HD</th><th width="55" data-type="checkbox">ST</th><th width="58" data-type="checkbox">RO</th><th>Notes</th></tr></thead><tbody><tr><td>View stacks</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Create a stack</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">3</a></td></tr><tr><td>Edit a stack</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>View stack details</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Change stack ownership</td><td>true</td><td>true</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Stop a stack</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Start a stack</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Duplicate a stack</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Migrate a stack</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Create template from a stack</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Update service in stack</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a>, <a href="docker-roles-and-permissions.md#notes">2</a></td></tr><tr><td>Remove service from stack</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a>, <a href="docker-roles-and-permissions.md#notes">2</a></td></tr><tr><td>Delete a stack</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr></tbody></table>

### Services

These operations are only relevant for Docker Swarm environments.

<table><thead><tr><th width="352">Operation</th><th width="62" data-type="checkbox">EA</th><th width="58" data-type="checkbox">OP</th><th width="58" data-type="checkbox">HD</th><th width="55" data-type="checkbox">ST</th><th width="58" data-type="checkbox">RO</th><th>Notes</th></tr></thead><tbody><tr><td>View services</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Create service</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">3.5</a></td></tr><tr><td>View service details</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Edit service</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a>, <a href="docker-roles-and-permissions.md#notes">3.5</a></td></tr><tr><td>Update service</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Roll back service</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>View service logs</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Change service ownership</td><td>true</td><td>true</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Delete service</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr></tbody></table>

### Containers

<table><thead><tr><th width="352">Operation</th><th width="62" data-type="checkbox">EA</th><th width="58" data-type="checkbox">OP</th><th width="59" data-type="checkbox">HD</th><th width="55" data-type="checkbox">ST</th><th width="58" data-type="checkbox">RO</th><th>Notes</th></tr></thead><tbody><tr><td>View containers</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Create container</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">3</a></td></tr><tr><td>Build an image from a container</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>View container details</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Start container</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Stop container</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Kill container</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Restart container</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Pause container</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Resume container</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Edit container</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a>, <a href="docker-roles-and-permissions.md#notes">3</a></td></tr><tr><td>Duplicate container</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a>, <a href="docker-roles-and-permissions.md#notes">3</a></td></tr><tr><td>Recreate container</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a>, <a href="docker-roles-and-permissions.md#notes">3</a></td></tr><tr><td>Container console</td><td>true</td><td>true</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Container attach</td><td>true</td><td>true</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Join container to network</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Remove container from network</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>View container logs</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Change container ownership</td><td>true</td><td>true</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Delete container</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr></tbody></table>

### Images

<table><thead><tr><th width="352">Operation</th><th width="62" data-type="checkbox">EA</th><th width="58" data-type="checkbox">OP</th><th width="58" data-type="checkbox">HD</th><th width="55" data-type="checkbox">ST</th><th width="58" data-type="checkbox">RO</th><th>Notes</th></tr></thead><tbody><tr><td>View images</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td></td></tr><tr><td>Pull an image</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td></td></tr><tr><td>Push an image</td><td>true</td><td>false</td><td>false</td><td>false</td><td>false</td><td></td></tr><tr><td>Build an image</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td></td></tr><tr><td>Import an image</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td></td></tr><tr><td>View image details</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td></td></tr><tr><td>Add tag to image</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td></td></tr><tr><td>Remove tag from image</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td></td></tr><tr><td>Export image</td><td>true</td><td>false</td><td>false</td><td>false</td><td>false</td><td></td></tr><tr><td>Delete an image</td><td>true</td><td>false</td><td>false</td><td>false</td><td>false</td><td></td></tr></tbody></table>

### Volumes

<table><thead><tr><th width="352">Operation</th><th width="62" data-type="checkbox">EA</th><th width="58" data-type="checkbox">OP</th><th width="58" data-type="checkbox">HD</th><th width="55" data-type="checkbox">ST</th><th width="58" data-type="checkbox">RO</th><th>Notes</th></tr></thead><tbody><tr><td>View volumes</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Create a volume</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td></td></tr><tr><td>View volume details</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Browse a volume</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a>, <a href="docker-roles-and-permissions.md#notes">4</a></td></tr><tr><td>Change volume ownership</td><td>true</td><td>true</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Delete a volume</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr></tbody></table>

### Networks

<table><thead><tr><th width="352">Operation</th><th width="62" data-type="checkbox">EA</th><th width="58" data-type="checkbox">OP</th><th width="58" data-type="checkbox">HD</th><th width="55" data-type="checkbox">ST</th><th width="58" data-type="checkbox">RO</th><th>Notes</th></tr></thead><tbody><tr><td>View networks</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Create a network</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td></td></tr><tr><td>View network details</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Change network ownership</td><td>true</td><td>true</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Delete a network</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr></tbody></table>

### Events

These operations are only relevant for Docker Standalone environments.

<table><thead><tr><th width="352">Operation</th><th width="62" data-type="checkbox">EA</th><th width="58" data-type="checkbox">OP</th><th width="57" data-type="checkbox">HD</th><th width="55" data-type="checkbox">ST</th><th width="58" data-type="checkbox">RO</th><th>Notes</th></tr></thead><tbody><tr><td>View events</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td></td></tr></tbody></table>

### Configs

These operations are only relevant for Docker Swarm environments.

<table><thead><tr><th width="352">Operation</th><th width="62" data-type="checkbox">EA</th><th width="58" data-type="checkbox">OP</th><th width="57" data-type="checkbox">HD</th><th width="55" data-type="checkbox">ST</th><th width="58" data-type="checkbox">RO</th><th>Notes</th></tr></thead><tbody><tr><td>View configs</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Create a config</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td></td></tr><tr><td>View config details</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Clone a config</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Change config ownership</td><td>true</td><td>true</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Delete a config</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr></tbody></table>

### Secrets

These operations are only relevant for Docker Swarm environments.

<table><thead><tr><th width="352">Operation</th><th width="62" data-type="checkbox">EA</th><th width="58" data-type="checkbox">OP</th><th width="58" data-type="checkbox">HD</th><th width="55" data-type="checkbox">ST</th><th width="58" data-type="checkbox">RO</th><th>Notes</th></tr></thead><tbody><tr><td>View secrets</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Create a secret</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td></td></tr><tr><td>View secret details</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Change secret ownership</td><td>true</td><td>true</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Delete a secret</td><td>true</td><td>false</td><td>false</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr></tbody></table>

### Host

These operations are only relevant for Docker Standalone environments.

<table><thead><tr><th width="352">Operation</th><th width="62" data-type="checkbox">EA</th><th width="58" data-type="checkbox">OP</th><th width="58" data-type="checkbox">HD</th><th width="55" data-type="checkbox">ST</th><th width="58" data-type="checkbox">RO</th><th>Notes</th></tr></thead><tbody><tr><td>View host details</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td></td></tr></tbody></table>

### Swarm

These operations are only relevant for Docker Swarm environments.

<table><thead><tr><th width="352">Operation</th><th width="62" data-type="checkbox">EA</th><th width="58" data-type="checkbox">OP</th><th width="58" data-type="checkbox">HD</th><th width="55" data-type="checkbox">ST</th><th width="58" data-type="checkbox">RO</th><th>Notes</th></tr></thead><tbody><tr><td>View cluster details</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td></td></tr></tbody></table>

### Registries

<table><thead><tr><th width="352">Operation</th><th width="62" data-type="checkbox">EA</th><th width="58" data-type="checkbox">OP</th><th width="58" data-type="checkbox">HD</th><th width="55" data-type="checkbox">ST</th><th width="58" data-type="checkbox">RO</th><th>Notes</th></tr></thead><tbody><tr><td>Read registry</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Browse registry</td><td>true</td><td>true</td><td>true</td><td>true</td><td>true</td><td><a href="docker-roles-and-permissions.md#notes">1</a></td></tr><tr><td>Update repositories</td><td>true</td><td>true</td><td>true</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">5</a></td></tr><tr><td>Delete repositories</td><td>true</td><td>true</td><td>true</td><td>true</td><td>false</td><td><a href="docker-roles-and-permissions.md#notes">5</a></td></tr></tbody></table>



## Notes

1. Standard / Read only users (and Operators in the case of ownership operations) have permission only if they are given access to the resource. This can be inherited, for example inheriting a service from a stack.
2. This operation is only relevant for Swarm environments.
3. This operation can be affected by the following security settings ([Docker](../user/docker/host/setup.md#docker-security-settings), [Swarm](../user/docker/swarm/setup.md#docker-security-settings)):
   1. **Disable privileged mode for non-administrators**
   2. **Disable the use of host PID 1 for non-administrators**
   3. **Disable device mappings for non-administrators**
   4. **Disable container capabilities for non-administrators**
   5. **Disable bind mounts for non-administrators**
4. This operation can be affected by the **Enable volume management for non-administrators** setting ([Docker](../user/docker/host/setup.md#enable-volume-management-for-non-administrators), [Swarm](../user/docker/swarm/setup.md#host-and-filesystem)), and requires the use of the Portainer Agent.
5. This operation can only be performed under the allowed registry.



================================================
FILE: advanced/edge-agent.md
================================================
# The Portainer Edge Agent

## The back story


For standard deployments, we used to assume that the Portainer instance and any environments shared the same network and could communicate seamlessly. If remote environments were on a different network (say, across the Internet) we could not manage them.

Then we changed the Edge agent architecture so only the environments need to access Portainer. There is now no need to expose the Portainer agents to the Internet.

Portainer now requires that only the `9443` and `8000` TCP ports are exposed. We used to serve the UI and the Portainer API from port `9000`, but we extended the API to allow the remote agents to poll for instructions. Port `8000` is a TLS tunnel server used to create a secure tunnel between the agent and the Portainer instance. More about that soon.

{% hint style="warning" %}
If your Portainer instance is deployed with TLS, the agent will use HTTPS for the connection it makes back to Portainer. However, if your Portainer instance uses a self-signed certificate, the Edge Agent must be deployed with the `-e EDGE_INSECURE_POLL=1` flag. If you do not deploy the Edge Agent with this flag, the agent won't be able to communicate with the Portainer instance.
{% endhint %}

## Creating an Edge Agent in Portainer


When you create an Edge Agent, you are first asked for a human-friendly endpoint name. You are then asked to confirm the FQDN:PORT of your Portainer instance. This is what agents will use to connect, so make sure it’s correct and that the DNS resolves.

During the creation process, an Edge ID is dynamically generated. This is a random UUID which is assigned to each environment. You can see it in the command syntax which is provided during the setup process.

<figure><img src="../.gitbook/assets/2.15-advanced-edgeagent-command.png" alt=""><figcaption></figcaption></figure>


The Edge ID and the join token are unique per environment. The join token (`EDGE_KEY`) is made up of the following base64 encoded data separated by the pipe (`|`) character:

* The Portainer instance API URL. This is how the Edge Agent knows how to ‘call home’ to your Portainer instance.
* The Portainer instance reverse tunnel server address. This is identical to the API URL (unless [changed during deployment](../admin/environments/add/docker/edge.md#deploying) or in [Edge Compute settings](../admin/settings/edge.md#edge-compute-settings)) but with the tunnel server port (`8000` is the default).
* The Portainer instance reverse-tunnel server fingerprint (prevents MITM when creating a tunnel).
* The environment identifier key (endpoint / environment ID).

Use the command syntax to deploy an Edge Agent across your remote node or remote swarm cluster.

## How Portainer and the Edge Agent communicate

### Polling



Agents poll the Portainer instance every 5 seconds by default (this is defined in Portainer settings).

### Connection process and checks

The agent says to Portainer, “Hi, I'm an agent. My join token is `abc123`. Do you need me right now?”. Portainer checks its database to ensure the Edge UUID and the join token match. If no UUID can be associated with the join token provided, Portainer will associate the UUID provided by the agent to the environment’s join token.

If the UUID/join token do not match, the connection is rejected. If the UUID/join token match, the Portainer instance responds with either: "No, I don’t need you. Please check in again in X seconds." (where X is the agent polling frequency), or "Yes, I do need you. Please connect using these tunnel credentials.”.

{% hint style="info" %}
Portainer encrypts the tunnel credentials using the Edge UUID as the encryption key (intended as one-time-use credentials).
{% endhint %}

### Opening a tunnel between the agent and Portainer

Once confirmation is received, the Edge Agent decrypts the credentials and opens a tunnel on port `8000` to the Portainer instance. If a remote environment is a swarm cluster, every node will run an instance of the agent (and every instance will poll Portainer). The 'you are required' flag causes the first agent in the cluster to establish the tunnel. Once in place, Portainer can then query the agent where the tunnel is open. If the tunnel closes for any reason, the agent will immediately re-establish it.

### When Portainer forces the Edge Agent to establish a tunnel

Sometimes Portainer will ask the agent to establish a tunnel. This happens when an admin selects an Edge environment for interactive management via the Portainer UI or the API. Once selected, the 'you are required' flag triggers the connection process. If default settings are in use, it takes about 10 seconds for the agent to poll and establish a tunnel. That’s about 5 seconds wait time until polling then a few seconds for the tunnel to open. The admin is shown this message while this happens:

<div align="center"><img src="../.gitbook/assets/edge-advanced-2.png" alt=""></div>

### Terminating the connection

The agent keeps a record of when Portainer last communicated with it. After 5 minutes of inactivity, it sends a snapshot of the current config to Portainer for its records, closes the tunnel and revokes the credentials. When admins have an active session with an Edge environment, ‘keep alives’ are sent every minute (even if the admin is not performing a task) so they are not kicked out by mistake.

## Network performance

### Adjusting the polling frequency to improve performance

Thousands of endpoints polling Portainer every 5 seconds is a lot. That’s about 324b/second per agent, not per environment. If you don’t do a lot of environment admin, we suggest you go into Portainer settings and increase the polling frequency. Simply change it back when you need to do some admin so you are not kept waiting.

<figure><img src="../.gitbook/assets/2.15-advanced-edgeagent-pollfreq.png" alt=""><figcaption></figcaption></figure>

### Ongoing improvements

We load-tested Portainer with 15,000 actively connected environments with a polling frequency of 5 seconds. This generated 7Mbps of network traffic to the Portainer instance, and Portainer needed 4 CPUs to handle the encryption/tunnel load. This Edge Agent release is our first attempt at massive-scale centralized management. Our end goal is to reduce the network overhead associated with polling.



================================================
FILE: advanced/helm-chart-configuration-options.md
================================================
# Helm chart configuration options

The following table lists the configurable parameters of the Portainer Helm chart and their default values. Find the values file under `deploy/helm/portainer/values.yaml`.

| Parameter                    | Description                                                                                               | Default                     |
| ---------------------------- | --------------------------------------------------------------------------------------------------------- | --------------------------- |
| `replicaCount`               | Number of Portainer service replicas (always set to 1).                                                   | `1`                         |
| `image.repository`           | Portainer Docker Hub repository.                                                                          | `portainer/portainer-ce`    |
| `image.tag`                  | Tag for the Portainer image.                                                                              | `latest`                    |
| `image.pullPolicy`           | Portainer image-pulling policy.                                                                           | `IfNotPresent`              |
| `imagePullSecrets`           | If the Portainer image needs to be in a private repository.                                               | `nil`                       |
| `nodeSelector`               | Used to apply a nodeSelector to the deployment.                                                           | `{}`                        |
| `serviceAccount.annotations` | Annotations to add to the service account.                                                                | `null`                      |
| `serviceAccount.name`        | The name of the service account to use.                                                                   | `portainer-sa-clusteradmin` |
| `service.type`               | Service type for the main Portainer Service. Valid values: `ClusterIP`, `NodePort`, `LoadBalancer`.       | `LoadBalancer`              |
| `service.httpPort`           | HTTP port for accessing the Portainer web interface.                                                      | `9000`                      |
| `service.httpNodePort`       | Static NodePort for accessing the Portainer web interface. Specify only if the type is `NodePort`.        | `30777`                     |
| `service.edgePort`           | TCP port for accessing Portainer Edge.                                                                    | `8000`                      |
| `service.edgeNodePort`       | Static NodePort for accessing Portainer Edge. Specify only if the type is `NodePort`.                     | `30776`                     |
| `service.annotations`        | Annotations to add to the service.                                                                        | `{}`                        |
| `ingress.enabled`            | Creates an ingress for Portainer.                                                                         | `false`                     |
| `ingress.annotations`        | <p>Annotations to add to the ingress. For example:<br><code>kubernetes.io/ingress.class: nginx</code></p> | `{}`                        |
| `ingress.hosts.host`         | URL for Portainer Web. For example, `portainer.example.io`.                                               | `nil`                       |
| `ingress.hosts.paths.path`   | Path for the Portainer web interface.                                                                     | `/`                         |
| `ingress.hosts.paths.port`   | Port for the Portainer web interface.                                                                     | `9000`                      |
| `ingress.tls`                | TLS support on ingress. Must create a secret with TLS certificates in advance.                            | `[]`                        |
| `resources`                  | Portainer resource requests and limits.                                                                   | `{}`                        |
| `persistence.enabled`        | Whether or not to enable data persistence.                                                                | `true`                      |
| `persistence.existingClaim`  | Name of an existing PVC to use for data persistence.                                                      | `nil`                       |
| `persistence.size`           | Size of the PVC used for persistence.                                                                     | `10Gi`                      |
| `persistence.annotations`    | Annotations to apply to PVC used for persistence.                                                         | `{}`                        |
| `persistence.storageClass`   | StorageClass to apply to PVC used for persistence.                                                        | `default`                   |
| `persistence.accessMode`     | AccessMode for persistence.                                                                               | `ReadWriteOnce`             |
| `persistence.selector`       | Selector for persistence.                                                                                 | `nil`                       |



================================================
FILE: advanced/kubernetes-roles-and-bindings.md
================================================
# Kubernetes roles and bindings

{% hint style="info" %}
Role-Based Access Control is only available in Portainer Business Edition.
{% endhint %}

When managing a Kubernetes environment with Portainer, the Role-Based Access Control (RBAC) configuration is based on two components:

* Kubernetes' cluster roles and namespace roles (which restrict access to Kubernetes itself)
* Portainer's authorization flags (which [restrict access](kubernetes-roles-and-bindings.md#portainer-access-restrictions) to Portainer's functionality)

The following tables provide a reference for how our Portainer roles map to capabilities within Kubernetes.

## Role Allocations <a href="#role-allocations" id="role-allocations"></a>

| Portainer Role            | Cluster Role Binding                                                                                                                                 | Namespace Role Binding                                                                                                                                          |
| ------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Environment Administrator | cluster-admin (k8s system)                                                                                                                           | N/A                                                                                                                                                             |
| Operator                  | [portainer-operator](kubernetes-roles-and-bindings.md#portainer-operator), [portainer-helpdesk](kubernetes-roles-and-bindings.md#portainer-helpdesk) | [portainer-view](kubernetes-roles-and-bindings.md#portainer-view) (all non-system namespaces)                                                                   |
| User                      | [portainer-basic](kubernetes-roles-and-bindings.md#portainer-basic)                                                                                  | [portainer-edit](kubernetes-roles-and-bindings.md#portainer-edit), [portainer-view](kubernetes-roles-and-bindings.md#portainer-view) (only assigned namespaces) |
| Helpdesk                  | [portainer-helpdesk](kubernetes-roles-and-bindings.md#portainer-helpdesk)                                                                            | [portainer-view](kubernetes-roles-and-bindings.md#portainer-view) (all non-system namespaces)                                                                   |
| Read-Only                 | [portainer-basic](kubernetes-roles-and-bindings.md#portainer-basic)                                                                                  | [portainer-view](kubernetes-roles-and-bindings.md#portainer-view) (only assigned namespaces)                                                                    |

## Cluster Roles <a href="#cluster-roles" id="cluster-roles"></a>

### portainer-basic <a href="#portainer-basic" id="portainer-basic"></a>

| API Group         | Resources               | Verbs     |
| ----------------- | ----------------------- | --------- |
| (Empty)           | namespaces, nodes       | get, list |
| storage.k8s.io    | storageclasses          | list      |
| metrics.k8s.io    | namespaces, pods, nodes | get, list |
| networking.k8s.io | ingressclasses          | list      |

### portainer-helpdesk <a href="#portainer-helpdesk" id="portainer-helpdesk"></a>

| API Group         | Resources                                               | Verbs            |
| ----------------- | ------------------------------------------------------- | ---------------- |
| (Empty)           | componentstatuses, endpoints, events, namespaces, nodes | get, list, watch |
| storage.k8s.io    | storageclasses                                          | get, list, watch |
| networking.k8s.io | ingresses                                               | get, watch       |
| networking.k8s.io | ingressclasses                                          | list             |
| metrics.k8s.io    | pods, nodes, nodes/stats, namespace                     | get, list, watch |

### portainer-operator <a href="#portainer-operator" id="portainer-operator"></a>

| API Group      | Resources                             | Verbs            |
| -------------- | ------------------------------------- | ---------------- |
| (Empty)        | configmaps                            | update           |
| (Empty)        | pods                                  | delete           |
| apps           | daemonsets, deployments, statefulsets | patch            |
| metrics.k8s.io | pods, nodes, nodes/stats, namespaces  | get, list, watch |

## Namespace Roles <a href="#namespace-roles" id="namespace-roles"></a>

### portainer-edit <a href="#portainer-edit" id="portainer-edit"></a>

| API Group         | Resources                                                                                                                                                                                                           | Verbs                                           |
| ----------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------- |
| (Empty)           | configmaps, endpoints, persistentvolumeclaims, pods, pods/attach, pods/exec, pods/portforward, pods/proxy, replicationcontrollers, replicationcontrollers/scale, secrets, serviceaccounts, services, services/proxy | create, delete, deletecollection, patch, update |
| (Empty)           | pods/attach, pods/exec, pods/portforward, pods/proxy, secrets, services/proxy                                                                                                                                       | get, list, watch                                |
| apps              | daemonsets, deployments, deployments/rollback, deployments/scale, replicasets, replicasets/scale, statefulsets, statefulsets/scale                                                                                  | create, delete, deletecollection, patch, update |
| autoscaling       | horizontalpodautoscalers                                                                                                                                                                                            | create, delete, deletecollection, patch, update |
| batch             | cronjobs, jobs                                                                                                                                                                                                      | create, delete, deletecollection, patch, update |
| extensions        | daemonsets, deployments, deployments/rollback, deployments/scale, ingresses, networkpolicies, replicasets, replicasets/scale, replicationcontrollers/scale                                                          | create, delete, deletecollection, patch, update |
| networking.k8s.io | ingresses, networkpolicies                                                                                                                                                                                          | create, delete, deletecollection, patch, update |
| policy            | poddisruptionbudgets                                                                                                                                                                                                | create, delete, deletecollection, patch, update |

### portainer-view <a href="#portainer-view" id="portainer-view"></a>

| API Group         | Resources                                                                                                                                                                                                                                                                                                                                                                   | Verbs            |
| ----------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------- |
| (Empty)           | bindings, componentstatuses, configmaps, endpoints, events, limitranges, namespaces, namespaces/status, persistentvolumeclaims, persistentvolumeclaims/status, pods, pods/log, pods/status, replicationcontrollers, replicationcontrollers/scale, replicationcontrollers/status, resourcequotas, resourcequotas/status, secrets, serviceaccounts, services, services/status | get, list, watch |
| apps              | controllerrevisions, daemonsets, daemonsets/status, deployments, deployments/scale, deployments/status, replicasets, replicasets/scale, replicasets/status, statefulsets, statefulsets/scale, statefulsets/status                                                                                                                                                           | get, list, watch |
| autoscaling       | horizontalpodautoscalers, horizontalpodautoscalers/status                                                                                                                                                                                                                                                                                                                   | get, list, watch |
| batch             | cronjobs, cronjobs/status, jobs, jobs/status                                                                                                                                                                                                                                                                                                                                | get, list, watch |
| extensions        | daemonsets, daemonsets/status, deployments, deployments/scale, deployments/status, ingresses, ingresses/status, networkpolicies, replicasets, replicasets/scale, replicasets/status, replicationcontrollers/scale                                                                                                                                                           | get, list, watch |
| networking.k8s.io | ingresses, ingresses/status, networkpolicies                                                                                                                                                                                                                                                                                                                                | get, list, watch |
| policy            | poddisruptionbudgets, poddisruptionbudgets/status                                                                                                                                                                                                                                                                                                                           | get, list, watch |

## Portainer Access Restrictions <a href="#portainer-access-restrictions" id="portainer-access-restrictions"></a>

| Function                    | Endpoint admin | Operator           | Helpdesk           | Standard User      | Read-only User     |
| --------------------------- | -------------- | ------------------ | ------------------ | ------------------ | ------------------ |
| Namespace Scope             | All            | All, EXCEPT System | All, EXCEPT System | Default + Assigned | Default + Assigned |
| Namespaces                  | RW             | R                  | R                  | R                  | R                  |
| Namespace Details           | RW             | R                  | R                  | R                  | R                  |
| Namespace Access Management | RW             |                    |                    |                    |                    |
| Applications                | RW             | R                  | R                  | RW                 | R                  |
| Application Details         | RW             | R                  | R                  | RW                 | R                  |
| Pod Delete                  | Yes            | Yes                |                    |                    |                    |
| Application Console         | RW             | RW                 |                    |                    |                    |
| Advanced Deployment         | RW             |                    |                    | RW                 |                    |
| ConfigMaps & Secrets        | RW             | R                  | R                  | RW                 | R                  |
| ConfigMap & Secret Details  | RW             | RW                 | R                  | RW                 | R                  |
| Volumes                     | RW             | R                  | R                  | RW                 | R                  |
| Volume Details              | RW             | R                  | R                  | RW                 | R                  |
| Cluster                     | RW             | R                  | R                  |                    |                    |
| Cluster Node View           | RW             | R                  | R                  |                    |                    |
| Cluster Setup               | RW             |                    |                    |                    |                    |
| Application Error Details   | R              | R                  | R                  |                    |                    |
| Storage Class Disabled      | R              | R                  | R                  |                    |                    |

## Community Edition

The following tables cover the two roles available in Portainer Community Edition (CE). Note there is no Portainer access restriction in Portainer CE.

| Portainer Role | Cluster Role Binding                                                    | Namespace Role Binding                            |
| -------------- | ----------------------------------------------------------------------- | ------------------------------------------------- |
| Admin          | (no restriction)                                                        | (no restriction)                                  |
| User           | [portainer-cr-user](kubernetes-roles-and-bindings.md#portainer-cr-user) | edit (default k8s role, only assigned namespaces) |

### portainer-cr-user

| API Group         | Resources         | Verbs |
| ----------------- | ----------------- | ----- |
| (Empty)           | namespaces, nodes | list  |
| storage.k8s.io    | storageclasses    | list  |
| networking.k8s.io | ingresses         | list  |



================================================
FILE: advanced/mtls.md
================================================
# Using mTLS with Portainer

Mutual TLS (or **mTLS**) is a certificate-based system whereby the client and server (in this case, the Portainer Edge Agent and the Portainer Server) authenticate each other cryptographically via a trusted source (a certificate authority). This can be used as an extra layer of security to protect the communications between the Edge Agent and Portainer. Under this setup, if a third-party system attempts to communicate with the Portainer Server and is not using a certificate signed by the certificate authority it will be rejected.

This article will walk you through the process of deploying the Portainer Server and the Edge Agents with mTLS support.&#x20;

{% hint style="info" %}
mTLS support is only available in Portainer Business Edition.
{% endhint %}

## Requirements

In order to configure Portainer with mTLS support, you will need the following:

* A Portainer Server and a Portainer Edge Agent.
* A certificate authority (CA). You can use your own corporate CA or a CA for which you completely control the certificate issuance policy.
* The CA certificate for your certificate authority, in PEM format (`mtlsca.crt`).
* A domain (or subdomain) you can point to your Portainer Server instance to be specifically used for mTLS. This will be the domain the server certificate is issued for.
* A server certificate (`mtlsserver.crt`) and corresponding key (`mtlsserver.key`) issued by your CA for the Portainer Server, in PEM format. Ensure these are issued with `serverAuth` selected for `extendedKeyUsage`. This certificate should have the domain (or subdomain) that will be used for mTLS as the Subject Alternative Name (SAN).
* A client certificate (`client.crt`) and corresponding key (`client.key`) issued by your CA for the Edge Agent, in PEM format. Ensure these are issued with `clientAuth` selected for `extendedKeyUsage`.

## Configuring the Portainer Server

To use mTLS with your Edge Agents, the Portainer Server instance must be configured with mTLS support. This can either be done during the initial installation of the Portainer Server instance, or after installation through the [Edge Compute settings](../admin/settings/edge.md#mtls-certificate).

### Configure mTLS during installation

When deploying your Portainer Server, you will need to make the CA certificate, server certificate and server key available to Portainer. How you do this will depend on your deployment.

#### Docker Standalone

On your Docker host, upload your CA certificate (`mtlsca.crt`), server certificate (`mtlsserver.crt`) and server key (`mtlsserver.key`) into a directory that will be bind mounted into the Portainer container. In this example we assume your certificates are located at `/root/certs`.

Modify your `docker run` command to mount the `/root/certs` directory to `/certs` and add the `--mtlscacert`, `--mtlscert`, and `--mtlskey` options:

```bash
docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always \ 
    -v /var/run/docker.sock:/var/run/docker.sock \
    -v portainer_data:/data \
    -v /root/certs:/certs \
    portainer/portainer-ee:lts \
    --mtlscacert /certs/mtlsca.crt \    
    --mtlscert /certs/mtlsserver.crt \
    --mtlskey /certs/mtlsserver.key

```

This will start Portainer using your provided CA and certificates.

#### Docker Swarm

To add mTLS certificates to Portainer Server on Docker Swarm during installation, we recommend adding the necessary files as secrets and then referencing those secrets within the YAML used to deploy Portainer.&#x20;

First, upload your CA certificate (`mtlsca.crt`), server certificate (`mtlsserver.crt`) and server key (`mtlsserver.key`) into a directory that will be referenced by the secret creation. In this example we assume your certificates are located at `/root/certs`. Once you have uploaded the files, create your secrets as follows:

```
docker secret create portainer.mtlscacert /root/certs/mtlsca.crt
docker secret create portainer.mtlscert /root/certs/mtlsserver.crt
docker secret create portainer.mtlskey /root/certs/mtlsserver.key
```

Modify your Portainer YAML file to attach the secrets and add the `--mtlscacert`, `--mtlscert` and `--mtlskey` options:

```yaml
  portainer:
    image: portainer/portainer-ee:lts
    command: -H tcp://tasks.agent:9001 --tlsskipverify --mtlscacert /run/secrets/portainer.mtlscacert --mtlscert /run/secrets/portainer.mtlscert --mtlskey /run/secrets/portainer.mtlskey
    ports:
      - "9443:9443"
      - "9000:9000"
      - "8000:8000"
    volumes:
      - portainer_data:/data
    networks:
      - agent_network
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.role == manager]
    secrets:
        - portainer.mtlscacert
        - portainer.mtlsscert
        - portainer.mtlskey
```

and to add the `secrets` definitions to include the secrets we just created:

```yaml
secrets:
  portainer.mtlscacert:
    external: true
  portainer.mtlscert:
    external: true
  portainer.mtlskey:
    external: true
```

#### Kubernetes (via Helm)

If it doesn't already exist, create the `portainer` namespace:

```
kubectl create namespace portainer
```

Next, create a secret containing the CA, certificate and matching private key:

```
kubectl create secret generic portainer-mtls-certs-secret -n portainer \
    --from-file=mtlsca.crt=ca.crt \
    --from-file=mtlscert.crt=server.crt \
    --from-file=mtlskey.key=server.key
```

Replace `ca.crt`, `server.crt` and `server.key` in the above command with the paths to your CA certificate, certificate and matching key respectively.

Install Portainer via Helm with the `mtls.existingSecret` parameter set to the name of the secret you just created:

{% tabs %}
{% tab title="NodePort" %}
```
helm install -n portainer portainer portainer/portainer \
    --set mtls.existingSecret=portainer-mtls-certs-secret \
    --set enterpriseEdition.enabled=true
```
{% endtab %}

{% tab title="Load Balancer" %}
```
helm install -n portainer portainer portainer/portainer \
    --set mtls.existingSecret=portainer-mtls-secret \
    --set service.type=LoadBalancer \
    --set enterpriseEdition.enabled=true
```
{% endtab %}
{% endtabs %}

### Configure mTLS post installation

If you already have Portainer Server deployed, you can configure mTLS support through the Portainer UI.

As an admin user, from the left menu select **Settings** then **Edge Compute**. Toggle on **Enable Edge Compute features** if it isn't already on and click **Save Settings**. Then scroll down to the **mTLS Certificate** section.

<figure><img src="../.gitbook/assets/2.18-settings-edge-mtls.png" alt=""><figcaption></figcaption></figure>

Here you can enable the use of mTLS with the **Use separate mTLS cert** toggle, and upload the CA certificate, server certificate and server key using the buttons for **TLS CA certificate**, **TLS certificate** and **TLS key** respectively.

{% hint style="warning" %}
If you add or change the mTLS CA certificate through this method you will need to restart the Portainer Server in order for the change to apply. You should also ensure any Edge Agents that are using mTLS are also updated to use the new CA certificate.
{% endhint %}

## Deploying the Edge Agents

Once you have the Portainer Server instance configured to use mTLS, you can then configure your Edge Agent deployments to use it as well.

When deploying an Edge Agent you will be provided with a command to run by the Portainer UI. We will take that command and modify it for mTLS support.

### Docker Standalone

On your Docker host, upload your CA certificate (`mtlsca.crt`), client certificate (`client.crt`) and client key (`client.key`) into a directory that will be bind mounted into the Edge Agent container. In this example we assume your certificates are located at `/root/certs`.

Once the certificates are in place and the secrets created, you can begin to set up your Edge Agent within the Portainer UI.&#x20;

{% hint style="warning" %}
When doing so, remember to use the domain (or subdomain) you chose for mTLS usage (and that the server certificate was issued for) as the Portainer API server URL and tunnel address (if appropriate).
{% endhint %}

When you have completed the Edge Agent setup in the Portainer UI and have your deployment command, modify the command to mount the `/root/certs` directory to `/certs`, change the `EDGE_INSECURE_POLL` option to `0`, and add the `--mtlscacert`, `--mtlscert`, and `--mtlskey` options:

```bash
docker run -d \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -v /var/lib/docker/volumes:/var/lib/docker/volumes \
  -v /:/host \
  -v /root/certs:/certs \
  -v portainer_agent_data:/data \
  --restart always \
  -e EDGE=1 \
  -e EDGE_ID=your-edge-id \
  -e EDGE_KEY=your-edge-key \
  -e EDGE_INSECURE_POLL=0 \
  --name portainer_edge_agent \
  portainer/agent:lts \
  --mtlscacert /certs/mtlsca.crt \
  --mtlscert /certs/client.crt \
  --mtlskey /certs/client.key
```

Run the command to deploy your Edge Agent with mTLS support.

### Docker Swarm

To add mTLS certificates to the Edge Agent, we recommend adding the necessary files as secrets and then referencing those secrets within the YAML used to deploy Portainer.&#x20;

First, upload your CA certificate (`mtlsca.crt`), client certificate (`client.crt`) and client key (`client.key`) into a directory that will be referenced by the secret creation. In this example we assume your certificates are located at `/root/certs`. Once you have uploaded the files, create your secrets as follows:

```
docker secret create portainer.mtlscacert /root/certs/mtlsca.crt
docker secret create portainer.mtlscert /root/certs/client.crt
docker secret create portainer.mtlskey /root/certs/client.key
```

Once the certificates are in place and the secrets created, you can begin to set up your Edge Agent within the Portainer UI.

{% hint style="warning" %}
When doing so, remember to use the domain (or subdomain) you chose for mTLS usage (and that the server certificate was issued for) as the Portainer API server URL and tunnel address (if appropriate).
{% endhint %}

When you have completed the Edge Agent setup in the Portainer UI and have your deployment command, modify the command to change the `EDGE_INSECURE_POLL` option to `0` and add the `--mtlscacert`, `--mtlscert` and `--mtlskey` options, using the secrets we defined above:

```bash
docker network create \
  --driver overlay \
  portainer_agent_network;

docker service create \
  --name portainer_edge_agent \
  --network portainer_agent_network \
  -e EDGE=1 \
  -e EDGE_ID=your-edge-id \
  -e EDGE_KEY=your-edge-key \
  -e EDGE_INSECURE_POLL=0 \
  -e AGENT_CLUSTER_ADDR=tasks.portainer_edge_agent \
  --mode global \
  --constraint 'node.platform.os == linux' \
  --mount type=bind,src=//var/run/docker.sock,dst=/var/run/docker.sock \
  --mount type=bind,src=//var/lib/docker/volumes,dst=/var/lib/docker/volumes \
  --mount type=bind,src=//,dst=/host \
  --mount type=volume,src=portainer_agent_data,dst=/data \
  portainer/agent:lts \
  --mtlscacert /run/secrets/portainer.mtlscacert \
  --mtlscert /run/secrets/portainer.mtlscert \
  --mtlskey /run/secrets/portainer.mtlskey

```

Run the commands to deploy your Edge Agent with mTLS support.

### Kubernetes

At present, mTLS support for the Portainer Agent running on a Kubernetes environment is a work in progress. If you require instructions for deploying a Portainer Agent with mTLS on a Kubernetes environment, please [get in touch with our support team](../#getting-support).



================================================
FILE: advanced/relative-paths.md
================================================
# How Relative Path Support works in Portainer

The relative path volumes support in Portainer Business Edition is intended to provide you with a way to reference files and directories that are supplied within the Git repository alongside your compose file without needing to know the absolute path at which they will appear when they are deployed to your environment.&#x20;

{% hint style="info" %}
Relative path support is only present in Portainer Business Edition, and needs to be [enabled when deploying your stack from Git](../user/docker/stacks/add.md#relative-path-volumes) for this article to apply.
{% endhint %}

In the background the way this works is as follows:

1. In Portainer, a stack deployment is initiated where the stack is located in a Git repository, **Enable relative path volumes** is selected and a **Local (or Network) filesystem path** is specified.
2. Portainer creates a temporary unpacker container that bind mounts the path specified in the Local (or Network) filesystem path field.
3. The unpacker container clones the Git repository to a subdirectory under the bind mounted path.
4. Portainer creates the stack using the compose file provided, specifying the working directory as where the specified compose file is located within where the Git repo was cloned.
5. Now that the stack has been deployed, the temporary unpacker container is removed.

To take advantage of this with your compose file, you can specify any references to files that are within your repository in a _relative_ manner to your compose file. For example, imagine this simple nginx deployment:

```
.
├── docker-compose.yml
└── static
    └── index.html
```

In this example, the `docker-compose.yml` file is at the base directory of the repository. Alongside it there is a directory named `static`, and within that directory is an `index.html` file.

The `docker-compose.yml` file looks like this:

```
version: '3.1'
services:
  webapp:
    image: nginx:latest
    restart: always
    ports:
      - "3002:80"
    volumes:
      - ./static:/usr/share/nginx/html
```

The last line is the important one here - you'll note that we're referencing the static directory with a leading `.` and `/` - this tells compose that the path specified is _relative_ to the working directory, which Portainer specified during deployment. If we excluded the leading `.` this would be an _absolute_ path, and would refer to `/static` at the root of the host filesystem.

Let's look at an example where you had your compose file in a subdirectory of your repository, and your content in a different subdirectory:

```
.
├── nginx
│   └── docker-compose.yml
└── static
    └── index.html
```

In this scenario, you would specify the compose file when deploying as `nginx/docker-compose.yml`. Portainer will pull the contents of the repository to the specified location and set the working directory to the location of the compose file (ie, within the `nginx` subdirectory). As such, relative references within the compose need to be aware of this. To mount the contents of the `static` directory, your compose file would look like:

```
version: '3.1'
services:
  webapp:
    image: nginx:latest
    restart: always
    ports:
      - "3002:80"
    volumes:
      - ../static:/usr/share/nginx/html
```

The double dots (`..`) indicate that the files are at a directory level above the working directory.

### A note about the local (or network) filesystem path

The path on the local (or network) filesystem that the Git repository is cloned to will be in:

```
portainer-compose-unpacker/stacks/yourstackname/
```

For example, if you deployed a stack named `nginx` and specified the local filesystem path as:

```
/mnt/stacks/
```

it would result in:

```
/mnt/stacks/portainer-compose-unpacker/stacks/nginx/
```

This is generally not relevant for relative path referencing as the definition of the working directory avoids needing to be aware of this full path, but it does mean the same local (or network) filesystem path can be used to deploy multiple stacks without worrying about collisions (as long as they don't share the same stack name).

This path is where your stack's mounted files will be sourced from, so you will want to ensure this path remains intact and unchanged. When a stack deployed with this method is removed, the file and directory structure for that stack are removed as well.



================================================
FILE: advanced/reset-admin.md
================================================
# Reset the admin user's password

If your Portainer admin forgets their password, follow these steps to reset it. There are three methods depending on your Portainer environment.

## Method 1: Resetting the admin password if Portainer runs as a container

{% hint style="info" %}
You would typically use this method if you run the Portainer Server on Docker Standalone.
{% endhint %}

First, go to our [reset password container helper](https://github.com/portainer/helper-reset-password) in GitHub, then stop the Portainer container by running this command:

```
docker stop "id-portainer-container"
```

Next, run the helper using the following command (you'll need to mount the Portainer data volume):

{% hint style="warning" %}
If your Portainer data volume has a different name than `portainer_data` or you are using a bind mount for your data volume, you will need to adjust the mount in the below `docker run` command to suit your path.
{% endhint %}

```
docker pull portainer/helper-reset-password
docker run --rm -v portainer_data:/data portainer/helper-reset-password
```

If successful, the output should look like this:

```
2020/06/04 00:13:58 Password successfully updated for user: admin
2020/06/04 00:13:58 Use the following password to login: &_4#\3^5V8vLTd)E"NWiJBs26G*9HPl1
```

If the helper is unable to find an admin user to update, it will create a new one for you. If the username `admin` is already used, it will create a user named `admin-[randomstring]`:

```
2022/08/10 07:36:33 [WARN] Unable to retrieve user with ID 1, will try to create, err: object not found inside the database
2022/08/10 07:36:33 Admin user admin-u0512b3f0v4dqk7o successfully created
2022/08/10 07:36:33 Use the following password to login: Sr#]YL_6D0k8Pd{pA9^|}F32j5J4I=av
```

Finally, use this command to start the Portainer container then try logging in with the new password:

```
docker start "id-portainer-container"
```

## Method 2: Resetting the admin password if Portainer runs as a stack/service

{% hint style="info" %}
You would typically use this method if you run the Portainer Server on Docker Swarm.
{% endhint %}

First, scale the Portainer service to zero using this command:

```
docker service scale portainer_portainer=0
```

Next, run the [reset password container helper](https://github.com/portainer/helper-reset-password) using the same bind-mount/volume as the data volume:

{% hint style="warning" %}
If your Portainer data volume has a different name than `portainer_data` or you are using a bind mount for your data volume, you will need to adjust the mount in the below `docker run` command to suit your path.
{% endhint %}

```
docker pull portainer/helper-reset-password
docker run --rm -v portainer_portainer_data:/data portainer/helper-reset-password
```

If successful, the output should look like this:

```
2020/06/04 00:13:58 Password successfully updated for user: admin
2020/06/04 00:13:58 Use the following password to login: &_4#\3^5V8vLTd)E"NWiJBs26G*9HPl1
```

If the helper is unable to find an admin user to update, it will create a new one for you. If the username `admin` is already used, it will create a user named `admin-[randomstring]`:

```
2022/08/10 07:36:33 [WARN] Unable to retrieve user with ID 1, will try to create, err: object not found inside the database
2022/08/10 07:36:33 Admin user admin-u0512b3f0v4dqk7o successfully created
2022/08/10 07:36:33 Use the following password to login: Sr#]YL_6D0k8Pd{pA9^|}F32j5J4I=av
```

Finally, start up the Portainer service scaling using this command then try logging in with the new password:

```
docker service scale portainer_portainer=1
```

## Method 3: Resetting the admin password if Portainer is deployed in a Kubernetes cluster

{% hint style="info" %}
You would typically use this method if you run the Portainer Server on a Kubernetes cluster.
{% endhint %}

First, scale the Portainer deployment to zero using this command:

```
kubectl scale deploy portainer --replicas=0 -n portainer
```

Next, create a pod using the [reset password container helper](https://github.com/portainer/helper-reset-password) image and mount the Portainer data volume. Create a pod YAML file using the command below:

{% hint style="info" %}
You may need to change the YAML below to match your Portainer deployment (for example if using a different `claimName`).
{% endhint %}

```
cat > passreset.yml<< EOF
apiVersion: v1
kind: Pod
metadata:
  name: passreset
spec:
  volumes:
    - name: data
      persistentVolumeClaim:
        claimName: portainer
  containers:
    - name: passreset
      image: portainer/helper-reset-password
      volumeMounts:
        - mountPath: "/data"
          name: data
  restartPolicy: Never
EOF
```

Create the password reset pod using the command below:

```
kubectl apply -f passreset.yml -n portainer
```

Once the new pod is created and transitions into a completed state, you can see the new password in the pod logs:

```
kubectl logs passreset -n portainer
```

If successful, the output should look something like this:

```
2020/06/04 00:13:58 Password successfully updated for user: admin
2020/06/04 00:13:58 Use the following password to login: &_4#\3^5V8vLTd)E"NWiJBs26G*9HPl1
```

Finally, scale up the Portainer deployment using this command then try logging in with the new password:

```
kubectl scale deploy portainer --replicas=1 -n portainer
```

You can delete the password reset pod using the below command:

```
kubectl delete pod passreset -n portainer
```



================================================
FILE: advanced/security.md
================================================
# Security and compliance

Portainer runs exclusively on your servers, within your network, behind your own firewalls. As a result, we do not currently hold any SOC or PCI/DSS compliance because we do not host any of your infrastructure. You can even run Portainer completely disconnected (air-gapped) without any impact on functionality.

We comply with GDPR in relation to the anonymous analytics we collect. Data collection can be disabled at startup (or at any time), and if you are disconnected, it silently fails.

The Portainer code itself does not undergo any formal code analysis, however we scan our published images for vulnerabilities as part of the DockerHub process.

We are also the subject of regular third-party vulnerability analyses. No issues have been reported for some time, and any issues that are discovered are resolved within six weeks.



================================================
FILE: advanced/siem.md
================================================
# Stream auth and activity logs to an external provider

{% hint style="warning" %}
This is an experimental feature.
{% endhint %}

With Portainer 2.20 and later, you can configure the streaming of Portainer's authentication and activity logs to an external Security Information and Event Management (SIEM) system in Syslog format. This is done via CLI flags when starting the Portainer container.

## Available CLI flags

| Flag                            | Description                                                                                                                          |
| ------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |
| `--syslog-address`              | Syslog Address to stream authentication and activity logs. FQDN or IP Address only.                                                  |
| `--syslog-port`                 | Syslog Port for the address above. Defaults to `514`.                                                                                |
| `--syslog-protocol`             | Syslog Protocol to send logs to the Syslog Server. Supported values are `udp`, `tcp`, or `tcp+tls`. Defaults to `udp`.               |
| `--syslog-format`               | Syslog Format to be used. Supported values are `rfc3164` or `rfc5424`. Defaults to `rfc5424.`                                        |
| `--syslog-source-hostname`      | The hostname value that will be shown in the Syslog server in the messages. Defaults to `portainer`.                                 |
| `--syslog-insecure-skip-verify` | Disable TLS server verification when using `tcp+tls` protocol. Should only be enabled for testing. Defaults to `false`.              |
| `--syslog-ca-cert`              | The path to the trusted CA used by the Syslog server. Defaults to `/syslog/certs/ca.pem`.                                            |
| `--syslog-cert`                 | The path to the client certificate that is used to authenticate to the Syslog server via mTLS. Defaults to `/syslog/certs/cert.pem`. |
| `--syslog-key`                  | The path to the client key that is used to authenticate to the Syslog server via mTLS. Defaults to `/syslog/certs/key.pem`.          |

## Example usage

The following is an example `docker run` command to start Portainer using the above options to stream logs to a SIEM provider at `syslog.mydomain.com` on UDP port `514`.

{% hint style="warning" %}
As the flags are Portainer options, they must be specified after the image specification.
{% endhint %}

```
docker run -d -p 8000:8000 -p 9443:9443 \
    --name portainer \
    --restart=always \
    -v /var/run/docker.sock:/var/run/docker.sock \
    -v portainer_data:/data \
    portainer/portainer-ee:lts \
    --syslog-address=syslog.mydomain.com \
    --syslog-port=514 \
    --syslog-source-hostname="my-portainer-instance"
```



================================================
FILE: advanced/ssl.md
================================================
# Using your own SSL certificate with Portainer

By default, Portainer’s web interface and API is exposed over HTTPS with a self-signed certificate generated by the installation. This can be replaced with your own SSL certificate either after installation [via the Portainer UI](../admin/settings/#ssl-certificate) or during installation, as explained in this article.

{% hint style="info" %}
When using your own externally-issued certificate, ensure that you include the full certificate chain (including any intermediate certificates) in the file you provide via `--sslcert`. Without this you may face certificate validation issues. Your certificate chain can be obtained either from your certificate issuer or the [What's My Chain Cert?](https://whatsmychaincert.com/) website.
{% endhint %}

## Using your own SSL certificate on Docker Standalone

{% hint style="info" %}
Portainer expects certificates in PEM format.
{% endhint %}

Use the `--sslcert` and `--sslkey` flags during installation.

Upload your certificate (including the chain) and key to the server running Portainer, then start Portainer referencing them. The following command assumes your certificates are stored in `/path/to/your/certs` with the filenames `portainer.crt` and `portainer.key`, and bind-mounts the directory to `/certs` in the Portainer container:

{% tabs %}
{% tab title="Business Edition" %}
```
docker run -d -p 9443:9443 -p 8000:8000 \
    --name portainer --restart always \
    -v /var/run/docker.sock:/var/run/docker.sock \
    -v portainer_data:/data \
    -v /path/to/your/certs:/certs \
    portainer/portainer-ee:lts \
    --sslcert /certs/portainer.crt \
    --sslkey /certs/portainer.key
```
{% endtab %}

{% tab title="Community Edition" %}
```
docker run -d -p 9443:9443 -p 8000:8000 \
    --name portainer --restart always \
    -v /var/run/docker.sock:/var/run/docker.sock \
    -v portainer_data:/data \
    -v /path/to/your/certs:/certs \
    portainer/portainer-ce:lts \
    --sslcert /certs/portainer.crt \
    --sslkey /certs/portainer.key
```
{% endtab %}
{% endtabs %}

Alternatively, Certbot can be used to generate a certificate and a key. Because Docker has issues with symlinks, if you use Certbot you will need to pass both the 'live' and 'archive' directories as volumes, as well as use the full chain certificate. For example:

{% tabs %}
{% tab title="Business Edition" %}
```
docker run -d -p 9443:9443 -p 8000:8000 \
    --name portainer --restart always \
    -v /var/run/docker.sock:/var/run/docker.sock \
    -v portainer_data:/data \
    -v /etc/letsencrypt/live/yourdomain:/certs/live/yourdomain:ro \
    -v /etc/letsencrypt/archive/yourdomain:/certs/archive/yourdomain:ro \
    portainer/portainer-ee:lts \
    --sslcert /certs/live/yourdomain/fullchain.pem \
    --sslkey /certs/live/yourdomain/privkey.pem
```
{% endtab %}

{% tab title="Community Edition" %}
```
docker run -d -p 9443:9443 -p 8000:8000 \
    --name portainer --restart always \
    -v /var/run/docker.sock:/var/run/docker.sock \
    -v portainer_data:/data \
    -v /etc/letsencrypt/live/yourdomain:/certs/live/yourdomain:ro \
    -v /etc/letsencrypt/archive/yourdomain:/certs/archive/yourdomain:ro \
    portainer/portainer-ce:lts \
    --sslcert /certs/live/yourdomain/fullchain.pem \
    --sslkey /certs/live/yourdomain/privkey.pem
```
{% endtab %}
{% endtabs %}

When you're finished, you can navigate to `https://$ip-docker-host:9443`.

## Using your own SSL certificate on Docker Swarm

To provide your own SSL certificate for Docker Swarm, simply define the `portainer.sslcert` and `portainer.sslkey` secrets, and the installation manifest will automatically detect and use them:

```
docker secret create portainer.sslcert /path/to/your/certificate.crt
docker secret create portainer.sslkey /path/to/your/certificate.key
```

Next, retrieve the stack YML manifest:

{% tabs %}
{% tab title="Linux and Windows with Docker Desktop" %}
**Business Edition:**

```
curl -L https://downloads.portainer.io/ee-lts/portainer-agent-stack-ssl.yml -o portainer-agent-stack.yml
```

**Community Edition:**

```
curl -L https://downloads.portainer.io/ce-lts/portainer-agent-stack-ssl.yml -o portainer-agent-stack.yml
```
{% endtab %}

{% tab title="Windows Container Services" %}
**Business Edition:**

```
curl https://downloads.portainer.io/ee-lts/portainer-windows-stack-ssl.yml -o portainer-agent-stack.yml
```

**Community Edition:**

```
curl https://downloads.portainer.io/ce-lts/portainer-windows-stack-ssl.yml -o portainer-agent-stack.yml
```
{% endtab %}
{% endtabs %}

Finally, use the downloaded YML manifest to deploy your stack:

```
docker stack deploy -c portainer-agent-stack.yml portainer
```

For more information about secrets, read [Docker's own documentation](https://docs.docker.com/compose/compose-file/#secrets).

## Using your own SSL certificate on Kubernetes (via Helm)

If it doesn't already exist, create the `portainer` namespace:

```
kubectl create namespace portainer
```

Next, create a TLS secret containing the full certificate chain and matching private key:

```
kubectl create secret tls portainer-tls-secret -n portainer \
    --cert=/path/to/cert/file \
    --key=/path/to/key/file
```

Install via helm with the `tls.existingSecret` parameter set to the name of the secret you just created:

{% tabs %}
{% tab title="NodePort" %}
**Business Edition:**

```
helm install -n portainer portainer portainer/portainer \
    --set tls.existingSecret=portainer-tls-secret \
    --set enterpriseEdition.enabled=true
```

**Community Edition:**

```
helm install -n portainer portainer portainer/portainer \
    --set tls.existingSecret=portainer-tls-secret
```
{% endtab %}

{% tab title="Load Balancer" %}
Business Edition:

```
helm install -n portainer portainer portainer/portainer \
    --set tls.existingSecret=portainer-tls-secret \
    --set service.type=LoadBalancer \
    --set enterpriseEdition.enabled=true 
```

Community Edition:

```
helm install -n portainer portainer portainer/portainer \
    --set tls.existingSecret=portainer-tls-secret \
    --set service.type=LoadBalancer
```
{% endtab %}
{% endtabs %}



================================================
FILE: advanced/app-templates/README.md
================================================
# App templates

You can deploy containers and services using Portainer's set of built-in app templates, or replace them with your own set of templates.&#x20;

{% content-ref url="build.md" %}
[build.md](build.md)
{% endcontent-ref %}

{% content-ref url="format.md" %}
[format.md](format.md)
{% endcontent-ref %}




================================================
FILE: advanced/app-templates/build.md
================================================
# Build and host your own app templates

To provide your own template files, you will need to host your files somewhere accessible by the Portainer Server instance. This could be somewhere like GitHub, a web server, or perhaps a container running nginx.

As an example, the Portainer templates repository includes a `Dockerfile` that lets you start it as a container to serve the JSON file. To set this up, first clone the [Portainer templates repository](https://github.com/portainer/templates), edit the templates file, then build and run the container:

```
git clone https://github.com/portainer/templates.git portainer-templates
cd portainer-templates
# Edit the file templates.json
docker build -t portainer-templates .
docker run -d -p "8080:80" portainer-templates
```

Access your template definitions at `http://docker-host:8080/templates.json`.

You can also mount the `templates.json` file inside the container, so you can edit the file and see live changes:

```
docker run -d -p "8080:80" -v "${PWD}/templates.json:/usr/share/nginx/html/templates.json" portainer-templates
```

For more information about the format of the app template, go [here](format.md).



================================================
FILE: advanced/app-templates/format.md
================================================
# App template JSON format

App template definitions are written in JSON. Valid templates consist of an array, and every template definition consists of one element.

## Container template definition format

A container template element must be a valid JSON object, composed of both mandatory and optional data fields. Here's an example of the format:

```
{
  "version": "2",
  "templates": [
    {
      // template1
    },
    {
      // template2
    },
    ...
  ]
}
```

### type

* **Description:** The template type.
* **Format:** Integer
* **Valid values:** `1` = container; `2` = Swarm stack; `3` = Compose stack
* **Required/Optional:** Required
* **Other information:** Type `3` is limited to using the version `"2"` stack format (this is a docker/libcompose limitation).

### title

* **Description:** The template title.
* **Format:** String
* **Valid values:** Any string value.
* **Required/Optional:** Required

### description

* **Description:** The template description.
* **Format:** String
* **Valid values:** Any string value.
* **Required/Optional:** Required

### image

* **Description:** The Docker image associated with a template.
* **Format:** String
* **Valid values:** Any valid URL.
* **Required/Optional:** Required

### administrator-only

* **Description:** Indicates whether or not a template should be available just to admin users.
* **Format:** Boolean
* **Valid values:** `true` = available to admins only; `false` = available to all users
* **Required/Optional:** Optional
* **Example:** See below.

```
{
  "administrator-only": true
}
```

### name

* **Description:** The default name of a template (shows in the Portainer UI).
* **Format:** String
* **Valid values:** Any valid string.
* **Required/Optional:** Optional

### logo

* **Description:** The template logo.
* **Format:** String
* **Valid values:** Any valid URL.
* **Required/Optional:** Optional

### registry

* **Description:** The registry where the Docker image is stored. If not specified, Portainer will use Docker Hub as the default.
* **Format:** String
* **Valid values:** Any string value.
* **Required/Optional:** Optional

### command

* **Description:** The command to run in the container. If not specified, the container will use the default command in its Dockerfile.
* **Format:** String
* **Valid values:** Any string value.
* **Required/Optional:** Optional
* **Example:** See below.

```
{
  "command": "/bin/bash -c \"echo hello\" && exit 777"
}
```

### env

* **Description:** A JSON array describing the environment variables required by a template. Each element in the array must be a valid JSON object. An input will be generated in the templates view for each element in the array. Depending on the object properties, different types of inputs can be generated (text input, select).
* **Format:** Array
* **Required/Optional:** Optional

Array format:

```
{
  "name": "the name of the environment variable, as supported in the container image (mandatory)",
  "label": "label for the input in the UI (mandatory unless set is present)",
  "description": "a short description for this input, will be available as a tooltip in the UI (optional)",
  "default": "default value associated to the variable (optional)",
  "preset": "boolean. If set to true, the UI will not generate an input (optional)",
  "select": "an array of possible values, will generate a select input (optional)"
}
```

Example:

```
{
  "env": [
    {
      "name": "MYSQL_ROOT_PASSWORD",
      "label": "Root password",
      "description": "Password used by the root user."
    },
    {
      "name": "ENV_VAR_WITH_DEFAULT_VALUE",
      "default": "default_value",
      "preset": true
    },
    {
      "name": "ENV_VAR_WITH_SELECT_VALUE",
      "label": "An environment variable",
      "description": "A description for this env var",
      "select": [
        {
          "text": "Yes, I agree",
          "value": "Y",
          "default": true
        },
        {
          "text": "No, I disagree",
          "value": "N"
        },
        {
          "text": "Maybe",
          "value": "YN"
        }
      ],
      "description": "Some environment variable."
    }
  ]
}
```

### network

* **Description:** A string that corresponds to the name of an existing Docker network. Will auto-select the network in the templates view.
* **Format:** String
* **Valid values:** Any string value. If the string does not match an existing network name when the template is used it will fall back to the first available network.
* **Required/Optional:** Optional
* **Example:** See below.

```
{
  "network": "host"
}
```

### volumes

* **Description:** A JSON array describing the volumes associated with a template. Each element in the array must be a valid JSON object with a required container property. For each element in the array, a Docker volume will be created and associated when starting the container. If a `bind` property is defined, it will be used as the source of a bind mount. If a `readonly` property is is defined and = true, the volume will be mounted in `readonly` mode.
* **Format:** Array
* **Required/Optional:** Optional
* **Example:** See below.

```
{
  "volumes": [
    {
      "container": "/etc/nginx"
    },
    {
      "container": "/usr/share/nginx/html",
      "bind": "/var/www",
      "readonly": true
    }
  ]
}
```

### ports

* **Description:** A JSON array describing the ports exposed by a template. Each element in the array must be a valid JSON string specifying the port number in the container, as well as the protocol. Can be optionally prefixed with a port number and colon (for example `8080:`) to define the port to be mapped on the host. If the host port is not specified, the Docker host will automatically assign it when starting the container.
* **Format:** Array
* **Required/Optional:** Optional
* **Example:** See below.

```
{
  "ports": ["8080:80/tcp", "443/tcp"]
}
```

### labels

* **Description:** A JSON array describing the labels associated with a template. Each element in the array must be a valid JSON object with two properties (`name:` and `"<value>"`).
* **Format:** Array
* **Required/Optional:** Optional
* **Example:** See below.

```
{
  "labels": [
    { "name": "com.example.vendor", "value": "Acme" },
    { "name": "com.example.license", "value": "GPL" },
    { "name": "com.example.version", "value": "1.0" }
  ]
}
```

### privileged

* **Description:** Indicates whether or not the container should be started in `privileged` mode. Defaults to `false` if not specified.
* **Format:** Boolean
* **Valid values:** `true` = start the container in privileged mode; `false` = do not start the container in privileged mode
* **Required/Optional:** Optional
* **Example:** See below.

```
{
  "privileged": true
}
```

### interactive

* **Description:** Indicates whether or not the container should be started in `foreground` mode. Defaults to `false` if not specified.
* **Format:** Boolean
* **Valid values:** `true` = start the container in foreground mode; `false` = do not start the container in foreground mode
* **Required/Optional:** Optional
* **Example:** See below.

```
{
  "interactive": true
}
```

### restart\_policy

* **Description:** The restart policy associated with the container. Will default to `"always"` if no value is specified.
* **Format:** String
* **Valid values:**
  * `"always"` Always restart the container regardless of the exit status.
  * `"no"` Never automatically restart the container.
  * `"on-failure"` Restart the container only if it exits with a non-zero status.
  * `"unless-stopped"` Always restart the container regardless of the exit status (unless the container was manually stopped).
* **Required/Optional:** Optional
* **Example:** See below.

```
{
  "restart_policy": "unless-stopped"
}
```

### hostname

* **Description:** The hostname of the container. Will default to Docker if not specified.
* **Format:** String
* **Valid values:** Any string value.
* **Required/Optional:** Optional
* **Example:** See below.

```
{
  "hostname": "mycontainername"
}
```

### note

* **Description:** Extra information about a template, for example what it is used for. Displayed inside the template-creation form in the Portainer UI. Supports HTML.
* **Format:** String
* **Valid values:** Any string value.
* **Required/Optional:** Optional
* **Example:** See below.

```
{
  "note": "You can use this field to record extra information about a template."
}
```

### platform

* **Description:** The supported platform. Displays a small platform-related icon in the Portainer UI. Must contain a valid value.
* **Format:** String
* **Valid values:** `"linux"`; `"windows"`
* **Required/Optional:** Optional
* **Example:** See below.

```
{
  "platform": "linux"
}
```

### categories

* **Description:** An array of categories associated with a template. Populates the category filter in the Portainer UI.
* **Format:** Array
* **Required/Optional:** Optional
* **Example:** See below.

```
{
  "categories": ["webserver", "open-source"]
}
```

## Stack template definition format

A stack template element must be a valid JSON object, composed of mandatory and optional data fields. Here's an example of the format:

```
{
  "type": 2,
  "title": "CockroachDB",
  "description": "CockroachDB cluster",
  "note": "Deploys an insecure CockroachDB cluster, please refer to CockroachDB documentation for production deployments.",
  "categories": ["database"],
  "platform": "linux",
  "logo": "https://cloudinovasi.id/assets/img/logos/cockroachdb.png",
  "repository": {
    "url": "https://github.com/portainer/templates",
    "stackfile": "stacks/cockroachdb/docker-stack.yml"
  }
}
```

### type

* **Description:** The template type. A Swarm stack will be deployed using the equivalent of `docker stack deploy`. A Compose stack will be deployed using the equivalent of `docker-compose.`
* **Format:** Integer
* **Valid values:** `1` = container; `2` = Swarm stack; `3` = Compose stack
* **Required/Optional:** Required
* **Other information:** Type `3` is limited to using the version `"2"` stack format (this is a docker/libcompose limitation).

### title

* **Description:** The template title.
* **Format:** String
* **Valid values:** Any string value.
* **Required/Optional:** Required

### description

* **Description:** The template description.
* **Format:** String
* **Valid values:** Any string value.
* **Required/Optional:** Required

### repository

* **Description:** A JSON object describing the public Git repository from where the stack template will be loaded. It indicates the URL of the Git repository as well as the path to the Compose file inside the repository.
* **Format:** Object
* **Valid values:** See the example below.
* **Required/Optional:** Required

{% hint style="warning" %}
This value **must** reference a Git repository.
{% endhint %}

Object format:

```
{
  "url": "URL of the public git repository (mandatory)",
  "stackfile": "Path to the Compose file inside the repository (mandatory)",
}
```

Example:

```
{
  "url": "https://github.com/portainer/templates",
  "stackfile": "stacks/cockroachdb/docker-stack.yml"
}
```

### administrator\_only

* **Description:** Indicates whether or not a template should be available just to admin users.
* **Format:** Boolean
* **Valid values:** `true` = available to admins only; `false` = available to all users
* **Required/Optional:** Optional
* **Example:** See below.

```
{
  "administrator_only": true
}
```

### name

* **Description:** The default name of a template (shows in the Portainer UI).
* **Format:** String
* **Valid values:** Any valid string.
* **Required/Optional:** Optional

### logo

* **Description:** The template logo.
* **Format:** String
* **Valid values:** Any valid URL.
* **Required/Optional:** Optional

### env

* **Description:** A JSON array describing the environment variables required by a template. Each element in the array must be a valid JSON object. An input will be generated in the templates view for each element in the array. Depending on the object properties, different types of inputs can be generated (text input, select).
* **Format:** Array
* **Required/Optional:** Optional

An input will be generated in the templates view for each element in the array. Depending on the object properties, different types of inputs can be generated (text input, select).

Array format:

```
{
  "name": "the name of the environment variable, as supported in the container image (mandatory)",
  "label": "label for the input in the UI (mandatory unless set is present)",
  "description": "a short description for this input, will be available as a tooltip in the UI (optional)",
  "default": "default value associated to the variable (optional)",
  "preset": "boolean. If set to true, the UI will not generate an input (optional)",
  "select": "an array of possible values, will generate a select input (optional)"
}
```

Example:

```
{
  "env": [
    {
      "name": "MYSQL_ROOT_PASSWORD",
      "label": "Root password",
      "description": "Password used by the root user."
    },
    {
      "name": "ENV_VAR_WITH_DEFAULT_VALUE",
      "default": "default_value",
      "preset": true
    },
    {
      "name": "ENV_VAR_WITH_SELECT_VALUE",
      "label": "An environment variable",
      "description": "A description for this env var",
      "select": [
        {
          "text": "Yes, I agree",
          "value": "Y",
          "default": true
        },
        {
          "text": "No, I disagree",
          "value": "N"
        },
        {
          "text": "Maybe",
          "value": "YN"
        }
      ],
      "description": "Some environment variable."
    }
  ]
}
```

### note

* **Description:** Extra information about a template, for example what it is used for. Displayed inside the template-creation form in the Portainer UI. Supports HTML.
* **Format:** String
* **Valid values:** Any string value.
* **Required/Optional:** Optional
* **Example:** See below.

```
{
  "note": "You can use this field to record extra information about a template."
}
```

### platform

* **Description:** The supported platform. Displays a small platform-related icon in the Portainer UI. Must contain a valid value.
* **Format:** String
* **Valid values:** `"linux"`; `"windows"`
* **Required/Optional:** Optional
* **Example:** See below.

```
{ "platform": "linux" }
```

### categories

* **Description:** An array of categories associated with a template. Populates the category filter in the Portainer UI.
* **Format:** Array
* **Required/Optional:** Optional
* **Example:** See below.

```
{
  "categories": ["webserver", "open-source"]
```



================================================
FILE: advanced/reverse-proxy/README.md
================================================
# Using Portainer with reverse proxies

If you need to, you can run Portainer behind a reverse proxy. We have guides for Traefik and nginx:

{% content-ref url="traefik.md" %}
[traefik.md](traefik.md)
{% endcontent-ref %}

{% content-ref url="nginx.md" %}
[nginx.md](nginx.md)
{% endcontent-ref %}




================================================
FILE: advanced/reverse-proxy/nginx.md
================================================
# Deploying Portainer behind nginx reverse proxy

## Deploying in a Docker Standalone scenario

To deploy Portainer behind an nginx proxy in a Docker standalone scenario you must use a Docker Compose file. In the following docker-compose.yml you will find the configuration of the nginx proxy and the Portainer Server.

{% hint style="info" %}
This example uses the excellent [nginxproxy/nginx-proxy](https://hub.docker.com/r/nginxproxy/nginx-proxy) image as the proxy container, which requires no additional configuration beyond the two environment variables added to the `portainer` container's definition.
{% endhint %}

{% tabs %}
{% tab title="Business Edition" %}
```
version: "2"

services:
  nginx-proxy:
    image: nginxproxy/nginx-proxy
    restart: always
    ports:
      - "80:80"
    volumes:
      - "/var/run/docker.sock:/tmp/docker.sock:ro"

  portainer:
    image: portainer/portainer-ee:lts
    command: -H unix:///var/run/docker.sock
    restart: always
    environment:
      - VIRTUAL_HOST=portainer.yourdomain.com
      - VIRTUAL_PORT=9000
    ports:
      - 8000:8000
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data

volumes:
  portainer_data:
```
{% endtab %}

{% tab title="Community Edition" %}
```
version: "2"

services:
  nginx-proxy:
    image: nginxproxy/nginx-proxy
    restart: always
    ports:
      - "80:80"
    volumes:
      - "/var/run/docker.sock:/tmp/docker.sock:ro"

  portainer:
    image: portainer/portainer-ce:lts
    command: -H unix:///var/run/docker.sock
    restart: always
    environment:
      - VIRTUAL_HOST=portainer.yourdomain.com
      - VIRTUAL_PORT=9000
    ports:
      - 8000:8000
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data

volumes:
  portainer_data:
```
{% endtab %}
{% endtabs %}

To start working with this recipe, change the `VIRTUAL_HOST` value then deploy Portainer by running the following:

```
docker-compose up -d
```

When this has finished, run `docker ps` . You should see an output similar to this:

```
CONTAINER ID   IMAGE                           COMMAND                  CREATED         STATUS         PORTS                                                           NAMES
8c8f2eac7c9a   portainer/portainer-ee:lts      "/portainer -H unix:…"   4 minutes ago   Up 4 minutes   9000/tcp, 0.0.0.0:8000->8000/tcp, :::8000->8000/tcp, 9443/tcp   portainer_portainer_1
3e7c8b5d71d7   nginxproxy/nginx-proxy          "/app/docker-entrypo…"   4 minutes ago   Up 4 minutes   0.0.0.0:80->80/tcp, :::80->80/tcp                               portainer_nginx-proxy_1
```

Once the deployment has finished you can browse `portainer.yourdomain.com`.

## Deploying in a Docker Swarm scenario

Deploying Portainer in Docker Swarm behind nginx has similar steps to the Docker Standalone scenario. Before deploying, you need to create two elements: networks and volumes.

{% hint style="warning" %}
This deployment assumes you are running one manager node. If you are using multiple managers we advise [reading this knowledge base article](https://portal.portainer.io/knowledge/how-can-i-ensure-portainers-configuration-is-retained) before proceeding.
{% endhint %}

First, create two networks:

* One for the agent and the communication with the Portainer Server.
* One to 'expose' the Portainer container to the same network as the reverse proxy.

```
 docker network create -d overlay proxy
```

```
 docker network create -d overlay agent_network
```

Next, create the volume:

```
 docker volume create portainer_data
```

And finally, save the following recipe as `portainer.yml`:

{% tabs %}
{% tab title="Business Edition" %}
```
version: '3.2'

services:
  nginx-proxy:
    image: nginxproxy/nginx-proxy
    networks:
      - proxy
    ports:
      - "80:80"
    volumes:
      - "/var/run/docker.sock:/tmp/docker.sock:ro"
      - "./vhost.d:/etc/nginx/vhost.d:ro"

  agent:
    image: portainer/agent:lts
    environment:
      # REQUIRED: Should be equal to the service name prefixed by "tasks." when
      # deployed inside an overlay network
      AGENT_CLUSTER_ADDR: tasks.agent
      # AGENT_PORT: 9001
      # LOG_LEVEL: DEBUG
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/lib/docker/volumes:/var/lib/docker/volumes
    networks:
      - agent_network
    deploy:
      mode: global
      placement:
        constraints: [node.platform.os == linux]

  portainer:
    image: portainer/portainer-ee:lts
    command: -H tcp://tasks.agent:9001 --tlsskipverify
    volumes:
      - data:/data
    environment:
      - VIRTUAL_HOST=portainer.yourdomain.com
      - VIRTUAL_PORT=9000
    ports:
      - 8000:8000
    networks:
      - proxy
      - agent_network
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.role == manager]


networks:
  proxy:
    external: true
  agent_network:
    external: true

volumes:
   data:
```
{% endtab %}

{% tab title="Community Edition" %}
```
version: '3.2'

services:
  nginx-proxy:
    image: nginxproxy/nginx-proxy
    networks:
      - proxy
    ports:
      - "80:80"
    volumes:
      - "/var/run/docker.sock:/tmp/docker.sock:ro"
      - "./vhost.d:/etc/nginx/vhost.d:ro"

  agent:
    image: portainer/agent:lts
    environment:
      # REQUIRED: Should be equal to the service name prefixed by "tasks." when
      # deployed inside an overlay network
      AGENT_CLUSTER_ADDR: tasks.agent
      # AGENT_PORT: 9001
      # LOG_LEVEL: DEBUG
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/lib/docker/volumes:/var/lib/docker/volumes
    networks:
      - agent_network
    deploy:
      mode: global
      placement:
        constraints: [node.platform.os == linux]

  portainer:
    image: portainer/portainer-ce:lts
    command: -H tcp://tasks.agent:9001 --tlsskipverify
    volumes:
      - data:/data
    environment:
      - VIRTUAL_HOST=portainer.yourdomain.com
      - VIRTUAL_PORT=9000
    ports:
      - 8000:8000
    networks:
      - proxy
      - agent_network
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.role == manager]


networks:
  proxy:
    external: true
  agent_network:
    external: true

volumes:
   data:
```
{% endtab %}
{% endtabs %}

To start working with this recipe, change the `VIRTUAL_HOST` value then deploy Portainer by running the following:

```
 docker stack deploy portainer -c portainer.yml
```

To check the deployment, run `docker service ls`. You should see an output similar to the following:

```
ID                  NAME                    MODE                REPLICAS            IMAGE                          PORTS
gy2bjxid0g4p        portainer_agent         global              1/1                 portainer/agent:lts
jwvjp5bux4sz        portainer_nginx-proxy   replicated          1/1                 nginxproxy/nginx-proxy:latest  *:80->80/tcp
5nflcvoxl3c7        portainer_portainer     replicated          1/1                 portainer/portainer-ee:lts     *:8000->8000/tcp
```

Once the services are running, you will be able to access Portainer from the URL you defined earlier, for example: `portainer.yourdomain.com`.



================================================
FILE: advanced/reverse-proxy/traefik.md
================================================
# Deploying Portainer behind Traefik Proxy

[Traefik Proxy](https://traefik.io/traefik/) is a reverse proxy and load balancing solution focused on micro services.

## Deploying in a Docker Standalone scenario

To deploy Portainer behind Traefik Proxy in a Docker standalone scenario you must use a Docker Compose file. In the following `docker-compose.yml` you will find the configuration for Portainer Traefik with SSL support and the Portainer Server.

{% tabs %}
{% tab title="Business Edition" %}
```
version: "3.3"

services:
  traefik:
    container_name: traefik
    image: "traefik:latest"
    command:
      - --entrypoints.web.address=:80
      - --entrypoints.websecure.address=:443
      - --providers.docker
      - --log.level=ERROR
      - --certificatesresolvers.leresolver.acme.httpchallenge=true
      - --certificatesresolvers.leresolver.acme.email=your-email #Set your email address here, is for the generation of SSL certificates with Let's Encrypt. 
      - --certificatesresolvers.leresolver.acme.storage=./acme.json
      - --certificatesresolvers.leresolver.acme.httpchallenge.entrypoint=web
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
      - "./acme.json:/acme.json"
    labels:
      - "traefik.http.routers.http-catchall.rule=hostregexp(`{host:.+}`)"
      - "traefik.http.routers.http-catchall.entrypoints=web"
      - "traefik.http.routers.http-catchall.middlewares=redirect-to-https"
      - "traefik.http.middlewares.redirect-to-https.redirectscheme.scheme=https"

  portainer:
    image: portainer/portainer-ee:lts
    command: -H unix:///var/run/docker.sock
    restart: always
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data
    labels:
      # Frontend
      - "traefik.enable=true"
      - "traefik.http.routers.frontend.rule=Host(`portainer.yourdomain.com`)"
      - "traefik.http.routers.frontend.entrypoints=websecure"
      - "traefik.http.services.frontend.loadbalancer.server.port=9000"
      - "traefik.http.routers.frontend.service=frontend"
      - "traefik.http.routers.frontend.tls.certresolver=leresolver"

      # Edge
      - "traefik.http.routers.edge.rule=Host(`edge.yourdomain.com`)"
      - "traefik.http.routers.edge.entrypoints=websecure"
      - "traefik.http.services.edge.loadbalancer.server.port=8000"
      - "traefik.http.routers.edge.service=edge"
      - "traefik.http.routers.edge.tls.certresolver=leresolver"


volumes:
  portainer_data:
```
{% endtab %}

{% tab title="Community Edition" %}
```
version: "3.3"

services:
  traefik:
    container_name: traefik
    image: "traefik:latest"
    command:
      - --entrypoints.web.address=:80
      - --entrypoints.websecure.address=:443
      - --providers.docker
      - --log.level=ERROR
      - --certificatesresolvers.leresolver.acme.httpchallenge=true
      - --certificatesresolvers.leresolver.acme.email=your-email #Set your email address here, is for the generation of SSL certificates with Let's Encrypt. 
      - --certificatesresolvers.leresolver.acme.storage=./acme.json
      - --certificatesresolvers.leresolver.acme.httpchallenge.entrypoint=web
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
      - "./acme.json:/acme.json"
    labels:
      - "traefik.http.routers.http-catchall.rule=hostregexp(`{host:.+}`)"
      - "traefik.http.routers.http-catchall.entrypoints=web"
      - "traefik.http.routers.http-catchall.middlewares=redirect-to-https"
      - "traefik.http.middlewares.redirect-to-https.redirectscheme.scheme=https"

  portainer:
    image: portainer/portainer-ce:lts
    command: -H unix:///var/run/docker.sock
    restart: always
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data
    labels:
      # Frontend
      - "traefik.enable=true"
      - "traefik.http.routers.frontend.rule=Host(`portainer.yourdomain.com`)"
      - "traefik.http.routers.frontend.entrypoints=websecure"
      - "traefik.http.services.frontend.loadbalancer.server.port=9000"
      - "traefik.http.routers.frontend.service=frontend"
      - "traefik.http.routers.frontend.tls.certresolver=leresolver"

      # Edge
      - "traefik.http.routers.edge.rule=Host(`edge.yourdomain.com`)"
      - "traefik.http.routers.edge.entrypoints=websecure"
      - "traefik.http.services.edge.loadbalancer.server.port=8000"
      - "traefik.http.routers.edge.service=edge"
      - "traefik.http.routers.edge.tls.certresolver=leresolver"


volumes:
  portainer_data:
```
{% endtab %}
{% endtabs %}

Before you run this file in Docker, you will need to create the `acme.json` file with permission `600` that will store the SSL certificates. Once it has been created, you can define the file path in the following sections in the Docker Compose file:

In the volumes and command section of the Traefik Proxy container:

```
- "./acme.json:/acme.json"
```

```
- --certificatesresolvers.leresolver.acme.storage=./acme.json
```

You also need to enter your email address for Let's Encrypt registration.

```
- --certificatesresolvers.leresolver.acme.email=your-email
```

Next, customize some labels in the Traefik container. The following labels need to be updated with the URL that you want use to access Portainer:

```
- "traefik.http.routers.frontend.rule=Host(`portainer.yourdomain.com`)"
```

```
- "traefik.http.routers.edge.rule=Host(`edge.yourdomain.com`)"
```

Once this is done, you're ready to deploy Portainer:

```
docker-compose up -d
```

After the images have been downloaded and deployed you will able to access Portainer from the URL you defined earlier, for example: `https://portainer.yourdomain.com`.

## Deploying in a Docker Swarm scenario

To deploy Portainer behind Traefik Proxy in a Docker Swarm scenario you must use a Docker Compose file. In the following `docker-compose.yml` you will find the configuration for Portainer Traefik with SSL support and the Portainer Server.

{% hint style="warning" %}
This deployment assumes you are running one manager node. If you are using multiple managers we advise [reading this knowledge base article](https://portal.portainer.io/knowledge/how-can-i-ensure-portainers-configuration-is-retained) before proceeding.
{% endhint %}

Before deploying the Docker Compose file, you need to create two elements: networks and volumes.

First, create two overlay networks:

```
 docker network create -d overlay agent_network
```

```
 docker network create -d overlay public
```

Then create the volume:

```
 docker volume create portainer_data
```

Save this recipe as `portainer.yml`:

{% tabs %}
{% tab title="Business Edition" %}
```
version: '3.2'

services:
  traefik:
    image: "traefik:latest"
    command:
      - --entrypoints.web.address=:80
      - --entrypoints.websecure.address=:443
      - --providers.docker=true
      - --providers.docker.swarmMode=true
      - --providers.docker.exposedbydefault=false
      - --providers.docker.network=public
      - --api
      - --log.level=ERROR
    ports:
      - "80:80"
      - "443:443"
    networks:
      - public
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:ro"

  agent:
    image: portainer/agent:lts
    environment:
      # REQUIRED: Should be equal to the service name prefixed by "tasks." when
      # deployed inside an overlay network
      AGENT_CLUSTER_ADDR: tasks.agent
      # AGENT_PORT: 9001
      # LOG_LEVEL: debug
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/lib/docker/volumes:/var/lib/docker/volumes
    networks:
      - agent_network
    deploy:
      mode: global
      placement:
        constraints: [node.platform.os == linux]

  portainer:
    image: portainer/portainer-ee:lts
    command: -H tcp://tasks.agent:9001 --tlsskipverify
    volumes:
      - data:/data
    networks:
      - public
      - agent_network
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.role == manager]
      labels:
      - "traefik.enable=true"
      - "traefik.http.routers.portainer.rule=Host(`portainer.yourdomain.com`)"
      - "traefik.http.routers.portainer.entrypoints=web"
      - "traefik.http.services.portainer.loadbalancer.server.port=9000"
      - "traefik.http.routers.portainer.service=portainer"
      # Edge
      - "traefik.http.routers.edge.rule=Host(`edge.yourdomain.com`)"
      - "traefik.http.routers.edge.entrypoints=web"
      - "traefik.http.services.edge.loadbalancer.server.port=8000"
      - "traefik.http.routers.edge.service=edge"

networks:
  public:
    external: true
  agent_network:
    external: true

volumes:
   data:
```
{% endtab %}

{% tab title="Community Edition" %}
```
version: '3.2'

services:
  traefik:
    image: "traefik:latest"
    command:
      - --entrypoints.web.address=:80
      - --entrypoints.websecure.address=:443
      - --providers.docker=true
      - --providers.swarm=true
      - --providers.docker.exposedbydefault=false
      - --providers.docker.network=public
      - --api
      - --log.level=ERROR
    ports:
      - "80:80"
      - "443:443"
    networks:
      - public
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:ro"

  agent:
    image: portainer/agent:lts
    environment:
      # REQUIRED: Should be equal to the service name prefixed by "tasks." when
      # deployed inside an overlay network
      AGENT_CLUSTER_ADDR: tasks.agent
      # AGENT_PORT: 9001
      # LOG_LEVEL: debug
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/lib/docker/volumes:/var/lib/docker/volumes
    networks:
      - agent_network
    deploy:
      mode: global
      placement:
        constraints: [node.platform.os == linux]

  portainer:
    image: portainer/portainer-ce:lts
    command: -H tcp://tasks.agent:9001 --tlsskipverify
    volumes:
      - data:/data
    networks:
      - public
      - agent_network
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.role == manager]
      labels:
      - "traefik.enable=true"
      - "traefik.http.routers.portainer.rule=Host(`portainer.yourdomain.com`)"
      - "traefik.http.routers.portainer.entrypoints=web"
      - "traefik.http.services.portainer.loadbalancer.server.port=9000"
      - "traefik.http.routers.portainer.service=portainer"
      # Edge
      - "traefik.http.routers.edge.rule=Host(`edge.yourdomain.com`)"
      - "traefik.http.routers.edge.entrypoints=web"
      - "traefik.http.services.edge.loadbalancer.server.port=8000"
      - "traefik.http.routers.edge.service=edge"

networks:
  public:
    external: true
  agent_network:
    external: true

volumes:
   data:
```
{% endtab %}
{% endtabs %}

Finally, customize these labels to match the URL that you want to use to access Portainer:

```
- "traefik.http.routers.frontend.rule=Host(`portainer.yourdomain.com`)"
```

```
- "traefik.http.routers.edge.rule=Host(`edge.yourdomain.com`)"
```

You can now deploy Portainer by executing the following:

```
 docker stack deploy portainer -c portainer.yml
```

To check the deployment, run `docker service ls`. You should see an output similar to the following:

```
ID                  NAME                  MODE                REPLICAS            IMAGE                          PORTS
lt21zrypsll6        portainer_agent       global              1/1                 portainer/agent:lts
m6912ynwdcd7        portainer_portainer   replicated          1/1                 portainer/portainer-ee:lts
tw2nb4i640e4        portainer_traefik     replicated          1/1                 traefik:latest                 *:80->80/tcp, *:443->443/tcp
```

Once the services are running, you will able to access Portainer from the URL you defined earlier, for example: `portainer.yourdomain.com`.



================================================
FILE: api/access.md
================================================
# Accessing the Portainer API

To access the Portainer API, you will need a few things:

* A user in Portainer
* An access token for that user
* The ability to make HTTPS requests to the Portainer server on port `9443` (or `9000` for legacy HTTP)

## Creating a new user

API access is provided on a per-user basis, with each users' API access dependent on that user's permissions within Portainer. For example, if your user had access to only one environment, API calls for that user would also be restricted to that environment.

To create a new user within Portainer, refer to our documentation:

{% content-ref url="../admin/user/add.md" %}
[add.md](../admin/user/add.md)
{% endcontent-ref %}

Once the user has been created, log in to Portainer as that user to create an API access token.

## Creating an access token

Once the user has been created, you can add an access token to that user. The access token will provide the same level of access to Portainer functionality as would be available to that user had they logged into the Portainer UI.

Once logged in as the user, click on your username in the top right and then select **My account**.

<figure><img src="../.gitbook/assets/2.20-api-access-myaccount.gif" alt=""><figcaption></figcaption></figure>

Scroll down to the **Access tokens** section. Here you can see any access tokens that exist for the user.&#x20;

<figure><img src="../.gitbook/assets/2.15-accountsettings-apitokens.png" alt=""><figcaption></figcaption></figure>

To add a new access token, click the **Add access token** button. You will be taken to a new page where you can set a **Description** for your access token. We recommend making this something recognizable for future reference.&#x20;

{% hint style="info" %}
For security we require you to re-enter your password when creating an access token.
{% endhint %}

<figure><img src="../.gitbook/assets/2.20-api-access-createtoken.png" alt=""><figcaption></figcaption></figure>

Once you have provided a description, click the **Add access token** button to generate your access token.

Your new access token will now be displayed. Please copy the access token and keep it in a safe place, as you will not be able to view the token again after creation.

<figure><img src="../.gitbook/assets/2.20-api-access-createdtoken.png" alt=""><figcaption></figcaption></figure>

When you have copied the access token, click the **Done** button to return to the User settings page. Your access token is ready to use.

## Using your access token

Now that you have created a user and access token, you are ready to access the API. The Portainer API follows the RESTful architecture, accepting `GET` / `POST` / `PUT` / `DELETE` requests and responding with JSON objects.

{% hint style="info" %}
The following examples use [httpie](https://httpie.org/) to execute API calls against Portainer. Feel free to replace this with your method of choice.
{% endhint %}

To make an API request, you will need to include your access token in the `X-API-Key` header to authenticate your request. For example, you can use the `/stacks` endpoint to list the stacks you have access to:

```
http GET https://portainer-url:9443/api/stacks X-API-Key:your_api_key_here
```

This will return a JSON object listing your stacks:

```
[
    {
        "AdditionalFiles": null,
        "AutoUpdate": null,
        "CreatedBy": "admin",
        "CreationDate": 1631852794,
        "EndpointId": 4,
        "EntryPoint": "docker-compose.yml",
        "Env": null,
        "GitConfig": {
            "Authentication": null,
            "ConfigFilePath": "docker-compose.yml",
            "ConfigHash": "2e71920bf1ee1bbac976d320f8f274411fba3bad",
            "ReferenceName": "refs/heads/master",
            "URL": "https://github.com/mygithubaccount/wordpress-stack"
        },
        "Id": 5,
        "IsComposeFormat": true,
        "Name": "",
        "Namespace": "my-namespace",
        "ProjectPath": "/data/compose/5",
        "ResourceControl": null,
        "Status": 1,
        "SwarmId": "",
        "Type": 3,
        "UpdateDate": 0,
        "UpdatedBy": ""
    },
]
```

If a user tries to access an area they do not have permission to access, an error message will be returned. For example, assume that a non-administrator user attempted to access the `/settings` endpoint, which requires administrator access:

```
http GET https://portainer:9443/api/settings X-API-Key:your_api_key_here
```

The user would be presented with the following response:

```
{
    "details": "Unauthorized",
    "message": "Access denied"
}
```

Now that you have access to the Portainer API, you can learn more about how to use it from the [API documentation](docs.md) and our [usage examples](examples.md).



================================================
FILE: api/docs.md
================================================
# API documentation

Portainer exposes an HTTP API that you can use to automate everything you do via the Portainer UI. You can also use Portainer as a gateway (HTTP queries against the Portainer API) to the underlying Docker/Kubernetes API.

{% hint style="info" %}
You will need an access token in order to use the Portainer API. If you have not already set up an access token for the API, we have [instructions on how to do so](access.md).
{% endhint %}

You can find our API documentation at SwaggerHub:

* [Business Edition (BE) 2.27.9 API Documentation](https://app.swaggerhub.com/apis/portainer/portainer-ee/2.27.9)
* [Community Edition (CE) 2.27.9 API Documentation](https://app.swaggerhub.com/apis/portainer/portainer-ce/2.27.9)

We have also provided some examples of API usage.

{% content-ref url="examples.md" %}
[examples.md](examples.md)
{% endcontent-ref %}



================================================
FILE: api/examples.md
================================================
# API usage examples

Portainer exposes an HTTP API that you can use to automate everything you do via the Portainer UI. You can also use Portainer as a gateway (HTTP queries against the Portainer API) to the underlying Docker/Kubernetes API.

{% hint style="info" %}
The following examples use [httpie](https://httpie.org/) to execute API calls against Portainer.
{% endhint %}

## Initialize the admin password

On a fresh install of Portainer, you need to create an admin account to initialize Portainer. You will be asked for this when you visit the Portainer URL for the first time. You can achieve the same outcome using this API call:

```
http POST <portainer url>/api/users/admin/init Username="<admin username>" Password="<adminpassword>"
```

## Authenticate against the API using the admin account

```
http POST <portainer url>/api/auth Username="<admin username>" Password="<adminpassword>"
```

The response is a JSON object containing the JWT token inside the `jwt` field. You will need to pass this token inside the authorization header when executing an authentication query against the API.

```
{
  "jwt":"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE"
}
```

The value of the authorization header must be of the form `Bearer <JWT_TOKEN>`:

```
Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsImV4cCI6MTQ5OTM3NjE1NH0.NJ6vE8FY1WG6jsRQzfMqeatJ4vh2TWAeeYfDhP71YEE
```

{% hint style="info" %}
This token is valid for 8 hours. Once it expires, you will need to generate another token to execute authenticated queries.
{% endhint %}

## Adding a new environment

On a fresh install, Portainer has no environments configured. You will first need to add an environment for Portainer to manage.

You can add an environment to manage [via the Portainer API](../admin/environments/add/api.md), or via the web interface both during the initial setup and after setup is complete.

## Execute Docker queries against a specific environment

The Portainer HTTP API endpoint acts as a reverse-proxy to the Docker HTTP API and can be used to execute any of the Docker HTTP API requests:

`/api/endpoints/<ENVIRONMENT_ID>/docker`

{% hint style="info" %}
Read [Docker's API documentation](https://docs.docker.com/engine/api/) to learn how to query the Docker Engine.
{% endhint %}

### **List all containers**

This call lists all of the containers available in a specific environment:

```
http GET <portainer url>/api/endpoints/1/docker/containers/json \
    X-API-Key:your_access-token \
    all==true
```

The response is identical to that returned by the `ContainerList` operation of the Docker API. See [Docker's documentation about this operation](https://docs.docker.com/engine/api/v1.41/#operation/ContainerList).

### **Create a container**

You can create a container in a specific environment using the Portainer HTTP API as a gateway. The following query will create a new Docker container inside the environment using ID 1. The container will be named `web01` and will use the `nginx:latest` Docker image. It will publish container port `80` on port `8080` on the host.

```
http POST <portainer url>/api/endpoints/1/docker/containers/create \
    X-API-Key:your_access-token \
    name=="web01" Image="nginx:latest" \
    ExposedPorts:='{ "80/tcp": {} }' \
    HostConfig:='{ "PortBindings": { "80/tcp": [{ "HostPort": "8080" }] } }'
```

The response is identical to that returned by the `ContainerCreate` operation of the Docker API. See [Docker's documentation about this operation](https://docs.docker.com/engine/api/v1.41/#operation/ContainerCreate).

Here is an example response:

```
{
    "Id": "5fc2a93d7a3d426a1c3937436697fc5e5343cc375226f6110283200bede3b107",
    "Warnings": null
}
```

You will need the container ID in order to execute actions against that container.

### **Start a container**

Using the ID you retrieved previously, you can start your new container using this endpoint:

`/api/endpoints/<ENVIRONMENT_ID>/docker/containers/<CONTAINER_ID>/start`

```
http POST <portainer url>/api/endpoints/1/docker/containers/5fc2a93d7a3d426a1c3937436697fc5e5343cc375226f6110283200bede3b107/start \
    X-API-Key:your_access-token
```

The response is identical to that returned by the `ContainerStart` operation of the Docker API. See [Docker's documentation about this operation](https://docs.docker.com/engine/api/v1.41/#operation/ContainerStart).

### **Delete a container**

You can create a container using the endpoint `/api/endpoints/<ENVIRONMENT_ID>/docker/containers/`:

```
http DELETE <portainer url>/api/endpoints/1/docker/containers/5fc2a93d7a3d426a1c3937436697fc5e5343cc375226f6110283200bede3b107 \
    X-API-Key:your_access-token \
    force==true
```

The response is identical to that returned by the `ContainerDelete` operation of the Docker API. See [Docker's documentation about this operation](https://docs.docker.com/engine/api/v1.41/#operation/ContainerDelete).



================================================
FILE: contribute/contribute.md
================================================
# Contribute

## Reporting bugs

If you find a bug, please tell us so we can triage it. All bugs are managed in this [GitHub repo](https://github.com/portainer/portainer/issues/new?assignees=\&labels=bug%2Fneed-confirmation%2C+kind%2Fbug\&template=Bug_report.md\&title=). When you click through, our template makes it easy to record all of the details. Before you report a bug, please check our list of [open bugs](https://github.com/portainer/portainer/labels/kind%2Fbug) in case someone else has already reported it.

[This knowledge base article](https://portal.portainer.io/knowledge/how-do-you-decide-which-bugs-and-features-to-work-on-first) covers how we prioritize bug fixes.

## Feature requests

You can request new features by posting an Idea in our [GitHub Discussions](https://github.com/orgs/portainer/discussions/categories/ideas) forum. Please check to see if someone has already requested the feature you want, and give it an upvote if so.

Learn how we prioritize feature development [in this knowledge base article](https://portal.portainer.io/knowledge/how-do-you-decide-which-bugs-and-features-to-work-on-first).

## Contributing to the Portainer CE codebase

The Portainer CE codebase is available in [GitHub](https://github.com/portainer/portainer). Please follow our build instructions and [contribution guidelines](https://github.com/portainer/portainer/blob/develop/CONTRIBUTING.md) when making a contribution.



================================================
FILE: faq/concepts.md
================================================
# Portainer Concepts

{% hint style="info" %}
This content has moved to the [Portainer Knowledge Base](https://portal.portainer.io/knowledge/getting-started).
{% endhint %}



================================================
FILE: faq/contributing.md
================================================
# Contributing

{% hint style="info" %}
This content has moved to the [Portainer Knowledge Base](https://portal.portainer.io/knowledge/contributing).
{% endhint %}



================================================
FILE: faq/installing.md
================================================
# Installing

{% hint style="info" %}
This content has moved to the [Portainer Knowledge Base](https://portal.portainer.io/knowledge/installing).
{% endhint %}



================================================
FILE: faq/troubleshooting.md
================================================
# Troubleshooting

{% hint style="info" %}
This content has moved to the [Portainer Knowledge Base](https://portal.portainer.io/knowledge/troubleshooting).
{% endhint %}



================================================
FILE: faq/upgrading.md
================================================
# Upgrading

{% hint style="info" %}
This content has moved to the [Portainer Knowledge base](https://portal.portainer.io/knowledge/upgrading-and-downgrading).
{% endhint %}



================================================
FILE: start/agent.md
================================================
# Add an environment to an existing installation

If you want to add another environment to your existing Portainer installation, first select the type of environment you would like to add.

You can choose to connect to existing environments:

<table data-view="cards"><thead><tr><th></th><th></th><th></th><th data-hidden data-card-target data-type="content-ref"></th><th data-hidden data-card-cover data-type="files"></th></tr></thead><tbody><tr><td><strong>Docker Standalone</strong></td><td>Connect to Docker Standalone via URL/IP, API or Socket</td><td></td><td><a href="../admin/environments/add/docker/">docker</a></td><td><a href="../.gitbook/assets/card-docker.png">card-docker.png</a></td></tr><tr><td><strong>Docker Swarm</strong></td><td>Connect to Docker Swarm via URL/IP, API or Socket</td><td></td><td><a href="../admin/environments/add/swarm/">swarm</a></td><td><a href="../.gitbook/assets/card-docker.png">card-docker.png</a></td></tr><tr><td><strong>Kubernetes</strong></td><td>Connect to a Kubernetes environment via URL/IP or via kubeconfig import</td><td></td><td><a href="../admin/environments/add/kubernetes/">kubernetes</a></td><td><a href="../.gitbook/assets/card-kubernetes.png">card-kubernetes.png</a></td></tr><tr><td><strong>Podman</strong></td><td>Connect to a Podman environment via URL/IP or Socket</td><td></td><td><a href="../admin/environments/add/podman/">podman</a></td><td><a href="../.gitbook/assets/podman-logo-tile.png">podman-logo-tile.png</a></td></tr><tr><td><strong>Azure ACI</strong></td><td>Connect to an Azure ACI environment via API</td><td></td><td><a href="../admin/environments/add/aci.md">aci.md</a></td><td><a href="../.gitbook/assets/card-aci.png">card-aci.png</a></td></tr></tbody></table>

Or alternatively set up new environments:

<table data-card-size="large" data-view="cards"><thead><tr><th></th><th></th><th></th><th data-hidden data-card-target data-type="content-ref"></th><th data-hidden data-card-cover data-type="files"></th></tr></thead><tbody><tr><td><strong>Provision KaaS Cluster</strong></td><td>Provision a Kubernetes cluster via a cloud provider's Kubernetes as a Service</td><td></td><td><a href="../admin/environments/add/kaas/">kaas</a></td><td><a href="../.gitbook/assets/card-kaas-large.png">card-kaas-large.png</a></td></tr><tr><td><strong>Create a Kubernetes cluster</strong></td><td>Create a Kubernetes cluster on existing infrastructure</td><td></td><td><a href="../admin/environments/add/kube-create/">kube-create</a></td><td><a href="../.gitbook/assets/card-kube-create-large.png">card-kube-create-large.png</a></td></tr></tbody></table>



================================================
FILE: start/architecture.md
================================================
# Portainer architecture

## Overview of Portainer architecture

Portainer consists of two elements: the Portainer Server and the Portainer Agent. Both run as lightweight containers on your existing containerized infrastructure. The Portainer Agent should be deployed to each node in your cluster and configured to report back to the Portainer Server container.

{% hint style="info" %}
For a deeper dive into the architecture of Portainer, have a look at our [reference architecture](https://academy.portainer.io/architecture).
{% endhint %}

A single Portainer Server will accept connections from any number of Portainer Agents, providing the ability to manage multiple clusters from one centralized interface. To do this, the Portainer Server container requires data persistence. The Portainer Agents are stateless, with data being shipped back to the Portainer Server container.

![The Portainer architecture](../.gitbook/assets/portainer-architecture-detailed.png)

{% hint style="info" %}
We don't currently support running multiple instances of the Portainer Server container to manage the same clusters. We recommend running the Portainer Server on a specific management node, with Portainer Agents deployed across the remaining nodes.
{% endhint %}

## Agent vs Edge Agent

In standard deployments, the central Portainer Server instance and any environments it manages are assumed to be on the same network, that is, Portainer Server and the Portainer Agents are able to seamlessly communicate with one another. However, in configurations where the remote environments are on a completely separate network to Portainer Server, say, across the internet, historically we would have been unable to centrally manage these devices.

With the new Edge Agent, we altered the architecture. Rather than the Portainer Server needing seamless access to the remote environment, only the remote environments need to be able to access the Portainer Server. This communication is performed over an encrypted TLS tunnel. This is important in Internet-connected configurations where there is no desire to expose the Portainer Agent to the internet.

## Security and compliance

Portainer runs exclusively on your servers, within your network, behind your own firewalls. As a result, we do not currently hold any SOC or PCI/DSS compliance because we do not host any of your infrastructure. You can even run Portainer completely disconnected (air-gapped) without any impact on functionality.

While we do (optionally) collect anonymous usage analytics from Portainer installations, we remain compliant with GDPR. Data collection can be disabled when you install the product, or at any time after that. If your installation is air-gapped, collection will silently fail without any adverse effects.

{% content-ref url="lifecycle.md" %}
[lifecycle.md](lifecycle.md)
{% endcontent-ref %}



================================================
FILE: start/intro.md
================================================
# Introduction

This section explains the Portainer architecture and how to install it. We recommend that you read the entire section to ensure your installation goes smoothly.

Learn about the [architecture](architecture.md) first, get familiar with the [prerequisites to installation](requirements-and-prerequisites.md), then finally, step through how to [install the product](install/) in your environment.

{% content-ref url="architecture.md" %}
[architecture.md](architecture.md)
{% endcontent-ref %}






================================================
FILE: start/lifecycle.md
================================================
# Lifecycle policy

Portainer makes this policy public so customers and partners can effectively plan, deploy, and support their container management infrastructure effectively using Portainer. It is published in an effort to provide as much transparency as possible but Portainer has the discretion to make exceptions from this policy should that be in Portainer’s or our customer’s best interests.

Any release dates are provided for guidance only and the exact dates may change.

## The Portainer lifecycle

Portainer releases approximately follow a monthly cadence for minor releases (X.Y) which can introduce feature enhancements and new features but endeavor to maintain backward compatibility.

Micro or patch releases (X.Y.z) are released as needed and are limited to backward compatible bug fixes only.

Major versions (X) will be much less frequent, will include potential breaking changes, and may require an upgrade or migration process from previous versions.

All releases are cumulative - all previous enhancements and fixes are included in each release.

## Terminology

### Supported versus maintained

When we say “supported”, we are referring to the commercial support that is included with Portainer Business Edition subscriptions at the Scale and Enterprise level. This includes access to all STS and LTS releases and patches. Our [support terms](https://www.portainer.io/support-terms) have more detail on what is and isn’t covered by our support.

For Starter, Home & Student, our free Business Edition offerings, and our Community Edition, support is provided through our [community support channels](https://www.portainer.io/get-support-for-portainer).

The term “maintained” refers to the act of releasing updated versions of our releases, for example patches to resolve bugs or security issues. All editions of Business Edition and Community Edition will be maintained according to each release’s respective lifecycle.

Portainer always recommends updating to the latest version in the release stream to ensure you have the latest security fixes, bug fixes, and performance improvements. It is at Portainer’s discretion to backport fixes to any version outside of the supported version window.

### STS versus LTS

Portainer has two release streams, STS and LTS and it’s important you know the differences so you can choose accordingly.

#### **Short Term Support (STS) releases**

Short Term Support releases are identified with an “STS” suffix.

These are supported and maintained until the release of the next STS or LTS version. Use STS versions if you are interested in getting the latest features faster and don’t mind upgrading more frequently.

#### **Long Term Support (LTS) releases**

Long Term Support releases are identified with an “LTS” suffix.

These releases are supported and maintained until the release of the next LTS version plus a three month migration window so are more suitable for environments where adding new features on a frequent basis is less desirable.

{% hint style="info" %}
Portainer LTS releases focus less on new features and more on stability so Portainer recommends LTS releases for production workloads.
{% endhint %}

## Current and planned releases

Each stream (LTS and STS) will have a number of patch releases throughout it’s life.

### Current releases

| Release      | Release Date | End of support/maintenance |
| ------------ | ------------ | -------------------------- |
| 2.31 STS     | Jun 2025     | Jul 2025                   |
| **2.27 LTS** | **Feb 2025** | **Jan 2026**               |

### Planned releases

| Release      | Release Date | End of support/maintenance |
| ------------ | ------------ | -------------------------- |
| 2.32 STS     | Jul 2025     | Aug 2025                   |
| **2.33 LTS** | **Aug 2025** | **Jul 2026**               |

<figure><img src="../.gitbook/assets/2.31-lifecycle-dates.png" alt=""><figcaption></figcaption></figure>

Sitting on an older release that is no longer maintained or supported is strongly discouraged and customers take full responsibility for doing so. Customers are strongly encouraged to ensure they are running the latest patch release for a given stream.

## Older releases that are no longer supported or maintained

The following releases have passed the end of support date and are no longer maintained or supported. If you are using one of these versions (or older), we recommend that you [update](upgrade/) as soon as possible.

| Release  | Release Date | End of support/maintenance |
| -------- | ------------ | -------------------------- |
| 2.17     | Feb 2023     | Apr 2023                   |
| 2.18     | Apr 2023     | Aug 2023                   |
| 2.19     | Aug 2023     | Aug 2024                   |
| 2.20 STS | Mar 2024     | Aug 2024                   |
| 2.22 STS | Sep 2024     | Oct 2024                   |
| 2.23 STS | Oct 2024     | Nov 2024                   |
| 2.24 STS | Nov 2024     | Dec 2024                   |
| 2.25 STS | Dec 2024     | Jan 2025                   |
| 2.26 STS | Jan 2025     | Feb 2025                   |
| 2.28 STS | Mar 2025     | Apr 2025                   |
| 2.29 STS | Apr 2025     | May 2025                   |
| 2.30 STS | May 2025     | Jun 2025                   |

## Notes

Portainer uses the [semantic versioning scheme](https://semver.org/) and while Portainer endeavors to follow best practices, we reserve the right to make exceptions should that be in Portainer’s and our customer’s best interests.

For information on the available options and best practices for updating Portainer deployments, [refer to our update documentation](upgrade/).

{% content-ref url="requirements-and-prerequisites.md" %}
[requirements-and-prerequisites.md](requirements-and-prerequisites.md)
{% endcontent-ref %}














================================================
FILE: start/requirements-and-prerequisites.md
================================================
# Requirements and prerequisites

Requirements specific to your environment will be covered in the installation process.

## Valid configurations

Every Portainer release goes through functional, release and post-release testing to ensure it works as expected. Because we cannot test against every configuration variant out there, we test against a subset.

The following tables list all of the configurations that we have tested, validated and consider to be functional. If a variant is not listed, it doesn't mean it won't work, it just means it hasn't been tested.

### Portainer Business Edition (BE)

| Portainer Version                                         | Release Date       | Docker Version            | Kubernetes Version       | Podman Version | Architectures                                                                                          |
| --------------------------------------------------------- | ------------------ | ------------------------- | ------------------------ | -------------- | ------------------------------------------------------------------------------------------------------ |
| [Business 2.27.9](../release-notes.md#release-2.27.9-lts) | July 2, 2025       | 26.0.2 27.0.3             | 1.29 1.30 1.31           | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.27.8](../release-notes.md#release-2.27.8)     | June 25, 2025      | 26.0.2 27.0.3             | 1.29 1.30 1.31           | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.27.7](../release-notes.md#release-2.27.7)     | June 17, 2025      | 26.0.2 27.0.3             | 1.29 1.30 1.31           | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.27.6](../release-notes.md#release-2.27.6)     | May 9, 2025        | 26.0.2 27.0.3             | 1.29 1.30 1.31           | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.27.5](../release-notes.md#release-2.27.5)     | May 2, 2025        | 26.0.2 27.0.3             | 1.29 1.30 1.31           | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.27.4](../release-notes.md#release-2.27.4)     | April 15, 2025     | 26.0.2 27.0.3             | 1.29 1.30 1.31           | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.27.3](../release-notes.md#release-2.27.3)     | March 25, 2025     | 26.0.2 27.0.3             | 1.29 1.30 1.31           | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.27.2](../release-notes.md#release-2.27.2)     | March 19, 2025     | 26.0.2 27.0.3             | 1.29 1.30 1.31           | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.27.1](../release-notes.md#release-2.27.1)     | February 27, 2025  | 26.0.2 27.0.3             | 1.29 1.30 1.31           | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.27.0](../release-notes.md#release-2.27.0)     | February 20, 2025  | 26.0.2 27.0.3             | 1.29 1.30 1.31           | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.26.1](../release-notes.md#release-2.26.1)     | January 21, 2025   | 26.0.2 27.0.1             | 1.28 1.29 1.30           | 5.2.2          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.26.0](../release-notes.md#release-2.26.0)     | January 15, 2025   | 26.0.2 27.0.1             | 1.28 1.29 1.30           | 5.2.2          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.25.1](../release-notes.md#release-2.25.1)     | December 20, 2024  | 26.0.2 27.0.1             | 1.28 1.29 1.30           | 5.2.2          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.21.5](../release-notes.md#release-2.21.5)     | December 20, 2024  | 26.0.2 27.0.1             | 1.28 1.29 1.30           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.25.0](../release-notes.md#release-2.25.0)     | December 16, 2024  | 26.0.2 27.0.1             | 1.28 1.29 1.30           | 5.2.2          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.24.1](../release-notes.md#release-2.24.1)     | December 3, 2024   | 26.0.2 27.0.1             | 1.28 1.29 1.30           | 5.2.2          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.24.0](../release-notes.md#release-2.24.0)     | November 20, 2024  | 26.0.2 27.0.1             | 1.28 1.29 1.30           | 5.2.2          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.21.4](../release-notes.md#release-2.21.4)     | October 25, 2024   | 26.0.2 27.0.1             | 1.28 1.29 1.30           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.23.0](../release-notes.md#release-2.23.0)     | October 16, 2024   | 26.0.2 27.0.1             | 1.28 1.29 1.30           | 5.2.2          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.21.3](../release-notes.md#release-2.21.3)     | October 8, 2024    | 26.0.2 27.0.1             | 1.28 1.29 1.30           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.22.0](../release-notes.md#release-2.22.0)     | October 3, 2024    | 26.0.2 27.0.1             | 1.28 1.29 1.30           | 5.2.2          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.21.2](../release-notes.md#release-2.21.2)     | September 24, 2024 | 26.0.2 27.0.1             | 1.28 1.29 1.30           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.21.1](../release-notes.md#release-2.21.1)     | September 10, 2024 | 26.0.2 27.0.1             | 1.28 1.29 1.30           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.21.0](../release-notes.md#release-2.21.0)     | August 27, 2024    | 26.0.2 27.0.1             | 1.28 1.29 1.30           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.20.3](../release-notes.md#release-2.20.3)     | May 21, 2024       | 25.0.5                    | 1.24 1.26 1.27           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.20.2](../release-notes.md#release-2.20.2)     | May 1, 2024        | 25.0.5                    | 1.24 1.26 1.27           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.19.5](../release-notes.md#release-2.19.5)     | April 22, 2024     | 23.0.6 24.0.4             | 1.23 1.24 1.26           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.20.1](../release-notes.md#release-2.20.1)     | April 5, 2024      | 23.0.6 24.0.6             | 1.24 1.26 1.27           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.20.0](../release-notes.md#release-2.20.0)     | March 19, 2024     | 23.0.6 24.0.6             | 1.24 1.26 1.27           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.19.4](../release-notes.md#release-2.19.4)     | December 6, 2023   | 23.0.6 24.0.4             | 1.23 1.24 1.26           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.19.3](../release-notes.md#release-2.19.3)     | November 22, 2023  | 23.0.6 24.0.4             | 1.23 1.24 1.26           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.19.2](../release-notes.md#release-2.19.2)     | November 13, 2023  | 23.0.6 24.0.4             | 1.23 1.24 1.26           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.19.1](../release-notes.md#release-2.19.1)     | September 20, 2023 | 23.0.6 24.0.4             | 1.23 1.24 1.26           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.19.0](../release-notes.md#release-2.19.0)     | August 31, 2023    | 23.0.6 24.0.4             | 1.23 1.24 1.26           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.18.4](../release-notes.md#release-2.18.4)     | July 7, 2023       | 23.0.6 24.0.4             | 1.22 1.23 1.24           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.18.3](../release-notes.md#release-2.18.3)     | May 22, 2023       | 20.10.9 20.10.13 20.10.17 | 1.22 1.23 1.24           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.18.2](../release-notes.md#release-2.18.2)     | May 1, 2023        | 20.10.9 20.10.13 20.10.17 | 1.22 1.23 1.24           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.18.1](../release-notes.md#release-2.18.1)     | April 18, 2023     | 20.10.9 20.10.13 20.10.17 | 1.22 1.23 1.24           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.17.1](../release-notes.md#release-2.17.1)     | February 22, 2023  | 20.10.9 20.10.13 20.10.17 | 1.22 1.23 1.24           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.17.0](../release-notes.md#release-2.17.0)     | February 7, 2023   | 20.10.9 20.10.13 20.10.17 | 1.22 1.23 1.24           | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.16.2](../release-notes.md#release-2.16.2)     | November 21, 2022  | 20.10.9 20.10.13 20.10.17 | 1.21.7 1.22 1.23         | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.16.1](../release-notes.md#release-2.16.1)     | November 9, 2022   | 20.10.9 20.10.13 20.10.17 | 1.21.7 1.22 1.23         | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.16.0](../release-notes.md#release-2.16.0)     | October 31, 2022   | 20.10.9 20.10.13 20.10.17 | 1.21.7 1.22 1.23         | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.15.1](../release-notes.md#release-2.15.1)     | September 16, 2022 | 20.10.9 20.10.12 20.10.13 | 1.21.7 1.22 1.23         | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.15.0](../release-notes.md#release-2.15.0)     | September 6, 2022  | 20.10.9 20.10.12 20.10.13 | 1.21.7 1.22 1.23         | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.14.2](../release-notes.md#release-2.14.2)     | July 26, 2022      | 20.10.9 20.10.12 20.10.13 | 1.21.7 1.22 1.23         | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.14.1](../release-notes.md#release-2.14.1)     | July 12, 2022      | 20.10.9 20.10.12 20.10.13 | 1.21.7 1.22 1.23         | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.14.0](../release-notes.md#release-2.14.0)     | June 28, 2022      | 20.10.9 20.10.12 20.10.13 | 1.21.7 1.22 1.23         | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.13.1](../release-notes.md#release-2.13.1)     | May 12, 2022       | 20.10.9 20.10.12 20.10.13 | 1.21.7 1.22 1.23         | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.13.0](../release-notes.md#release-2.13.0)     | May 9, 2022        | 20.10.9 20.10.12 20.10.13 | 1.21.7 1.22 1.23         | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.12.2](../release-notes.md#release-2.12.2)     | April 4, 2022      | 20.10.7 20.10.11 20.10.12 | 1.21.7 1.22 1.23         | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.12.1](../release-notes.md#release-2.12.1)     | March 9, 2022      | 20.10.7 20.10.11 20.10.12 | 1.21.7 1.22 1.23         | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.12.0](../release-notes.md#release-2.12.0)     | March 8, 2022      | 20.10.7 20.10.11 20.10.12 | 1.21.7 1.22 1.23         | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.10.0](../release-notes.md#release-2.10.0)     | November 15, 2021  | 20.10.6 20.10.7 20.10.8   | 1.19.11 1.20.7 1.21 1.22 | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.7.0](../release-notes.md#release-2.7.0)       | July 29, 2021      | 20.10.6 20.10.7           | 1.19 1.20.2 1.21         | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.4.0](../release-notes.md#release-2.4.0)       | May 4, 2021        | 20.10.5                   | 1.19 1.20.2 1.21         | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.0.1](../release-notes.md#release-2.0.1)       | February 22, 2021  | 19.03.13                  | 1.17.3 1.18.6 1.19.3     | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| [Business 2.0.0](../release-notes.md#release-2.0.0)       | December 3, 2020   | 19.03.13                  | 1.17.3 1.18.6 1.19.3     | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |

### Portainer Community Edition (CE)

| Portainer Version | Release Date       | Docker Version            | Kubernetes Version           | Podman Version | Architectures                                                                                                                                                                                         |
| ----------------- | ------------------ | ------------------------- | ---------------------------- | -------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Community 2.27.9  | July 2, 2025       | 26.0.2 27.0.3             | 1.29 1.30 1.31               | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.27.8  | June 25, 2025      | 26.0.2 27.0.3             | 1.29 1.30 1.31               | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.27.7  | June 17, 2025      | 26.0.2 27.0.3             | 1.29 1.30 1.31               | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.27.6  | May 9, 2025        | 26.0.2 27.0.3             | 1.29 1.30 1.31               | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.27.5  | May 2, 2025        | 26.0.2 27.0.3             | 1.29 1.30 1.31               | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.27.4  | April 15, 2025     | 26.0.2 27.0.3             | 1.29 1.30 1.31               | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.27.3  | March 25, 2025     | 26.0.2 27.0.3             | 1.29 1.30 1.31               | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.27.2  | March 19, 2025     | 26.0.2 27.0.3             | 1.29 1.30 1.31               | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.27.1  | February 27, 2025  | 26.0.2 27.0.3             | 1.29 1.30 1.31               | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.27.0  | February 20, 2025  | 26.0.2 27.0.3             | 1.29 1.30 1.31               | 5.2.3          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.26.1  | January 21, 2025   | 26.0.2 27.0.1             | 1.28 1.29 1.30               | 5.2.2          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.26.0  | January 15, 2025   | 26.0.2 27.0.1             | 1.28 1.29 1.30               | 5.2.2          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.25.1  | December 20, 2024  | 26.0.2 27.0.1             | 1.28 1.29 1.30               | 5.2.2          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.21.5  | December 20, 2024  | 26.0.2 27.0.1             | 1.28 1.29 1.30               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.25.0  | December 16, 2024  | 26.0.2 27.0.1             | 1.28 1.29 1.30               | 5.2.2          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.24.1  | December 3, 2024   | 26.0.2 27.0.1             | 1.28 1.29 1.30               | 5.2.2          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.24.0  | November 15, 2024  | 26.0.2 27.0.1             | 1.28 1.29 1.30               | 5.2.2          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.21.4  | October 25, 2024   | 26.0.2 27.0.1             | 1.28 1.29 1.30               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.23.0  | October 16, 2024   | 26.0.2 27.0.1             | 1.28 1.29 1.30               | 5.2.2          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.21.3  | October 8, 2024    | 26.0.2 27.0.1             | 1.28 1.29 1.30               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.22.0  | October 3, 2024    | 26.0.2 27.0.1             | 1.28 1.29 1.30               | 5.2.2          | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.21.2  | September 24, 2024 | 26.0.2 27.0.1             | 1.28 1.29 1.30               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.21.1  | September 10, 2024 | 26.0.2 27.0.1             | 1.28 1.29 1.30               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.21.0  | August 27, 2024    | 26.0.2 27.0.1             | 1.28 1.29 1.30               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.20.3  | May 21, 2024       | 25.0.5                    | 1.24 1.26 1.27               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.20.2  | May 1, 2024        | 25.0.5                    | 1.24 1.26 1.27               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.19.5  | April 22, 2024     | 23.0.6 24.0.4             | 1.23 1.24 1.26               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.20.1  | April 5, 2024      | 23.0.6 24.0.6             | 1.24 1.26 1.27               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.20.0  | March 19, 2024     | 23.0.6 24.0.6             | 1.24 1.26 1.27               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.19.4  | December 6, 2023   | 23.0.6 24.0.4             | 1.23 1.24 1.26               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.19.3  | November 22, 2023  | 23.0.6 24.0.4             | 1.23 1.24 1.26               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.19.2  | November 13, 2023  | 23.0.6 24.0.4             | 1.23 1.24 1.26               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.19.1  | September 20, 2023 | 23.0.6 24.0.4             | 1.23 1.24 1.26               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.19.0  | August 31, 2023    | 23.0.6 24.0.4             | 1.23 1.24 1.26               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.18.4  | July 7, 2023       | 23.0.6 24.0.4             | 1.22 1.23 1.24               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.18.3  | May 22, 2023       | 20.10.9 20.10.13 20.10.17 | 1.22 1.23 1.24               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.18.2  | May 1, 2023        | 20.10.9 20.10.13 20.10.17 | 1.22 1.23 1.24               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.18.1  | April 18, 2023     | 20.10.9 20.10.13 20.10.17 | 1.22 1.23 1.24               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.17.1  | February 22, 2023  | 20.10.9 20.10.13 20.10.17 | 1.22 1.23 1.24               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.17.0  | February 7, 2023   | 20.10.9 20.10.13 20.10.17 | 1.22 1.23 1.24               | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.16.2  | November 21, 2022  | 20.10.9 20.10.13 20.10.17 | 1.21.7 1.22 1.23             | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.16.1  | November 9, 2022   | 20.10.9 20.10.13 20.10.17 | 1.21.7 1.22 1.23             | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.16.0  | October 31, 2022   | 20.10.9 20.10.13 20.10.17 | 1.21.7 1.22 1.23             | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.15.1  | September 16, 2022 | 20.10.9 20.10.12 20.10.13 | 1.21.7 1.22 1.23             | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.15.0  | September 6, 2022  | 20.10.9 20.10.12 20.10.13 | 1.21.7 1.22 1.23             | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.14.2  | July 26, 2022      | 20.10.9 20.10.12 20.10.13 | 1.21.7 1.22 1.23             | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.14.1  | July 12, 2022      | 20.10.9 20.10.12 20.10.13 | 1.21.7 1.22 1.23             | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.14.0  | June 28, 2022      | 20.10.9 20.10.12 20.10.13 | 1.21.7 1.22 1.23             | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.13.1  | May 12, 2022       | 20.10.9 20.10.12 20.10.13 | 1.21.7 1.22 1.23             | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.13.0  | May 9, 2022        | 20.10.9 20.10.12 20.10.13 | 1.21.7 1.22 1.23             | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.11.1  | February 8, 2022   | 20.10.8 20.10.11 20.10.12 | 1.20.13 1.21.7 1.22.4        | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.11.0  | December 9, 2021   | 20.10.6 20.10.8 20.10.11  | 1.19.11 1.20.7 1.21 1.22     | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.9.3   | November 22, 2021  | 20.10.5 20.10.6           | 1.19.11 1.20.7 1.21 1.22     | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.9.2   | October 26, 2021   | 20.10.5 20.10.6           | 1.19 1.20 1.21 1.22          | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.9.1   | October 11, 2021   | 20.10.5 20.10.6           | 1.19 1.20 1.21 1.22          | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.9.0   | September 23, 2021 | 20.10.5 20.10.6           | 1.19 1.20 1.21 1.22          | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.6.3   | August 27, 2021    | 20.10.5 20.10.6           | 1.19 1.20 1.21 1.22          | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.6.2   | August 2, 2021     | 20.10.5 20.10.6           | 1.19 1.20.2 1.21             | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.6.1   | July 12, 2021      | 20.10.5 20.10.6           | 1.19 1.20.2 1.21             | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.6.0   | June 25, 2021      | 20.10.5 20.10.6           | 1.19 1.20.2 1.21             | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.5.1   | May 18, 2021       | 20.10.5 20.10.6           | 1.19 1.20.2 1.21             | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.5.0   | May 18, 2021       | 20.10.5                   | 1.19 1.20.2 1.21             | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.1.x   | February 2, 2021   | 20.10.2                   | 1.20.0                       | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.0.1   | January 7, 2021    | 20.10.0                   | 1.17.13 1.18.9 1.19.3 1.20.0 | N/A            | [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64                                                                                                |
| Community 2.0     | August 31, 2020    | 19.03.12                  | 1.17.13 1.18.6 1.18.9 1.19.3 | N/A            | [ARM32](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| 1.24.1            | July 23, 2020      | 19.03.12                  | N/A                          | N/A            | [ARM32](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| 1.24.0            | June 2, 2020       | 19.03.10                  | N/A                          | N/A            | [ARM32](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |
| 1.23.2            | March 25, 2020     | 19.03.6                   | N/A                          | N/A            | [ARM32](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), [ARM64](https://portal.portainer.io/knowledge/which-arm-architectures-does-portainer-support), x86\_64 |

{% hint style="info" %}
If you find an issue with an unlisted configuration, before reporting a bug, update your environment to a valid configuration and try to replicate the issue.
{% endhint %}

## Persistent storage

The Portainer Server requires persistent storage in order to maintain the database and configuration information it needs to function. The installation process provides a basic storage configuration for your platform. By default, both Docker and Kubernetes provide local (to the node) storage only, and if cluster-wide persistent storage is desired we recommend implementing it at the infrastructure level.

Additionally, you will want to ensure that your persistent storage for Portainer's data volume is right-sized for your needs. If you intend to use Portainer's Git deployment functionality for example, you will need to be aware that as part of the deployment from Git, Portainer will clone the remote repository locally to the Portainer data volume, which in the case of larger or multiple Git repos may consume significant amounts of disk space.

For larger or performance-critical deployments, we suggest you look to provision persistent storage with the highest possible throughput and lowest available latency. SSD-level performance (\~3.5 MB/s, 30,000 IOPS or above, under 10ms write IO latency) is ideal. Be careful when using cloud provider storage both in terms of latency and "burstable" or noisy-neighbor performance characteristics.

If you would like more assistance with verifying your scaled deployment please [get in touch](https://www.portainer.io/contact-sales) with our team.

## Ports

In order to access the UI and API, and for the Portainer Server instance and the Portainer Agents to communicate, certain ports need to be accessible.

On the Portainer Server the following ports must be open:

* TCP port `9443` (or `30779` for Kubernetes with NodePort) for the UI and API
* TCP port `8000` (or `30776` for Kubernetes with NodePort) for the TCP tunnel server for Edge Agents. This port is optional and only required if using Edge Compute features with Edge Agents.

For the Portainer Agent:

* TCP port `9001` (or `30778` for Kubernetes with NodePort) must be accessible on the Agent from the Portainer Server instance.

The Portainer Edge Agent does not require any open ports.

{% hint style="info" %}
All ports can be changed during installation.
{% endhint %}

{% content-ref url="install/" %}
[install](install/)
{% endcontent-ref %}

{% content-ref url="install-ce/" %}
[install-ce](install-ce/)
{% endcontent-ref %}



================================================
FILE: start/install/README.md
================================================
# Install Portainer BE

{% hint style="info" %}
These installation instructions are for Portainer Business Edition (BE). For Portainer Community Edition (CE) refer to the [CE install documentation](../install-ce/).
{% endhint %}

Portainer Business Edition is straightforward to install. There are two options: installing new or adding an environment to an existing installation.

For a detailed, step-by-step guide to setting up Portainer for production, have a look at our [Best Practice Install Guide](https://academy.portainer.io/install/) in the Portainer Academy.

{% hint style="info" %}
If you haven't already, please check that your environments meet [our requirements](../requirements-and-prerequisites.md) before proceeding.
{% endhint %}

{% content-ref url="server/" %}
[server](server/)
{% endcontent-ref %}

{% content-ref url="../agent.md" %}
[agent.md](../agent.md)
{% endcontent-ref %}



================================================
FILE: start/install/server/README.md
================================================
# Set up a new Portainer BE Server installation

{% hint style="info" %}
These installation instructions are for Portainer Business Edition (BE). For Portainer Community Edition (CE) refer to the [CE install documentation](../../install-ce/server/).
{% endhint %}

Select the environment for your new Portainer installation:

{% content-ref url="docker/" %}
[docker](docker/)
{% endcontent-ref %}

{% content-ref url="swarm/" %}
[swarm](swarm/)
{% endcontent-ref %}

{% content-ref url="podman/" %}
[podman](podman/)
{% endcontent-ref %}

{% content-ref url="kubernetes/" %}
[kubernetes](kubernetes/)
{% endcontent-ref %}



================================================
FILE: start/install/server/setup.md
================================================
# Initial setup

Once the Portainer Server has been deployed, and you have navigated to the instance's URL, you are ready for the initial setup.

## Creating the first user

Your first user will be an administrator. The username defaults to `admin` but you can change it if you prefer. The password must be at least 12 characters long and meet the listed password requirements.

<figure><img src="../../../.gitbook/assets/2.15-install-server-setup-user.png" alt=""><figcaption></figcaption></figure>

## Enabling or disabling the collection of statistics

We use a tool called [Matomo](https://matomo.org/) to collect anonymous information about how Portainer is used. We recommend enabling this option so we can make improvements based on usage. For more about what we do with the information we collect, read our [privacy policy](https://www.portainer.io/privacy-policy).

During installation, you can enable or disable connection statistics using the checkbox. If you change your mind later, you can easily update this option under [Settings](../../../admin/settings/general.md#allow-the-collection-of-anonymous-statistics) in the Portainer UI.

<figure><img src="../../../.gitbook/assets/2.15-install-server-setup-matomo.png" alt=""><figcaption></figcaption></figure>

## Add your license key

You will now be asked to provide your license key. You will have been provided this when signing up for Business Edition or the free trial. If you don't have a license key, you can either click the **Don't have a license?** link or [get in touch with our team](mailto:success@portainer.io).

Paste the license key you were provided into the box and click **Submit**.

<figure><img src="../../../.gitbook/assets/2.20-initial-setup-license.png" alt=""><figcaption></figcaption></figure>

## Connecting Portainer to your environments

Once the admin user has been created, the **Environment Wizard** will automatically launch. The wizard will help get you started with Portainer.

<figure><img src="../../../.gitbook/assets/2.15-install-server-setup-wizard.png" alt=""><figcaption></figcaption></figure>

The installation process automatically detects your local environment and sets it up for you. If you want to add additional environments to manage with this Portainer instance, click **Add Environments**. Otherwise, click **Get Started** to start using Portainer!



================================================
FILE: start/install/server/docker/README.md
================================================
# Docker Standalone

{% hint style="info" %}
These installation instructions are for Portainer Business Edition (BE). For Portainer Community Edition (CE) refer to the [CE install documentation](../../../install-ce/server/docker/).
{% endhint %}

Installation instructions can differ between platforms. Please choose your platform below:

{% content-ref url="linux.md" %}
[linux.md](linux.md)
{% endcontent-ref %}

{% content-ref url="wsl.md" %}
[wsl.md](wsl.md)
{% endcontent-ref %}

{% content-ref url="wcs.md" %}
[wcs.md](wcs.md)
{% endcontent-ref %}




================================================
FILE: start/install/server/docker/linux.md
================================================
# Install Portainer BE with Docker on Linux

{% hint style="info" %}
These installation instructions are for Portainer Business Edition (BE). For Portainer Community Edition (CE) refer to the [CE install documentation](../../../install-ce/server/docker/linux.md).
{% endhint %}

## Introduction

Portainer consists of two elements, the _Portainer Server_, and the _Portainer Agent_. Both elements run as lightweight Docker containers on a Docker engine. This document will help you install the Portainer Server container on your Linux environment. To add a new Linux environment to an existing Portainer Server installation, please refer to the [Portainer Agent installation instructions](../../../../admin/environments/add/docker/agent.md).

To get started, you will need:

* The latest version of Docker installed and working. We recommend following the [official installation instructions](https://docs.docker.com/engine/install/) for Docker - in particular, we advise _against_ installing Docker via snap on Ubuntu distributions as you may run into compatibility issues.
* sudo access on the machine that will host your Portainer Server instance
* By default, Portainer Server will expose the UI over port `9443` and expose a TCP tunnel server over port `8000`. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents.
* A license key for Portainer Business Edition.

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* You are accessing Docker via Unix sockets. Alternatively, you can also connect via TCP.
* SELinux is disabled on the machine running Docker. If you require SELinux, you will need to pass the `--privileged` flag to Docker when deploying Portainer.
* Docker is running as root. Portainer with rootless Docker has some limitations, and requires additional configuration.

## Deployment

First, create the volume that Portainer Server will use to store its database:

```bash
docker volume create portainer_data
```

Then, download and install the Portainer Server container:

<pre><code><strong>docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee:lts
</strong></code></pre>

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-docker-standalone) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

{% hint style="info" %}
If you require HTTP port `9000` open for legacy reasons, add the following to your `docker run` command:

`-p 9000:9000`
{% endhint %}

Portainer Server has now been installed. You can check to see whether the Portainer Server container has started by running `docker ps`:

```bash
root@server:~# docker ps
CONTAINER ID   IMAGE                          COMMAND                  CREATED       STATUS      PORTS                                                                                  NAMES             
de5b28eb2fa9   portainer/portainer-ee:lts     "/portainer"             2 weeks ago   Up 9 days   0.0.0.0:8000->8000/tcp, :::8000->8000/tcp, 0.0.0.0:9443->9443/tcp, :::9443->9443/tcp   portainer
```

## Logging In

Now that the installation is complete, you can log into your Portainer Server instance by opening a web browser and going to:

```bash
https://localhost:9443
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../setup.md" %}
[setup.md](../setup.md)
{% endcontent-ref %}



================================================
FILE: start/install/server/docker/wcs.md
================================================
# Install Portainer BE with Docker on Windows Container Service

{% hint style="info" %}
These installation instructions are for Portainer Business Edition (BE). For Portainer Community Edition (CE) refer to the [CE install documentation](../../../install-ce/server/docker/wcs.md).
{% endhint %}

## Introduction

Portainer consists of two elements, the _Portainer Server_, and the _Portainer Agent_. Both elements run as lightweight Docker containers on a Docker engine. This document will help you install the Portainer Server container on your Windows server with Windows Containers. To add a new WCS environment to an existing Portainer Server installation, please refer to the [Portainer Agent installation instructions](../../../../admin/environments/add/docker/agent.md).

To get started, you will need:

* Administrator access on the machine that will host your Portainer Server instance
* By default, Portainer Server will expose the UI over port `9443` and expose a TCP tunnel server over port `8000`. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents.
* A license key for Portainer Business Edition.

The installation instructions also make the following assumption about your environment:

* Your environment meets [our requirements](../../../requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.

## Preparation

To run Portainer Server in a Windows Server/Desktop Environment you need to create exceptions in the firewall. These can easily be added through PowerShell by running the following commands:

```
netsh advfirewall firewall add rule name="cluster_management" dir=in action=allow protocol=TCP localport=2377
netsh advfirewall firewall add rule name="node_communication_tcp" dir=in action=allow protocol=TCP localport=7946
netsh advfirewall firewall add rule name="node_communication_udp" dir=in action=allow protocol=UDP localport=7946
netsh advfirewall firewall add rule name="overlay_network" dir=in action=allow protocol=UDP localport=4789
netsh advfirewall firewall add rule name="swarm_dns_tcp" dir=in action=allow protocol=TCP localport=53
netsh advfirewall firewall add rule name="swarm_dns_udp" dir=in action=allow protocol=UDP localport=53
```

You will also need to install the Windows Container Host Service and install Docker. Microsoft have [provided](https://learn.microsoft.com/en-us/virtualization/windowscontainers/quick-start/set-up-environment?tabs=dockerce#windows-server-1) a PowerShell script to perform the necessary actions. You can download the script and run it with the following commands:

```
Invoke-WebRequest -UseBasicParsing "https://raw.githubusercontent.com/microsoft/Windows-Containers/Main/helpful_tools/Install-DockerCE/install-docker-ce.ps1" -o install-docker-ce.ps1
.\install-docker-ce.ps1
```

Once this is complete you will need to restart your Windows server. After the restart completes, you're ready to install Portainer itself.

## Deployment

First, create the volume that Portainer Server will use to store its database. Using PowerShell:

```
docker volume create portainer_data
```

Then, download and install the Portainer Server container:

```
docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart always -v \\.\pipe\docker_engine:\\.\pipe\docker_engine -v portainer_data:C:\data portainer/portainer-ee:lts
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

{% hint style="warning" %}
If you see an error message similar to:&#x20;

`"\\.\pipe\dockerDesktopEngine" includes invalid characters for a local volume name`

then you may not have Windows containers properly enabled. If you are using Docker Desktop, right click the icon in your tray and select **Switch to Windows Containers**.
{% endhint %}

{% hint style="info" %}
If you require HTTP port `9000` open for legacy reasons, add the following to your `docker run` command:

`-p 9000:9000`
{% endhint %}

## Logging In

Now that the installation is complete, you can log into your Portainer Server instance by opening a web browser and going to:

```bash
https://localhost:9443
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../setup.md" %}
[setup.md](../setup.md)
{% endcontent-ref %}



================================================
FILE: start/install/server/docker/wsl.md
================================================
# Install Portainer BE with Docker on WSL / Docker Desktop

{% hint style="info" %}
These installation instructions are for Portainer Business Edition (BE). For Portainer Community Edition (CE) refer to the [CE install documentation](../../../install-ce/server/docker/wsl.md).
{% endhint %}

## Introduction

Portainer consists of two elements, the _Portainer Server_, and the _Portainer Agent_. Both elements run as lightweight Docker containers on a Docker engine. This document will help you install the Portainer Server container on your Windows environment with WSL and Docker Desktop. To add a new WSL / Docker Desktop environment to an existing Portainer Server installation, please refer to the [Portainer Agent installation instructions](../../../../admin/environments/add/docker/agent.md).

To get started, you will need:

* The latest version of Docker Desktop installed and working.
* Administrator access on the machine that will host your Portainer Server instance.
* Windows Subsystem for Linux (WSL) installed and a Linux distribution selected. For a new installation we recommend WSL2.
* By default, Portainer Server will expose the UI over port `9443` and expose a TCP tunnel server over port `8000`. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents.
* A license key for Portainer Business Edition.

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* You are accessing Docker via Unix sockets. Alternatively, you can also connect via TCP.
* SELinux is disabled within the Linux distribution used by WSL. If you require SELinux, you will need to pass the `--privileged` flag to Docker when deploying Portainer.
* Docker is running as root. Portainer with rootless Docker has some limitations, and requires additional configuration.

## Deployment

First, create the volume that Portainer Server will use to store its database:

```bash
docker volume create portainer_data
```

Then, download and install the Portainer Server container:

```
docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee:lts
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-docker-standalone) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

{% hint style="info" %}
If you require HTTP port `9000` open for legacy reasons, add the following to your `docker run` command:

`-p 9000:9000`
{% endhint %}

Portainer Server has now been installed. You can check to see whether the Portainer Server container has started by running `docker ps`:

```bash
root@server:~# docker ps
CONTAINER ID   IMAGE                                              COMMAND                  CREATED        STATUS        PORTS                                                                                  NAMES
f4ab79732007   portainer/portainer-ee:lts                         "/portainer"             2 weeks ago    Up 29 hours   0.0.0.0:8000->8000/tcp, :::8000->8000/tcp, 0.0.0.0:9443->9000/tcp, :::9443->9443/tcp   portainer
```

## Logging In

Now that the installation is complete, you can log into your Portainer Server instance by opening a web browser and going to:

```bash
https://localhost:9443
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../setup.md" %}
[setup.md](../setup.md)
{% endcontent-ref %}



================================================
FILE: start/install/server/kubernetes/README.md
================================================
# Kubernetes

{% hint style="info" %}
These installation instructions are for Portainer Business Edition (BE). For Portainer Community Edition (CE) refer to the [CE install documentation](../../../install-ce/server/kubernetes/).
{% endhint %}

Installation instructions can differ between platforms. Please choose your platform below:

{% content-ref url="baremetal.md" %}
[baremetal.md](baremetal.md)
{% endcontent-ref %}

{% content-ref url="wsl.md" %}
[wsl.md](wsl.md)
{% endcontent-ref %}




================================================
FILE: start/install/server/kubernetes/baremetal.md
================================================
# Install Portainer BE on your Kubernetes environment

{% hint style="info" %}
These installation instructions are for Portainer Business Edition (BE). For Portainer Community Edition (CE) refer to the [CE install documentation](../../../install-ce/server/kubernetes/baremetal.md).
{% endhint %}

## Introduction

Portainer consists of two elements, the _Portainer Server_ and the _Portainer Agent_. Both elements run as lightweight containers on Kubernetes.

To get started, you will need:

* A working and up to date Kubernetes cluster.
* Access to run `helm` or `kubectl` commands on your cluster.
* Cluster Admin rights on your Kubernetes cluster. This is so Portainer can create the necessary `ServiceAccount` and `ClusterRoleBinding` for it to access the Kubernetes cluster.
* A `default` StorageClass configured (see below).
* A license key for Portainer Business Edition.

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* Kubernetes RBAC is enabled and working (this is required for the access control functionality in Portainer).
* You will be using the `portainer` namespace for Portainer. At present this is a requirement - other namespaces are currently unsupported.
* Kubernetes' metrics server is installed and working (if you wish to use the metrics within Portainer).

## Data Persistence

Portainer requires data persistence, and as a result needs at least one StorageClass available to use. Portainer will attempt to use the default StorageClass during deployment. If you do not have a StorageClass tagged as `default` the deployment will likely fail.

{% hint style="info" %}
We recommend using block storage for Kubernetes rather than network storage for the best performance and reliability, but do pay attention to the IOPS of your block storage devices when choosing the volume to use as some options are slower than others.
{% endhint %}

You can check if you have a default StorageClass by running the following command on your cluster:

```
kubectl get sc
```

and looking for a StorageClass with `(default)` after its name:

```
root@kubemaster01:~# kubectl get sc
NAME                            PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
managed-nfs-storage (default)   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           false                  11d
```

To set a StorageClass as default, you can use the following:

```
kubectl patch storageclass <storage-class-name> -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
```

replacing `<storage-class-name>` with the name of your StorageClass. Alternatively, if you are installing using our Helm chart, you can pass the following parameter in your helm install command to specify the StorageClass to use for Portainer:

```
--set persistence.storageClass=<storage-class-name>
```

{% hint style="info" %}
In some Kubernetes clusters (for example microk8s), the default StorageClass simply creates hostPath volumes, which are not explicitly tied to a particular node. In a multi-node cluster, this can create an issue when the pod is terminated and rescheduled on a different node, "leaving" all the persistent data behind and starting the pod with an "empty" volume.

While this behavior is inherently a limitation of using hostPath volumes, a suitable workaround is to use add a nodeSelector to the deployment, which effectively "pins" the Portainer pod to a particular node. You can do this by editing your own values.yaml file to set the nodeSelector value:

`nodeSelector: kubernetes.io/hostname: \<YOUR_NODE_NAME>`

or alternatively follow the instructions below for each deployment method.
{% endhint %}

## Deployment

To deploy Portainer within a Kubernetes cluster you can use our provided Helm charts or YAML manifests.

### Deploy using Helm

{% hint style="info" %}
Ensure you're using at least Helm v3.2, which includes support for the `--create-namespace` argument.
{% endhint %}

First add the Portainer Helm repository by running the following commands:

```
helm repo add portainer https://portainer.github.io/k8s/
helm repo update
```

Once the update completes, you're ready to begin the installation. Which method you choose will depend on how you wish to expose the Portainer service:

{% tabs %}
{% tab title="Expose via NodePort" %}
Using the following command, Portainer will be available on port `30779` for HTTPS:

```
helm upgrade --install --create-namespace -n portainer portainer portainer/portainer \
    --set enterpriseEdition.enabled=true \
    --set enterpriseEdition.image.tag=lts \
    --set tls.force=true
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `30779`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-kubernetes-via-helm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

{% hint style="info" %}
If you need to access Portainer via HTTP on port `30777`, remove the `--set tls.force=true` option.
{% endhint %}
{% endtab %}

{% tab title="Expose via Ingress" %}
In this example, Portainer will be deployed to your cluster and assigned a Cluster IP, with an nginx Ingress Controller at the defined hostname. For more on Ingress options, refer to the list of [Chart Configuration Options](../../../../advanced/helm-chart-configuration-options.md).

```
helm upgrade --install --create-namespace -n portainer portainer portainer/portainer \
    --set enterpriseEdition.enabled=true \
    --set enterpriseEdition.image.tag=lts \
    --set service.type=ClusterIP \
    --set tls.force=true \
    --set ingress.enabled=true \
    --set ingress.ingressClassName=<ingressClassName (eg: nginx)> \
    --set ingress.annotations."nginx\.ingress\.kubernetes\.io/backend-protocol"=HTTPS \
    --set ingress.hosts[0].host=<fqdn (eg: portainer.example.io)> \
    --set ingress.hosts[0].paths[0].path="/"
```

{% hint style="info" %}
If you need to access Portainer via HTTP, remove the `--set tls.force=true` option.
{% endhint %}
{% endtab %}

{% tab title="Expose via Load Balancer" %}
Using the following command, Portainer will be available at an assigned Load Balancer IP on port `9443` for HTTPS:

```
helm upgrade --install --create-namespace -n portainer portainer portainer/portainer \
    --set service.type=LoadBalancer \
    --set enterpriseEdition.enabled=true \
    --set enterpriseEdition.image.tag=lts \
    --set tls.force=true
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-kubernetes-via-helm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

{% hint style="info" %}
If you need to access Portainer via HTTP on port `9000`, remove the `--set tls.force=true` option.
{% endhint %}
{% endtab %}
{% endtabs %}

{% hint style="info" %}
If you want to explicitly set the target node when deploying the Helm chart on the CLI, include `--set nodeSelector.kubernetes\.io/hostname=<YOUR NODE NAME>` in your `helm install` command.
{% endhint %}

### Deploy using YAML manifests

Our YAML manifests support exposing Portainer via either NodePort or Load Balancer.

{% tabs %}
{% tab title="Expose via NodePort" %}
To expose via NodePort, you can use the following command (Portainer will be available on port `30777`  for HTTP and `30779` for  HTTPS):

```
kubectl apply -n portainer -f https://downloads.portainer.io/ee-lts/portainer.yaml
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `30779`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-kubernetes-via-helm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}
{% endtab %}

{% tab title="Expose via Load Balancer" %}
To expose via Load Balancer, use the following command to provision Portainer at an assigned Load Balancer IP on port `9000` for HTTP and `9443` for HTTPS:

```
kubectl apply -n portainer -f https://downloads.portainer.io/ee-lts/portainer-lb.yaml
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-kubernetes-via-helm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}
{% endtab %}
{% endtabs %}

{% hint style="info" %}
If you want to explicitly set the target node when deploying using YAML manifests, run the following one-liner to "patch" the deployment, forcing the pod to always be scheduled on the node it's currently running on:
{% endhint %}

```
kubectl patch deployments -n portainer portainer -p '{"spec": {"template": {"spec": {"nodeSelector": {"kubernetes.io/hostname": "'$(kubectl get pods -n portainer -o jsonpath='{ ..nodeName }')'"}}}}}' || (echo Failed to identify current node of portainer pod; exit 1)
```

## Logging In

Now that the installation is complete, you can log into your Portainer Server instance. Depending on how you chose to expose your Portainer installation, open a web browser and navigate to the following URL:

{% tabs %}
{% tab title="NodePort" %}
```bash
https://localhost:30779/ or http://localhost:30777/
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.
{% endtab %}

{% tab title="Ingress" %}
```bash
https://<FQDN>/
```

Replace `<FQDN>` with the FQDN of your Portainer instance.
{% endtab %}

{% tab title="Load Balancer" %}
```bash
https://<loadbalancer IP>:9443/ or http://<loadbalancer IP>:9000/
```

Replace `<loadbalancer IP>` with the IP address or FQDN of the load balancer, and adjust the port if you changed it earlier.
{% endtab %}
{% endtabs %}

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../setup.md" %}
[setup.md](../setup.md)
{% endcontent-ref %}



================================================
FILE: start/install/server/kubernetes/wsl.md
================================================
# Install Portainer BE with Kubernetes on WSL / Docker Desktop

{% hint style="info" %}
These installation instructions are for Portainer Business Edition (BE). For Portainer Community Edition (CE) refer to the [CE install documentation](../../../install-ce/server/kubernetes/wsl.md).
{% endhint %}

## Introduction

The following instructions will guide you in setting up _Portainer Server_ with Kubernetes running on Docker Desktop with WSL.

{% hint style="info" %}
This scenario is for testing purposes only.
{% endhint %}

{% hint style="warning" %}
We are aware of an issue where namespace and application access privileges are not fully implemented when running Kubernetes via Docker Desktop. We are looking into the root cause and hope to have a resolution soon.
{% endhint %}

## Preparation

Before you start, you must make sure that Kubernetes is enabled and running within your Docker Desktop installation. To enable Kubernetes in Docker Desktop, you need to open the dashboard of Docker Desktop. Right click the Docker icon in the system tray and click **Dashboard**:

![](../../../../.gitbook/assets/kube-wsl-1.png)

Click **Settings**, then select **Kubernetes**, tick **Enable Kubernetes**, then click **Apply and Restart** (clicking **Install** in the dialog to install Kubernetes):

![](../../../../.gitbook/assets/kube-wsl-2.gif)

After a few minutes, you will see that Kubernetes is running in the bottom left status bar of Docker Desktop:

![Docker is on the left, Kubernetes is on the right](../../../../.gitbook/assets/kube-wsl-4.png)

## Deployment

To deploy Portainer within a Kubernetes cluster you can use our provided Helm charts or YAML manifests.

### Deploy using Helm

{% hint style="info" %}
Ensure you're using at least Helm v3.2, which includes support for the `--create-namespace` argument.
{% endhint %}

First add the Portainer Helm repository by running the following commands:

```
helm repo add portainer https://portainer.github.io/k8s/
helm repo update
```

Once the update completes, you're ready to begin the installation. Which method you choose will depend on how you wish to expose the Portainer service:

{% tabs %}
{% tab title="Expose via NodePort" %}
Using the following command, Portainer will be available on port `30777` for HTTP and `30779` for HTTPS:

```
helm upgrade --install --create-namespace -n portainer portainer portainer/portainer \
    --set enterpriseEdition.enabled=true \
    --set enterpriseEdition.image.tag=lts
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-kubernetes-via-helm) or [via the Portainer UI](https://app.gitbook.com/admin/settings#ssl-certificate) after installation is complete.
{% endhint %}
{% endtab %}

{% tab title="Expose via Ingress" %}
In this example, Portainer will be deployed to your cluster and assigned a Cluster IP, with an nginx Ingress Controller at the defined hostname. For more on Ingress options, refer to the list of [Chart Configuration Options](../../../../advanced/helm-chart-configuration-options.md).

```
helm upgrade --install --create-namespace -n portainer portainer portainer/portainer \
    --set enterpriseEdition.enabled=true \
    --set enterpriseEdition.image.tag=lts \
    --set service.type=ClusterIP \
    --set tls.force=true \
    --set ingress.enabled=true \
    --set ingress.ingressClassName=<ingressClassName (eg: nginx)> \
    --set ingress.annotations."nginx\.ingress\.kubernetes\.io/backend-protocol"=HTTPS \
    --set ingress.hosts[0].host=<fqdn (eg: portainer.example.io)> \
    --set ingress.hosts[0].paths[0].path="/"
```
{% endtab %}

{% tab title="Expose via Load Balancer" %}
Using the following command, Portainer will be available at an assigned Load Balancer IP on port `9000` for HTTP and `9443` for HTTPS:

```
helm upgrade --install --create-namespace -n portainer portainer portainer/portainer \
    --set service.type=LoadBalancer \
    --set enterpriseEdition.enabled=true \
    --set enterpriseEdition.image.tag=lts
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-kubernetes-via-helm) or [via the Portainer UI](https://app.gitbook.com/admin/settings#ssl-certificate) after installation is complete.
{% endhint %}
{% endtab %}
{% endtabs %}

{% hint style="info" %}
To explicitly set the target node when deploying the Helm chart on the CLI, include `--set nodeSelector.kubernetes.io/hostname=<YOUR NODE NAME>` in your `helm install` command.
{% endhint %}

### Deploy using YAML manifests

Our YAML manifests support exposing Portainer via either NodePort or Load Balancer.

{% tabs %}
{% tab title="Expose via NodePort" %}
To expose via NodePort, you can use the following command (Portainer will be available on port `30777`  for HTTP and `30779` for  HTTPS):

```
kubectl apply -n portainer -f https://downloads.portainer.io/ee-lts/portainer.yaml
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `30779`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-kubernetes-via-helm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}
{% endtab %}

{% tab title="Expose via Load Balancer" %}
To expose via Load Balancer, use the following command to provision Portainer at an assigned Load Balancer IP on port `9000` for HTTP and `9443` for HTTPS:

```
kubectl apply -n portainer -f https://downloads.portainer.io/ee-lts/portainer-lb.yaml
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-kubernetes-via-helm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}
{% endtab %}
{% endtabs %}

{% hint style="info" %}
To explicitly set the target node when deploying using YAML manifests, run the following one-liner to "patch" the deployment, forcing the pod to always be scheduled on the node it's currently running on:
{% endhint %}

```
kubectl patch deployments -n portainer portainer -p '{"spec": {"template": {"spec": {"nodeSelector": {"kubernetes.io/hostname": "'$(kubectl get pods -n portainer -o jsonpath='{ ..nodeName }')'"}}}}}' || (echo Failed to identify current node of portainer pod; exit 1)
```

## Logging In

Now that the installation is complete, you can log into your Portainer Server instance. Depending on how you chose to expose your Portainer installation, open a web browser and navigate to the following URL:

{% tabs %}
{% tab title="NodePort" %}
```bash
https://localhost:30779/ or http://localhost:30777/
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.
{% endtab %}

{% tab title="Ingress" %}
```bash
https://<FQDN>/
```

Replace `<FQDN>` with the FQDN of your Portainer instance.
{% endtab %}

{% tab title="Load Balancer" %}
```bash
https://<loadbalancer IP>:9443/ or http://<loadbalancer IP>:9000/
```

Replace `<loadbalancer IP>` with the IP address or FQDN of the load balancer, and adjust the port if you changed it earlier.
{% endtab %}
{% endtabs %}

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../setup.md" %}
[setup.md](../setup.md)
{% endcontent-ref %}



================================================
FILE: start/install/server/podman/README.md
================================================
# Podman

{% hint style="info" %}
These installation instructions are for Portainer Business Edition (BE). For Portainer Community Edition (CE) refer to the [CE install documentation](../../../install-ce/server/podman/).
{% endhint %}

Installation instructions can differ between platforms. Please choose your platform below:

{% content-ref url="linux.md" %}
[linux.md](linux.md)
{% endcontent-ref %}




================================================
FILE: start/install/server/podman/linux.md
================================================
# Install Portainer BE with Podman on Linux

{% hint style="info" %}
These installation instructions are for Portainer Business Edition (BE). For Portainer Community Edition (CE) refer to the [CE install documentation](../../../install-ce/server/podman/linux.md).
{% endhint %}

## Introduction

Portainer consists of two elements, the _Portainer Server_, and the _Portainer Agent_. Both elements run as lightweight containers on a Podman engine. This document will help you install the Portainer Server container on your Linux environment. To add a new Linux environment to an existing Portainer Server installation, please refer to the [Portainer Agent installation instructions](../../../../admin/environments/add/podman/agent.md).

To get started, you will need:

* CentOS 9 with the latest version of Podman 5.x installed and working on your Podman host. Other Podman versions and Linux distros may work but we currently only support the above. We recommend following the [official installation instructions](https://podman.io/docs/installation#installing-on-linux) for Podman.
* sudo access on the machine that will host your Portainer Server instance
* By default, Portainer Server will expose the UI over port `9443` and expose a TCP tunnel server over port `8000`. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents.
* A license key for Portainer Business Edition.

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* You are accessing Podman via Unix sockets.
* Podman is running as root. Portainer with rootless Podman may work but is currently not officially supported.

## Deployment

First, ensure the Podman socket is enabled:

```
systemctl enable --now podman.socket
```

Next, create the volume that Portainer Server will use to store its database:

```bash
podman volume create portainer_data
```

Then, download and install the Portainer Server container:

<pre><code><strong>podman run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always --privileged -v /run/podman/podman.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee:lts
</strong></code></pre>

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-docker-standalone) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

{% hint style="info" %}
If you require HTTP port `9000` open for legacy reasons, add the following to your `podman run` command:

`-p 9000:9000`
{% endhint %}

Portainer Server has now been installed. You can check to see whether the Portainer Server container has started by running `podman ps`:

```bash
root@server:~# podman ps
CONTAINER ID   IMAGE                          COMMAND                  CREATED       STATUS      PORTS                                                                                  NAMES             
de5b28eb2fa9   portainer/portainer-ee:lts     "/portainer"             2 weeks ago   Up 9 days   0.0.0.0:8000->8000/tcp, :::8000->8000/tcp, 0.0.0.0:9443->9443/tcp, :::9443->9443/tcp   portainer
```

## Logging In

Now that the installation is complete, you can log into your Portainer Server instance by opening a web browser and going to:

```bash
https://localhost:9443
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../setup.md" %}
[setup.md](../setup.md)
{% endcontent-ref %}



================================================
FILE: start/install/server/swarm/README.md
================================================
# Docker Swarm

{% hint style="info" %}
These installation instructions are for Portainer Business Edition (BE). For Portainer Community Edition (CE) refer to the [CE install documentation](../../../install-ce/server/swarm/).
{% endhint %}

Installation instructions can differ between platforms. Please choose your platform below:

{% content-ref url="linux.md" %}
[linux.md](linux.md)
{% endcontent-ref %}

{% content-ref url="wsl.md" %}
[wsl.md](wsl.md)
{% endcontent-ref %}

{% content-ref url="wcs.md" %}
[wcs.md](wcs.md)
{% endcontent-ref %}



================================================
FILE: start/install/server/swarm/linux.md
================================================
# Install Portainer BE with Docker Swarm on Linux

{% hint style="info" %}
These installation instructions are for Portainer Business Edition (BE). For Portainer Community Edition (CE) refer to the [CE install documentation](../../../install-ce/server/swarm/linux.md).
{% endhint %}

## Introduction <a href="#introduction" id="introduction"></a>

Portainer consists of two elements, the _Portainer Server_ and the _Portainer Agent_. Both elements run as lightweight Docker containers on a Docker engine. This document will help you deploy the Portainer Server and Agent containers on your Linux environment. To add a new Linux Swarm environment to an existing Portainer Server installation, please refer to the [Portainer Agent installation instructions](../../../../admin/environments/add/swarm/agent.md).

To get started, you will need:

* The latest version of Docker installed and working. We recommend following the [official installation instructions](https://docs.docker.com/engine/install/) for Docker - in particular, we advise _against_ installing Docker via snap on Ubuntu distributions as you may run into compatibility issues.
* Swarm mode [enabled](https://docs.docker.com/engine/swarm/swarm-mode/) and working, including the overlay network for the swarm service communication
* `sudo` access on the manager node of your swarm cluster
* By default, Portainer will expose the UI over port `9443` and expose a TCP tunnel server over port `8000`. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents.
* The manager and worker nodes must be able to communicate with each other over port `9001`.
* A license key for Portainer Business Edition.

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* You are accessing Docker via Unix sockets. Connecting via TCP is not supported in Docker Swarm.
* SELinux is disabled on the machine running Docker.
* Docker is running as root. Portainer with rootless Docker has some limitations, and requires additional configuration.
* You are running a single manager node in your swarm. If you have more than one, please [read this knowledge base article](https://portal.portainer.io/knowledge/how-can-i-ensure-portainers-configuration-is-retained) before proceeding.
* If your nodes are using DNS records to communicate, that all records are resolvable across the cluster.

## Deployment <a href="#deployment" id="deployment"></a>

{% embed url="https://www.youtube.com/watch?v=S2VuHKxrT3s" %}

Portainer can be directly deployed as a service in your Docker cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploy the Portainer Agent as a global service on every node in your cluster.

{% hint style="danger" %}
Only do this **once** for your environment, regardless of how many nodes are in the cluster. You **do not** need to add each node in your cluster as a separate environment in Portainer. Deploying the manifest to your swarm will include every node in the cluster automatically. Adding each node as a separate environment will also consume more of your licensed node count than you may expect.
{% endhint %}

First, retrieve the stack YML manifest:

```
curl -L https://downloads.portainer.io/ee-lts/portainer-agent-stack.yml -o portainer-agent-stack.yml
```

Then use the downloaded YML manifest to deploy your stack:

```
docker stack deploy -c portainer-agent-stack.yml portainer
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-docker-swarm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

Portainer Server and the Agents have now been installed. You can check to see whether the Portainer Server and Agent containers have started by running `docker ps`:

```
root@manager01:~# docker ps
CONTAINER ID   IMAGE                           COMMAND                  CREATED              STATUS              PORTS                NAMES
59ee466f6b15   portainer/agent:lts             "./agent"                About a minute ago   Up About a minute                        portainer_agent.xbb8k6r7j1tk9gozjku7e43wr.5sa6b3e8cl6hyu0snlt387sgv
2db7dd4bfba0   portainer/portainer-ee:lts      "/portainer -H tcp:/…"   About a minute ago   Up About a minute   8000/tcp, 9443/tcp   portainer_portainer.1.gpuvu3pqmt1m19zxfo44v7izx
```

## Logging In <a href="#logging-in" id="logging-in"></a>

Now that the installation is complete, you can log into your Portainer Server instance by opening a web browser and going to:

```
https://localhost:9443
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../setup.md" %}
[setup.md](../setup.md)
{% endcontent-ref %}



================================================
FILE: start/install/server/swarm/wcs.md
================================================
# Install Portainer BE with Docker Swarm on Windows Container Service

{% hint style="info" %}
These installation instructions are for Portainer Business Edition (BE). For Portainer Community Edition (CE) refer to the [CE install documentation](../../../install-ce/server/swarm/wcs.md).
{% endhint %}

## Introduction

Portainer consists of two elements, the _Portainer Server_, and the _Portainer Agent_. Both elements run as lightweight Docker containers on a Docker engine. This document will help you install the Portainer Server container on your Windows server with Windows Containers. To add a new WCS environment to an existing Portainer Server installation, please refer to the [Portainer Agent installation instructions](../../../../admin/environments/add/swarm/agent.md).

To get started, you will need:

* The latest version of Docker installed and working.
* Swarm mode [enabled](https://docs.docker.com/engine/swarm/swarm-mode/) and working, including the overlay network for the swarm service communication.
* Administrator access on the manager node of your Swarm cluster.
* By default, Portainer will expose the UI over port `9443` and expose a TCP tunnel server over port `8000`. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents.
* The manager and worker nodes must be able to communicate with each other over port `9001`.
* A license key for Portainer Business Edition.

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* You are running a single manager node in your swarm. If you have more than one, please [read this knowledge base article](https://portal.portainer.io/knowledge/how-can-i-ensure-portainers-configuration-is-retained) before proceeding.
* If your nodes are using DNS records to communicate, that all records are resolvable across the cluster.

## Preparation

To run Portainer Server in a Windows Server/Desktop Environment you need to create exceptions in the firewall. These can easily be added through PowerShell by running the following commands:

```
netsh advfirewall firewall add rule name="cluster_management" dir=in action=allow protocol=TCP localport=2377
netsh advfirewall firewall add rule name="node_communication_tcp" dir=in action=allow protocol=TCP localport=7946
netsh advfirewall firewall add rule name="node_communication_udp" dir=in action=allow protocol=UDP localport=7946
netsh advfirewall firewall add rule name="overlay_network" dir=in action=allow protocol=UDP localport=4789
netsh advfirewall firewall add rule name="swarm_dns_tcp" dir=in action=allow protocol=TCP localport=53
netsh advfirewall firewall add rule name="swarm_dns_udp" dir=in action=allow protocol=UDP localport=53
```

You will also need to install the Windows Container Host Service and install Docker. Microsoft have [provided](https://learn.microsoft.com/en-us/virtualization/windowscontainers/quick-start/set-up-environment?tabs=dockerce#windows-server-1) a PowerShell script to perform the necessary actions. You can download the script and run it with the following commands:

```
Invoke-WebRequest -UseBasicParsing "https://raw.githubusercontent.com/microsoft/Windows-Containers/Main/helpful_tools/Install-DockerCE/install-docker-ce.ps1" -o install-docker-ce.ps1
.\install-docker-ce.ps1
```

Once this is complete you will need to restart your Windows server. After the restart completes, you're ready to install Portainer itself.

## Deployment

Portainer can be directly deployed as a service in your Docker cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploy the Portainer Agent as a global service on every node in your cluster.

{% hint style="danger" %}
Only do this **once** for your environment, regardless of how many nodes are in the cluster. You **do not** need to add each node in your cluster as a separate environment in Portainer. Deploying the manifest to your swarm will include every node in the cluster automatically. Adding each node as a separate environment will also consume more of your licensed node count than you may expect.
{% endhint %}

You can use our YML manifest to run Portainer in Windows using Windows Containers. In PowerShell, run:

```
curl https://downloads.portainer.io/ee-lts/portainer_windows_stack.yml -o portainer-windows-stack.yml
```

Then use the downloaded YML manifest to deploy your stack:

```bash
docker stack deploy --compose-file=portainer-windows-stack.yml portainer
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-docker-swarm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

## Logging In

Now that the installation is complete, you can log into your Portainer Server instance by opening a web browser and going to:

```bash
https://localhost:9443
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../setup.md" %}
[setup.md](../setup.md)
{% endcontent-ref %}



================================================
FILE: start/install/server/swarm/wsl.md
================================================
# Install Portainer BE with Docker Swarm on WSL / Docker Desktop

{% hint style="info" %}
These installation instructions are for Portainer Business Edition (BE). For Portainer Community Edition (CE) refer to the [CE install documentation](../../../install-ce/server/swarm/wsl.md).
{% endhint %}

## Introduction

Portainer consists of two elements, the _Portainer Server_, and the _Portainer Agent_. Both elements run as lightweight Docker containers on a Docker engine. This document will help you install the Portainer Server container on your Windows environment with WSL and Docker Desktop. To add a new WSL / Docker Desktop Swarm environment to an existing Portainer Server installation, please refer to the [Portainer Agent installation instructions](../../../../admin/environments/add/swarm/agent.md).

To get started, you will need:

* The latest version of Docker Desktop installed and working.
* Swarm mode [enabled](https://docs.docker.com/engine/swarm/swarm-mode/) and working, including the overlay network for the swarm service communication.
* Administrator access on the manager node of your Swarm cluster.
* Windows Subsystem for Linux (WSL) installed and a Linux distribution selected. For a new installation we recommend WSL2.
* By default, Portainer will expose the UI over port `9443` and expose a TCP tunnel server over port `8000`. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents.
* The manager and worker nodes must be able to communicate with each other over port `9001`.
* A license key for Portainer Business Edition.

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* You are accessing Docker via Unix sockets. Alternatively, you can also connect via TCP.
* SELinux is disabled within the Linux distribution used by WSL.
* Docker is running as root. Portainer with rootless Docker has some limitations, and requires additional configuration.
* You are running a single manager node in your swarm. If you have more than one, please [read this knowledge base article](https://portal.portainer.io/knowledge/how-can-i-ensure-portainers-configuration-is-retained) before proceeding.
* If your nodes are using DNS records to communicate, that all records are resolvable across the cluster.

## Deployment

Portainer can be directly deployed as a service in your Docker Swarm cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploy the Portainer Agent as a global service on every node in your cluster.

{% hint style="danger" %}
Only do this **once** for your environment, regardless of how many nodes are in the cluster. You **do not** need to add each node in your cluster as a separate environment in Portainer. Deploying the manifest to your swarm will include every node in the cluster automatically. Adding each node as a separate environment will also consume more of your licensed node count than you may expect.
{% endhint %}

To begin the installation, first retrieve the stack YML manifest:

```
curl -L https://downloads.portainer.io/ee-lts/portainer-agent-stack.yml -o portainer-agent-stack.yml
```

Then use the downloaded YML manifest to deploy your stack:

```bash
docker stack deploy -c portainer-agent-stack.yml portainer
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-docker-swarm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

## Logging In

Now that the installation is complete, you can log into your Portainer Server instance by opening a web browser and going to:

```bash
https://localhost:9443
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../setup.md" %}
[setup.md](../setup.md)
{% endcontent-ref %}



================================================
FILE: start/install-ce/README.md
================================================
# Install Portainer CE

{% hint style="info" %}
These installation instructions are for Portainer Community Edition (CE). For Portainer Business Edition (BE) refer to the [BE install documentation](../install/).
{% endhint %}

Portainer Community Edition is straightforward to install. There are two options: installing new or adding an environment to an existing installation.

{% hint style="info" %}
If you haven't already, please check that your environments meet [our requirements](../requirements-and-prerequisites.md) before proceeding.
{% endhint %}

{% content-ref url="server/" %}
[server](server/)
{% endcontent-ref %}

{% content-ref url="../agent.md" %}
[agent.md](../agent.md)
{% endcontent-ref %}



================================================
FILE: start/install-ce/server/README.md
================================================
# Set up a new Portainer CE Server installation

{% hint style="info" %}
These installation instructions are for Portainer Community Edition (CE). For Portainer Business Edition (BE) refer to the [BE install documentation](../../install/server/).
{% endhint %}

Select the environment for your new Portainer installation:

{% content-ref url="docker/" %}
[docker](docker/)
{% endcontent-ref %}

{% content-ref url="swarm/" %}
[swarm](swarm/)
{% endcontent-ref %}

{% content-ref url="podman/" %}
[podman](podman/)
{% endcontent-ref %}

{% content-ref url="kubernetes/" %}
[kubernetes](kubernetes/)
{% endcontent-ref %}



================================================
FILE: start/install-ce/server/setup.md
================================================
# Initial setup

Once the Portainer Server has been deployed, and you have navigated to the instance's URL, you are ready for the initial setup.

## Creating the first user

Your first user will be an administrator. The username defaults to `admin` but you can change it if you prefer. The password must be at least 12 characters long and meet the listed password requirements.

<figure><img src="../../../.gitbook/assets/2.15-install-server-setup-user.png" alt=""><figcaption></figcaption></figure>

## Enabling or disabling the collection of statistics

We use a tool called [Matomo](https://matomo.org/) to collect anonymous information about how Portainer is used. We recommend enabling this option so we can make improvements based on usage. For more about what we do with the information we collect, read our [privacy policy](https://www.portainer.io/privacy-policy).

During installation, you can enable or disable connection statistics using the checkbox. If you change your mind later, you can easily update this option under [Settings](../../../admin/settings/general.md#allow-the-collection-of-anonymous-statistics) in the Portainer UI.

<figure><img src="../../../.gitbook/assets/2.15-install-server-setup-matomo.png" alt=""><figcaption></figcaption></figure>

## Connecting Portainer to your environments

Once the admin user has been created, the **Environment Wizard** will automatically launch. The wizard will help get you started with Portainer.

<figure><img src="../../../.gitbook/assets/2.15-install-server-setup-wizard.png" alt=""><figcaption></figcaption></figure>

The installation process automatically detects your local environment and sets it up for you. If you want to add additional environments to manage with this Portainer instance, click **Add Environments**. Otherwise, click **Get Started** to start using Portainer!



================================================
FILE: start/install-ce/server/docker/README.md
================================================
# Docker Standalone

{% hint style="info" %}
These installation instructions are for Portainer Community Edition (CE). For Portainer Business Edition (BE) refer to the [BE install documentation](../../../install/server/docker/).
{% endhint %}

Installation instructions can differ between platforms. Please choose your platform below:

{% content-ref url="linux.md" %}
[linux.md](linux.md)
{% endcontent-ref %}

{% content-ref url="wsl.md" %}
[wsl.md](wsl.md)
{% endcontent-ref %}

{% content-ref url="wcs.md" %}
[wcs.md](wcs.md)
{% endcontent-ref %}




================================================
FILE: start/install-ce/server/docker/linux.md
================================================
# Install Portainer CE with Docker on Linux

{% hint style="info" %}
These installation instructions are for Portainer Community Edition (CE). For Portainer Business Edition (BE) refer to the [BE install documentation](../../../install/server/docker/linux.md).
{% endhint %}

## Introduction

Portainer consists of two elements, the _Portainer Server_, and the _Portainer Agent_. Both elements run as lightweight Docker containers on a Docker engine. This document will help you install the Portainer Server container on your Linux environment. To add a new Linux environment to an existing Portainer Server installation, please refer to the [Portainer Agent installation instructions](../../../../admin/environments/add/docker/agent.md).

To get started, you will need:

* The latest version of Docker installed and working. We recommend following the [official installation instructions](https://docs.docker.com/engine/install/) for Docker - in particular, we advise _against_ installing Docker via snap on Ubuntu distributions as you may run into compatibility issues.
* sudo access on the machine that will host your Portainer Server instance
* By default, Portainer Server will expose the UI over port `9443` and expose a TCP tunnel server over port `8000`. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents.

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* You are accessing Docker via Unix sockets. Alternatively, you can also connect via TCP.
* SELinux is disabled on the machine running Docker. If you require SELinux, you will need to pass the `--privileged` flag to Docker when deploying Portainer.
* Docker is running as root. Portainer with rootless Docker has some limitations, and requires additional configuration.

## Deployment

First, create the volume that Portainer Server will use to store its database:

```bash
docker volume create portainer_data
```

Then, download and install the Portainer Server container:

```
docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:lts
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-docker-standalone) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

{% hint style="info" %}
If you require HTTP port `9000` open for legacy reasons, add the following to your `docker run` command:

`-p 9000:9000`
{% endhint %}

Portainer Server has now been installed. You can check to see whether the Portainer Server container has started by running `docker ps`:

```bash
root@server:~# docker ps
CONTAINER ID   IMAGE                          COMMAND                  CREATED       STATUS      PORTS                                                                                  NAMES             
de5b28eb2fa9   portainer/portainer-ce:lts     "/portainer"             2 weeks ago   Up 9 days   0.0.0.0:8000->8000/tcp, :::8000->8000/tcp, 0.0.0.0:9443->9443/tcp, :::9443->9443/tcp   portainer
```

## Logging In

Now that the installation is complete, you can log into your Portainer Server instance by opening a web browser and going to:

```bash
https://localhost:9443
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../setup.md" %}
[setup.md](../setup.md)
{% endcontent-ref %}



================================================
FILE: start/install-ce/server/docker/wcs.md
================================================
# Install Portainer CE with Docker on Windows Container Service

{% hint style="info" %}
These installation instructions are for Portainer Community Edition (CE). For Portainer Business Edition (BE) refer to the [BE install documentation](../../../install/server/docker/wcs.md).
{% endhint %}

## Introduction

Portainer consists of two elements, the _Portainer Server_, and the _Portainer Agent_. Both elements run as lightweight Docker containers on a Docker engine. This document will help you install the Portainer Server container on your Windows server with Windows Containers. To add a new WCS environment to an existing Portainer Server installation, please refer to the [Portainer Agent installation instructions](../../../../admin/environments/add/docker/agent.md).

To get started, you will need:

* Administrator access on the machine that will host your Portainer Server instance
* By default, Portainer Server will expose the UI over port `9443` and expose a TCP tunnel server over port `8000`. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents.

The installation instructions also make the following assumption about your environment:

* Your environment meets [our requirements](../../../requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.

## Preparation

To run Portainer Server in a Windows Server/Desktop Environment you need to create exceptions in the firewall. These can easily be added through PowerShell by running the following commands:

```
netsh advfirewall firewall add rule name="cluster_management" dir=in action=allow protocol=TCP localport=2377
netsh advfirewall firewall add rule name="node_communication_tcp" dir=in action=allow protocol=TCP localport=7946
netsh advfirewall firewall add rule name="node_communication_udp" dir=in action=allow protocol=UDP localport=7946
netsh advfirewall firewall add rule name="overlay_network" dir=in action=allow protocol=UDP localport=4789
netsh advfirewall firewall add rule name="swarm_dns_tcp" dir=in action=allow protocol=TCP localport=53
netsh advfirewall firewall add rule name="swarm_dns_udp" dir=in action=allow protocol=UDP localport=53
```

You will also need to install the Windows Container Host Service and install Docker. Microsoft have [provided](https://learn.microsoft.com/en-us/virtualization/windowscontainers/quick-start/set-up-environment?tabs=dockerce#windows-server-1) a PowerShell script to perform the necessary actions. You can download the script and run it with the following commands:

```
Invoke-WebRequest -UseBasicParsing "https://raw.githubusercontent.com/microsoft/Windows-Containers/Main/helpful_tools/Install-DockerCE/install-docker-ce.ps1" -o install-docker-ce.ps1
.\install-docker-ce.ps1
```

Once this is complete you will need to restart your Windows server. After the restart completes, you're ready to install Portainer itself.

## Deployment

First, create the volume that Portainer Server will use to store its database. Using PowerShell:

```
docker volume create portainer_data
```

Then, download and install the Portainer Server container:

```
docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart always -v \\.\pipe\docker_engine:\\.\pipe\docker_engine -v portainer_data:C:\data portainer/portainer-ce:lts
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

{% hint style="warning" %}
If you see an error message similar to:&#x20;

`"\\.\pipe\dockerDesktopEngine" includes invalid characters for a local volume name`

then you may not have Windows containers properly enabled. If you are using Docker Desktop, right click the icon in your tray and select **Switch to Windows Containers**.
{% endhint %}

{% hint style="info" %}
If you require HTTP port `9000` open for legacy reasons, add the following to your `docker run` command:

`-p 9000:9000`
{% endhint %}

## Logging In

Now that the installation is complete, you can log into your Portainer Server instance by opening a web browser and going to:

```bash
https://localhost:9443
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../setup.md" %}
[setup.md](../setup.md)
{% endcontent-ref %}



================================================
FILE: start/install-ce/server/docker/wsl.md
================================================
# Install Portainer CE with Docker on WSL / Docker Desktop

{% hint style="info" %}
These installation instructions are for Portainer Community Edition (CE). For Portainer Business Edition (BE) refer to the [BE install documentation](../../../install/server/docker/wsl.md).
{% endhint %}

## Introduction

Portainer consists of two elements, the _Portainer Server_, and the _Portainer Agent_. Both elements run as lightweight Docker containers on a Docker engine. This document will help you install the Portainer Server container on your Windows environment with WSL and Docker Desktop. To add a new WSL / Docker Desktop environment to an existing Portainer Server installation, please refer to the [Portainer Agent installation instructions](../../../../admin/environments/add/docker/agent.md).

To get started, you will need:

* The latest version of Docker Desktop installed and working.
* Administrator access on the machine that will host your Portainer Server instance.
* Windows Subsystem for Linux (WSL) installed and a Linux distribution selected. For a new installation we recommend WSL2.
* By default, Portainer Server will expose the UI over port `9443` and expose a TCP tunnel server over port `8000`. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents.

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* You are accessing Docker via Unix sockets. Alternatively, you can also connect via TCP.
* SELinux is disabled within the Linux distribution used by WSL. If you require SELinux, you will need to pass the `--privileged` flag to Docker when deploying Portainer.
* Docker is running as root. Portainer with rootless Docker has some limitations, and requires additional configuration.

## Deployment

First, create the volume that Portainer Server will use to store its database:

```bash
docker volume create portainer_data
```

Then, download and install the Portainer Server container:

```
docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:lts
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-docker-standalone) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

{% hint style="info" %}
If you require HTTP port `9000` open for legacy reasons, add the following to your `docker run` command:

`-p 9000:9000`
{% endhint %}

Portainer Server has now been installed. You can check to see whether the Portainer Server container has started by running `docker ps`:

```bash
root@server:~# docker ps
CONTAINER ID   IMAGE                                              COMMAND                  CREATED        STATUS        PORTS                                                                                  NAMES
f4ab79732007   portainer/portainer-ce:lts                         "/portainer"             2 weeks ago    Up 29 hours   0.0.0.0:8000->8000/tcp, :::8000->8000/tcp, 0.0.0.0:9443->9000/tcp, :::9443->9443/tcp   portainer
```

## Logging In

Now that the installation is complete, you can log into your Portainer Server instance by opening a web browser and going to:

```bash
https://localhost:9443
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../setup.md" %}
[setup.md](../setup.md)
{% endcontent-ref %}



================================================
FILE: start/install-ce/server/kubernetes/README.md
================================================
# Kubernetes

{% hint style="info" %}
These installation instructions are for Portainer Community Edition (CE). For Portainer Business Edition (BE) refer to the [BE install documentation](../../../install/server/kubernetes/).
{% endhint %}

Installation instructions can differ between platforms. Please choose your platform below:

{% content-ref url="baremetal.md" %}
[baremetal.md](baremetal.md)
{% endcontent-ref %}

{% content-ref url="wsl.md" %}
[wsl.md](wsl.md)
{% endcontent-ref %}




================================================
FILE: start/install-ce/server/kubernetes/baremetal.md
================================================
# Install Portainer CE on your Kubernetes environment

{% hint style="info" %}
These installation instructions are for Portainer Community Edition (CE). For Portainer Business Edition (BE) refer to the [BE install documentation](../../../install/server/kubernetes/baremetal.md).
{% endhint %}

## Introduction

Portainer consists of two elements, the _Portainer Server_ and the _Portainer Agent_. Both elements run as lightweight containers on Kubernetes.

To get started, you will need:

* A working and up to date Kubernetes cluster.
* Access to run `helm` or `kubectl` commands on your cluster.
* Cluster Admin rights on your Kubernetes cluster. This is so Portainer can create the necessary `ServiceAccount` and `ClusterRoleBinding` for it to access the Kubernetes cluster.
* A `default` StorageClass configured (see below).

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* Kubernetes RBAC is enabled and working (this is required for the access control functionality in Portainer).
* You will be using the `portainer` namespace for Portainer. At present this is a requirement - other namespaces are currently unsupported.
* Kubernetes' metrics server is installed and working (if you wish to use the metrics within Portainer).

## Data Persistence

Portainer requires data persistence, and as a result needs at least one StorageClass available to use. Portainer will attempt to use the default StorageClass during deployment. If you do not have a StorageClass tagged as `default` the deployment will likely fail.

{% hint style="info" %}
We recommend using block storage for Kubernetes rather than network storage for the best performance and reliability, but do pay attention to the IOPS of your block storage devices when choosing the volume to use as some options are slower than others.
{% endhint %}

You can check if you have a default StorageClass by running the following command on your cluster:

```
kubectl get sc
```

and looking for a StorageClass with `(default)` after its name:

```
root@kubemaster01:~# kubectl get sc
NAME                            PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
managed-nfs-storage (default)   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           false                  11d
```

To set a StorageClass as default, you can use the following:

```
kubectl patch storageclass <storage-class-name> -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
```

replacing `<storage-class-name>` with the name of your StorageClass. Alternatively, if you are installing using our Helm chart, you can pass the following parameter in your helm install command to specify the StorageClass to use for Portainer:

```
--set persistence.storageClass=<storage-class-name>
```

{% hint style="info" %}
In some Kubernetes clusters (for example microk8s), the default StorageClass simply creates hostPath volumes, which are not explicitly tied to a particular node. In a multi-node cluster, this can create an issue when the pod is terminated and rescheduled on a different node, "leaving" all the persistent data behind and starting the pod with an "empty" volume.

While this behavior is inherently a limitation of using hostPath volumes, a suitable workaround is to use add a nodeSelector to the deployment, which effectively "pins" the Portainer pod to a particular node. You can do this by editing your own values.yaml file to set the nodeSelector value:

`nodeSelector: kubernetes.io/hostname: \<YOUR_NODE_NAME>`

or alternatively follow the instructions below for each deployment method.
{% endhint %}

## Deployment

To deploy Portainer within a Kubernetes cluster you can use our provided Helm charts or YAML manifests.

### Deploy using Helm

{% hint style="info" %}
Ensure you're using at least Helm v3.2, which includes support for the `--create-namespace` argument.
{% endhint %}

First add the Portainer Helm repository by running the following commands:

```
helm repo add portainer https://portainer.github.io/k8s/
helm repo update
```

Once the update completes, you're ready to begin the installation. Which method you choose will depend on how you wish to expose the Portainer service:

{% tabs %}
{% tab title="Expose via NodePort" %}
Using the following command, Portainer will be available on port `30779` for HTTPS:

```
helm upgrade --install --create-namespace -n portainer portainer portainer/portainer \
    --set tls.force=true \
    --set image.tag=lts
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `30779`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-kubernetes-via-helm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

{% hint style="info" %}
If you need to access Portainer via HTTP on port `30777`, remove the `--set tls.force=true` option.
{% endhint %}
{% endtab %}

{% tab title="Expose via Ingress" %}
In this example, Portainer will be deployed to your cluster and assigned a Cluster IP, with an nginx Ingress Controller at the defined hostname. For more on Ingress options, refer to the list of [Chart Configuration Options](../../../../advanced/helm-chart-configuration-options.md).

```
helm upgrade --install --create-namespace -n portainer portainer portainer/portainer \
    --set service.type=ClusterIP \
    --set tls.force=true \
    --set image.tag=lts \
    --set ingress.enabled=true \
    --set ingress.ingressClassName=<ingressClassName (eg: nginx)> \
    --set ingress.annotations."nginx\.ingress\.kubernetes\.io/backend-protocol"=HTTPS \
    --set ingress.hosts[0].host=<fqdn (eg: portainer.example.io)> \
    --set ingress.hosts[0].paths[0].path="/"
```

{% hint style="info" %}
If you need to access Portainer via HTTP, remove the `--set tls.force=true` option.
{% endhint %}
{% endtab %}

{% tab title="Expose via Load Balancer" %}
Using the following command, Portainer will be available at an assigned Load Balancer IP on port `9443` for HTTPS:

```
helm upgrade --install --create-namespace -n portainer portainer portainer/portainer \
    --set service.type=LoadBalancer \
    --set tls.force=true \
    --set image.tag=lts
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-kubernetes-via-helm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

{% hint style="info" %}
If you need to access Portainer via HTTP on port `9000`, remove the `--set tls.force=true` option.
{% endhint %}
{% endtab %}
{% endtabs %}

{% hint style="info" %}
If you want to explicitly set the target node when deploying the Helm chart on the CLI, include `--set nodeSelector.kubernetes\.io/hostname=<YOUR NODE NAME>` in your `helm install` command.
{% endhint %}

### Deploy using YAML manifests

Our YAML manifests support exposing Portainer via either NodePort or Load Balancer.

{% tabs %}
{% tab title="Expose via NodePort" %}
To expose via NodePort, you can use the following command (Portainer will be available on port `30777`  for HTTP and `30779` for  HTTPS):

```
kubectl apply -n portainer -f https://downloads.portainer.io/ce-lts/portainer.yaml
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `30779`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-kubernetes-via-helm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}
{% endtab %}

{% tab title="Expose via Load Balancer" %}
To expose via Load Balancer, use the following command to provision Portainer at an assigned Load Balancer IP on port `9000` for HTTP and `9443` for HTTPS:

```
kubectl apply -n portainer -f https://downloads.portainer.io/ce-lts/portainer-lb.yaml
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-kubernetes-via-helm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}
{% endtab %}
{% endtabs %}

{% hint style="info" %}
If you want to explicitly set the target node when deploying using YAML manifests, run the following one-liner to "patch" the deployment, forcing the pod to always be scheduled on the node it's currently running on:
{% endhint %}

```
kubectl patch deployments -n portainer portainer -p '{"spec": {"template": {"spec": {"nodeSelector": {"kubernetes.io/hostname": "'$(kubectl get pods -n portainer -o jsonpath='{ ..nodeName }')'"}}}}}' || (echo Failed to identify current node of portainer pod; exit 1)
```

## Logging In

Now that the installation is complete, you can log into your Portainer Server instance. Depending on how you chose to expose your Portainer installation, open a web browser and navigate to the following URL:

{% tabs %}
{% tab title="NodePort" %}
```bash
https://localhost:30779/ or http://localhost:30777/
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.
{% endtab %}

{% tab title="Ingress" %}
```bash
https://<FQDN>/
```

Replace `<FQDN>` with the FQDN of your Portainer instance.
{% endtab %}

{% tab title="Load Balancer" %}
```bash
https://<loadbalancer IP>:9443/ or http://<loadbalancer IP>:9000/
```

Replace `<loadbalancer IP>` with the IP address or FQDN of the load balancer, and adjust the port if you changed it earlier.
{% endtab %}
{% endtabs %}

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../setup.md" %}
[setup.md](../setup.md)
{% endcontent-ref %}



================================================
FILE: start/install-ce/server/kubernetes/wsl.md
================================================
# Install Portainer CE with Kubernetes on WSL / Docker Desktop

{% hint style="info" %}
These installation instructions are for Portainer Community Edition (CE). For Portainer Business Edition (BE) refer to the [BE install documentation](../../../install/server/kubernetes/wsl.md).
{% endhint %}

## Introduction

The following instructions will guide you in setting up _Portainer Server_ with Kubernetes running on Docker Desktop with WSL.

{% hint style="info" %}
This scenario is for testing purposes only.
{% endhint %}

{% hint style="warning" %}
We are aware of an issue where namespace and application access privileges are not fully implemented when running Kubernetes via Docker Desktop. We are looking into the root cause and hope to have a resolution soon.
{% endhint %}

## Preparation

Before you start, you must make sure that Kubernetes is enabled and running within your Docker Desktop installation. To enable Kubernetes in Docker Desktop, you need to open the dashboard of Docker Desktop. Right click the Docker icon in the system tray and click **Dashboard**:

![](../../../../.gitbook/assets/kube-wsl-1.png)

Click **Settings**, then select **Kubernetes**, tick **Enable Kubernetes**, then click **Apply and Restart** (clicking **Install** in the dialog to install Kubernetes):

![](../../../../.gitbook/assets/kube-wsl-2.gif)

After a few minutes, you will see that Kubernetes is running in the bottom left status bar of Docker Desktop:

![Docker is on the left, Kubernetes is on the right](../../../../.gitbook/assets/kube-wsl-4.png)

## Deployment

To deploy Portainer within a Kubernetes cluster you can use our provided Helm charts or YAML manifests.

### Deploy using Helm

{% hint style="info" %}
Ensure you're using at least Helm v3.2, which includes support for the `--create-namespace` argument.
{% endhint %}

First add the Portainer Helm repository by running the following commands:

```
helm repo add portainer https://portainer.github.io/k8s/
helm repo update
```

Once the update completes, you're ready to begin the installation. Which method you choose will depend on how you wish to expose the Portainer service:

{% tabs %}
{% tab title="Expose via NodePort" %}
Using the following command, Portainer will be available on port `30777` for HTTP and `30779` for HTTPS:

```
helm upgrade --install --create-namespace -n portainer portainer portainer/portainer \
    --set image.tag=lts
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-kubernetes-via-helm) or [via the Portainer UI](https://app.gitbook.com/admin/settings#ssl-certificate) after installation is complete.
{% endhint %}
{% endtab %}

{% tab title="Expose via Ingress" %}
In this example, Portainer will be deployed to your cluster and assigned a Cluster IP, with an nginx Ingress Controller at the defined hostname. For more on Ingress options, refer to the list of [Chart Configuration Options](../../../../advanced/helm-chart-configuration-options.md).

```
helm upgrade --install --create-namespace -n portainer portainer portainer/portainer \
    --set service.type=ClusterIP \
    --set tls.force=true \
    --set image.tag=lts \
    --set ingress.enabled=true \
    --set ingress.ingressClassName=<ingressClassName (eg: nginx)> \
    --set ingress.annotations."nginx\.ingress\.kubernetes\.io/backend-protocol"=HTTPS \
    --set ingress.hosts[0].host=<fqdn (eg: portainer.example.io)> \
    --set ingress.hosts[0].paths[0].path="/"
```
{% endtab %}

{% tab title="Expose via Load Balancer" %}
Using the following command, Portainer will be available at an assigned Load Balancer IP on port `9000` for HTTP and `9443` for HTTPS:

```
helm upgrade --install --create-namespace -n portainer portainer portainer/portainer \
    --set service.type=LoadBalancer \
    --set image.tag=lts
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-kubernetes-via-helm) or [via the Portainer UI](https://app.gitbook.com/admin/settings#ssl-certificate) after installation is complete.
{% endhint %}
{% endtab %}
{% endtabs %}

{% hint style="info" %}
To explicitly set the target node when deploying the Helm chart on the CLI, include `--set nodeSelector.kubernetes.io/hostname=<YOUR NODE NAME>` in your `helm install` command.
{% endhint %}

### Deploy using YAML manifests

Our YAML manifests support exposing Portainer via either NodePort or Load Balancer.

{% tabs %}
{% tab title="Expose via NodePort" %}
To expose via NodePort, you can use the following command (Portainer will be available on port `30777`  for HTTP and `30779` for  HTTPS):

```
kubectl apply -n portainer -f https://downloads.portainer.io/ce-lts/portainer.yaml
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `30779`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-kubernetes-via-helm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}
{% endtab %}

{% tab title="Expose via Load Balancer" %}
To expose via Load Balancer, use the following command to provision Portainer at an assigned Load Balancer IP on port `9000` for HTTP and `9443` for HTTPS:

```
kubectl apply -n portainer -f https://downloads.portainer.io/ce-lts/portainer-lb.yaml
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-kubernetes-via-helm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}
{% endtab %}
{% endtabs %}

{% hint style="info" %}
To explicitly set the target node when deploying using YAML manifests, run the following one-liner to "patch" the deployment, forcing the pod to always be scheduled on the node it's currently running on:
{% endhint %}

```
kubectl patch deployments -n portainer portainer -p '{"spec": {"template": {"spec": {"nodeSelector": {"kubernetes.io/hostname": "'$(kubectl get pods -n portainer -o jsonpath='{ ..nodeName }')'"}}}}}' || (echo Failed to identify current node of portainer pod; exit 1)
```

## Logging In

Now that the installation is complete, you can log into your Portainer Server instance. Depending on how you chose to expose your Portainer installation, open a web browser and navigate to the following URL:

{% tabs %}
{% tab title="NodePort" %}
```bash
https://localhost:30779/ or http://localhost:30777/
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.
{% endtab %}

{% tab title="Ingress" %}
```bash
https://<FQDN>/
```

Replace `<FQDN>` with the FQDN of your Portainer instance.
{% endtab %}

{% tab title="Load Balancer" %}
```bash
https://<loadbalancer IP>:9443/ or http://<loadbalancer IP>:9000/
```

Replace `<loadbalancer IP>` with the IP address or FQDN of the load balancer, and adjust the port if you changed it earlier.
{% endtab %}
{% endtabs %}

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../setup.md" %}
[setup.md](../setup.md)
{% endcontent-ref %}



================================================
FILE: start/install-ce/server/podman/README.md
================================================
# Podman

{% hint style="info" %}
These installation instructions are for Portainer Community Edition (CE). For Portainer Business Edition (BE) refer to the [BE install documentation](../../../install/server/podman/).
{% endhint %}

Installation instructions can differ between platforms. Please choose your platform below:

{% content-ref url="linux.md" %}
[linux.md](linux.md)
{% endcontent-ref %}




================================================
FILE: start/install-ce/server/podman/linux.md
================================================
# Install Portainer CE with Podman on Linux

{% hint style="info" %}
These installation instructions are for Portainer Community Edition (CE). For Portainer Business Edition (BE) refer to the [BE install documentation](../../../install/server/podman/linux.md).
{% endhint %}

## Introduction

Portainer consists of two elements, the _Portainer Server_, and the _Portainer Agent_. Both elements run as lightweight containers on a Podman engine. This document will help you install the Portainer Server container on your Linux environment. To add a new Linux environment to an existing Portainer Server installation, please refer to the [Portainer Agent installation instructions](../../../../admin/environments/add/podman/agent.md).

To get started, you will need:

* CentOS 9 with the latest version of Podman 5.x installed and working on your Podman host. Other Podman versions and Linux distros may work but we currently only support the above. We recommend following the [official installation instructions](https://podman.io/docs/installation#installing-on-linux) for Podman.
* sudo access on the machine that will host your Portainer Server instance
* By default, Portainer Server will expose the UI over port `9443` and expose a TCP tunnel server over port `8000`. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents.

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* You are accessing Podman via Unix sockets.
* Podman is running as root. Portainer with rootless Podman may work but is currently not officially supported.

## Deployment

First, ensure the Podman socket is enabled:

```
systemctl enable --now podman.socket
```

Next, create the volume that Portainer Server will use to store its database:

```bash
podman volume create portainer_data
```

Then, download and install the Portainer Server container:

<pre><code><strong>podman run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always --privileged -v /run/podman/podman.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:lts
</strong></code></pre>

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-docker-standalone) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

{% hint style="info" %}
If you require HTTP port `9000` open for legacy reasons, add the following to your `podman run` command:

`-p 9000:9000`
{% endhint %}

Portainer Server has now been installed. You can check to see whether the Portainer Server container has started by running `podman ps`:

```bash
root@server:~# podman ps
CONTAINER ID   IMAGE                          COMMAND                  CREATED       STATUS      PORTS                                                                                  NAMES             
de5b28eb2fa9   portainer/portainer-ce:lts     "/portainer"             2 weeks ago   Up 9 days   0.0.0.0:8000->8000/tcp, :::8000->8000/tcp, 0.0.0.0:9443->9443/tcp, :::9443->9443/tcp   portainer
```

## Logging In

Now that the installation is complete, you can log into your Portainer Server instance by opening a web browser and going to:

```bash
https://localhost:9443
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../../../install/server/setup.md" %}
[setup.md](../../../install-ce/server/setup.md)
{% endcontent-ref %}



================================================
FILE: start/install-ce/server/swarm/README.md
================================================
# Docker Swarm

{% hint style="info" %}
These installation instructions are for Portainer Community Edition (CE). For Portainer Business Edition (BE) refer to the [BE install documentation](../../../install/server/swarm/).
{% endhint %}

Installation instructions can differ between platforms. Please choose your platform below:

{% content-ref url="linux.md" %}
[linux.md](linux.md)
{% endcontent-ref %}

{% content-ref url="wsl.md" %}
[wsl.md](wsl.md)
{% endcontent-ref %}

{% content-ref url="wcs.md" %}
[wcs.md](wcs.md)
{% endcontent-ref %}



================================================
FILE: start/install-ce/server/swarm/linux.md
================================================
# Install Portainer CE with Docker Swarm on Linux

{% hint style="info" %}
These installation instructions are for Portainer Community Edition (CE). For Portainer Business Edition (BE) refer to the [BE install documentation](../../../install/server/swarm/linux.md).
{% endhint %}

## Introduction <a href="#introduction" id="introduction"></a>

Portainer consists of two elements, the _Portainer Server_ and the _Portainer Agent_. Both elements run as lightweight Docker containers on a Docker engine. This document will help you deploy the Portainer Server and Agent containers on your Linux environment. To add a new Linux Swarm environment to an existing Portainer Server installation, please refer to the [Portainer Agent installation instructions](../../../../admin/environments/add/swarm/agent.md).

To get started, you will need:

* The latest version of Docker installed and working. We recommend following the [official installation instructions](https://docs.docker.com/engine/install/) for Docker - in particular, we advise _against_ installing Docker via snap on Ubuntu distributions as you may run into compatibility issues.
* Swarm mode [enabled](https://docs.docker.com/engine/swarm/swarm-mode/) and working, including the overlay network for the swarm service communication
* `sudo` access on the manager node of your swarm cluster
* By default, Portainer will expose the UI over port `9443` and expose a TCP tunnel server over port `8000`. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents.
* The manager and worker nodes must be able to communicate with each other over port `9001`.

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* You are accessing Docker via Unix sockets. Connecting via TCP is not supported in Docker Swarm.
* SELinux is disabled on the machine running Docker.
* Docker is running as root. Portainer with rootless Docker has some limitations, and requires additional configuration.
* You are running a single manager node in your swarm. If you have more than one, please [read this knowledge base article](https://portal.portainer.io/knowledge/how-can-i-ensure-portainers-configuration-is-retained) before proceeding.
* If your nodes are using DNS records to communicate, that all records are resolvable across the cluster.

## Deployment <a href="#deployment" id="deployment"></a>

{% embed url="https://www.youtube.com/watch?v=S2VuHKxrT3s" %}

Portainer can be directly deployed as a service in your Docker cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploy the Portainer Agent as a global service on every node in your cluster.

{% hint style="danger" %}
Only do this **once** for your environment, regardless of how many nodes are in the cluster. You **do not** need to add each node in your cluster as a separate environment in Portainer. Deploying the manifest to your swarm will include every node in the cluster automatically. Adding each node as a separate environment will also consume more of your licensed node count than you may expect.
{% endhint %}

First, retrieve the stack YML manifest:

```
curl -L https://downloads.portainer.io/ce-lts/portainer-agent-stack.yml -o portainer-agent-stack.yml
```

Then use the downloaded YML manifest to deploy your stack:

```
docker stack deploy -c portainer-agent-stack.yml portainer
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-docker-swarm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

Portainer Server and the Agents have now been installed. You can check to see whether the Portainer Server and Agent containers have started by running `docker ps`:

```
root@manager01:~# docker ps
CONTAINER ID   IMAGE                           COMMAND                  CREATED              STATUS              PORTS                NAMES
59ee466f6b15   portainer/agent:lts             "./agent"                About a minute ago   Up About a minute                        portainer_agent.xbb8k6r7j1tk9gozjku7e43wr.5sa6b3e8cl6hyu0snlt387sgv
2db7dd4bfba0   portainer/portainer-ce:lts      "/portainer -H tcp:/…"   About a minute ago   Up About a minute   8000/tcp, 9443/tcp   portainer_portainer.1.gpuvu3pqmt1m19zxfo44v7izx
```

## Logging In <a href="#logging-in" id="logging-in"></a>

Now that the installation is complete, you can log into your Portainer Server instance by opening a web browser and going to:

```
https://localhost:9443
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../setup.md" %}
[setup.md](../setup.md)
{% endcontent-ref %}



================================================
FILE: start/install-ce/server/swarm/wcs.md
================================================
# Install Portainer CE with Docker Swarm on Windows Container Service

{% hint style="info" %}
These installation instructions are for Portainer Community Edition (CE). For Portainer Business Edition (BE) refer to the [BE install documentation](../../../install/server/swarm/wcs.md).
{% endhint %}

## Introduction

Portainer consists of two elements, the _Portainer Server_, and the _Portainer Agent_. Both elements run as lightweight Docker containers on a Docker engine. This document will help you install the Portainer Server container on your Windows server with Windows Containers. To add a new WCS environment to an existing Portainer Server installation, please refer to the [Portainer Agent installation instructions](../../../../admin/environments/add/swarm/agent.md).

To get started, you will need:

* The latest version of Docker installed and working.
* Swarm mode [enabled](https://docs.docker.com/engine/swarm/swarm-mode/) and working, including the overlay network for the swarm service communication.
* Administrator access on the manager node of your Swarm cluster.
* By default, Portainer will expose the UI over port `9443` and expose a TCP tunnel server over port `8000`. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents.
* The manager and worker nodes must be able to communicate with each other over port `9001`.

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* You are running a single manager node in your swarm. If you have more than one, please [read this knowledge base article](https://portal.portainer.io/knowledge/how-can-i-ensure-portainers-configuration-is-retained) before proceeding.
* If your nodes are using DNS records to communicate, that all records are resolvable across the cluster.

## Preparation

To run Portainer Server in a Windows Server/Desktop Environment you need to create exceptions in the firewall. These can easily be added through PowerShell by running the following commands:

```
netsh advfirewall firewall add rule name="cluster_management" dir=in action=allow protocol=TCP localport=2377
netsh advfirewall firewall add rule name="node_communication_tcp" dir=in action=allow protocol=TCP localport=7946
netsh advfirewall firewall add rule name="node_communication_udp" dir=in action=allow protocol=UDP localport=7946
netsh advfirewall firewall add rule name="overlay_network" dir=in action=allow protocol=UDP localport=4789
netsh advfirewall firewall add rule name="swarm_dns_tcp" dir=in action=allow protocol=TCP localport=53
netsh advfirewall firewall add rule name="swarm_dns_udp" dir=in action=allow protocol=UDP localport=53
```

You will also need to install the Windows Container Host Service and install Docker. Microsoft have [provided](https://learn.microsoft.com/en-us/virtualization/windowscontainers/quick-start/set-up-environment?tabs=dockerce#windows-server-1) a PowerShell script to perform the necessary actions. You can download the script and run it with the following commands:

```
Invoke-WebRequest -UseBasicParsing "https://raw.githubusercontent.com/microsoft/Windows-Containers/Main/helpful_tools/Install-DockerCE/install-docker-ce.ps1" -o install-docker-ce.ps1
.\install-docker-ce.ps1
```

Once this is complete you will need to restart your Windows server. After the restart completes, you're ready to install Portainer itself.

## Deployment

Portainer can be directly deployed as a service in your Docker cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploy the Portainer Agent as a global service on every node in your cluster.

{% hint style="danger" %}
Only do this **once** for your environment, regardless of how many nodes are in the cluster. You **do not** need to add each node in your cluster as a separate environment in Portainer. Deploying the manifest to your swarm will include every node in the cluster automatically. Adding each node as a separate environment will also consume more of your licensed node count than you may expect.
{% endhint %}

You can use our YML manifest to run Portainer in Windows using Windows Containers. In PowerShell, run:

```
curl https://downloads.portainer.io/ce-lts/portainer_windows_stack.yml -o portainer-windows-stack.yml
```

Then use the downloaded YML manifest to deploy your stack:

```bash
docker stack deploy --compose-file=portainer-windows-stack.yml portainer
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-docker-swarm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

## Logging In

Now that the installation is complete, you can log into your Portainer Server instance by opening a web browser and going to:

```bash
https://localhost:9443
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../setup.md" %}
[setup.md](../setup.md)
{% endcontent-ref %}



================================================
FILE: start/install-ce/server/swarm/wsl.md
================================================
# Install Portainer CE with Docker Swarm on WSL / Docker Desktop

{% hint style="info" %}
These installation instructions are for Portainer Community Edition (CE). For Portainer Business Edition (BE) refer to the [BE install documentation](../../../install/server/swarm/wsl.md).
{% endhint %}

## Introduction

Portainer consists of two elements, the _Portainer Server_, and the _Portainer Agent_. Both elements run as lightweight Docker containers on a Docker engine. This document will help you install the Portainer Server container on your Windows environment with WSL and Docker Desktop. To add a new WSL / Docker Desktop Swarm environment to an existing Portainer Server installation, please refer to the [Portainer Agent installation instructions](../../../../admin/environments/add/swarm/agent.md).

To get started, you will need:

* The latest version of Docker Desktop installed and working.
* Swarm mode [enabled](https://docs.docker.com/engine/swarm/swarm-mode/) and working, including the overlay network for the swarm service communication.
* Administrator access on the manager node of your Swarm cluster.
* Windows Subsystem for Linux (WSL) installed and a Linux distribution selected. For a new installation we recommend WSL2.
* By default, Portainer will expose the UI over port `9443` and expose a TCP tunnel server over port `8000`. The latter is optional and is only required if you plan to use the Edge compute features with Edge agents.
* The manager and worker nodes must be able to communicate with each other over port `9001`.

The installation instructions also make the following assumptions about your environment:

* Your environment meets [our requirements](../../../requirements-and-prerequisites.md). While Portainer may work with other configurations, it may require configuration changes or have limited functionality.
* You are accessing Docker via Unix sockets. Alternatively, you can also connect via TCP.
* SELinux is disabled within the Linux distribution used by WSL.
* Docker is running as root. Portainer with rootless Docker has some limitations, and requires additional configuration.
* You are running a single manager node in your swarm. If you have more than one, please [read this knowledge base article](https://portal.portainer.io/knowledge/how-can-i-ensure-portainers-configuration-is-retained) before proceeding.
* If your nodes are using DNS records to communicate, that all records are resolvable across the cluster.

## Deployment

Portainer can be directly deployed as a service in your Docker Swarm cluster. Note that this method will automatically deploy a single instance of the Portainer Server, and deploy the Portainer Agent as a global service on every node in your cluster.

{% hint style="danger" %}
Only do this **once** for your environment, regardless of how many nodes are in the cluster. You **do not** need to add each node in your cluster as a separate environment in Portainer. Deploying the manifest to your swarm will include every node in the cluster automatically. Adding each node as a separate environment will also consume more of your licensed node count than you may expect.
{% endhint %}

To begin the installation, first retrieve the stack YML manifest:

```
curl -L https://downloads.portainer.io/ce-lts/portainer-agent-stack.yml -o portainer-agent-stack.yml
```

Then use the downloaded YML manifest to deploy your stack:

```bash
docker stack deploy -c portainer-agent-stack.yml portainer
```

{% hint style="info" %}
By default, Portainer generates and uses a self-signed SSL certificate to secure port `9443`. Alternatively you can provide your own SSL certificate [during installation](../../../../advanced/ssl.md#using-your-own-ssl-certificate-on-docker-swarm) or [via the Portainer UI](../../../../admin/settings/#ssl-certificate) after installation is complete.
{% endhint %}

## Logging In

Now that the installation is complete, you can log into your Portainer Server instance by opening a web browser and going to:

```bash
https://localhost:9443
```

Replace `localhost` with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.

You will be presented with the initial setup page for Portainer Server.

{% content-ref url="../setup.md" %}
[setup.md](../setup.md)
{% endcontent-ref %}



================================================
FILE: start/upgrade/README.md
================================================
# Updating Portainer

Portainer releases contain new features and bug fixes so it's important to keep your installation up to date. We have [tested and validated](../requirements-and-prerequisites.md#valid-configurations) all Portainer version upgrades from 2.0.0 up to the latest release.

While it's possible that an untested unvalidated update path might work, we recommend that all update paths are tested and validated on a non-critical system before applying them to your production systems.

{% hint style="info" %}
We added a [backup and restore feature](../../admin/settings/#backup-portainer) to Portainer BE 2.7 and strongly recommend that you take a backup of your Portainer instance before updating.
{% endhint %}

{% hint style="info" %}
Starting with CE 2.9 and BE 2.10 Portainer is HTTPS enabled by default and uses port `9443` to serve the UI. HTTP can still be enabled on port `9000` if required.
{% endhint %}

## Update order

In general, we recommend updating your Portainer Server deployment _before_ you update the Portainer Agents. When we release new versions of Portainer we ensure that Portainer Server is able to talk to older versions of the Agent, and in most cases the reverse is true, but in some instances we make changes to the Agent that are not fully backward compatible with older versions of Portainer Server.

## Updating Portainer

### From within Portainer

{% hint style="warning" %}
Updating from within Portainer to STS versions (or within STS versions) is currently not available. Only LTS versions will be offered through the in-app update. To switch to or update to STS versions, follow the [manual instructions](./#manually-update-portainer) below.
{% endhint %}

From 2.19, Business Edition users are able to update their Portainer installation directly from within Portainer. To do so, click the **Update now** link in the update notification in the bottom left of the Portainer UI.

<figure><img src="../../.gitbook/assets/2.19-update-notification.png" alt=""><figcaption></figcaption></figure>

In the confirmation dialog, click **Start update** to proceed with the update.

{% hint style="warning" %}
Remember to [back up your Portainer installation](../../admin/settings/#backup-portainer) before updating!
{% endhint %}

<figure><img src="../../.gitbook/assets/2.19-update-confirmation.png" alt=""><figcaption></figcaption></figure>

### Manually update Portainer

If you would prefer to manually update your Portainer installation, choose your platform then follow the instructions:

{% content-ref url="docker.md" %}
[docker.md](docker.md)
{% endcontent-ref %}

{% content-ref url="swarm.md" %}
[swarm.md](swarm.md)
{% endcontent-ref %}

{% content-ref url="podman.md" %}
[podman.md](podman.md)
{% endcontent-ref %}

{% content-ref url="kubernetes.md" %}
[kubernetes.md](kubernetes.md)
{% endcontent-ref %}

### Update the Portainer Agent

To update the standard (non-Edge) Portainer Agent, you can find instructions in the above platform-specific links ([Docker Standalone](docker.md#agent-only-upgrade), [Docker Swarm](swarm.md), [Podman](podman.md) and [Kubernetes](kubernetes.md)).

If you are using the Portainer Edge Agent, we have specific update instructions for you:

{% content-ref url="edge.md" %}
[edge.md](edge.md)
{% endcontent-ref %}

### Upgrading to Business Edition

If you are coming from Portainer CE or the 1.24.x branch, we have guides for you as well.

{% content-ref url="tobe/" %}
[tobe](tobe/)
{% endcontent-ref %}



================================================
FILE: start/upgrade/docker.md
================================================
# Updating on Docker Standalone

{% hint style="info" %}
Always match the agent version to the Portainer Server version. In other words, when you're installing or updating to Portainer 2.27.9 make sure all of the agents are also on version 2.27.9.
{% endhint %}

{% hint style="danger" %}
If you are updating from the 1.x version of Portainer, you **must** first [update to 2.0.0](from-1.x.md) **before** updating to the newest version or you will run into issues.
{% endhint %}

{% hint style="danger" %}
Before beginning any update, we highly recommend [taking a backup](../../admin/settings/general.md#back-up-portainer) of your current Portainer configuration.
{% endhint %}

## Updating your Portainer Server

{% hint style="warning" %}
Starting from Portainer CE 2.9 and BE 2.10, HTTPS is enabled by default on port `9443.` These instructions will configure Portainer to use 9443 for HTTPS and do not expose 9000 for HTTP. If you need to retain HTTP access, you can add:

`-p 9000:9000`

to your command.

You can also choose to [completely disable HTTP](https://github.com/portainer/portainer-docs/blob/2.21/admin/settings/general/README.md#force-https-only) after the update. Before you make Portainer HTTPS only, make sure you have all your Agents and Edge Agents already communicating with Portainer using HTTPS.
{% endhint %}

{% hint style="info" %}
This article assumes that you used our recommended deployment scripts.
{% endhint %}

To update to the latest version of Portainer Server, use the following commands to stop then remove the old version. Your other applications/containers will not be removed.

```
docker stop portainer
```

```
docker rm portainer
```

Now that you have stopped and removed the old version of Portainer, you must ensure that you have the most up to date version of the image locally. You can do this with a `docker pull` command:

{% tabs %}
{% tab title="Business Edition" %}
```
docker pull portainer/portainer-ee:lts
```
{% endtab %}

{% tab title="Community Edition" %}
```
docker pull portainer/portainer-ce:lts
```
{% endtab %}
{% endtabs %}

Finally, deploy the updated version of Portainer:

{% tabs %}
{% tab title="Business Edition" %}
```
docker run -d -p 8000:8000 -p 9443:9443 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee:lts
```
{% endtab %}

{% tab title="Community Edition" %}
```
docker run -d -p 8000:8000 -p 9443:9443 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:lts
```
{% endtab %}
{% endtabs %}

{% hint style="warning" %}
These `docker run` commands include opening port `8000` which is used for Edge Agent communication as included in our [installation instructions](../install/server/docker/linux.md). If you do not need this port open, you can remove it from the command.
{% endhint %}

{% hint style="info" %}
To provide your own SSL certs you may use `--sslcert` and `--sslkey` flags as below to provide the certificate and key files. The certificate file needs to be the full chain and in PEM format. For example, for Business Edition:

```
docker run -d -p 8000:8000 -p 9443:9443 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee:lts --sslcert /path/to/cert/portainer.crt --sslkey /path/to/cert/portainer.key
```
{% endhint %}

The newest version of Portainer will now be deployed on your system, using the persistent data from the previous version, and will also upgrade the Portainer database to the new version.

When the deployment is finished, go to `https://your-server-address:9443` or `http://your-server-address:9000` and log in. You should notice that the update notification has disappeared and the version number has been updated.

## Agent-only update

To update to the latest version of Portainer Agent, use the following commands to stop then remove the old version. Your other applications/containers will not be removed.

```
docker stop portainer_agent
```

```
docker rm portainer_agent
```

Next, pull the updated version of the image:

```
docker pull portainer/agent:lts
```

Finally, start the agent with the updated image:

```
docker run -d -p 9001:9001 --name portainer_agent --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes portainer/agent:lts
```

{% hint style="warning" %}
If you have set a custom `AGENT_SECRET` on your Portainer Server instance (by specifying an `AGENT_SECRET` environment variable when starting the Portainer Server container) you must remember to explicitly provide the same secret to your Agent in the same way (as an environment variable) when updating your Agent:

`-e AGENT_SECRET=yoursecret`
{% endhint %}



================================================
FILE: start/upgrade/edge.md
================================================
# Updating the Edge Agent

To update the Portainer Edge Agent to the latest version, follow the below instructions for your Edge environment.

{% hint style="info" %}
Always match the agent version to the Portainer Server version. In other words, when you're installing or updating to Portainer 2.27.9 make sure all of the agents are also on version 2.27.9.
{% endhint %}

{% hint style="danger" %}
Before beginning any update, we highly recommend [taking a backup](../../admin/settings/general.md#back-up-portainer) of your current Portainer configuration.
{% endhint %}

## Docker Standalone

{% hint style="info" %}
Portainer now also has the ability to update Edge Agents on Docker Standalone [directly from within the UI](../../admin/environments/update.md).
{% endhint %}

To upgrade the Portainer Edge Agent on a Docker Standalone platform, you will first need to note the **Edge identifier** and the **Edge key** for the Edge environment. To find these values, log into Portainer and click **Environments**, then click the name of the environment you are updating.

At the top of the page in the **Edge information** section, you will see the two values you require in the next steps.

<figure><img src="../../.gitbook/assets/2.15-upgrade-edge-edgeinfo.png" alt=""><figcaption></figcaption></figure>

Next, on the Edge environment, we need to stop and remove the Edge Agent container.

```
docker stop portainer_edge_agent
docker rm portainer_edge_agent
```

We also want to ensure we have the updated version of the container image locally:

```
docker pull portainer/agent:lts
```

To deploy the updated Edge Agent, replace the `your-edge-identifier-here` and `your-edge-key-here` values in the following command with those you retrieved earlier, then run the command:

```
docker run -d -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes -v /:/host -v portainer_agent_data:/data --restart always -e EDGE=1 -e EDGE_ID=your-edge-identifier-here -e EDGE_KEY=your-edge-key-here -e EDGE_INSECURE_POLL=1 --name portainer_edge_agent portainer/agent:lts
```

## Docker Swarm

To update the Portainer Edge Agent on a Docker Swarm environment, run the following commands.

First, to ensure you have the updated container image locally, pull the image:

```
docker pull portainer/agent:lts
```

Then, update the service to use the new image version:

```
docker service update --image portainer/agent:lts --force portainer_edge_agent 
```

## Kubernetes

To update the Portainer Edge Agent on a Kubernetes environment, you will need to first download an updated YAML manifest, then apply that manifest to your existing environment.

To download the manifest, you can use one of the following commands:

{% tabs %}
{% tab title="Business Edition" %}
```
curl -L https://downloads.portainer.io/ee-lts/portainer-agent-edge-k8s.yaml  -o portainer-agent-edge-k8s.yaml
```
{% endtab %}

{% tab title="Community Edition" %}
```
curl -L https://downloads.portainer.io/ce-lts/portainer-agent-edge-k8s.yaml -o portainer-agent-edge-k8s.yaml  
```
{% endtab %}
{% endtabs %}

To apply this manifest to your environment, run the following command:

```
kubectl apply -f portainer-agent-edge-k8s.yaml
```



================================================
FILE: start/upgrade/from-1.x.md
================================================
# Updating from Portainer 1.x

If you are updating a Portainer install that is currently running an image from the 1.x series, there are additional steps you must first take before updating to the most recent version. This document covers the steps depending on your current version - start from the instructions for your current version and work your way down.

* [Version 1.24.0 or older](from-1.x.md#updating-from-versions-older-than-1.24.1)
* [Version 1.24.1 or 1.24.2](from-1.x.md#updating-from-1.24.1-and-1.24.2)

{% hint style="info" %}
We only provide instructions for Docker Standalone and Docker Swarm environments here, as Portainer 1.x did not support Kubernetes environments.
{% endhint %}

## **Updating from versions older than 1.24.1** <a href="#updating-from-versions-older-than-1.24.1" id="updating-from-versions-older-than-1.24.1"></a>

If you are running a version prior to 1.24.1, you must first update to `portainer/portainer:1.24.2`. Your other applications/containers will not be removed.

### Docker Standalone <a href="#docker-standalone" id="docker-standalone"></a>

Use the following commands to stop then remove the old version, then run Portainer release 1.24.2.

```
docker stop portainer

docker rm portainer

docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer:1.24.2
```

### Docker Swarm <a href="#docker-swarm" id="docker-swarm"></a>

Run the following command to update the Portainer service to 1.24.2. This assumes your service is named `portainer_portainer` (you can confirm this by checking the output of `docker service ls`).

```
docker service update --image portainer/portainer:1.24.2 --force portainer_portainer
```

Verify that you are running version 1.24.2 by logging into Portainer and reading the version number on the bottom-left of the UI. You should now proceed to [update to version 2.0.0](from-1.x.md#updating-from-1.24.1-and-1.24.2).

## Updating from 1.24.1 and 1.24.2 <a href="#updating-from-1.24.1-and-1.24.2" id="updating-from-1.24.1-and-1.24.2"></a>

If you are running version 1.24.1 or 1.24.2 and want to update to the latest Portainer release, you must first update to `portainer/portainer-ce:2.0.0`. Use the following commands to stop then remove the old version. Your other applications/containers will not be removed.

### Docker Standalone <a href="#docker-standalone-1" id="docker-standalone-1"></a>

```
docker stop portainer
docker rm portainer
```

Now that you have stopped and removed the old version of Portainer, you must ensure that you have the latest version of the 2.0.0 image locally. You can do this with a `docker pull` command:

```
docker pull portainer/portainer-ce:2.0.0
```

Finally, deploy the updated version of Portainer:

```
docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:2.0.0
```

### Docker Swarm <a href="#docker-swarm-1" id="docker-swarm-1"></a>

Run the following command to update the Portainer service to 2.0.0. This assumes your service is named `portainer_portainer` (you can confirm this by checking the output of `docker service ls`).

```
docker service update --image portainer/portainer-ce:2.0.0 --force portainer_portainer
```

Portainer CE 2.0.0 will now be deployed on your system, using the persistent data from the previous version, and will also update the Portainer database to the new version.

When the deployment is finished, go to `http://your-server-address:9000` and log in. Verify that you are running version 2.0.0 by logging into Portainer and reading the version number on the bottom-left of the UI.

## Updating from 2.0.0 <a href="#updating-from-2.0.0" id="updating-from-2.0.0"></a>

Once you have updated to 2.0.0 you can proceed with the [standard update instructions](./) for your platform, or if you are moving to Business Edition you can follow the [upgrade instructions](tobe/).



================================================
FILE: start/upgrade/kubernetes.md
================================================
# Updating on Kubernetes

{% hint style="info" %}
Always match the agent version to the Portainer Server version. In other words, when you're installing or updating to Portainer 2.27.9 make sure all of the agents are also on version 2.27.9.
{% endhint %}

{% hint style="warning" %}
Starting from Portainer CE 2.9 and BE 2.10, HTTPS is enabled by default on port `9443.` These instructions will configure Portainer to use both `9443` for HTTPS and `9000` for HTTP. You can choose to [completely disable HTTP](../../admin/settings/#force-https-only) after the update.&#x20;

Before you make Portainer HTTPS only, make sure you have all your Agents and Edge Agents already communicating with Portainer using HTTPS.&#x20;
{% endhint %}

{% hint style="danger" %}
Before beginning any update, we highly recommend [taking a backup](../../admin/settings/general.md#back-up-portainer) of your current Portainer configuration.
{% endhint %}

Select the Portainer update method which matches the original installation method used.

## Method 1: Updating using Helm

Add the Portainer Helm repository by running the following commands. Ignore any warnings about the repo already being there:

```
helm repo add portainer https://portainer.github.io/k8s/
helm repo update
```

Next, run one of the following commands to update Portainer:

{% tabs %}
{% tab title="Business Edition" %}
```
helm upgrade -n portainer portainer portainer/portainer \
    --set enterpriseEdition.image.tag=lts
```
{% endtab %}

{% tab title="Community Edition" %}
```
helm upgrade -n portainer portainer portainer/portainer \
    --set image.tag=lts
```
{% endtab %}
{% endtabs %}

## Method 2: Updating using YAML Manifest

### Option 1: Via the Portainer UI

The easiest way to update is to use the Portainer UI along with our manifest files. Copy the contents of the manifest file that matches the method you used to deploy Portainer:

{% tabs %}
{% tab title="NodePort" %}
Copy the contents of the relevant NodePort manifest file:

**Business Edition:**

```
https://downloads.portainer.io/ee-lts/portainer.yaml
```

**Community Edition:**

```
https://downloads.portainer.io/ce-lts/portainer.yaml
```

For an agent-only deployment, use one of the following manifests instead:

**Business Edition:**

```
https://downloads.portainer.io/ee-lts/portainer-agent-k8s-nodeport.yaml
```

**Community Edition:**

```
https://downloads.portainer.io/ce-lts/portainer-agent-k8s-nodeport.yaml
```

{% hint style="warning" %}
If you have set a custom `AGENT_SECRET` on your Portainer Server instance (by specifying an `AGENT_SECRET` environment variable when starting the Portainer Server container) you must remember to explicitly provide the same secret to your Agent in the same way (as an environment variable) in the YAML when updating your Agent:

`environment:`\
&#x20; `- AGENT_SECRET: yoursecret`
{% endhint %}
{% endtab %}

{% tab title="Load Balancer" %}
Copy the contents of the relevant Load Balancer manifest file:

**Business Edition:**

```
https://downloads.portainer.io/ee-lts/portainer-lb.yaml
```

**Community Edition:**

```
https://downloads.portainer.io/ce-lts/portainer-lb.yaml
```

For an agent-only deployment, use one of the following manifests instead:

**Business Edition:**

```
https://downloads.portainer.io/ee-lts/portainer-agent-k8s-lb.yaml
```

**Community Edition:**

```
https://downloads.portainer.io/ce-lts/portainer-agent-k8s-lb.yaml
```

{% hint style="warning" %}
If you have set a custom `AGENT_SECRET` on your Portainer Server instance you must remember to explicitly provide this in the YAML when updating your agent:

`environment:`

&#x20; `- AGENT_SECRET: yoursecret`
{% endhint %}
{% endtab %}
{% endtabs %}

Log into Portainer and connect to the Kubernetes environment where Portainer is installed. From the menu select **Applications** then select **Create from manifest**. Toggle **Use namespace(s) specified from manifest** to on, then enter `portainer` in the **Name** field.&#x20;

{% hint style="warning" %}
If you used a different name for your Portainer deployment, use that instead.
{% endhint %}

From the **Build method** selection choose **Web Editor** and ensure **Kubernetes** is selected as the **Deploy type**. Paste the contents of the YAML file then click **Deploy**. Portainer will process the manifest and should return you to the login page once the update is complete.

### Option 2: Via the command line

If you prefer to use the command line to update, you can do so using `kubectl` commands:

{% tabs %}
{% tab title="NodePort" %}
Log into the control node of your Kubernetes cluster and run one of the following commands:

**Business Edition:**

```
kubectl apply -n portainer -f https://downloads.portainer.io/ee-lts/portainer.yaml
```

**Community Edition:**

```
kubectl apply -n portainer -f https://downloads.portainer.io/ce-lts/portainer.yaml
```

For an agent-only deployment, use one of the following commands instead:

**Business Edition:**

```
kubectl apply -n portainer -f https://downloads.portainer.io/ee-lts/portainer-agent-k8s-nodeport.yaml
```

**Community Edition:**

```
kubectl apply -n portainer -f https://downloads.portainer.io/ce-lts/portainer-agent-k8s-nodeport.yaml
```

{% hint style="warning" %}
If you have set a custom `AGENT_SECRET` on your Portainer Server instance (by specifying an `AGENT_SECRET` environment variable when starting the Portainer Server container) you must remember to explicitly provide the same secret to your Agent in the same way (as an environment variable) in the YAML when updating your Agent:

`environment:`\
&#x20; `- AGENT_SECRET: yoursecret`
{% endhint %}
{% endtab %}

{% tab title="Load Balancer" %}
Log into the control node of your Kubernetes cluster and run one of the following commands:

**Business Edition:**

```
kubectl apply -n portainer -f https://downloads.portainer.io/ee-lts/portainer-lb.yaml
```

**Community Edition:**

```
kubectl apply -n portainer -f https://downloads.portainer.io/ce-lts/portainer.yaml
```

For an agent-only deployment, use one of the following commands instead:

**Business Edition:**

```
kubectl apply -n portainer -f https://downloads.portainer.io/ee-lts/portainer-agent-k8s-lb.yaml
```

**Community Edition:**

```
kubectl apply -n portainer -f https://downloads.portainer.io/ce-lts/portainer-agent-k8s-lb.yaml
```

{% hint style="warning" %}
If you have set a custom `AGENT_SECRET` on your Portainer Server instance you must remember to explicitly provide this in the YAML when updating your agent:

`environment:`

&#x20; `- AGENT_SECRET: yoursecret`
{% endhint %}
{% endtab %}
{% endtabs %}

When the deployment is finished you will be able to log into Portainer. You should notice the new version number at the bottom-left of the Portainer UI.

## Method 3: Force an update

If Portainer does not update after running the above commands, you can force a download of the latest image by running the following command:

```
kubectl -n portainer rollout restart deployment.apps/portainer
```

Or, for an agent-only deployment, use this command instead:

```
kubectl -n portainer rollout restart deployment.apps/portainer-agent
```



================================================
FILE: start/upgrade/nomad.md
================================================
# Updating on Nomad

In our ongoing efforts to refine and optimize Portainer, we have made the decision to discontinue support for HashiCorp Nomad as an environment type from Portainer version 2.20.0. This decision is based on limited user adoption and the considerable development resources required to maintain Nomad support.



================================================
FILE: start/upgrade/podman.md
================================================
# Updating on Podman

{% hint style="info" %}
Always match the agent version to the Portainer Server version. In other words, when you're installing or updating to Portainer 2.27.9 make sure all of the agents are also on version 2.27.9.
{% endhint %}

{% hint style="danger" %}
Before beginning any update, we highly recommend [taking a backup](../../admin/settings/general.md#back-up-portainer) of your current Portainer configuration.
{% endhint %}

## Updating your Portainer Server

{% hint style="warning" %}
Starting from Portainer CE 2.9 and BE 2.10, HTTPS is enabled by default on port `9443.` These instructions will configure Portainer to use 9443 for HTTPS and do not expose 9000 for HTTP. If you need to retain HTTP access, you can add:

`-p 9000:9000`

to your command.

You can also choose to [completely disable HTTP](https://github.com/portainer/portainer-docs/blob/2.21/admin/settings/general/README.md#force-https-only) after the update. Before you make Portainer HTTPS only, make sure you have all your Agents and Edge Agents already communicating with Portainer using HTTPS.
{% endhint %}

{% hint style="info" %}
This article assumes that you used our recommended deployment scripts.
{% endhint %}

To update to the latest version of Portainer Server, use the following commands to stop then remove the old version. Your other applications/containers will not be removed.

```
podman stop portainer
```

```
podman rm portainer
```

Now that you have stopped and removed the old version of Portainer, you must ensure that you have the most up to date version of the image locally. You can do this with a `podman pull` command:

{% tabs %}
{% tab title="Business Edition" %}
```
podman pull portainer/portainer-ee:lts
```
{% endtab %}

{% tab title="Community Edition" %}
```
podman pull portainer/portainer-ce:lts
```
{% endtab %}
{% endtabs %}

Finally, deploy the updated version of Portainer:

{% tabs %}
{% tab title="Business Edition" %}
```
podman run -d -p 8000:8000 -p 9443:9443 --name=portainer --restart=always --privileged -v /run/podman/podman.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee:lts
```
{% endtab %}

{% tab title="Community Edition" %}
```
podman run -d -p 8000:8000 -p 9443:9443 --name=portainer --restart=always --privileged -v /run/podman/podman.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:lts
```
{% endtab %}
{% endtabs %}

{% hint style="warning" %}
These `podman run` commands include opening port `8000` which is used for Edge Agent communication as included in our [installation instructions](../install/server/docker/linux.md). If you do not need this port open, you can remove it from the command.
{% endhint %}

{% hint style="info" %}
To provide your own SSL certs you may use `--sslcert` and `--sslkey` flags as below to provide the certificate and key files. The certificate file needs to be the full chain and in PEM format. For example, for Business Edition:

```
podman run -d -p 8000:8000 -p 9443:9443 --name=portainer --restart=always --privileged -v /run/podman/podman.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee:lts --sslcert /path/to/cert/portainer.crt --sslkey /path/to/cert/portainer.key
```
{% endhint %}

The newest version of Portainer will now be deployed on your system, using the persistent data from the previous version, and will also upgrade the Portainer database to the new version.

When the deployment is finished, go to `https://your-server-address:9443` or `http://your-server-address:9000` and log in. You should notice that the update notification has disappeared and the version number has been updated.

## Agent-only update

To update to the latest version of Portainer Agent, use the following commands to stop then remove the old version. Your other applications/containers will not be removed.

```
podman stop portainer_agent
```

```
podman rm portainer_agent
```

Next, pull the updated version of the image:

```
podman pull portainer/agent:lts
```

Finally, start the agent with the updated image:

```
podman run -d -p 9001:9001 --name portainer_agent --restart=always --privileged -v /run/podman/podman.sock:/var/run/docker.sock -v /var/lib/containers/storage/volumes:/var/lib/docker/volumes portainer/agent:lts
```

{% hint style="warning" %}
If you have set a custom `AGENT_SECRET` on your Portainer Server instance (by specifying an `AGENT_SECRET` environment variable when starting the Portainer Server container) you must remember to explicitly provide the same secret to your Agent in the same way (as an environment variable) when updating your Agent:

`-e AGENT_SECRET=yoursecret`
{% endhint %}



================================================
FILE: start/upgrade/swarm.md
================================================
# Updating on Docker Swarm

{% hint style="info" %}
Always match the agent version to the Portainer Server version. In other words, when you're installing or updating to Portainer 2.27.9 make sure all of the agents are also on version 2.27.9.
{% endhint %}

{% hint style="warning" %}
Starting from Portainer CE 2.9 and BE 2.10, HTTPS is enabled by default on port `9443.` These instructions will configure Portainer to use 9443 for HTTPS  and 9000 for HTTP. You can choose to [completely disable HTTP](../../admin/settings/#force-https-only) after the update.&#x20;

Before you make Portainer HTTPS only, make sure you have all your Agents and Edge Agents already communicating with Portainer using HTTPS.&#x20;
{% endhint %}

{% hint style="danger" %}
If you are updating from the 1.x version of Portainer, you **must** first [update to 2.0.0](from-1.x.md) **before** updating to the newest version or you will run into issues.
{% endhint %}

{% hint style="danger" %}
Before beginning any update, we highly recommend [taking a backup](../../admin/settings/general.md#back-up-portainer) of your current Portainer configuration.
{% endhint %}

To update the Portainer Server and the agents on Docker Swarm, first run the following command on the manager node of your Docker Swarm cluster:

```
docker service ls 
```

Make note of the service names for Portainer. You will need them later.

```
ID             NAME                    MODE         REPLICAS   IMAGE                          PORTS
tb9gtxc647fw   portainer-agent_agent   global       3/3        portainer/agent:2.26.0
m3a3mtuy55ed   portainer_portainer     replicated   1/1        portainer/portainer-ee:2.26.0  *:8000->8000/tcp, *:9000->9000/tcp
```

To update Portainer Server to the most recent version, run one of the sets of commands below depending on your edition of Portainer (replace the `portainer_portainer` service name if your setup differs):

{% tabs %}
{% tab title="Business Edition" %}
```
docker pull portainer/portainer-ee:lts
docker service update --image portainer/portainer-ee:lts --publish-add 9443:9443 --force portainer_portainer
```
{% endtab %}

{% tab title="Community Edition" %}
```
docker pull portainer/portainer-ce:lts
docker service update --image portainer/portainer-ce:lts --publish-add 9443:9443 --force portainer_portainer
```
{% endtab %}
{% endtabs %}

To update the Portainer Agent to the latest version, run the commands below (replace the `portainer_agent` service name if your setup differs):

```
docker pull portainer/agent:lts
docker service update --image portainer/agent:lts --force portainer_agent 
```

This will deploy the newest version of Portainer and the agent across your swarm and upgrade the Portainer database to match.

When this is finished, go to `https://your-server-address:9443` or `http://your-server-address:9000` and log in. You should notice that the update notification has disappeared and the version number has been updated.



================================================
FILE: start/upgrade/tobe/README.md
================================================
# Switching to Portainer Business Edition

It’s easy and quick to upgrade from Portainer CE (both 1.x and 2.x branches) to Portainer Business Edition without losing your data. The following instructions apply whether you’re using a 5 node free license or you’ve purchased a license for Portainer Business Edition.

From version 2.17, you can upgrade your Portainer CE installation to Portainer BE from within Portainer itself.

{% content-ref url="inapp.md" %}
[inapp.md](inapp.md)
{% endcontent-ref %}

If you would like to upgrade manually, you can find instructions for your environment at the following links:

{% content-ref url="docker.md" %}
[docker.md](docker.md)
{% endcontent-ref %}

{% content-ref url="swarm.md" %}
[swarm.md](swarm.md)
{% endcontent-ref %}

{% content-ref url="kubernetes.md" %}
[kubernetes.md](kubernetes.md)
{% endcontent-ref %}

For Agent-only deployments, you do not need to upgrade the Agent to Business Edition.

{% content-ref url="agent.md" %}
[agent.md](agent.md)
{% endcontent-ref %}




================================================
FILE: start/upgrade/tobe/agent.md
================================================
# Upgrading Agent-only deployments

Both Portainer Community Edition and Portainer Business Edition use the same Portainer Agent container image to run, so if you are upgrading from CE to BE and have Agent-only environments, you don't need to upgrade them as well - just ensure they are on the same version (for example, if the Portainer Server is version 2.27.9 then the Portainer Agent should be 2.27.9 as well).



================================================
FILE: start/upgrade/tobe/docker.md
================================================
# Docker Standalone

{% hint style="warning" %}
This article assumes that you used our recommended deployment scripts.
{% endhint %}

{% hint style="info" %}
Before you begin, copy the license key from the email we sent you.
{% endhint %}

The process for switching to Portainer Business Edition is straightforward but does depend on which version of Portainer you are currently running. Start from the instructions for your current version and work your way down.

* [Version 1.24.0 or older](docker.md#upgrading-from-versions-older-than-1.24.1)
* [Version 1.24.1 or 1.24.2](docker.md#upgrading-from-1.24.1-and-1.24.2)
* [Version 2.0.0 or newer](docker.md#upgrading-from-version-2.0.0-and-later)

## **Upgrading from versions older than 1.24.1**

If you are running a version prior to 1.24.1, you must first upgrade to `portainer/portainer:1.24.2`. Your other applications/containers will not be removed. Use the following commands to stop then remove the old version, then run Portainer release 1.24.2:

```
docker stop portainer

docker rm portainer

docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer:1.24.2
```

Verify that you are running version 1.24.2 by logging into Portainer and reading the version number on the bottom-left of the UI. You should now proceed to [upgrade to version 2.0.0](docker.md#upgrading-from-1.24.1-and-1.24.2).

## Upgrading from 1.24.1 and 1.24.2

If you are running a version prior to 1.24.1 and want to upgrade to the latest Portainer release, you must first upgrade to `portainer/portainer-ce:2.0.0`, use the following commands to stop then remove the old version. Your other applications/containers will not be removed.

```
docker stop portainer
```

```
docker rm portainer
```

Now that you have stopped and removed the old version of Portainer, you must ensure that you have the latest version of the image locally. You can do this with a `docker pull` command:

```
docker pull portainer/portainer-ce:2.0.0
```

Finally, deploy the updated version of Portainer:

```
docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:2.0.0
```

Portainer CE 2.0.0 will now be deployed on your system, using the persistent data from the previous version, and will also upgrade the Portainer database to the new version.

When the deployment is finished, go to `http://your-server-address:9000` and log in. Verify that you are running version 2.0.0 by logging into Portainer and reading the version number on the bottom-left of the UI. You can now [upgrade to the latest version](docker.md#upgrading-from-version-2.0.0-and-later) of Portainer Business Edition.

## Upgrading from version 2.0.0 and later

To upgrade to Portainer Business Edition for Docker Standalone, use the following commands to stop then remove the old version. Your other applications/containers will not be removed.

```
docker stop portainer
docker rm portainer
```

Now that you have stopped and removed the old version of Portainer, run this command to deploy the most up to date version of Portainer Business:

```
docker run -d -p 8000:8000 -p 9000:9000 -p 9443:9443 --name=portainer --restart=always --pull=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ee:lts
```

Log out of Portainer (if currently logged in) then log back in. When you log in for the first time, you'll be asked to enter your license key. Paste this in from the email we sent you.

<figure><img src="../../../.gitbook/assets/2.20-initial-setup-license.png" alt=""><figcaption></figcaption></figure>

'Business Edition' now appears in the bottom-left corner.



================================================
FILE: start/upgrade/tobe/inapp.md
================================================
# Upgrade to Business Edition from within Portainer Community Edition

To upgrade from Portainer Community Edition to Portainer Business Edition from within Portainer, log in as an administrator and click the **Upgrade to Business Edition** message in the top left.

<figure><img src="../../../.gitbook/assets/2.17-upgrade-tobe-inapp.gif" alt=""><figcaption></figcaption></figure>

If you already have a license for Portainer Business Edition, paste it in the box and click **Start upgrade** to begin the upgrade process.

If you do not currently have a license, click **Get a license** and fill out the form to receive a trial key.

<figure><img src="../../../.gitbook/assets/2.17-upgrade-tobe-inapp-licenseform.png" alt=""><figcaption></figcaption></figure>

Your trial key will be sent to the email address you provided and you will be returned to the license entry form.

{% hint style="info" %}
Your license should be sent automatically within a few minutes. If you have not received it please check your spam folders, or [get in touch with our team](mailto:success@portainer.io) if you have not received it in 24 hours.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.17-upgrade-tobe-inapp-licensesent.png" alt=""><figcaption></figcaption></figure>

When you receive your license, paste the key into the box and click **Start upgrade** to begin the upgrade process.




================================================
FILE: start/upgrade/tobe/kubernetes.md
================================================
# Kubernetes

{% hint style="info" %}
Select the Portainer CE to Portainer Business upgrade method below which matches the original installation method used.
{% endhint %}

## Method 1: Upgrade via Helm

To update your Helm repository, run this command first:

```
helm repo update
```

Run this command next to deploy the latest version of Portainer Business on your Kubernetes cluster with all of the settings used in your Helm deployment:

```
helm upgrade -n portainer portainer portainer/portainer --set enterpriseEdition.enabled=true
```

## Method 2: Upgrade via YAML Manifests

Choose the right YAML manifest based on your original deployment:

{% tabs %}
{% tab title="NodePort" %}
Use the following `kubectl` command to update a NodePort deployment:

```
kubectl apply -n portainer -f https://downloads.portainer.io/ee-lts/portainer.yaml
```
{% endtab %}

{% tab title="Load Balancer" %}
Use the following `kubectl` command to update a Load Balancer deployment:

```
kubectl apply -n portainer -f https://downloads.portainer.io/ee-lts/portainer-lb.yaml
```
{% endtab %}
{% endtabs %}

This will deploy the newest version of Portainer Business on your Kubernetes cluster.

## Logging back in

When the upgrade is complete, log out of Portainer (if currently logged in) then log back in. When you log in for the first time, you'll be asked to enter your license key. Paste this in from the email we sent you.

<figure><img src="../../../.gitbook/assets/2.20-initial-setup-license.png" alt=""><figcaption></figcaption></figure>

'Business Edition' now appears in the bottom-left corner.



================================================
FILE: start/upgrade/tobe/podman.md
================================================
# Podman

{% hint style="warning" %}
This article assumes that you used our recommended deployment scripts.
{% endhint %}

{% hint style="info" %}
Before you begin, copy the license key from the email we sent you.
{% endhint %}

To upgrade to Portainer Business Edition for Podman, use the following commands to stop then remove the old version. Your other applications/containers will not be removed.

```
podman stop portainer
podman rm portainer
```

Now that you have stopped and removed the old version of Portainer, run this command to deploy the most up to date version of Portainer Business:

```
podman run -d -p 8000:8000 -p 9000:9000 -p 9443:9443 --name=portainer --restart=always --pull=always --privileged -v /run/podman/podman.sock:/run/podman/podman.sock -v portainer_data:/data portainer/portainer-ee:lts
```

Log out of Portainer (if currently logged in) then log back in. When you log in for the first time, you'll be asked to enter your license key. Paste this in from the email we sent you.

<figure><img src="../../../.gitbook/assets/2.20-initial-setup-license.png" alt=""><figcaption></figcaption></figure>

'Business Edition' now appears in the bottom-left corner.



================================================
FILE: start/upgrade/tobe/swarm.md
================================================
# Docker Swarm

{% hint style="warning" %}
This article assumes that you used our recommended deployment scripts.
{% endhint %}

{% hint style="info" %}
Before you begin, copy the license key from the email we sent you.
{% endhint %}

To upgrade to Portainer Business Edition for Docker Swarm, use the following commands to deploy the newest version of Portainer Business on your Swarm Cluster:

```
docker service update --image portainer/portainer-ee:lts --force portainer_portainer
```

Log out of Portainer (if currently logged in) then log back in. When you log in for the first time, you'll be asked to enter your license key. Paste this in from the email we sent you.

<figure><img src="../../../.gitbook/assets/2.20-initial-setup-license.png" alt=""><figcaption></figcaption></figure>

'Business Edition' now appears in the bottom-left corner.



================================================
FILE: user/account-settings.md
================================================
# Account settings

To get access to and update your user settings, click your username in the top-right of the Portainer UI and select **My account**.

<figure><img src="../.gitbook/assets/2.20-api-access-myaccount.gif" alt=""><figcaption></figcaption></figure>

## Changing the theme

Portainer lets you choose between light, dark and high-contrast themes, or to auto-select the theme based on your system theme. The chosen theme applies only to this user.

Select a theme from the options. The change will be automatically applied.

<figure><img src="../.gitbook/assets/2.15-accountsettings-theme.png" alt=""><figcaption></figcaption></figure>

## Changing your password

Enter the following details, using the table below as a guide. When you're finished, click **Update password**.

<figure><img src="../.gitbook/assets/2.15-accountsettings-changepw.png" alt=""><figcaption></figcaption></figure>

| Field/Option     | Overview                                                    |
| ---------------- | ----------------------------------------------------------- |
| Current password | Enter the password you currently use to log into Portainer. |
| New password     | Enter a new password for your account.                      |
| Confirm password | Enter the new password again.                               |

[Minimum password length requirements](../admin/settings/authentication/) are set by the administrator.

## Application settings

In this section you can enable or disable front-end data caching for your Kubernetes environments. When this this option is enabled, Portainer will cache data provided about your Kubernetes cluster in the front-end in order to improve load times when viewing the cluster. This caching can however mean that you may not see fully up-to-date information, and changes made by other users or outside of Portainer may take up to five minutes to update in your session.

<figure><img src="../.gitbook/assets/2.20-account-application.png" alt=""><figcaption></figcaption></figure>

## Access tokens

This section allows you to manage your API access tokens. You can see a list of the access tokens that exist for your user as well as add and remove tokens as required.

<figure><img src="../.gitbook/assets/2.15-accountsettings-apitokens.png" alt=""><figcaption></figcaption></figure>

For more information on access tokens, refer to our [API access documentation](../api/access.md#creating-an-access-token).

## Git credentials

This section lets you manage your saved Git credentials for use in deployments. These credentials are available only to your user.

{% hint style="info" %}
This feature is only available in Portainer Business Edition.
{% endhint %}

<figure><img src="../.gitbook/assets/2.16-account-gitcreds.png" alt=""><figcaption></figcaption></figure>

To add a new credential, click the **Add git credential** button and fill out the fields using the table below as a guide:

| Field                 | Overview                                                                                                     |
| --------------------- | ------------------------------------------------------------------------------------------------------------ |
| Name                  | Enter a name for this credential entry. This is how it will appear when selecting it for use when deploying. |
| Username              | Enter the username, if relevant.                                                                             |
| Personal Access Token | Enter the personal access token.                                                                             |

<figure><img src="../.gitbook/assets/2.16-account-gitcreds-add.png" alt=""><figcaption></figcaption></figure>

Once you've entered the relevant details, click **Save git credential** to save the entry.

## Helm repositories

By default, Portainer ships with the [Bitnami Helm chart repository](https://bitnami.com/stacks/helm) already pre-configured. In this section you can add additional Helm repositories to reference when deploying Helm charts.

<figure><img src="../.gitbook/assets/2.20-account-helmrepos.png" alt=""><figcaption></figcaption></figure>

If you would like to add an additional third-party repo, click on **Add Helm repository**, enter the repository URL and click **Save Helm repository**.

{% hint style="info" %}
Repositories added here are only available to your user. You can configure a Helm repository that will be available to all users in [Settings](../admin/settings/general.md#helm-repository).
{% endhint %}

<figure><img src="../.gitbook/assets/2.20-account-helmrepos-add.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/nomad.md
================================================
# Nomad

In our ongoing efforts to refine and optimize Portainer, we have made the decision to discontinue support for HashiCorp Nomad as an environment type from Portainer version 2.20.0. This decision is based on limited user adoption and the considerable development resources required to maintain Nomad support.



================================================
FILE: user/aci/README.md
================================================
# Azure ACI

{% hint style="info" %}
Support for Azure ACI is currently experimental.
{% endhint %}

The following sections describe how to manage an Azure ACI environment using menu options available in the Portainer Server. To learn how to add an Azure ACI environment, see our [environment guide](../../admin/environments/add/aci.md).

{% content-ref url="dashboard.md" %}
[dashboard.md](dashboard.md)
{% endcontent-ref %}

{% content-ref url="containers/" %}
[containers](containers/)
{% endcontent-ref %}




================================================
FILE: user/aci/dashboard.md
================================================
# Dashboard

The Azure ACI dashboard summarizes your Azure ACI environment and shows the components that make up the environment. Tiles show the number of subscriptions, resource groups and container instances that make up your Azure application.

<figure><img src="../../.gitbook/assets/2.22.0-aci-dashboard.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/aci/containers/README.md
================================================
# Container instances

The **Container Instances** page allows you to interact with containers in your Azure application, letting you add and remove containers as needed.

<figure><img src="../../../.gitbook/assets/2.22.0-aci-containers-list.png" alt=""><figcaption></figcaption></figure>

You can click on a container name to view details about that container.

{% content-ref url="details.md" %}
[details.md](details.md)
{% endcontent-ref %}

From this page you can add a new container or remove existing containers:

{% content-ref url="add.md" %}
[add.md](add.md)
{% endcontent-ref %}

{% content-ref url="remove.md" %}
[remove.md](remove.md)
{% endcontent-ref %}



\



================================================
FILE: user/aci/containers/add.md
================================================
# Add a new container

From the menu select **Container instances** then click **Add container**.

<figure><img src="../../../.gitbook/assets/2.22.0-aci-container-create.gif" alt=""><figcaption></figcaption></figure>

Complete the configuration, using the table below as a guide:

| Field/Option   | Overview                                                                                                                                                       |
| -------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Subscription   | Select the subscription you want to use for the container.                                                                                                     |
| Resource group | If two or more resource groups exist, select the resource group to use.                                                                                        |
| Location       | Select which Azure datacenter to run the container in. If virtual networks are available in a location, a count will be displayed alongside the location name. |
| Name           | Give the container a descriptive name.                                                                                                                         |
| Image          | Enter the name of the image that will be used to deploy the container.                                                                                         |
| OS             | Select the OS (typically Linux or Windows).                                                                                                                    |
| Tags           | Click **Add tag** to add a new tag, and provide the **Name** and **Value** for each tag as needed. Click the trash icon next to a tag to remove it.            |

<figure><img src="../../../.gitbook/assets/2.22.0-aci-container-create-1.png" alt=""><figcaption></figcaption></figure>

### Network Settings

In this section you can configure the network for your container as well as the ports to publish.

| Field/Option    | Overview                                                                                                                                              |
| --------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |
| Private Network | Toggle this option on if you wish to use a pre-existing private network for your container.                                                           |
| Virtual Network | When Private Network is enabled, select the network to use. The selection will be limited on what is available in your selected location.             |
| Subnet          | When Private Network is enabled, select the subnet to use within your network (where relevant).                                                       |
| Ports           | Enter the port number and select TCP or UDP to publish your container on the specified port and protocol. Click Add port to publish additional ports. |

<figure><img src="../../../.gitbook/assets/2.22.0-aci-container-create-2.png" alt=""><figcaption></figcaption></figure>

### Container Resources

Here you can specify the resources available to your container.

| Field/Option | Overview                                                   |
| ------------ | ---------------------------------------------------------- |
| CPU          | Define how many CPUs to allocate to the container.         |
| Memory (GB)  | Define how much memory in GB to allocate to the container. |

<figure><img src="../../../.gitbook/assets/2.22.0-aci-container-create-3.png" alt=""><figcaption></figcaption></figure>

### Volumes

This section lets you specify a volume you want to be accessible from the container.

| Field/Option        | Overview                                                             |
| ------------------- | -------------------------------------------------------------------- |
| Enable volumes      | Toggle this option on to enable adding a volume to this container.   |
| File share name     | Enter the file share name for the volume.                            |
| Storage account     | Enter the name of the storage account with access to the file share. |
| Storage account key | Enter the key for the above storage account.                         |
| Mount path          | Enter the path within the container to mount the volume.             |

<figure><img src="../../../.gitbook/assets/2.22.0-aci-container-create-4.png" alt=""><figcaption></figcaption></figure>

### GPUs

Here you can enable GPU support for the container and specify the GPU to use.

{% hint style="warning" %}
GPUs are currently a preview feature for Azure Container Instances and only available in select locations. Ensure you have access to GPUs before using this feature.
{% endhint %}

| Field/Option | Overview                                                 |
| ------------ | -------------------------------------------------------- |
| Enable GPUs  | Toggle this on to enable GPU support for this container. |
| GPU type     | Select the type of GPU to use.                           |
| GPU count    | Enter the number of GPUs to use.                         |

<figure><img src="../../../.gitbook/assets/2.22.0-aci-container-create-5.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Deploy the container**. When the deployment has finished, you'll see it in the list of  Azure container instances.



================================================
FILE: user/aci/containers/details.md
================================================
# View container details

To view the details of an existing container, from the **Container instances** list click the container's name.

<figure><img src="../../../.gitbook/assets/2.22.0-aci-container-details.gif" alt=""><figcaption></figcaption></figure>

### Container

The Container Instance details page displays information about the selected container under the **Container** tab.&#x20;

<figure><img src="../../../.gitbook/assets/2.22.0-aci-container-details.png" alt=""><figcaption></figcaption></figure>

### Events

You can view past events in the container's lifecycle in the **Events** tab.

<figure><img src="../../../.gitbook/assets/2.22.0-aci-container-details-events.png" alt=""><figcaption></figcaption></figure>

Events can be sorted by date, type, message and count (the number of times the event has fired) and can be filtered from the search box.

### Actions

From this section you can start, stop, restart or remove your container.

<figure><img src="../../../.gitbook/assets/2.22.0-aci-container-details-actions.png" alt=""><figcaption></figcaption></figure>

### Access control

This section shows the current ownership and access for the container and allows you to change it.

<figure><img src="../../../.gitbook/assets/2.22.0-aci-container-details-accesscontrol.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/aci/containers/remove.md
================================================
# Remove a container

From the menu select **Container instances**, tick the checkbox next to the container you want to remove then click **Remove**.

<figure><img src="../../../.gitbook/assets/2.22.0-aci-container-remove.gif" alt=""><figcaption></figcaption></figure>

When the confirmation message appears, click **Remove**.

<figure><img src="../../../.gitbook/assets/2.15-aci-remove-confirm.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/README.md
================================================
# Docker/Swarm/Podman

The following sections describe how to manage a Docker Standalone, Docker Swarm or Podman environment using menu options available in the Portainer Server.

{% content-ref url="dashboard.md" %}
[dashboard.md](dashboard.md)
{% endcontent-ref %}

{% content-ref url="templates/" %}
[templates](templates/)
{% endcontent-ref %}

{% content-ref url="stacks/" %}
[stacks](stacks/)
{% endcontent-ref %}

{% content-ref url="services/" %}
[services](services/)
{% endcontent-ref %}

{% content-ref url="containers/" %}
[containers](containers/)
{% endcontent-ref %}

{% content-ref url="images/" %}
[images](images/)
{% endcontent-ref %}

{% content-ref url="networks/" %}
[networks](networks/)
{% endcontent-ref %}

{% content-ref url="volumes/" %}
[volumes](volumes/)
{% endcontent-ref %}

{% content-ref url="configs/" %}
[configs](configs/)
{% endcontent-ref %}

{% content-ref url="secrets/" %}
[secrets](secrets/)
{% endcontent-ref %}

{% content-ref url="events.md" %}
[events.md](events.md)
{% endcontent-ref %}

{% content-ref url="host/" %}
[host](host/)
{% endcontent-ref %}

{% content-ref url="swarm/" %}
[swarm](swarm/)
{% endcontent-ref %}




================================================
FILE: user/docker/dashboard.md
================================================
# Dashboard

The Docker/Swarm dashboard summarizes your Docker Standalone or Docker Swarm environment and shows the components that make up the environment.&#x20;

## Environment info

{% hint style="info" %}
This section is visible only to Docker Standalone and Podman environments.
{% endhint %}

This section shows the environment name, its URL and port along with any [tags](../../admin/environments/tags.md#tagging-an-environment). You can also see the number of CPU cores (and their available memory), the Docker/Podman version, and whether or not the Portainer Agent is installed.&#x20;

<figure><img src="../../.gitbook/assets/2.15-docker-standalone-dashboard.png" alt=""><figcaption></figcaption></figure>

## Cluster information

{% hint style="info" %}
This section is visible only to Docker Swarm environments.
{% endhint %}

This section shows how many nodes are in the cluster and a link to the [cluster visualizer](swarm/cluster-visualizer.md).

<figure><img src="../../.gitbook/assets/2.15-docker-dashboard-swarm.png" alt=""><figcaption></figcaption></figure>

## Summary tiles

The remaining dashboard is made up of tiles showing the number of [stacks](stacks/), [services](services/) (for Docker Swarm), [containers](containers/) (including health and running-status metrics), [images](images/) (and how much disk space they consume), [volumes](volumes/) and [networks](networks/), and GPUs (if enabled).

<figure><img src="../../.gitbook/assets/2.15-docker-dashboard-tiles.png" alt=""><figcaption></figcaption></figure>




================================================
FILE: user/docker/events.md
================================================
# Events

{% hint style="info" %}
The **Events** menu is only available to Docker Standalone environments.
{% endhint %}

The **Events** section in Portainer lists container events that have occurred. You can filter the list using search, and you can also [view more information about each container](containers/inspect.md).

<figure><img src="../../.gitbook/assets/2.15-docker_events_events_list.png" alt=""><figcaption></figcaption></figure>




================================================
FILE: user/docker/configs/README.md
================================================
# Configs

{% hint style="info" %}
The **Configs** menu is only available to Docker Swarm environments.
{% endhint %}

Docker 17.06 introduced swarm service configs which allow you to store non-sensitive information, such as configuration files, outside a service’s image or running containers. This allows you to keep your images as generic as possible, without the need to bind-mount configuration files into the containers or use environment variables. [Secrets](../secrets/) is another option for storing sensitive information.

<figure><img src="../../../.gitbook/assets/2.15-docker_configs_config_list.png" alt=""><figcaption></figcaption></figure>

In Portainer you can add and remove custom configurations for use in deployments.

{% content-ref url="add.md" %}
[add.md](add.md)
{% endcontent-ref %}

{% content-ref url="remove.md" %}
[remove.md](remove.md)
{% endcontent-ref %}




================================================
FILE: user/docker/configs/add.md
================================================
# Add a new config

From the menu select **Configs** then click **Add config**.

<figure><img src="../../../.gitbook/assets/2.15-docker_configs_configs_add.gif" alt=""><figcaption></figcaption></figure>

&#x20;In the editor, write the configuration. You can also add labels and configure access control.

<figure><img src="../../../.gitbook/assets/2.15-docker_configs_myconfig.png" alt=""><figcaption></figcaption></figure>

When you're finished, click **Create config**.




================================================
FILE: user/docker/configs/remove.md
================================================
# Remove a config

From the menu select **Configs**, tick the checkbox next to the config you want to remove then click **Remove**.

<figure><img src="../../../.gitbook/assets/2.15-docker_configs_configs_remove.gif" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/containers/README.md
================================================
# Containers

Put simply, a container is a runnable instance of an image. Containers do not hold any persistent data and therefore can be destroyed and recreated as needed.

<figure><img src="../../../.gitbook/assets/2.20-containers-list.png" alt=""><figcaption></figcaption></figure>

When the [new image indicator](../host/setup.md#other) feature is enabled, the **Images up to date** column indicates whether the local images in the container are up to date, with a green tick indicating they are up to date and an orange cross indicating that there is a newer version of an image available at the remote registry. A grey hyphen indicates Portainer was unable to determine whether there is an update available for the images.

You can click the reload button next to the search box to recheck the images for all your containers for updates, or to recheck a single container's image you can click the image indicator icon for that container.

For more on how this works, have a look at [this knowledge base article](https://portal.portainer.io/knowledge/how-does-the-image-update-notification-icon-work).

To add a new container, click **Add container**.

{% content-ref url="add.md" %}
[add.md](add.md)
{% endcontent-ref %}

Once a container has been created you can inspect it, edit or duplicate it, toggle a container webhook, attach volumes, view logs and statistics, edit ownership, and access its console.

{% content-ref url="view.md" %}
[view.md](view.md)
{% endcontent-ref %}

{% content-ref url="inspect.md" %}
[inspect.md](inspect.md)
{% endcontent-ref %}

{% content-ref url="edit.md" %}
[edit.md](edit.md)
{% endcontent-ref %}

{% content-ref url="advanced.md" %}
[advanced.md](advanced.md)
{% endcontent-ref %}

{% content-ref url="webhooks.md" %}
[webhooks.md](webhooks.md)
{% endcontent-ref %}

{% content-ref url="attach-volume.md" %}
[attach-volume.md](attach-volume.md)
{% endcontent-ref %}

{% content-ref url="logs.md" %}
[logs.md](logs.md)
{% endcontent-ref %}

{% content-ref url="ownership.md" %}
[ownership.md](ownership.md)
{% endcontent-ref %}

{% content-ref url="stats.md" %}
[stats.md](stats.md)
{% endcontent-ref %}

{% content-ref url="console.md" %}
[console.md](console.md)
{% endcontent-ref %}

If you no longer need a container, you can remove it.

{% content-ref url="remove.md" %}
[remove.md](remove.md)
{% endcontent-ref %}






================================================
FILE: user/docker/containers/add.md
================================================
# Add a new container

Select **Containers** from the menu then click **Add container**.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_add_container.gif" alt=""><figcaption></figcaption></figure>

Configure the container settings as required.

## Image configuration section

| Field/Option          | Overview                                                                                                                                   |
| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------ |
| Name                  | Give the container a descriptive name.                                                                                                     |
| Registry              | Select the registry that contains the image that you want to use for your container.                                                       |
| Image                 | Enter the name of the image you want to use.                                                                                               |
| Always pull the image | Toggle on to enforce pulling the image from the registry instead of using the locally cached copy (if you have used the image previously). |

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_image_config.png" alt=""><figcaption></figcaption></figure>

{% hint style="info" %}
When using Docker Hub you can use the **Search** button to search for the image you have entered, and ensure that you have the correct name and tag. Portainer also displays the number of pulls remaining for your Docker Hub account when using an anonymous account.
{% endhint %}

Alternatively you can switch to advanced mode to manually enter registry and image details. This is useful if you want to do a one-off container deployment from a registry that isn't configured within Portainer.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_image_config_simple.png" alt=""><figcaption></figcaption></figure>

## Webhooks

Toggle **Create a container webhook** on to create a [webhook](webhooks.md) for the container. You can send a POST request to this endpoint to automate pulling the most up-to-date image and re-deploy your container.

<figure><img src="../../../.gitbook/assets/2.15-docker_container_webhook.png" alt=""><figcaption></figcaption></figure>

## Network ports configuration section

| Field/Option                                           | Overview                                                                                                 |
| ------------------------------------------------------ | -------------------------------------------------------------------------------------------------------- |
| Publish all exposed network ports to random host ports | Toggle on to allow Portainer to randomly assign ports on the host to the exposed ports in the container. |
| Manual network port publishing                         | Click **publish a new network port** to create manual port mappings for the container.                   |

<figure><img src="../../../.gitbook/assets/2.15-docker_container_network_port_config.png" alt=""><figcaption></figcaption></figure>

## Actions section

| Field/Option | Overview                                                                                                                            |
| ------------ | ----------------------------------------------------------------------------------------------------------------------------------- |
| Auto remove  | Toggle this option on to automatically remove the container once it exits. This is useful if you want to run a container only once. |

<figure><img src="../../../.gitbook/assets/2.15-docker_container_actions.png" alt=""><figcaption></figcaption></figure>

Once complete, set any advanced options (see below) then click **Deploy the container.** If successful your container will be shown in the container list.

## Advanced container settings

Choose from a [range of options](advanced.md) to customize the deployment.

<figure><img src="../../../.gitbook/assets/2.15-containers-advanced.png" alt=""><figcaption></figcaption></figure>




================================================
FILE: user/docker/containers/advanced.md
================================================
# Advanced container settings

When creating or editing a container you can configure a number of additional settings in the **Advanced container settings** section.

<figure><img src="../../../.gitbook/assets/2.15-containers-advanced.png" alt=""><figcaption></figcaption></figure>

## Command & logging

In this section you can configure the command that runs when the container starts as well as configure logging for the container.

| Field/Option | Overview                                                                                                                                                                                                        |
| ------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Command      | Set the command that is run when the container starts. Select `Default` to use the default command provided by the container's image, or select `Override` and provide a command to override the default value. |
| Entrypoint   | Set the entrypoint for the container. Select `Default` to use the default entrypoint provided by the container's image, or select `Override` and provide an entrypoint to override the default value.           |
| Working Dir  | Set the working directory your container should start in (within the container's filesystem).                                                                                                                   |
| User         | Specify the user that the container's command should run as.                                                                                                                                                    |
| Console      | Set the console configuration for your container.                                                                                                                                                               |
| Driver       | Select the logging driver to use for your container. Available options will depend on the logging drivers configured on your Docker host.                                                                       |
| Options      | Set additional options for your logging driver. To add a new option click **add logging driver option** and configure accordingly.                                                                              |

<figure><img src="../../../.gitbook/assets/2.15-containers-advanced-command.png" alt=""><figcaption></figcaption></figure>

## Volumes

Here you can configure volume mappings for your container. You can map to [existing named volumes](../volumes/) or bind mount to locations on your Docker host.

| Field/Option         | Overview                                                                                                                                                            |
| -------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Container path       | Specify where you want to make the volume or bind mount available within the container's filesystem.                                                                |
| Mapping type         | Select `Volume` to map a named volume, or select `Bind` to map a bind mount.                                                                                        |
| Volume               | If using the `Volume` mapping type, select the named volume to mount from the dropdown.                                                                             |
| Host path            | If using the `Bind` mapping type, specify the path on the Docker host you want to bind mount in the container.                                                      |
| Writable / Read-only | Select `Writable` if you want the container to be able to write to the mapping. Select `Read-only` if the container should **not** be able to write to the mapping. |

<figure><img src="../../../.gitbook/assets/2.15-containers-advanced-volumes.png" alt=""><figcaption></figcaption></figure>

## Network

In this section you can configure the network settings for the container.&#x20;

{% hint style="warning" %}
Note that you cannot assign a static IP address to a container that is in Docker's default `bridge` network. This is a Docker limitation rather than Portainer. If you need to specify the IP for your container then you will need to [create a custom network](../networks/add.md) and assign the container to it.
{% endhint %}

| Field/Option         | Overview                                                                                                                                                                        |
| -------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Network              | Select the [network](../networks/) to attach the container to from the dropdown.                                                                                                |
| Hostname             | Specify the hostname for the container.                                                                                                                                         |
| Domain Name          | Specify the domain name for the container.                                                                                                                                      |
| Mac Address          | Specify the MAC address to set on the container.                                                                                                                                |
| IPv4 Address         | Specify the IPv4 address to use for the container. This must be within the range for the chosen network and should not be already assigned to a container.                      |
| IPv6 Address         | Specify the IPv6 address to use for the container. This must be within the range for the chosen network and should not be already assigned to a container.                      |
| Primary DNS Server   | Specify the primary DNS server to use within the container.                                                                                                                     |
| Secondary DNS Server | Specify the secondary DNS server to use within the container.                                                                                                                   |
| Hosts file entries   | Click **add additional entry** to add a new host file entry for the container. Host file values should be formatted as `hostname:address` (for example `database:192.168.1.1`). |

<figure><img src="../../../.gitbook/assets/2.15-containers-advanced-network.png" alt=""><figcaption></figcaption></figure>

## Env

Use this section to add or edit environment variables made available in the container. Click **Add an environment variable** to create a new variable, or edit an existing variable with the fields provided. You can also click **Load variables from .env file** to import an existing .env file with your variables. To remove a variable, click the trash can icon to the right of the variable to remove.

| Field/Option | Overview                                    |
| ------------ | ------------------------------------------- |
| Name         | Set the name for the environment variable.  |
| Value        | Set the value for the environment variable. |

<figure><img src="../../../.gitbook/assets/2.15-containers-advanced-env.png" alt=""><figcaption></figcaption></figure>

If you want to add multiple variables at once, click on **Advanced mode** to switch to an editor view where you can paste a block of variables and values.

## Labels

You can set labels on your container using this section. Click add label to add a new label, or edit an existing label using the fields provided. To remove a label, click the trash can icon to the right of the label to remove.

| Field/Option | Overview                     |
| ------------ | ---------------------------- |
| Name         | Set the name for the label.  |
| Value        | Set the value for the label. |

<figure><img src="../../../.gitbook/assets/2.15-containers-advanced-labels.png" alt=""><figcaption></figcaption></figure>

## Restart policy

Use this section to configure the restart policy for your container. Possible options are:

* **Never**: Do not automatically restart the container when it exits. This is the default.
* **Always**: Always restart the container regardless of the exit status. When you specify always, Docker will try to restart the container indefinitely. The container will also always start on Docker startup, regardless of the current state of the container.
* **On failure**: Restart only if the container exits with a non-zero exit status.
* **Unless stopped**: Always restart the container regardless of the exit status, including on Docker startup, except if the container was put into a stopped state before Docker was stopped.

<figure><img src="../../../.gitbook/assets/2.15-containers-advanced-restart.png" alt=""><figcaption></figcaption></figure>

## Runtime & Resources

This section lets you configure runtime options for your container, add or configure GPUs for use within the container, and specify resource limitations on the container.

### Runtime

Here you can configure runtime options for the container.

| Field/Option       | Overview                                                                                                                                                                                                                                                           |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Privileged mode    | Enable this option to run the container in [privileged mode](https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities).                                                                                                              |
| Init               | Enable this option to tell Docker that an init process should be used as PID 1 in the container.                                                                                                                                                                   |
| Type               | Select the runtime type to use to start the container. Options will depend on available runtimes on your Docker host.                                                                                                                                              |
| Devices            | Use this option to make devices on your Docker host available within the container. Click **add device** to add a new device, and define the **host** path for the device and the **container** path for where you want the device to appear within the container. |
| Sysctls            | Use this option to specify sysctls to make available within the container. Click **add sysctl** to add a new sysctl, and set the **name** and **value** for your sysctl as required.                                                                               |
| Shared memory size | Specify the size (in MB) of the shared memory device (`/dev/shm`) for the container.                                                                                                                                                                               |

<figure><img src="../../../.gitbook/assets/2.20-containers-advanced-runtime.png" alt=""><figcaption></figcaption></figure>

### GPU

Here you can enable GPU access for the container and configure the GPU settings as required.

{% hint style="info" %}
GPU support is currently only available on Docker Standalone environments, and only supports NVIDIA GPUs.
{% endhint %}

| Field/Option | Overview                                                                                                                                                            |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Enable GPU   | Toggle this option on to enable GPU access for the container.                                                                                                       |
| GPU selector | Select the GPU(s) to make available to the container, or choose `Use All GPUs` to provide access to all the GPUs on the Docker host.                                |
| Capabilities | Select the capabilities you want to use with the container. Portainer preselects `compute` and `utility` as they are the defaults when not specifying capabilities. |
| Control      | View a generated equivalent of the Docker CLI's `--gpus` option based on your selections above.                                                                     |

<figure><img src="../../../.gitbook/assets/2.20-containers-advanced-gpu.png" alt=""><figcaption></figcaption></figure>

### Resources

Here you can configure resource limits for your container. You can use the sliders to set the value or enter a value in the fields.

| Field/Option            | Overview                                                                                                                                                      |
| ----------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Memory reservation (MB) | Specify the amount of memory (in MB) to reserve for the container.                                                                                            |
| Memory limit (MB)       | Specify the maximum amount of memory (in MB) the container is allowed to use.                                                                                 |
| Maximum CPU usage       | Specify the maximum amount of CPU the container is allowed to use. This is specified based on the number of processing threads available on your Docker host. |

<figure><img src="../../../.gitbook/assets/2.15-containers-advanced-resources.png" alt=""><figcaption></figcaption></figure>

## Capabilities

In this section you can configure the individual capabilities for your container. For more information refer to the [Docker documentation](https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities).

<figure><img src="../../../.gitbook/assets/2.15-containers-advanced-capabilities.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/containers/attach-volume.md
================================================
# Attach a volume to a container

{% hint style="danger" %}
This article explains how to attach a new [volume](../volumes/) to a running container. This operation destroys the running container and starts a new one with the volume attached.

**Always back up your data before running this operation.**
{% endhint %}

From the menu select **Containers**, select the container that you want to attach a volume to, then click **Duplicate/Edit**.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_edit.gif" alt=""><figcaption></figcaption></figure>

Scroll down to **Advanced container settings**. Click **Volumes** then click **map additional volume**.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_add_volumes.png" alt=""><figcaption></figcaption></figure>

In the **container** field enter the path. In the **volume** field enter the volume to attach to the container.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_adv_volume_mapping.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Deploy the container**. When the confirmation message appears, click **Replace**.

<figure><img src="../../../.gitbook/assets/2.15-container-edit-confirm.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/containers/console.md
================================================
# Access a container's console

From the menu select **Containers**, select the container then select **Console**.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_console.gif" alt=""><figcaption></figcaption></figure>

Select the command and the user you want to give access to, then click **Connect**.

{% hint style="info" %}
For Alpine Linux containers, you must select the`/bin/ash` command.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_console_execute.png" alt=""><figcaption></figcaption></figure>

If you need to define a command other than those provided, toggle the **Use custom command** option on. Once connected, you can run commands in the console the same as any other Linux system.

<figure><img src="../../../.gitbook/assets/2.20-containers-console-connected.png" alt=""><figcaption></figcaption></figure>

To disconnect from the console session, click the **Disconnect** button.



================================================
FILE: user/docker/containers/edit.md
================================================
# Edit or duplicate a container

{% hint style="warning" %}
Editing a container effectively creates a new container with the updated settings and replaces the old container.
{% endhint %}

## Editing a running container

From the menu select **Containers**, select the container you want to edit then click **Duplicate/Edit**.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_edit.gif" alt=""><figcaption></figcaption></figure>

Make the required changes to the container configuration. When you're finished, click **Deploy the container**. When the confirmation message appears, click **Replace**.

<figure><img src="../../../.gitbook/assets/2.15-container-edit-confirm.png" alt=""><figcaption></figcaption></figure>

If successful, a message will appear confirming that a new container has been created with the new settings, replacing the old container.

## Duplicating a running container

From the menu select **Containers**, select the container you want to duplicate then click **Duplicate/Edit**.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_edit.gif" alt=""><figcaption></figcaption></figure>

Make the required changes to the container configuration, making sure you enter a new container name in order to create a duplicate. When you're finished, click **Deploy the container**.




================================================
FILE: user/docker/containers/inspect.md
================================================
# Inspect a container

View information about any container, such as network settings, volumes and images.

From the menu select **Containers**, select the container then select **Inspect**.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_inspect.gif" alt=""><figcaption></figcaption></figure>

All of the information about the container will display in a tree view. Select any parameter to show more details (if available).

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_inspect.png" alt=""><figcaption></figcaption></figure>

You can also inspect the container in a raw JSON format by clicking **Text**.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_inspect_text.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/containers/logs.md
================================================
# View container logs

From the menu select **Containers**, select the container then select **Logs**.

<figure><img src="../../../.gitbook/assets/2.30-containers-logs.gif" alt=""><figcaption></figcaption></figure>

Here you can see the contents of the Docker logs for your container.&#x20;

<table><thead><tr><th width="241">Field/Option</th><th>Overview</th></tr></thead><tbody><tr><td>Search</td><td>Enter a string to search the log output. You can see the number of results for your search and move through each result with the up and down arrows.</td></tr><tr><td>Filter search results</td><td>When enabled, display only the log lines that contain your search string.</td></tr><tr><td>Copy</td><td>Click this button to copy the currently displayed log lines to your clipboard.</td></tr><tr><td>Download logs</td><td>Click this button to download your log.</td></tr></tbody></table>

<figure><img src="../../../.gitbook/assets/2.17-containers-logs-search.png" alt=""><figcaption></figcaption></figure>

You can also set various options for how the logs are displayed:

<table><thead><tr><th width="244">Field/Option</th><th>Overview</th></tr></thead><tbody><tr><td>Date picker</td><td>Select the time period from which to retrieve the logs.</td></tr><tr><td>Lines</td><td>Limit the number of lines per log file (the default is 1000).</td></tr><tr><td>Line numbers</td><td>When enabled, display line numbers for each log line.</td></tr><tr><td>Timestamp</td><td>When enabled, display a timestamp before each log line.</td></tr><tr><td>Wrap lines</td><td>When enabled, lines longer than the screen width will be wrapped onto the next line.</td></tr><tr><td>Auto refresh</td><td>Enable this option to automatically refresh the log view. When off, you can click the refresh icon to the right of the button to manually refresh the view.</td></tr><tr><td>Full screen</td><td>Click the full screen icon to expand the log display to fill your screen.</td></tr></tbody></table>

<figure><img src="../../../.gitbook/assets/2.30-containers-logs-options.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/containers/ownership.md
================================================
# Change container ownership

Portainer allows you to limit container management to specific teams or users.

From the menu select **Containers** then select the container whose ownership you want to change.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_details.gif" alt=""><figcaption></figcaption></figure>

Under the **Access control** section tick the **Change ownership** checkbox then select the new ownership type, using the table below as a guide.

| Ownership Type | Overview                                                                                                    |
| -------------- | ----------------------------------------------------------------------------------------------------------- |
| Administrators | Only Portainer administrators can manage the container.                                                     |
| Restricted     | Only teams or users you specify can manage the container.                                                   |
| Public         | Anyone who has [access to the environment](../../../admin/environments/access.md) can manage the container. |

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_access_control.png" alt=""><figcaption></figcaption></figure>

When you've made your selection, click **Update ownership**. When the confirmation message appears, click **Change ownership**.

<figure><img src="../../../.gitbook/assets/2.15-container-ownership-confirm.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/containers/remove.md
================================================
# Remove a container

From the menu select **Containers**, tick the checkbox next to the container you want to remove then click **Remove**.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_remove.gif" alt=""><figcaption></figcaption></figure>

When the confirmation message appears, opt whether or not to automatically remove non-persistent volumes then click **Remove**.

<figure><img src="../../../.gitbook/assets/2.15-container-remove-confirm.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/containers/stats.md
================================================
# View container statistics

From the menu select **Containers**, select the container then select **Stats**.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_stats.gif" alt=""><figcaption></figcaption></figure>

The information available includes:

* Memory usage.
* CPU usage.
* Network usage (RX and TX).
* I/O usage.
* Processes running in the container

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_stats_usage.png" alt=""><figcaption></figcaption></figure>

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container-stats-proc.png" alt=""><figcaption></figcaption></figure>

{% hint style="info" %}
You can change the refresh rate at any time.
{% endhint %}



================================================
FILE: user/docker/containers/view.md
================================================
# View a container's details

From the menu select **Containers**, then select the container you want to view.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_details.gif" alt=""><figcaption></figcaption></figure>

Here you can view the container's status and details, including port configurations, environment variables, labels, attached volumes and networks, and more. You also have a number of actions available, including starting, stopping and removing the container.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_details_actions.png" alt=""><figcaption></figcaption></figure>

You can also toggle the container [webhook](webhooks.md), view the [container logs](logs.md), [inspect](inspect.md) the container's configuration, view container [stats](stats.md), access the [console](console.md), and (if the container is running in interactive mode) attach to the running container.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_status.png" alt=""><figcaption></figcaption></figure>

You can create an image from a deployed container to use when creating other containers.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_create_image.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/containers/webhooks.md
================================================
# Webhooks

A webhook is a POST request sent to a URL that you define in Docker Hub or another registry. Use webhooks to trigger an action in response to an event such as a repository push.

{% hint style="info" %}
This functionality is only available in [Portainer Business Edition](https://www.portainer.io/business-upsell?from=container-webhook).
{% endhint %}

{% hint style="info" %}
Webhooks are only available on non-Edge environments (environments running Portainer Server or Portainer Agent, not the Portainer Edge Agent). This is because the tunnel to the Portainer Edge Agent is only opened on-demand, and therefore would mean there is no way to expose a webhook permanently.
{% endhint %}

## Enabling a container webhook

From the menu select **Containers** then select the container that you want to configure the webhook for.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_details.gif" alt=""><figcaption></figcaption></figure>

In the **Container details** screen toggle the **Container webhook** option on. When the URL appears, click **Copy link**. This URL will be used to configure the webhook in your chosen registry.

<figure><img src="../../../.gitbook/assets/2.15-docker_containers_container_webhook.png" alt=""><figcaption></figcaption></figure>

This example shows how to trigger the webhook using `redeploy`:

```
<form action="https://portainer:9443/api/webhooks/638e6967-ef77-4906-8af8-236800621360" method="post">
  Redeploy with latest image of same tag <input type="submit" />
</form>
```

This example shows how to trigger the webhook to update the container to use a different image tag:

```
<form action="https://portainer:9443/api/webhooks/638e6967-ef77-4906-8af8-236800621360?tag=latest" method="post">
  Update container image with different tag <input type="submit" />
</form>
```

## Configuring the webhook in Docker Hub

To finish the configuration, refer to [Docker's own documentation](https://docs.docker.com/docker-hub/webhooks/).



================================================
FILE: user/docker/host/README.md
================================================
# Host

{% hint style="info" %}
The **Host** menu is only available to Docker Standalone and Podman environments.
{% endhint %}

The **Host** section provides an overview of your environment. You can view information about your environment as well as configure environment-specific settings.

{% content-ref url="details.md" %}
[details.md](details.md)
{% endcontent-ref %}

{% content-ref url="setup.md" %}
[setup.md](setup.md)
{% endcontent-ref %}

{% content-ref url="registries.md" %}
[registries.md](registries.md)
{% endcontent-ref %}



================================================
FILE: user/docker/host/details.md
================================================
# Details

This page provides information about the Docker host for the selected environment. The page is split into the following sections: Host Details, Engine Details, and (if enabled) PCI Devices and Physical Disks.

{% hint style="info" %}
This page is only available on Docker Standalone environments.
{% endhint %}

## Host Details

This section describes the host's basic configuration, including the hostname, OS information, kernel version, total CPU and memory. If the environment has the Portainer Agent installed, [host management features](setup.md#enable-host-management-features) are enabled, and a `/host` mount has been configured, you can also browse the host file system from here.&#x20;

<figure><img src="../../../.gitbook/assets/2.15-docker-host-details.png" alt=""><figcaption></figcaption></figure>

## Engine Details

Learn more about the Docker or Podman engine running on your environment, including the Docker/Podman version, the root directory, storage and logging drivers and available volume and network plugins.

<figure><img src="../../../.gitbook/assets/2.15-docker-host-engine.png" alt=""><figcaption></figcaption></figure>

## PCI Devices and Physical Disks

These sections list the available PCI devices and physical disks on the host.

{% hint style="info" %}
These sections are only visible when [host management features](setup.md#enable-host-management-features) are enabled for the environment.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-docker-host-pci.png" alt=""><figcaption></figcaption></figure>




================================================
FILE: user/docker/host/registries.md
================================================
# Registries

**Registries** lets you manage access to each of the registries that are currently available.

{% hint style="warning" %}
Registry access assigned here only applies to the selected environment. It is not global.
{% endhint %}

## Adding a new registry

From the menu select **Host**, select **Registries** then click **Add registry**. When the global registries page appears, follow [these instructions](../../../admin/registries/add/).

<figure><img src="../../../.gitbook/assets/2.15-host-registries-add.gif" alt=""><figcaption></figcaption></figure>

## Managing access

To configure access to a registry, from the menu select **Host** then select **Registries**.

<figure><img src="../../../.gitbook/assets/2.15-docker_hosts_registries.gif" alt=""><figcaption></figcaption></figure>

Find the registry you want to manage then select **Manage access**.&#x20;

<figure><img src="../../../.gitbook/assets/2.15-docker_hosts_registries_manage_access.png" alt=""><figcaption></figcaption></figure>

From the dropdown, select the users or teams that you would like to have access, then click **Create access**.

<figure><img src="../../../.gitbook/assets/2.15-docker_hosts_registries_access.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/host/setup.md
================================================
# Setup

{% hint style="info" %}
The **Host Setup** section is only available to Docker Standalone environments.
{% endhint %}

Under **Setup**, you can make changes to your environment, enabling and disabling features and security settings.

## Host and Filesystem

For environments running the Portainer Agent, this section is where you configure how Portainer interacts with elements of the host.

{% hint style="danger" %}
For security, these features are disabled by default. Be sure that you understand their impact before enabling them.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.22.0-host-setup-filesystem.png" alt=""><figcaption></figcaption></figure>

### Enable host management features

Enabling host management features allows you to see the available devices and storage on the physical node as well as browse the node's filesystem. The environment must be [running the Portainer Agent](../../../start/agent.md) to use this functionality, and the root of the host must be bind-mounted to`/host` in the agent deployment:

```
-v /:/host
```

For example, starting the Portainer Agent on Docker on Linux with the host filesystem mounted at `/host`:

```
docker run -d -p 9001:9001 --name portainer_agent --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker/volumes:/var/lib/docker/volumes -v /:/host portainer/agent:2.22.0
```

### Enable volume management for non-administrators

Enabling this feature allows non-administrator users to manage volumes on an environment. If this is disabled, users below administrator level have read-only access to volumes.

## Change Window Settings

This setting allows you to specify a window within which [GitOps updates](../stacks/add.md#gitops-updates) to your applications can be applied.

{% hint style="warning" %}
If this setting is enabled and an update is made to an application outside of this window, it will not be applied.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-cluster-setup-changewindow.png" alt=""><figcaption></figcaption></figure>

## Docker Security Settings

This section allows you to toggle assorted Docker-related security settings for the environment.

<figure><img src="../../../.gitbook/assets/2.15-docker_hosts_security_settings.png" alt=""><figcaption></figcaption></figure>

| Option                                                | Overview                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ----------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Disable bind mounts for non-administrators            | Prevents non-admin users within Portainer from using bind mounts when creating containers and/or services/stacks. When toggled on, the option to attach to a host file system path is removed.                                                                                                                                                                                                                                                                                                                                                              |
| Disable privileged mode for non-administrators        | Prevents non-admin users from elevating the privilege of a container to bypass SELinux/AppArmor. When toggled on, the option to select **Privileged** mode when [adding a container](../containers/add.md) is removed.                                                                                                                                                                                                                                                                                                                                      |
| Disable the use of host PID 1 for non-administrators  | Prevents non-admin users from requesting that a deployed container operates as the host PID. This is a security risk if used by a non-trustworthy authorized user because when they operate as PID1, they are in effect able to run any command in the container console as root on the host.                                                                                                                                                                                                                                                               |
| Disable the use of Stacks for non-administrators      | This is a 'sledgehammer' approach to removing any possibility for non-admin users within Portainer to find and use weaknesses in the Docker architecture. Whilst Portainer has the ability to disable some of the more common exploits, we cannot possibly block them all because there are any number of capabilities that could be added to a container to attempt to gain access to the host. This feature simply allows an admin to disable all possible entry points.                                                                                  |
| Disable device mappings for non-administrators        | Blocks users from mapping host devices into containers. Whilst the ability to map devices is generally used for good (e.g. mapping a GPU into a container), it can equally be used by non-trustworthy authorized users to map a physical storage device into a container. It is possible to mount `/dev/sda1` into a container, and then from a console of that container, the user would have complete access to the sda1 device without restriction. By toggling this on, Portainer blocks the ability for non-admins to map ANY devices into containers. |
| Disable container capabilities for non-administrators | Toggle on to hide the **Container capabilities** tab for non-administrators when they are [adding a container](../containers/add.md).                                                                                                                                                                                                                                                                                                                                                                                                                       |
| Disable sysctl settings for non-administrators        | Toggle on to stop non-admin users from using sysctl options, preventing them from recreating, duplicating or editing containers.                                                                                                                                                                                                                                                                                                                                                                                                                            |

## Other

This section contains other assorted environment-specific settings.

<figure><img src="../../../.gitbook/assets/2.18-host-setup-other.png" alt=""><figcaption></figcaption></figure>

| Option                                                                    | Overview                                                                                                                                                                                                                        |
| ------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Show GPU in the UI                                                        | Toggle on to enable GPU assignments in the Portainer UI. This adds additional processing to the container and stack listing pages, so if you are not using GPUs on your environment we recommend toggling this off.             |
| Add GPU                                                                   | <p>When <strong>Show GPU in the UI</strong> is toggled on, click Add GPU to add GPUs to your environment for use by your containers.<br>To add a GPU, provide a name for the GPU and an index or UUID to reference the GPU.</p> |
| Show an image(s) up to date indicator for Stacks, Services and Containers | <p>Toggle on to enable the <a href="../containers/">new image indicator</a> feature for this environment. Toggle off to disable the feature.<br><br>This feature is only available in Portainer Business Edition.</p>           |



================================================
FILE: user/docker/images/README.md
================================================
# Images

Images are what is used to build containers. Each image defines the pieces required to build and configure a container and can be reused many times. The **Images** section in Portainer lets you interact with the images in an environment.

<figure><img src="../../../.gitbook/assets/2.15-images-splash.png" alt=""><figcaption></figcaption></figure>

You can pull images from Docker Hub or any other [registry](../../../admin/registries/add/):

{% content-ref url="pull.md" %}
[pull.md](pull.md)
{% endcontent-ref %}

You can also view a list of the images that are currently available in an environment, including their IDs, usage states, tags, sizes and creation dates. There are many other options available:

{% content-ref url="build.md" %}
[build.md](build.md)
{% endcontent-ref %}

{% content-ref url="import.md" %}
[import.md](import.md)
{% endcontent-ref %}

{% content-ref url="export.md" %}
[export.md](export.md)
{% endcontent-ref %}




================================================
FILE: user/docker/images/build.md
================================================
# Build a new image

There are three ways you can build new images.

{% hint style="info" %}
On a multi-node environment, the built image will only be available on the node you select in the **Deployment** section. To make the image available to all nodes, consider [adding a registry](../../../admin/registries/add/) to Portainer.
{% endhint %}

{% hint style="warning" %}
When building an image with Portainer, you are unable to use `ADD` or `COPY` commands referencing files on the host. We recommend using `wget` or similar to retrieve files from a HTTP/S URL instead.
{% endhint %}

## Method 1: Using the Portainer web editor

From the menu select **Images** then click **Build a new image**.

<figure><img src="../../../.gitbook/assets/2.15-docker_images_build_image.gif" alt=""><figcaption></figcaption></figure>

Next, give the image a descriptive name (you can enter multiple names), select the **Web editor** option under **Build method**, then write your Dockerfile in the web editor.

{% hint style="info" %}
You can search within the web editor at any time by pressing `Ctrl-F` (or `Cmd-F` on Mac).
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-docker_images_build_web_editor.png" alt=""><figcaption></figcaption></figure>

Optionally, you can upload one or more local files to be included in an image by clicking **Select files** and selecting the files to include. You can then reference them in your Dockerfile.

<figure><img src="../../../.gitbook/assets/2.16-images-build-upload.png" alt=""><figcaption></figcaption></figure>

Select the node you want to save the image on (if on a multi-node environment) then click **Build the image**.

<figure><img src="../../../.gitbook/assets/2.15-docker_images_build_deployment.png" alt=""><figcaption></figcaption></figure>

When the build is finished, select the **Output** tab to view the build history and the result.

## Method 2: Uploading a Dockerfile

If you have an existing Dockerfile, you can upload it to Portainer and use it to build the image.

From the menu select **Images** then click **Build a new image**.

<figure><img src="../../../.gitbook/assets/2.15-docker_images_build_image_upload.gif" alt=""><figcaption></figcaption></figure>

Next, give the image a descriptive name (you can enter multiple names), select the **Upload** option under **Build method**, then browse to and upload the Dockerfile.

<figure><img src="../../../.gitbook/assets/2.15-docker_images_build_upload.png" alt=""><figcaption></figcaption></figure>

Scroll down and select the node you want to save the image on (if on a multi-node environment) then click **Build the image**.

<figure><img src="../../../.gitbook/assets/2.15-docker_images_build_deployment.png" alt=""><figcaption></figcaption></figure>

When the build is finished, select the **Output** tab to view the build history and the result.

## Method 3: Providing a Dockerfile from a URL

If the Dockerfile is hosted on the Internet (either in a tarball or a public GitHub repository), you can download it directly to Portainer via its URL.

From the menu select **Images** then click **Build a new image**.

<figure><img src="../../../.gitbook/assets/2.15-docker_images_build_image_URL.gif" alt=""><figcaption></figcaption></figure>

Next, give the image a descriptive name (you can enter multiple names), select the **Upload** option under **Build method**, then enter the **URL** of the file and the **Dockerfile path** within the tarball or repository.

<figure><img src="../../../.gitbook/assets/2.15-docker_images_build_URL.png" alt=""><figcaption></figcaption></figure>

Scroll down and select the node you want to save the image on (if on a multi-node environment) click **Build the image**.

<figure><img src="../../../.gitbook/assets/2.15-docker_images_build_deployment.png" alt=""><figcaption></figcaption></figure>

When the build is finished, select the **Output** tab to view the build history and the result.



================================================
FILE: user/docker/images/export.md
================================================
# Export an image

You can export any Docker image stored on any node. This is useful when you need to move a container from one host to another, or simply make a backup of the images.

{% hint style="warning" %}
If you export a container to a tar file, the volumes won't get exported with it. You will need to save the data from those volumes using a different method.
{% endhint %}

From the menu select **Images**, select the image you want to export then click **Export this image**.

<figure><img src="../../../.gitbook/assets/2.15-docker_images_build_image_export.gif" alt=""><figcaption></figcaption></figure>

When the warning message appears, click **Continue**.

<figure><img src="../../../.gitbook/assets/2.15-images-export-confirm.png" alt=""><figcaption></figcaption></figure>

When the image has downloaded, a success message will appear, and your browser should automatically download the resulting tar file.\



================================================
FILE: user/docker/images/import.md
================================================
# Import an image

You can import images from other Portainer instances, the Docker CLI or the Docker Swarm CLI.

From the menu select **Images** then click **Import**.

<figure><img src="../../../.gitbook/assets/2.15-docker_images_build_image_import.gif" alt=""><figcaption></figcaption></figure>

Click **Select file** to browse for the image file to upload. Portainer supports `.tar`, `.tar.gz`, `.tar.bz2` and `.tar.xz` files. If you are on a multi-node environment, select the node where you wish to save the image.

{% hint style="info" %}
On a multi-node environment, the image you import will only be available on the node selected under **Deployment**. If you want to make the image available to all nodes, consider [adding a registry](../../../admin/registries/add/) to Portainer.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-docker_images_upload_file.png" alt=""><figcaption></figcaption></figure>

When importing an image you can also select to tag the image using a registry you have preconfigured in Portainer. Select the **Registry** from the dropdown and enter the image name and tag.&#x20;

<figure><img src="../../../.gitbook/assets/2.15-docker_images_upload_file_tag_image.png" alt=""><figcaption></figcaption></figure>

If you wish to tag the image with a registry that is not configured within Portainer, click **Advanced mode** and enter the registry, port, image and tag as required.

{% hint style="info" %}
If you want to tag the image locally rather than in a registry, use **Advanced mode** and simply specify the image name and tag, without a registry.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-docker_images_import_simple.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Upload** to import your image.




================================================
FILE: user/docker/images/pull.md
================================================
# Pull an image

You can pull images from any registry that has been [added to Portainer](../../../admin/registries/), or using advanced mode, from a custom external registry.

{% hint style="info" %}
On a multi-node environment, the pulled image will only be available on the node you select in the **Deployment** section. To make the image available to all nodes, consider [adding a registry](../../../admin/registries/add/) to Portainer.
{% endhint %}

## Method 1: Pulling images in simple mode

This method lets you pull images from Docker Hub or from another registry that you have connected with before.

From the menu select **Images**. Select the registry to use then enter the name of the image. On a multi-node environment, select the node to deploy to.

<figure><img src="../../../.gitbook/assets/2.15-docker_images_pull_images (1).png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Pull the image**.

## Method 2: Pulling images in advanced mode

Using advanced mode, you can define a custom registry URL, port and image. This is ideal if you run your own private registry but don't want to add it to the [registries](../../../admin/registries/) list in Portainer.

From the menu select **Images** then select **Advanced mode**. Next, enter the registry, port and image in the **Image** box. On a multi-node environment, select the node to deploy to.

<figure><img src="../../../.gitbook/assets/2.15-docker_images_pull_image_simple.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Pull the image**.



================================================
FILE: user/docker/networks/README.md
================================================
# Networks

Portainer lets you add, remove and manage networks in your environment.

<figure><img src="../../../.gitbook/assets/2.20-networks-list.png" alt=""><figcaption></figcaption></figure>

{% content-ref url="add.md" %}
[add.md](add.md)
{% endcontent-ref %}

{% content-ref url="remove.md" %}
[remove.md](remove.md)
{% endcontent-ref %}

## Supported network types

Portainer supports these types of networks:

### bridge

If you don’t specify a driver, this type of network will be created by default. Bridge networks are normally used when your applications run in standalone containers that need to communicate with each other.

### macvlan

macvlan networks allow you to assign a MAC address to a container, making it appear as a physical device on your network. The Docker daemon routes traffic to containers based on their MAC addresses. Using the macvlan driver is sometimes the best choice when dealing with legacy applications that expect to be directly connected to the physical network, rather than routed through the Docker host’s network stack.

### ipvlan

Similar to macvlan, the key difference being that the endpoints have the same MAC address. ipvlan supports L2 and L3 modes. In ipvlan L2 mode, each endpoint gets the same MAC address but different IP addresses. In ipvlan L3 mode, packets are routed between endpoints, giving better scalability.

### overlay

overlay networks connect multiple Docker daemons together and enable swarm services to communicate with each other. You can also use overlay networks to facilitate communication between a swarm service and a standalone container, or between two standalone containers on different Docker daemons.



================================================
FILE: user/docker/networks/add.md
================================================
# Add a new network

From the menu select **Networks** then click **Add network**.

<figure><img src="../../../.gitbook/assets/2.20-networks-add.gif" alt=""><figcaption></figcaption></figure>

Define the new network, using the table below as a guide.

| Field/Option                       | Overview                                                                                                                                                                                                                                                  |
| ---------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                               | Give the network a descriptive name.                                                                                                                                                                                                                      |
| Driver                             | Define the [type of network](./#supported-network-types) you will use.                                                                                                                                                                                    |
| Driver options                     | Set in place any options related to your network driver, if required.                                                                                                                                                                                     |
| IPv4 Network configuration         | <p>Define IPv4 range, subnet, gateway and exclude IP. If no information is entered here, Docker will automatically assign an IPv4 range.<br>If you need to exclude IPs from the range, click <strong>Add excluded IP</strong> and complete the field.</p> |
| IPv6 Network configuration         | <p>Define IPv6 range, subnet, gateway and exclude IP. If no information is entered here, Docker will automatically assign an IPv6 range.<br>If you need to exclude IPs from the range, click <strong>Add excluded IP</strong> and complete the field.</p> |
| Labels                             | Click **Add label** and complete the name and value fields to specify a label for the network.                                                                                                                                                            |
| Isolated network                   | Toggle this option on to isolate any containers created in this network to this network only, with no inbound or outbound connectivity.                                                                                                                   |
| Enable manual container attachment | Toggle this option on to allow users to attach the network to running containers.                                                                                                                                                                         |
| Deployment                         | On multi-node clusters, select the node where the network will be created.                                                                                                                                                                                |

<figure><img src="../../../.gitbook/assets/2.20-networks-add-details.png" alt=""><figcaption></figcaption></figure>

When you're finished, click **Create the network**.



================================================
FILE: user/docker/networks/remove.md
================================================
# Remove a network

{% hint style="warning" %}
You must detach all containers from a network before you can remove it.
{% endhint %}

From the menu select **Networks**, tick the checkbox next to the network you want to remove then click **Remove**.

<figure><img src="../../../.gitbook/assets/2.20-networks-remove.gif" alt=""><figcaption></figcaption></figure>

To confirm the removal, click **Remove** in the dialog box.



================================================
FILE: user/docker/secrets/README.md
================================================
# Secrets

{% hint style="info" %}
The Secrets menu is only available to Docker Swarm environments.
{% endhint %}

A secret is a blob of data, such as a password, SSH private key, SSL certificate, or another piece of data that should not be transmitted over a network, stored unencrypted in a Dockerfile, or stored in your application’s source code. In Docker 1.13 and later, you can use Docker Secrets to centrally manage this data and securely transmit it only to those containers that need access to it.

<figure><img src="../../../.gitbook/assets/2.15-docker_secrets_secrets_list.png" alt=""><figcaption></figcaption></figure>

Secrets are encrypted during transit and at rest in Docker Swarm. A given secret is only accessible to those services which have been granted explicit access to it, and only while those service tasks are running.

You can use secrets to manage any sensitive data that a container needs at runtime, but you don’t want to store in the image or in source control, such as:

* Usernames and passwords.
* TLS certificates and keys.
* SSH keys.
* Other important data such as the name of a database or internal server.
* Generic strings or binary content (up to 500Kb in size).

For less sensitive data or larger content, see [configs](../configs/).

In Portainer you can add and remove secrets for use in deployments.

{% content-ref url="add.md" %}
[add.md](add.md)
{% endcontent-ref %}

{% content-ref url="remove.md" %}
[remove.md](remove.md)
{% endcontent-ref %}






================================================
FILE: user/docker/secrets/add.md
================================================
# Add a new secret

From the menu select **Secrets** then click **Add secret**.

<figure><img src="../../../.gitbook/assets/2.15-docker_secrets_secret_add.gif" alt=""><figcaption></figcaption></figure>

Next, give the secret a descriptive name and write a definition of the secret in the **Secret** field. Toggle **Encode secret** on if you want to encode the secret (useful when you use a plain-text password).

<figure><img src="../../../.gitbook/assets/2.15-docker_secrets_secret_create.png" alt=""><figcaption></figcaption></figure>

&#x20;When you're finished, click **Create the secret**.



================================================
FILE: user/docker/secrets/remove.md
================================================
# Remove a secret

From the menu select **Secrets**, tick the checkbox next to the secret you want remove then click **Remove**.

<figure><img src="../../../.gitbook/assets/2.15-docker_secrets_secret_remove.gif" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/services/README.md
================================================
# Services

{% hint style="info" %}
The **Services** menu is only available to Docker Swarm endpoints.
{% endhint %}

A service consists of an image definition and container configuration as well as instructions on how those containers will be deployed across a Swarm cluster.

<figure><img src="../../../.gitbook/assets/2.20-services-list.png" alt=""><figcaption></figcaption></figure>

When the [new image indicator](../swarm/setup.md#other) feature is enabled, the **Images up to date** column indicates whether the local images in the service are up to date, with a green tick indicating they are up to date and an orange cross indicating that there is a newer version of an image available at the remote registry. A grey hyphen indicates Portainer was unable to determine whether there is an update available for the images.

You can click the **Reload image indicators** button to recheck the images for all your services for updates, or to recheck a single service's images you can click the image indicator icon for that service.

For more on how this works, have a look at [this knowledge base article](https://portal.portainer.io/knowledge/how-does-the-image-update-notification-icon-work).

{% content-ref url="add.md" %}
[add.md](add.md)
{% endcontent-ref %}

{% content-ref url="configure.md" %}
[configure.md](configure.md)
{% endcontent-ref %}

Once a service has been created you can scale it to meet your needs, as well as view individual task status and logs.

{% content-ref url="scale.md" %}
[scale.md](scale.md)
{% endcontent-ref %}

{% content-ref url="tasks.md" %}
[tasks.md](tasks.md)
{% endcontent-ref %}

{% content-ref url="logs.md" %}
[logs.md](logs.md)
{% endcontent-ref %}

If you need to undo some changes to a service, you can roll it back.

{% content-ref url="rollback.md" %}
[rollback.md](rollback.md)
{% endcontent-ref %}

You can also configure webhooks for your services.

{% content-ref url="webhooks.md" %}
[webhooks.md](webhooks.md)
{% endcontent-ref %}




================================================
FILE: user/docker/services/add.md
================================================
# Add a new service

From the menu click **Services** then click **Add service**.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_add_service.gif" alt=""><figcaption></figcaption></figure>

Complete the fields, using the table below as a guide.

| Field/Option             | Overview                                                                                                                                                                             |
| ------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Name                     | Give the service a descriptive name.                                                                                                                                                 |
| Registry                 | Select the registry that contains the image you wish to use for the service.                                                                                                         |
| Image                    | Enter the name of the image. If you're using Docker Hub you can also search for images from here.                                                                                    |
| Scheduling mode          | Select either to replicate the service on the same host or deploy it globally with one container on each host.                                                                       |
| Replicas                 | Set the number of replicas (only if the scheduling mode is set to **Replicated**).                                                                                                   |
| Port mapping             | Define the ports to expose on the new service.                                                                                                                                       |
| Create a service webhook | Toggle on to create a [webhook](webhooks.md) for the service. You can send a POST request to this endpoint to automate pulling the most up-to-date image and re-deploy your service. |

<figure><img src="../../../.gitbook/assets/2.15-docker_service_create_service.png" alt=""><figcaption></figcaption></figure>

You can also configure any advanced options for the service in the bottom section.

When you're finished click **Create the service**.



================================================
FILE: user/docker/services/configure.md
================================================
# Configure service options

From the menu select **Services** then select the service you want to configure.&#x20;

<figure><img src="../../../.gitbook/assets/2.15-docker_services_configure.gif" alt=""><figcaption></figcaption></figure>

## Service details

In this section you can:

* View a summary of the details about the service.
* Configure the number of replicas.
* Toggle the [service webhook](webhooks.md) on or off.
* View the [service logs](logs.md).
* Update, [roll back](rollback.md) or delete the service.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_details (1).png" alt=""><figcaption></figcaption></figure>

## Container specification configuration options

### Change container image

Here you can replace the container image with a different image. Select the registry, enter the image name, then click **Apply changes**.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_change_container_image.png" alt=""><figcaption></figcaption></figure>

### Environment variables

It's best to set environment variables when you [create a container](../containers/add.md) and before deployment. You can still set or edit these variables after deployment if you wish.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_env_var.png" alt=""><figcaption></figcaption></figure>

### Container labels

Labels give you a way to record information about a container, such as the way it's configured. Labels can also be used by Portainer to [hide containers from the interface](../../../admin/settings/#hidden-containers).

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_container_labels.png" alt=""><figcaption></figcaption></figure>

### Mounts

You have the option to either mount or bind volumes in Portainer, and you can also make them read only. To add a mount, first select either **Volume** or **Bind** from the **Type** dropdown.

#### For volume mounts:

Select the volume from the **Source** dropdown, enter the container path in the **Target** field tick **Read only** if required then click **Apply changes**.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_mounts_volume.png" alt=""><figcaption></figcaption></figure>

#### For bind mounts:

Enter the source path in the **Source** field, enter the container path in the **Target** field, tick **Read only** if required then click **Apply changes**.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_mounts_bind.png" alt=""><figcaption></figcaption></figure>

## Networks & ports configuration options

### Networks

You can define one or more networks for a service either before or after deployment. Simply select the network from the dropdown then click **Apply changes**.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_networks.png" alt=""><figcaption></figcaption></figure>

### Published ports

Use this setting to publish ports so they can access a container from outside of the host. You can either add new ports or update existing ports.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_published_ports.png" alt=""><figcaption></figcaption></figure>

### Hosts file entries

Lets you manually specify a hostname or URL and associate the URL to an internal or external IP address.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_host_entries.png" alt=""><figcaption></figcaption></figure>

## Service specification settings

### Resource limits and reservations

Sets limits on resource utilization, such as memory, CPU reservation and CPU limit.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_resource_limits.png" alt=""><figcaption></figcaption></figure>

### Placement constraints

Use placement constraints to control which nodes a service can be assigned to.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_placement_constraint.png" alt=""><figcaption></figcaption></figure>

### Placement preferences

While placement constraints limit the nodes a service can run on, placement preferences attempt to place tasks on appropriate nodes in an algorithmic way (by default they are spread evenly).

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_placement_pref.png" alt=""><figcaption></figcaption></figure>

### Restart policy

Docker's restart policies ensure that linked containers are restarted in the correct order, and control the conditions under which they are restarted:

* **Any**: Restart the container under any conditions (restarted host or Docker daemon).
* **On Failure**: Restart the container if it exits due to an error which manifests as a non-zero exit code.
* **None**: Do not automatically restart the container.

You can also adjust the restart delay, maximum attempts and restart window.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_restart_policy.png" alt=""><figcaption></figcaption></figure>

### Update configuration

Updates a service according to the parameters you specify. The parameters specified here are the same as `docker service create` (see [Docker's own documentation](https://docs.docker.com/engine/reference/commandline/service_create/) for more information).

Normally, updating a service will only cause the service’s tasks to be replaced with new ones if a change to the service requires recreating the tasks for it to take effect.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_update_config.png" alt=""><figcaption></figcaption></figure>

### Logging driver

Docker includes logging mechanisms called _logging drivers_ that get information from the containers and services you're running. Each Docker daemon has a default logging driver which each container will use, unless you configure them to use a different logging driver.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_logging_driver.png" alt=""><figcaption></figcaption></figure>

### Service labels

Lets you add metadata to containers using Docker labels either via an array or a dictionary. We recommend that you use reverse-DNS notation to stop labels from conflicting with those used by other software.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_labels.png" alt=""><figcaption></figcaption></figure>

### Configs

Docker 17.06 introduced Swarm service configs. These allow you to store non-sensitive information such as configuration files outside a service’s image or running containers. This keeps images as generic as possible and removes the need to bind-mount configuration files into containers or use environment variables.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_configs.png" alt=""><figcaption></figcaption></figure>

### Secrets

In the context of Docker Swarm services, a secret is a blob of data such as a password, SSH private key, SSL certificate, or another piece of data that should not be transmitted over a network or stored unencrypted in a Dockerfile or in your application’s source code.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_secrets.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/services/logs.md
================================================
# View service logs

From the menu select **Services**, select the service whose logs you want to view then click **Service logs**.

<figure><img src="../../../.gitbook/assets/2.30-services-logs.gif" alt=""><figcaption></figcaption></figure>

Here you can see the contents of the Docker logs for your service.&#x20;

<table><thead><tr><th width="236">Field/Option</th><th>Overview</th></tr></thead><tbody><tr><td>Search</td><td>Enter a string to search the log output. You can see the number of results for your search and move through each result with the up and down arrows.</td></tr><tr><td>Filter search results</td><td>When enabled, display only the log lines that contain your search string.</td></tr><tr><td>Copy</td><td>Click this button to copy the currently displayed log lines to your clipboard.</td></tr><tr><td>Download logs</td><td>Click this button to download your log.</td></tr></tbody></table>

<figure><img src="../../../.gitbook/assets/2.17-containers-logs-search.png" alt=""><figcaption></figcaption></figure>

You can also set various options for how the logs are displayed:

<table><thead><tr><th width="238">Field/Option</th><th>Overview</th></tr></thead><tbody><tr><td>Date picker</td><td>Select the time period from which to retrieve the logs.</td></tr><tr><td>Lines</td><td>Limit the number of lines per log file (the default is 1000).</td></tr><tr><td>Line numbers</td><td>When enabled, display line numbers for each log line.</td></tr><tr><td>Timestamp</td><td>When enabled, display a timestamp before each log line.</td></tr><tr><td>Wrap lines</td><td>When enabled, lines longer than the screen width will be wrapped onto the next line.</td></tr><tr><td>Auto refresh</td><td>Enable this option to automatically refresh the log view. When off, you can click the refresh icon to the right of the button to manually refresh the view.</td></tr><tr><td>Full screen</td><td>Click the full screen icon to expand the log display to fill your screen.</td></tr></tbody></table>

<figure><img src="../../../.gitbook/assets/2.30-containers-logs-options.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/services/rollback.md
================================================
# Roll back a service

If you make a change to a service in Docker Swarm and your applications are no longer working as you expect, you can roll back to the previous state.

From the menu select **Services**, select the service to roll back then click **Rollback the service**.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_rollback.gif" alt=""><figcaption></figcaption></figure>

When the confirmation message appears, click **Yes**.

<figure><img src="../../../.gitbook/assets/2.15-service-rollback-confirm.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/services/scale.md
================================================
# Scale a service

From the menu select **Services** then select **scale** next to the service you want to scale (in the **Scheduling Mode** column).

<figure><img src="../../../.gitbook/assets/2.15-docker_services_scale.gif" alt=""><figcaption></figcaption></figure>

Select the number of replicas you want to create for the service then click the tick icon to apply. If scaling is successful, a success message will appear at the top-right of the screen. Refresh the page until the running replicas appear.

{% hint style="info" %}
Depending on container size, there might be a slight delay before the replicas appear on screen.
{% endhint %}



================================================
FILE: user/docker/services/tasks.md
================================================
# View the status of a service task

Services in a Docker Swarm environment are a collection of tasks (or individual containers). This article explains how to quickly see the status of the containers that make up each service.

From the menu select **Services** then click the down-arrow to the left of the service you want to inspect. The tasks that make up the service will be shown.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_tasks.gif" alt=""><figcaption></figcaption></figure>

Select any individual task to go to the container details page for that task. You can also perform various actions on individual tasks by using the icons in the **Actions** column.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_actions.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/services/webhooks.md
================================================
# Webhooks

A webhook is a POST request sent to a URL that you define in Docker Hub or another registry. Use webhooks to trigger an action or a service in response to a repository push event.

{% hint style="info" %}
Webhooks are only available on non-Edge environments (environments running Portainer Server or Portainer Agent, not the Portainer Edge Agent). This is because the tunnel to the Portainer Edge Agent is only opened on-demand, and therefore would mean there is no way to expose a webhook permanently.
{% endhint %}

## Enabling a service webhook

From the menu select **Services** then select the service that you want to configure the webhook for.

<figure><img src="../../../.gitbook/assets/2.15-docker_services.gif" alt=""><figcaption></figcaption></figure>

In the **Service details** screen toggle the **Service webhook** option on. When the URL appears, click **Copy link**. This URL will be used to configure the webhook in your chosen registry.

<figure><img src="../../../.gitbook/assets/2.15-docker_services_service_webhook.png" alt=""><figcaption></figcaption></figure>

This example shows how to trigger the webhook using `redeploy`:

```
<form action="https://portainer:9443/api/webhooks/638e6967-ef77-4906-8af8-236800621360" method="post">
  Redeploy with latest image of same tag <input type="submit" />
</form>
```

This example shows how to trigger the webhook using `update service image with a different tag`:

```
<form action="https://portainer:9443/api/webhooks/638e6967-ef77-4906-8af8-236800621360?tag=latest" method="post">
  Update Service image with different tag <input type="submit" />
</form>
```

## Using environment variables with webhooks

When triggering a webhook, environment variables can be passed through the endpoint and referenced within services' compose files.

{% hint style="info" %}
This functionality is only available in Portainer Business Edition.
{% endhint %}

To specify an environment variable on a webhook, add it as a variable to the URL. For example, to pass a `SERVICE_TAG` variable with the value `development`:

```
https://portainer:9443/api/webhooks/1d251d96-fb34-4172-a0a1-d0655467b897?SERVICE_TAG=development
```

To reference the `SERVICE_TAG` variable in your compose file with a fallback to the value `stable`:

```
services:
  my-service:
    image: repository/image:${SERVICE_TAG:-stable}
```

## Configuring the webhook in Docker Hub

To finish the configuration, refer to [Docker's own documentation](https://docs.docker.com/docker-hub/webhooks/).



================================================
FILE: user/docker/stacks/README.md
================================================
# Stacks

A stack is a collection of services, usually related to one application or usage. For example, a WordPress stack definition may include a web server container (such as nginx) and a database container (such as MySQL).

<figure><img src="../../../.gitbook/assets/2.20-stacks-list.png" alt=""><figcaption></figcaption></figure>

When the [new image indicator](../host/setup.md#other) feature is enabled, the **Images up to date** column indicates whether the local images in the stack are up to date, with a green tick indicating they are up to date and an orange cross indicating that there is a newer version of an image available at the remote registry. A grey hyphen indicates Portainer was unable to determine whether there is an update available for the images.

You can click the **Reload image indicators** button to recheck the images for your stacks for updates, or to recheck a single stack's images you can click the image indicator icon for that stack.

For more on how this works, have a look at [this knowledge base article](https://portal.portainer.io/knowledge/how-does-the-image-update-notification-icon-work).

{% content-ref url="add.md" %}
[add.md](add.md)
{% endcontent-ref %}

{% content-ref url="edit.md" %}
[edit.md](edit.md)
{% endcontent-ref %}

{% content-ref url="template.md" %}
[template.md](template.md)
{% endcontent-ref %}

{% content-ref url="webhooks.md" %}
[webhooks.md](webhooks.md)
{% endcontent-ref %}

{% content-ref url="migrate.md" %}
[migrate.md](migrate.md)
{% endcontent-ref %}

{% content-ref url="remove.md" %}
[remove.md](remove.md)
{% endcontent-ref %}



================================================
FILE: user/docker/stacks/add.md
================================================
# Add a new stack

{% embed url="https://www.youtube.com/watch?v=gRk9rOMX598" %}

## Options when deploying a new stack

There are four ways to deploy a new stack from Portainer:

| Option                                           | Overview                                                                                                 |
| ------------------------------------------------ | -------------------------------------------------------------------------------------------------------- |
| [Web editor](add.md#option-1-web-editor)         | Use our web editor to define the services for the stack using a docker-compose format.                   |
| [Upload](add.md#option-2-upload)                 | If you have a `stack.yml` file, you can upload it from your computer and use it to deploy the stack.     |
| [Git repository](add.md#option-3-git-repository) | You can use a docker-compose format file hosted in a Git repository.                                     |
| Custom template                                  | If you have created a [custom stack template](../templates/custom.md), you can deploy using this option. |

## Option 1: Web editor

From the menu select **Stacks**, click **Add stack**, give the stack a descriptive name then select **Web editor**. Use the web editor to define the services.

<figure><img src="../../../.gitbook/assets/2.15-docker_add_stack_web_editor.gif" alt=""><figcaption></figcaption></figure>

{% hint style="info" %}
You can search within the web editor at any time by pressing `Ctrl-F` (or `Cmd-F` on Mac).
{% endhint %}

As part of the stack creation you can enable a stack webhook, allowing you to remotely trigger redeployments of the stack from your repository, for example. You can read more on this in our documentation on [stack webhooks](webhooks.md).

<figure><img src="../../../.gitbook/assets/2.15-docker_stack_web_editor_webhook.png" alt=""><figcaption></figcaption></figure>

As an optional step, you can also use the web editor to define environment variables. You can use these to define values in your compose file that would vary between deployments (for example, hostnames, database names, etc).

Environment variables can be set individually within Portainer or you can use **Load variables from .env file** to upload a file containing your environment variables. Environment variables you define (either individually or via a .env file) will be available to use in your compose file using an `environment` definition:

```
environment:
  MY_ENVIRONMENT_VARIABLE: ${MY_ENVIRONMENT_VARIABLE}
```

Alternatively, on Docker Standalone and Podman environments you can add `stack.env` as an `env_file` definition to add all the environment variables that you have defined individually as well as those included in an uploaded .env file:

```
env_file:
  - stack.env
```

**Note:** Using `env_file` to define a file does not work in Docker Swarm due to the lack of `env_file` support in `docker stack deploy` (used on Swarm environments to deploy your stack). On Docker Swarm, you will need to define each environment variable manually.

{% hint style="info" %}
Note the compose file is not changed when environment variables are used - this allows variables to be updated within Portainer without editing the compose file itself. You will still see the `${MY_ENVIRONMENT_VARIABLE}` style entry in the compose file.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-docker_stack_wed_editor_env_var.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Deploy the stack**.

## Option 2: Upload

In Portainer you can create stacks from Compose YML files. To do this, from the menu select **Stacks**, click **Add stack**, then give the stack a descriptive name.

<figure><img src="../../../.gitbook/assets/2.15-docker_add_stack_upload.gif" alt=""><figcaption></figcaption></figure>

Select **Upload** then select the Compose file from your computer.

As part of the stack creation you can enable a stack webhook, allowing you to remotely trigger redeployments of the stack from your repository, for example. You can read more on this in our documentation on [stack webhooks](webhooks.md).

<figure><img src="../../../.gitbook/assets/2.15-docker_stack_web_editor_webhook.png" alt=""><figcaption></figcaption></figure>

As an optional step, enter any environment variables. You can use these to define values in your compose file that would vary between deployments (for example, hostnames, database names, etc).

Environment variables can be set individually within Portainer or you can use **Load variables from .env file** to upload a file containing your environment variables. Environment variables you define (either individually or via a .env file) will be available to use in your compose file using an `environment` definition:

```
environment:
  MY_ENVIRONMENT_VARIABLE: ${MY_ENVIRONMENT_VARIABLE}
```

Alternatively, you can add `stack.env` as an `env_file` definition to add all the environment variables that you have defined individually as well as those included in an uploaded .env file:

```
env_file:
  - stack.env
```

{% hint style="info" %}
Note the compose file is not changed when environment variables are used - this allows variables to be updated within Portainer without editing the compose file itself which would take it out of sync with your local copy. You will still see the `${MY_ENVIRONMENT_VARIABLE}` style entry in the compose file.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-docker_add_stack_upload_env_var.png" alt=""><figcaption></figcaption></figure>

When you're ready click **Deploy the stack**.

## Option 3: Git repository

If your Compose file is hosted in a Git repository, you can deploy from there. From the menu select **Stacks**, click **Add stack**, then give the stack a descriptive name.

{% hint style="warning" %}
When a stack is deployed from Git, Portainer will clone the entire Git repository as part of the deployment process. Ensure you have enough free space to accommodate this.
{% endhint %}

{% hint style="warning" %}
Portainer's Git deployment functionality does not currently support the use of Git submodules. If your repository includes submodules, they will not be pulled as part of the deployment. We [hope to add support](https://github.com/orgs/portainer/discussions/9767) for submodules in a future release.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-docker_add_stack_git.gif" alt=""><figcaption></figcaption></figure>

Select **Git Repository** then enter information about your Git repo.

{% hint style="info" %}
Any Git-compatible repository should work here. Substitute the details as required.
{% endhint %}

| Field/Option          | Overview                                                                                                                                                                  |
| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Authentication        | Toggle this on if your Git repository requires authentication.                                                                                                            |
| Git Credentials       | If the **Authentication** toggle is enabled and you have [configured Git credentials](../../account-settings.md#git-credentials), you can select them from this dropdown. |
| Username              | Enter your Git username.                                                                                                                                                  |
| Personal Access Token | Enter your personal access token or password.                                                                                                                             |
| Save credential       | Check this option to save the credentials entered above for future use under the name provided in the **credential name** field.                                          |

{% hint style="info" %}
If you have 2FA configured in GitHub, your passcode is your password.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.16-stacks-add-gitcreds.png" alt=""><figcaption></figcaption></figure>

| Field/Option          | Overview                                                                                                                                                                                          |
| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Repository URL        | Enter the repository URL. If you have enabled Authentication above the credentials will be used to access the repository. The below options will be populated by what is found in the repository. |
| Skip TLS verification | Toggle this on to skip the verification of TLS certificates used by your repository. This is useful if your repo uses a self-signed certificate.                                                  |
| Repository reference  | Select the reference to use when deploying the stack (for example, the branch).                                                                                                                   |
| Compose path          | Enter the path to the Compose file from the root of the repository.                                                                                                                               |
| Additional paths      | Click **Add file** to add additional files to be parsed by the build (for example, an environment-specific compose file).                                                                         |
| GitOps updates        | Toggle this on to enable GitOps updates (see below).                                                                                                                                              |

<figure><img src="../../../.gitbook/assets/2.24.0-docker-stacks-add-git.png" alt=""><figcaption></figcaption></figure>

### GitOps updates

Portainer supports automatically updating your stacks deployed from Git repositories. To enable this, toggle on **GitOps updates** and configure your settings.

{% hint style="info" %}
For more detail on how GitOps updates function under the hood, have a look at [this knowledge base article](https://portal.portainer.io/knowledge/how-do-automatic-updates-for-stacks-applications-work).
{% endhint %}

| Field/Option   | Overview                                                                                                                                                                                                                                                                            |
| -------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Mechanism      | Select the method to use when checking for updates:                                                                                                                                                                                                                                 |
|                | <p><strong>Polling:</strong> Periodically poll the Git repository from Portainer to check for updates to the repository.</p><p><strong>Webhook:</strong> Generate a webhook URL to add to your Git repository to trigger the update on demand (for example via GitHub actions).</p> |
| Fetch interval | If **Polling** is selected, how often Portainer will check the Git repository for updates.                                                                                                                                                                                          |
| Webhook        | When **Webhook** is selected, displays the webhook URL to use in your integration. Click **Copy link** to copy the webhook URL to the clipboard.                                                                                                                                    |

<figure><img src="../../../.gitbook/assets/2.19-stacks-add-git-polling.png" alt=""><figcaption><p>Automatic updates when using polling</p></figcaption></figure>

<figure><img src="../../../.gitbook/assets/2.19-stacks-add-git-webhook.png" alt=""><figcaption><p>Automatic updates when using webhooks</p></figcaption></figure>

| Field/Option       | Overview                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Re-pull image      | <p>Enable this setting to always pull the most recent version of container images when updating the stack. This is equivalent to the <code>--pull=always</code> flag for <code>docker run</code>.<br>This option was previously labeled as <strong>Pull latest image</strong>.</p>                                                                                                                                                                                                                                                                          |
| Force redeployment | <p>Enable this setting to force the redeployment of your stack at the specified interval (or when the webhook is triggered), overwriting any changes that have been made in the local environment, even if there has been no update to the stack in Git. This is useful if you want to ensure that your Git repository is the source of truth for your stacks and are happy with the local stack being replaced.</p><p>If this option is left disabled, automatic updates will only trigger if Portainer detects a change in the remote Git repository.</p> |

<figure><img src="../../../.gitbook/assets/2.19-stacks-add-git-repull-force.png" alt=""><figcaption></figcaption></figure>

### Relative path volumes

When you toggle **Enable relative path volumes** to on, you are able to specify relative path references in your compose files. Portainer will create the required directory structure and populate the directories with the relevant files from your Git repository.

{% hint style="info" %}
This feature is only available in Portainer Business Edition.
{% endhint %}

On Docker Standalone and Podman environments, specify the path at which you want your files to be created on your host filesystem in the **Local filesystem path** field.

{% hint style="warning" %}
Ensure this directory exists on your local filesystem and is writable.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.17-stacks-add-relativepath.png" alt=""><figcaption></figcaption></figure>

On Docker Swarm environments, specify the path at which you want your files to be created in the Network filesystem path field.

{% hint style="warning" %}
Ensure that this path is available on all of your Docker Swarm nodes and is writable.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.17-stacks-add-relativepath-swarm.png" alt=""><figcaption></figcaption></figure>

{% hint style="info" %}
For more detail on how this feature works, have a look at [this article](../../../advanced/relative-paths.md).
{% endhint %}

### Environment variables

As an optional step, you can also set environment variables. You can use these to define values in your compose file that would vary between deployments (for example, hostnames, database names, etc).

Environment variables can be set individually within Portainer or you can use **Load variables from .env file** to upload a file containing your environment variables. Environment variables you define (either individually or via a .env file) will be available to use in your compose file using an `environment` definition:

```
environment:
  MY_ENVIRONMENT_VARIABLE: ${MY_ENVIRONMENT_VARIABLE}
```

Alternatively, you can add `stack.env` as an `env_file` definition to add all the environment variables that you have defined individually as well as those included in an uploaded .env file:

```
env_file:
  - stack.env
```

{% hint style="info" %}
Note the compose file is not changed when environment variables are used - this allows variables to be updated within Portainer without editing the compose file itself which would take it out of sync with the Git repository. You will still see the `${MY_ENVIRONMENT_VARIABLE}` style entry in the compose file.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-docker_stack_wed_editor_env_var.png" alt=""><figcaption></figcaption></figure>

Enter environment variables if required then click **Deploy the stack**.



================================================
FILE: user/docker/stacks/edit.md
================================================
# Inspect or edit a stack

## Inspecting a stack

From the menu select **Stacks** then select the stack you want to inspect.

<figure><img src="../../../.gitbook/assets/2.20-stacks-edit.gif" alt=""><figcaption></figcaption></figure>

From here you can stop, delete or [create a template from the stack](template.md), and if deployed from Git you can [detach the stack from the Git repository](edit.md#detach-from-git).

<figure><img src="../../../.gitbook/assets/2.20-stacks-edit-options.png" alt=""><figcaption></figcaption></figure>

If the stack was deployed from a Git repository, you can:

* Configure [GitOps updates](add.md#gitops-updates) or manually pull and redeploy the stack.
* View and edit the stack's environment variables.

<figure><img src="../../../.gitbook/assets/2.20-stacks-edit-git.png" alt=""><figcaption></figcaption></figure>

If the stack was deployed using the [Web Editor](add.md#option-1-web-editor) or [uploaded](add.md#option-2-upload), you will have the option to [edit your compose file manually](edit.md#editing-a-stack).

Regardless of the deployment method used, you can also [migrate or duplicate](migrate.md) the stack.

### Docker Standalone / Podman

When using Docker Standalone or Podman, you can:

* View the containers that make up the stack.
* Check to see if they are running or stopped.
* Get access to logs.
* Inspect individual containers.
* View container statistics.
* Get access to the container's console.

You can also see the image update indicator for each container in the stack. To recheck the image update status for all containers in the stack you can click the reload button next to the search box, or to recheck a single container's image, click the image update indicator icon for that container.&#x20;

<figure><img src="../../../.gitbook/assets/2.20-stacks-edit-containers.png" alt=""><figcaption></figcaption></figure>

### Docker Swarm

When using Docker Swarm, you can:

* View the services that make up the stack, and the individual tasks that make up each service.
* Check to see if they are running or stopped.
* See how many replicas are running on each host.
* Get access to logs.
* Inspect individual services.
* View service statistics.
* Get access to the service's console.

You can also see the image update indicator for each service in the stack. To recheck the image update status for all services in the stack you can click the Reload image indicators button, or to recheck a single service's image, click the image update indicator icon for that service.&#x20;

<figure><img src="../../../.gitbook/assets/2.20-stacks-edit-services.png" alt=""><figcaption></figcaption></figure>

## Editing a stack

Editing a stack allows you to make changes to the configuration and redeploy those changes. To edit a stack, from the menu select **Stacks**, select the stack you want to edit, then select the **Editor** tab.

{% hint style="info" %}
The Editor tab is only available for stacks that were deployed using the [Web Editor](add.md#option-1-web-editor). For stacks deployed from a Git repository, the compose file must be edited in the repository itself.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.19-stacks-edit-webeditor.png" alt=""><figcaption></figcaption></figure>

Here, you can edit the Compose file for the stack to suit your needs. Using the **Version** dropdown you can also select a previous version of your stack file (if one exists) to switch back to if required. Selecting a different version from the dropdown will replace the contents of the editor with that of the selected version.&#x20;

{% hint style="info" %}
You can search within the web editor at any time by pressing `Ctrl-F` (or `Cmd-F` on Mac).
{% endhint %}

In this section you can expand the Environment variables section to view and make changes to the stack's environment variables.

<figure><img src="../../../.gitbook/assets/2.20-stacks-edit-envvars.png" alt=""><figcaption></figcaption></figure>

You can also toggle the stack [webhook](webhooks.md) and retrieve the webhook URL:&#x20;

<figure><img src="../../../.gitbook/assets/2.20-stacks-edit-webhook.png" alt=""><figcaption></figcaption></figure>

You can choose to **Prune services** if you have made changes that remove some services from the stack.

<figure><img src="../../../.gitbook/assets/2.20-stacks-edit-swarm-prune.png" alt=""><figcaption></figcaption></figure>

When you have finished making changes, click **Update the stack**.

## Detach from Git

If your stack was created from a Git repository, you have the option to detach the stack from the repository. This means you can [edit the stack directly within Portainer](edit.md#editing-a-stack), but it does mean that the stack can't be updated from Git anymore. This action also cannot be reversed.

{% hint style="info" %}
Detaching downloads the main compose file for the stack and stores it in Portainer. It does not download any additional compose files or `.env` files that may be contained within the repository.
{% endhint %}

Click **Detach from Git** to detach. You will be asked to confirm the action - click **Detach** to do so.



================================================
FILE: user/docker/stacks/migrate.md
================================================
# Migrate or duplicate a stack

## Migrating a stack

From the menu select **Stacks** then select the stack you want to migrate.

<figure><img src="../../../.gitbook/assets/2.20-stacks-edit.gif" alt=""><figcaption></figcaption></figure>

In the **Stack duplication / migration** section, select the destination environment for the stack, and optionally define a new name for the stack. Click **Migrate**.

<figure><img src="../../../.gitbook/assets/2.20-stacks-migrate-migrate.png" alt=""><figcaption></figcaption></figure>

When the confirmation message appears, click **Migrate**.

<figure><img src="../../../.gitbook/assets/2.15-stack-migrate-confirm.png" alt=""><figcaption></figcaption></figure>

## Duplicating a stack

From the menu select **Stacks** then select the stack you want to duplicate.

<figure><img src="../../../.gitbook/assets/2.20-stacks-edit.gif" alt=""><figcaption></figcaption></figure>

In the **Stack duplication / migration** section, give the new stack a descriptive name then select the environment that the stack is currently on.

<figure><img src="../../../.gitbook/assets/2.20-stacks-migrate-duplicate.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Duplicate**.




================================================
FILE: user/docker/stacks/remove.md
================================================
# Remove a stack

From the menu select **Stacks**, tick the checkbox next to the stack you want to remove, then click **Remove**.&#x20;

<figure><img src="../../../.gitbook/assets/2.20-stacks-remove.gif" alt=""><figcaption></figcaption></figure>

When the confirmation message appears, click **Remove**.

<figure><img src="../../../.gitbook/assets/2.15-stack-remove-confirm.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/stacks/template.md
================================================
# Create a template from a deployed stack

In Portainer you can create an [app template](../templates/) from deployed stacks. This is useful if you need to deploy the same stack several times.

From the menu select **Stacks**, select the already-deployed stack, then click **Create template from stack**.

<figure><img src="../../../.gitbook/assets/2.20-stacks-template.gif" alt=""><figcaption></figcaption></figure>

Define some properties for the new template, using the table below as a guide.

| Field/Option | Overview                                                                                    |
| ------------ | ------------------------------------------------------------------------------------------- |
| Title        | Give the template a descriptive name.                                                       |
| Description  | Enter a brief description of what your template includes.                                   |
| Note         | Note any extra information about the template (optional).                                   |
| Logo         | Enter the URL to a logo to be used for the template when it appears in the list (optional). |
| Platform     | Select the compatible platform for the template. Options are **Linux** or **Windows**.      |
| Type         | Select the type of template. Options are **Standalone / Podman** or **Swarm**.              |

<figure><img src="../../../.gitbook/assets/2.22.0-templates-custom-new.png" alt=""><figcaption></figcaption></figure>

The **Web editor** will be pre-populated with the Compose file for your stack. Make any changes you need here.

{% hint style="info" %}
You can search within the web editor at any time by pressing `Ctrl-F` (or `Cmd-F` on Mac).
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.20-stacks-template-webeditor.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Create custom template**.



================================================
FILE: user/docker/stacks/webhooks.md
================================================
# Webhooks

A webhook is a POST request sent to a URL that you define in Docker Hub or another registry. Use webhooks to trigger an action in response to an event such as a repository push.

{% hint style="info" %}
This functionality is only available in [Portainer Business Edition](https://www.portainer.io/business-upsell?from=stack-webhook).
{% endhint %}

{% hint style="info" %}
Webhooks are only available on non-Edge environments (environments running Portainer Server or Portainer Agent, not the Portainer Edge Agent). This is because the tunnel to the Portainer Edge Agent is only opened on-demand, and therefore would mean there is no way to expose a webhook permanently.
{% endhint %}

## Enabling a stack webhook

From the menu select **Stacks** then select the container that you want to configure the webhook for. Then select the **Edit** tab.

<figure><img src="../../../.gitbook/assets/2.20-stacks-webhooks.gif" alt=""><figcaption></figcaption></figure>

Scroll down to the **Webhooks** section and toggle the **Create a stack webhook** option on. When the URL appears, click **Copy link**. This URL will be used to configure the webhook in your chosen registry.

<figure><img src="../../../.gitbook/assets/2.15-docker_stack_create_webhook.png" alt=""><figcaption></figcaption></figure>

This example shows how to trigger the webhook using `redeploy`:

```
<form action="https://portainer:9443/api/stacks/webhooks/638e6967-ef77-4906-8af8-236800621360" method="post">
  Redeploy stack containers with latest image of same tag <input type="submit" />
</form>
```

This example shows how to trigger the webhook to update the stack to use a different image tag:

```
<form action="https://portainer:9443/api/stacks/webhooks/638e6967-ef77-4906-8af8-236800621360?tag=latest" method="post">
  Update stack container images with different tag <input type="submit" />
</form>
```

## Preventing a pull

In some cases you may want to override the pulling of images when using the webhook to do a redeploy. In that scenario, you can specify `pullimage=false` as a parameter on your webhook to disable pulling of images.&#x20;

{% hint style="info" %}
This option is only available in Portainer Business Edition.
{% endhint %}

```
<form action="https://portainer:9443/api/stacks/webhooks/638e6967-ef77-4906-8af8-236800621360?pullimage=false" method="post">
  Update stack without pulling images <input type="submit" />
</form>
```

## Using environment variables with webhooks

When triggering a webhook, environment variables can be passed through the endpoint and referenced within stacks' compose files.

To specify an environment variable on a webhook, add it as a variable to the URL. For example, to pass a `SERVICE_TAG` variable with the value `development`:

```
https://portainer:9443/api/stacks/webhooks/1d251d96-fb34-4172-a0a1-d0655467b897?SERVICE_TAG=development
```

To reference the `SERVICE_TAG` variable in your compose file with a fallback to the value `stable`:

```
services:
  my-service:
    image: repository/image:${SERVICE_TAG:-stable}
```

## Configuring the webhook in Docker Hub

To finish the configuration, refer to [Docker's own documentation](https://docs.docker.com/docker-hub/webhooks/).



================================================
FILE: user/docker/swarm/README.md
================================================
# Swarm

{% hint style="info" %}
The **Swarm** menu is only available to Docker Swarm environments.
{% endhint %}

This section provides an overview of your Swarm environment. You can view information about environments and nodes, view cluster information, and configure environment-specific settings.

{% content-ref url="details.md" %}
[details.md](details.md)
{% endcontent-ref %}

{% content-ref url="cluster-visualizer.md" %}
[cluster-visualizer.md](cluster-visualizer.md)
{% endcontent-ref %}

{% content-ref url="setup.md" %}
[setup.md](setup.md)
{% endcontent-ref %}

{% content-ref url="registries.md" %}
[registries.md](registries.md)
{% endcontent-ref %}



================================================
FILE: user/docker/swarm/cluster-visualizer.md
================================================
# Cluster visualizer

{% hint style="info" %}
This feature is only available to Docker Swarm environments.
{% endhint %}

The **Cluster visualizer** section gives you an overview of your cluster and the tasks on it.

## Cluster information

View the details about the cluster including the number of nodes, services and tasks. You can also adjust the visualizer display.

<figure><img src="../../../.gitbook/assets/2.15-docker_swarm_cluster_visualizer.png" alt=""><figcaption></figcaption></figure>

### Options

**Only display running tasks** filters the task list in the visualizer to only include running tasks.&#x20;

**Display node labels** toggles the display of labels on the nodes in the visualizer.

### Refresh

Use this option to define the refresh rate of the visualizer (the default is every 5 seconds).

## Cluster visualizer

The **Cluster visualizer** section gives you a visual representation of the nodes in your cluster and the tasks on each node.&#x20;

<figure><img src="../../../.gitbook/assets/2.15-docker_swarm_cluster_info.png" alt=""><figcaption></figcaption></figure>




================================================
FILE: user/docker/swarm/details.md
================================================
# Details

This page provides information about the Docker Swarm cluster for the selected environment. The page is split into the following sections: Cluster status and Nodes, with clicking a node name taking you to the Node overview for that node.

{% hint style="info" %}
This page is only available on Docker Swarm environments.
{% endhint %}

## Cluster status

This section describes the cluster's basic configuration, including the number of nodes, the Docker API version, and the total CPU and memory available. A link to the [cluster visualizer](cluster-visualizer.md) is also included.

<figure><img src="../../../.gitbook/assets/2.15-swarm-clusterstatus.png" alt=""><figcaption></figcaption></figure>

## Nodes

Lists all of the nodes in the cluster along with a summary of each node, including:

* The role of the node.
* The number of CPUs and memory available on the node.
* The Docker Engine version running on the node.
* The node's IP address.
* The status and availability of the node.

<figure><img src="../../../.gitbook/assets/2.15-swarm-nodes.png" alt=""><figcaption></figcaption></figure>

Clicking on an individual node's name will take you to an overview page for that node.

## Node overview

### Host Details

This section describes the node's basic configuration, including the hostname, OS information, and total CPU and memory.

<figure><img src="../../../.gitbook/assets/2.15-swarm-nodedetail.png" alt=""><figcaption></figcaption></figure>

### Engine Details

Information such as the Docker version and the available volume and network plugins helps you to understand more about the Docker engine running on your node.

<figure><img src="../../../.gitbook/assets/2.15-swarm-nodedetail-engine.png" alt=""><figcaption></figcaption></figure>

### PCI Devices and Physical Disks

These sections list the available PCI devices and physical disks on the node.&#x20;

{% hint style="info" %}
These sections are only visible when [host management features](setup.md#host-and-filesystem) are enabled for the cluster.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-docker-host-pci.png" alt=""><figcaption></figcaption></figure>

### Node Details

Here you'll find details about the node's configuration as part of the cluster. You can view the role, set the availability status of the node, view the current status and apply labels to the node.

<figure><img src="../../../.gitbook/assets/2.15-swarm-nodedetail-detail.png" alt=""><figcaption></figcaption></figure>




================================================
FILE: user/docker/swarm/registries.md
================================================
# Registries

**Registries** lets you manage access to each of the registries that are currently available.

{% hint style="warning" %}
Registry access assigned here only applies to the selected environment. It is not global.
{% endhint %}

## Adding a new registry

From the menu select **Swarm**, select **Registries** then click **Add registry**. When the global registries page appears, follow [these instructions](../../../admin/registries/add/).

<figure><img src="../../../.gitbook/assets/2.15-docker_swarm_add_registries.gif" alt=""><figcaption></figcaption></figure>

## Managing access

To configure access to a registry, from the menu select **Swarm** then select **Registries**.

<figure><img src="../../../.gitbook/assets/2.15-docker_swarm_registries_manage_access.gif" alt=""><figcaption></figcaption></figure>

Find the registry you want to manage then select **Manage access**.&#x20;

<figure><img src="../../../.gitbook/assets/2.15-docker_swarm_registry_manage_access.png" alt=""><figcaption></figcaption></figure>

From the dropdown, select the users or teams that you would like to have access then click **Create access**.

<figure><img src="../../../.gitbook/assets/2.15-docker_hosts_registries_access.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/swarm/setup.md
================================================
# Setup

{% hint style="info" %}
The **Swarm Setup** section is only available to Docker Swarm environments.
{% endhint %}

Under **Setup**, you can make changes to your environment, enabling and disabling features and security settings.

## Host and Filesystem

This section is where you configure how Portainer interacts with elements of the host.

{% hint style="danger" %}
For security, these features are disabled by default. Be sure that you understand their impact before enabling them.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-docker_hosts_features_config.png" alt=""><figcaption></figcaption></figure>

| Option                                          | Overview                                                                                                                                                                         |
| ----------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Enable host management features                 | Enabling host management features allows you to see the available devices and storage on the physical nodes across your cluster as well as browse the nodes' filesystems.        |
| Enable volume management for non-administrators | Enabling this feature allows non-administrator users to manage volumes on an environment. If this is disabled, users below administrator level have read-only access to volumes. |

## Change Window Settings

This setting allows you to specify a window within which [GitOps updates](../stacks/add.md#gitops-updates) to your applications can be applied.

{% hint style="warning" %}
If this setting is enabled and an update is made to an application outside of this window, it will not be applied.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-cluster-setup-changewindow.png" alt=""><figcaption></figcaption></figure>

## Docker Security Settings

This section allows you to toggle assorted Docker-related security settings for an environment.

<figure><img src="../../../.gitbook/assets/2.15-docker_hosts_security_settings.png" alt=""><figcaption></figcaption></figure>



| Option                                                | Overview                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ----------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Disable bind mounts for non-administrators            | Prevents non-admin users within Portainer from using bind mounts when creating containers and/or services/stacks. When toggled on, the option to attach to a host file system path is removed.                                                                                                                                                                                                                                                                                                                                                              |
| Disable privileged mode for non-administrators        | Prevents non-admin users from elevating the privilege of a container to bypass SELinux/AppArmor. When toggled on, the option to select **Privileged** mode when [adding a container](../containers/add.md) is removed.                                                                                                                                                                                                                                                                                                                                      |
| Disable the use of host PID 1 for non-administrators  | Prevents non-admin users from requesting that a deployed container operates as the host PID. This is a security risk if used by a non-trustworthy authorized user because when they operate as PID1, they are in effect able to run any command in the container console as root on the host.                                                                                                                                                                                                                                                               |
| Disable the use of Stacks for non-administrators      | This is a 'sledgehammer' approach to removing any possibility for non-admin users within Portainer to find and use weaknesses in the Docker architecture. Whilst Portainer has the ability to disable some of the more common exploits, we cannot possibly block them all because there are any number of capabilities that could be added to a container to attempt to gain access to the host. This feature simply allows an admin to disable all possible entry points.                                                                                  |
| Disable device mappings for non-administrators        | Blocks users from mapping host devices into containers. Whilst the ability to map devices is generally used for good (e.g. mapping a GPU into a container), it can equally be used by non-trustworthy authorized users to map a physical storage device into a container. It is possible to mount `/dev/sda1` into a container, and then from a console of that container, the user would have complete access to the sda1 device without restriction. By toggling this on, Portainer blocks the ability for non-admins to map ANY devices into containers. |
| Disable container capabilities for non-administrators | Toggle on to hide the **Container capabilities** tab for non-administrators when they are [adding a container](../containers/add.md).                                                                                                                                                                                                                                                                                                                                                                                                                       |
| Disable sysctl settings for non-administrators        | Toggle on to stop non-admin users from using sysctl options, preventing them from recreating, duplicating or editing containers.                                                                                                                                                                                                                                                                                                                                                                                                                            |

## Other

This section contains other assorted environment-specific settings.

<figure><img src="../../../.gitbook/assets/2.18-swarm-setup-other.png" alt=""><figcaption></figcaption></figure>

| Option                                                                    | Overview                                                                                                                                                                                                               |
| ------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Show GPU in the UI                                                        | GPU functionality is currently not available in Docker Swarm environments so this toggle is disabled.                                                                                                                  |
| Show an image(s) up to date indicator for Stacks, Services and Containers | <p>Toggle on to enable the <a href="../services/">new image notification</a> feature for this environment. Toggle off to disable the feature.<br><br>This feature is only available in Portainer Business Edition.</p> |



================================================
FILE: user/docker/templates/README.md
================================================
# Templates

Templates let you deploy a container (or a stack of containers) to an environment with a set of predetermined configuration values while still allowing you to customize the configuration (for example, environment variables).

{% content-ref url="application.md" %}
[application.md](application.md)
{% endcontent-ref %}

{% content-ref url="custom.md" %}
[custom.md](custom.md)
{% endcontent-ref %}



================================================
FILE: user/docker/templates/application.md
================================================
# Application

An application template lets you deploy a container (or a stack of containers) to an environment with a set of predetermined configuration values while still allowing you to customize the configuration (for example, environment variables). This page lists the application templates available to deploy on your environment.

<figure><img src="../../../.gitbook/assets/2.20-templates-application-list.png" alt=""><figcaption></figcaption></figure>

Portainer supports templates of both individual containers and stacks of containers.

{% content-ref url="deploy-stack.md" %}
[deploy-stack.md](deploy-stack.md)
{% endcontent-ref %}

{% content-ref url="deploy-container.md" %}
[deploy-container.md](deploy-container.md)
{% endcontent-ref %}

By default, Portainer provides a pre-built set of app templates, but you are free to modify or [replace these with your own](../../../advanced/app-templates/build.md). You can also create your own custom templates either manually or from an existing stack.



================================================
FILE: user/docker/templates/custom.md
================================================
# Custom templates

A custom template can be used to help streamline the deployment of a container or stack.

{% hint style="info" %}
You can also [create a template from an existing deployed stack](../stacks/template.md).
{% endhint %}

## Viewing the list of custom templates

To view a list of custom templates, from the menu expand **Templates** then select **Custom**.

<figure><img src="../../../.gitbook/assets/2.20-templates-custom.gif" alt=""><figcaption></figcaption></figure>

## Creating a new custom template

### Entering the basic information

Click **Add Custom Template** then complete the details, using the table below as a guide.

| Field/Option | Overview                                                                                    |
| ------------ | ------------------------------------------------------------------------------------------- |
| Title        | Give the template a descriptive name.                                                       |
| Description  | Enter a brief description of what your template includes.                                   |
| Note         | Note any extra information about the template (optional).                                   |
| Logo         | Enter the URL to a logo to be used for the template when it appears in the list (optional). |
| Platform     | Select the compatible platform for the template. Options are **Linux** or **Windows**.      |
| Type         | Select the type of template. Options are **Standalone / Podman** or **Swarm**.              |

<figure><img src="../../../.gitbook/assets/2.22.0-templates-custom-new.png" alt=""><figcaption></figcaption></figure>

### Selecting the build method

Next, choose the build method that suits your needs. You can use the web editor to manually enter your docker-compose file, upload a `docker-compose.yml` file from your local computer, or pull the compose file from a Git repository.

#### Web editor

Paste the contents of your docker-compose file into the box provided. Once all the details have been completed, click **Create custom template**.

{% hint style="info" %}
You can search within the web editor at any time by pressing `Ctrl-F` (or `Cmd-F` on Mac).
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.20-templates-custom-add-webeditor.png" alt=""><figcaption></figcaption></figure>

#### Upload

Click **Select file** to browse for a docker-compose file to upload. Once all the details have been completed, click **Create custom template**.

<figure><img src="../../../.gitbook/assets/2.20-templates-custom-add-upload.png" alt=""><figcaption></figcaption></figure>

#### Git repository

Fill in the details for your Git repository.

| Field/Option          | Overview                                                                                                                                               |
| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Authentication        | Enable this if your Git repository requires authentication.                                                                                            |
| Git Credentials       | When Authentication is enabled, either select a pre-saved Git credential set or leave unset to provide new credentials.                                |
| Username              | When Authentication is enabled, enter your Git username.                                                                                               |
| Personal Access Token | When Authentication is enabled, enter your personal access token or password.                                                                          |
| Save credential       | When Authentication is enabled and you have provided new credentials, you can tick this box and enter a name to save those credentials for future use. |
| Repository URL        | Enter the URL to your Git repository.                                                                                                                  |
| Repository reference  | Select the repository reference to define the branch or tag to pull from.                                                                              |
| Compose path          | Enter the path within the repository to your docker-compose file.                                                                                      |
| Skip TLS Verification | Enable this option to skip verification of your Git repository's TLS certificate.                                                                      |

<figure><img src="../../../.gitbook/assets/2.20-templates-custom-add-git.png" alt=""><figcaption></figcaption></figure>

When all the details have been entered, click **Create custom template**.

## Variables in templates

Custom templates support the use of variables to provide further customization of the deployed stack. A stack can define a variable that can then be adjusted by the user at deployment.

{% hint style="info" %}
This feature is only available in Portainer Business Edition.
{% endhint %}

Variables are identified in stacks with `{{ }}`. For example, the following stack provides a `MYSQL_PASSWORD` variable:

<figure><img src="../../../.gitbook/assets/2.15-docker-templates-custom-variables-set.png" alt=""><figcaption></figcaption></figure>

When a variable is defined, options appear to customize how the variable appears when deploying the stack. You can set the **label**, **description** and **default value**.

When a template is deployed, any variables that have been configured are editable:

<figure><img src="../../../.gitbook/assets/2.15-docker-templates-custom-variables-create.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/templates/deploy-container.md
================================================
# Deploy a container

Portainer lets you deploy a standalone container from the default templates list.

From the menu expand **Templates** then select **Application** or **Custom** (depending on the container). On the Application templates page you can choose to display only Container templates using the **Type** dropdown.

<figure><img src="../../../.gitbook/assets/2.20-templates-deploy-container.gif" alt=""><figcaption></figcaption></figure>

Then, select the container template you want to deploy. Define a name, a network, port mapping and volumes, and toggle **Enable access control** on if needed.

<figure><img src="../../../.gitbook/assets/2.15-docker_deploy_container_nginx.png" alt=""><figcaption></figcaption></figure>

You can also make changes to container settings such as port and volume mapping, host file entries, labels and the hostname by clicking **Show advanced options**.

<figure><img src="../../../.gitbook/assets/2.15-docker_deploy_container_nginx_adv_opts.png" alt=""><figcaption></figcaption></figure>

Once you have configured the container, click **Deploy the container**.



================================================
FILE: user/docker/templates/deploy-stack.md
================================================
# Deploy a stack

Portainer lets you deploy an entire stack from either a default template or a custom template.

{% hint style="info" %}
You can also [create a template from a stack](../stacks/template.md).
{% endhint %}

From the menu expand **Templates**, select **Application** or **Custom** (depending on the template) then select the template you want to deploy. In this example we'll create a WordPress stack.

<figure><img src="../../../.gitbook/assets/2.20-templates-deploy-stack.gif" alt=""><figcaption></figcaption></figure>

Enter a name for the stack and set any required configuration values (these will differ from template to template). Toggle **Enable access control** on or off as required.

<figure><img src="../../../.gitbook/assets/2.15-docker-deploy-stack-wordpress.png" alt=""><figcaption></figcaption></figure>

Click **Deploy the stack** then wait for the deployment to finish. If the deployment is successful, the new stack will appear in the list. Select it to view the [deployment details](../stacks/edit.md).

<figure><img src="../../../.gitbook/assets/2.20-templates-deploy-stack-stacklist.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/volumes/README.md
================================================
# Volumes

A volume is a data storage area that can be mounted into a container to provide persistent storage. Unlike bind mounts, volumes are independent of the underlying OS and are fully managed by the Docker Engine.

<figure><img src="../../../.gitbook/assets/2.15-docker_volumes_volumes.png" alt=""><figcaption></figcaption></figure>

A volume with the **external** flag was created outside of Portainer, which means Portainer has limited knowledge on it compared to one created within Portainer. A label of **unused** means that Portainer cannot see any applications that are using this volume. This label may also appear on **external** resources because of the limited information available.

In Portainer you can view a list of the volumes on your environment, add new volumes and remove existing volumes.

{% content-ref url="add.md" %}
[add.md](add.md)
{% endcontent-ref %}

{% content-ref url="remove.md" %}
[remove.md](remove.md)
{% endcontent-ref %}

If you're running Docker Swarm or the Portainer Agent on your environment, you can also browse existing volumes on that environment.

{% content-ref url="browse.md" %}
[browse.md](browse.md)
{% endcontent-ref %}






================================================
FILE: user/docker/volumes/add.md
================================================
# Add a new volume

## Adding a local volume

From the menu select **Volumes** then click **Add volume**.

<figure><img src="../../../.gitbook/assets/2.15-docker_volumes_add_volume.gif" alt=""><figcaption></figcaption></figure>

Complete the information in the **Create volume** screen, using the table below as a guide.

| Field/Option    | Overview                                                            |
| --------------- | ------------------------------------------------------------------- |
| Name            | Give the volume a descriptive name.                                 |
| Driver          | Select `local`.                                                     |
| Use NFS volume  | Toggle this off.                                                    |
| Use CIFS volume | Toggle this off.                                                    |
| Deployment      | On a multi-node cluster, define the node that will hold the volume. |

<figure><img src="../../../.gitbook/assets/2.15-docker_volumes_create_volume.png" alt=""><figcaption></figcaption></figure>

When you're finished, click **Create the volume**.

## Adding an NFS volume

{% hint style="info" %}
In Portainer, you can mount an NFS volume to persist the data of your containers.
{% endhint %}

From the menu select **Volumes** then click **Add volume**.&#x20;

<figure><img src="../../../.gitbook/assets/2.15-docker_volumes_add_volume.gif" alt=""><figcaption></figcaption></figure>

Complete the information in the **Create volume** screen, using the table below as a guide.

| Field/Option    | Overview                                                            |
| --------------- | ------------------------------------------------------------------- |
| Name            | Give the volume a descriptive name.                                 |
| Driver          | Select `local`.                                                     |
| Use NFS volume  | Toggle this on.                                                     |
| Use CIFS volume | Toggle this off.                                                    |
| Deployment      | On a multi-node cluster, define the node that will hold the volume. |

<figure><img src="../../../.gitbook/assets/2.15-docker_volumes_create_volume_nfs.png" alt=""><figcaption></figcaption></figure>

Under the **NFS Settings** section, complete the following.

| Field/Option | Overview                                                              |
| ------------ | --------------------------------------------------------------------- |
| Address      | Enter the hostname or IP address of your NFS server.                  |
| NFS Version  | Select the NFS version that your NFS server uses.                     |
| Mount point  | Enter the path where the volume is mounted, for example `/mnt/nfs01`. |
| Options      | Leave the default values.                                             |

<figure><img src="../../../.gitbook/assets/2.15-docker_volumes_create_volume_nfs_settings.png" alt=""><figcaption></figcaption></figure>

When you're finished, click **Create the volume**.

## Adding a CIFS volume

{% hint style="info" %}
In Portainer, you can mount a CIFS volume to persist the data of your containers.
{% endhint %}

From the menu select **Volumes** then click **Add volume**.



Complete the information in the **Create volume** screen, using the table below as a guide.

| Field/Option    | Overview                                                            |
| --------------- | ------------------------------------------------------------------- |
| Name            | Give the volume a descriptive name.                                 |
| Driver          | Select `local`.                                                     |
| Use NFS volume  | Toggle this off.                                                    |
| Use CIFS volume | Toggle this on.                                                     |
| Deployment      | On a multi-node cluster, define the node that will hold the volume. |

<figure><img src="../../../.gitbook/assets/2.15-docker_volumes_create_volume_cifs.png" alt=""><figcaption></figcaption></figure>

Under the **CIFS Settings** section, complete the following:

| Field/Option | Overview                                    |
| ------------ | ------------------------------------------- |
| Address      | Enter the CIFS server name or IP address.   |
| Share        | Enter the name of the share resource.       |
| CIFS Version | Select the CIFS version that you are using. |
| Username     | Enter the user to authenticate.             |
| Password     | Enter the password to authenticate.         |

<figure><img src="../../../.gitbook/assets/2.15-docker_volumes_create_volume_cifs_settings.png" alt=""><figcaption></figcaption></figure>

When you're finished, click **Create the volume**.

## Adding a tmpfs volume

From the menu select **Volumes** then click **Add volume**.&#x20;

<figure><img src="../../../.gitbook/assets/2.15-docker_volumes_add_volume.gif" alt=""><figcaption></figcaption></figure>

Complete the information in the **Create volume** screen, using the table below as a guide.

| Field/Option    | Overview                                                                                                                                                                                                                                                                          |
| --------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name            | Give the volume a descriptive name.                                                                                                                                                                                                                                               |
| Driver          | Select `local`.                                                                                                                                                                                                                                                                   |
| Driver options  | Click **add driver option** then add the following name/value combinations:                                                                                                                                                                                                       |
|                 | <ul><li><p>name: <code>type</code></p><p>value: <code>tmpfs</code></p></li><li><p>name: <code>device</code></p><p>value: <code>tmpfs</code></p></li><li>name: <code>o</code></li><li>value: <code>size=100m,uid=1000</code> (customize these values to suit your needs)</li></ul> |
| Use NFS volume  | Toggle this off.                                                                                                                                                                                                                                                                  |
| Use CIFS volume | Toggle this off.                                                                                                                                                                                                                                                                  |
| Deployment      | On a multi-node cluster, define the node that will hold the volume.                                                                                                                                                                                                               |

<figure><img src="../../../.gitbook/assets/2.15-docker_volumes_create_volume_tmpfs.png" alt=""><figcaption></figcaption></figure>

When you're finished, click **Create the volume**. The volume can now be attached to a container in the same way as any other volume.

<figure><img src="../../../.gitbook/assets/2.15-docker_volumes_volume_adv_settings.png" alt=""><figcaption></figcaption></figure>

Once attached, you can confirm that the tmpfs volume has been mounted correctly within the container:

<figure><img src="../../../.gitbook/assets/2.15-docker_volumes_volume_console_exec_tmpfs.png" alt=""><figcaption></figcaption></figure>




================================================
FILE: user/docker/volumes/browse.md
================================================
# Browse a volume

{% hint style="info" %}
This feature is only available when running Docker Swarm or the Portainer Agent on the environment.
{% endhint %}

From the menu select **Volumes** then click **browse** next to the volume you want to explore.

<figure><img src="../../../.gitbook/assets/2.15-docker_volumes_volume_browse.gif" alt=""><figcaption></figcaption></figure>

You can upload files to the volume (by clicking the icon in the top right), and quickly expose them to the container without the need for a CLI. You can also download, rename and delete files in the volume.

<figure><img src="../../../.gitbook/assets/2.15-docker_volumes_volume_browser_files.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/docker/volumes/remove.md
================================================
# Remove a volume

{% hint style="danger" %}
When you delete a volume, all of the content inside the volume will be erased.
{% endhint %}

From the menu select **Volumes**, tick the checkbox next to the volume you want remove then click **Remove**.

{% hint style="info" %}
You cannot remove volumes attached to a container. If you want to do this, first remove the container then remove the volumes.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-docker_volumes_volume_remove.gif" alt=""><figcaption></figcaption></figure>

When the confirmation message appears, click **Remove**.

<figure><img src="../../../.gitbook/assets/2.15-volumes-remove-confirm.png" alt=""><figcaption></figcaption></figure>




================================================
FILE: user/edge/README.md
================================================
# Edge Compute

The following sections describe how to manage Edge Compute environments using menu options available in the Portainer Server.

{% hint style="info" %}
This functionality requires you to [enable Edge Compute](../../admin/settings/edge.md) features.
{% endhint %}

{% content-ref url="groups.md" %}
[groups.md](groups.md)
{% endcontent-ref %}

{% content-ref url="stacks/" %}
[stacks](stacks/)
{% endcontent-ref %}

{% content-ref url="jobs.md" %}
[jobs.md](jobs.md)
{% endcontent-ref %}

{% content-ref url="configurations.md" %}
[configurations.md](configurations.md)
{% endcontent-ref %}

{% content-ref url="waiting-room.md" %}
[waiting-room.md](waiting-room.md)
{% endcontent-ref %}




================================================
FILE: user/edge/configurations.md
================================================
# Edge Configurations

Edge Configurations are sets of files that can be pre-deployed to your Edge environments in order to provide dynamic configurability on each Edge environment as well as avoid storing large amounts of config files in deployment repositories.

From the menu under **Edge compute** select **Edge Configurations**.

<figure><img src="../../.gitbook/assets/2.19-edge-configurations.gif" alt=""><figcaption></figcaption></figure>

Here you can see a list of your current configurations, the Edge groups they apply to, creation and update dates, as well as the progress in pushing the configuration to your Edge environments.&#x20;

<figure><img src="../../.gitbook/assets/2.19-edge-configurations-list.png" alt=""><figcaption></figcaption></figure>

## Add a new configuration

To add a new configuration, click **Add configuration** and fill in the resulting form.

| Field/Option | Overview                                                                                                                                                                                            |
| ------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name         | Enter a name for your configuration.                                                                                                                                                                |
| Edge Groups  | Select the Edge groups this configuration will apply to.                                                                                                                                            |
| Directory    | Enter the directory on the Edge device that will be used to store the configurations. This directory should be the same on all devices, and should be writable by the user the Edge Agent runs as.  |

<figure><img src="../../.gitbook/assets/2.19-edge-configurations-name.png" alt=""><figcaption></figcaption></figure>

### Type

Next select the **Type** of configuration to deploy. When choosing the **General configuration** type, the contents of your configuration will be deployed to all devices in the selected groups in the directory specified, and the resulting configuration files will be available to all the devices in the same location.

<figure><img src="../../.gitbook/assets/2.19-edge-configurations-type-general.png" alt=""><figcaption></figcaption></figure>

Alternatively you can choose **Device specific configuration**, which will let you deploy subsets of the configuration to the devices you specify based on the Portainer Edge ID of the device.&#x20;

{% hint style="info" %}
You can find the Edge IDs for your Edge environments under **Environments**, select the environment, and note the **Edge identifier** value in the **Edge information** box. It will look like the following:

`73149964-56f4-473b-81b3-5ecdc397e490`
{% endhint %}

You can specify the **Matching rule** to match either the file name or folder name within your configuration to the Portainer Edge ID.&#x20;

<figure><img src="../../.gitbook/assets/2.19-edge-configurations-type-device-specific.png" alt=""><figcaption></figcaption></figure>

When using **file name** matching, any files in your configuration package with a filename (any extension) matching an Edge ID will be deployed to the matching remote Edge environment, in the location specified in the **Directory** field.&#x20;

When using **folder name** matching, any folders in your configuration package with a name matching an Edge ID will have their contents deployed to the matching remote Edge environment, in the location specified in the **Directory** field.

### Configuration

Finally, select a package to upload by clicking **Upload from package**. This package should be a ZIP file containing the configuration files you want to deploy on your Edge environments, with the contents structured based on the **Type** selected above.

{% hint style="info" %}
When using folder name matching, your Edge ID named folders should be in the base directory of the package file contents and not in any subdirectories.
{% endhint %}

<figure><img src="../../.gitbook/assets/2.19-edge-configurations-configuration.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Create configuration and push**. Your configuration will be uploaded to Portainer and deployed to the relevant Edge environments based on your selections.

## Using your Edge Configurations in an Edge Stack

When using Edge Configurations, your files will be available at the path you specified on the selected Edge devices. You can reference this path directly in your Edge Stack configuration to access the files within.

When using a device specific configuration, your uploaded configuration will have a file name or folder name (depending on your **Matching rule** selection) based on the Portainer Edge ID of each device. You can reference this ID in your stack files with the `PORTAINER_EDGE_ID` environment variable. For example, to mount the device-specific folder in your container on each of the devices, you can use the following syntax:

```
version: '3'

services:
  myservice:
    image: myimage:latest
    volumes:
      - /var/edge/configs/${PORTAINER_EDGE_ID}:/my-device-config
```

In this example, each Edge device the stack was deployed to would mount their specific device (based on the Portainer Edge ID) folder to the `/my-device-config` folder in the container.



================================================
FILE: user/edge/groups.md
================================================
# Edge Groups

The Edge Groups feature lets you group together Edge environments either by manually selecting them or based on their [tags](../../admin/environments/tags.md). This is useful if you manage multiple Edge environments in multiple zones.

{% hint style="info" %}
This functionality requires you to [enable Edge Compute](../../admin/settings/edge.md) features.
{% endhint %}

From the menu select **Edge Groups** then click **Add Edge group**.&#x20;

<figure><img src="../../.gitbook/assets/2.15-edge-groups.gif" alt=""><figcaption></figcaption></figure>

Give the group a descriptive name then select either **Static** or **Dynamic**:

<figure><img src="../../.gitbook/assets/2.15-edge-groups-name.png" alt=""><figcaption></figcaption></figure>

### **Option 1: Static**

This option lets you manually add environments to the group from a list. Select the required environments then click **Add edge group**.

<figure><img src="../../.gitbook/assets/2.15-edge-groups-static.png" alt=""><figcaption></figcaption></figure>

### Option 2: Dynamic

This option lets you automatically associate environments via their tags. If you choose this option you will need to refine how Edge environments are dynamically associated.

| Option        | Overview                                                                                                              |
| ------------- | --------------------------------------------------------------------------------------------------------------------- |
| Partial Match | Will associate any environments matching at least one of the selected tags (environments can have more than one tag). |
| Full Match    | Will associate any environments matching all of the selected tags.                                                    |

When you select a tag from the dropdown, environments with that tag will appear in the results.

<figure><img src="../../.gitbook/assets/2.15-edge-groups-dynamic.png" alt=""><figcaption></figcaption></figure>

Click **Add edge group** to associate the environments to the group.



================================================
FILE: user/edge/jobs.md
================================================
# Edge Jobs

{% hint style="warning" %}
This is a beta feature.
{% endhint %}

Adding an Edge job is a great way to schedule jobs in your Edge hosts. Jobs can be used to run any scripts you need, for example running a backup in a specified period of time.

{% hint style="info" %}
This functionality requires you to [enable Edge Compute](../../admin/settings/edge.md) features, and is currently only available for Docker Standalone environments that use `/etc/cron.d` for job scheduling.
{% endhint %}

{% hint style="danger" %}
Edge jobs run by modifying the crontab on the underlying host, not in a container. This means that Edge jobs can make changes to the host directly, which is very powerful but also very dangerous, so use with caution.
{% endhint %}

From the menu select **Edge Jobs** then click **Add Edge job**.

<figure><img src="../../.gitbook/assets/2.15-edge-jobs.gif" alt=""><figcaption></figcaption></figure>

Give the job a descriptive name then select one of the following options:

| Option                 | Overview                         |
| ---------------------- | -------------------------------- |
| Basic Configuration    | Select a date from the calendar. |
| Advanced Configuration | Write your own `cron` rule.      |

If you select **Recurring Edge job** also enter the **Edge job time**.

{% hint style="info" %}
The Edge job time is based on the time on the host, not the Portainer Server. Bear this in mind when scheduling jobs across time zones.
{% endhint %}

<figure><img src="../../.gitbook/assets/2.15-edge-jobs-config.png" alt=""><figcaption></figcaption></figure>

You can then use the web editor to write the script or paste a copy in.

Once your script is ready, you can choose where to deploy it. You can select [Edge Groups](groups.md) to deploy to with the **Edge Groups** dropdown.

<figure><img src="../../.gitbook/assets/2.17-edge-jobs-groups.png" alt=""><figcaption></figcaption></figure>

You can also select environments individually in **Target environments**. Click on an environment in the **Available environments** list to move it to the **Associated environments** list as a deployment target.

<figure><img src="../../.gitbook/assets/2.15-edge-jobs-targetenvs.png" alt=""><figcaption></figcaption></figure>

Once you have made your selections, click **Create edge job** to create and run the job.



================================================
FILE: user/edge/waiting-room.md
================================================
# Waiting Room

The Edge Devices Waiting room lists any Edge Devices that have connected using the pre-deploy script and are pending association with the Portainer instance. The list can be filtered by Edge Group, group, and tag.

<figure><img src="../../.gitbook/assets/2.18-edge-waitingroom.png" alt=""><figcaption></figcaption></figure>

To associate a device with your Portainer instance, tick the box next to the device and click **Associate Device**.



================================================
FILE: user/edge/stacks/README.md
================================================
# Edge Stacks

Edge Stacks is a feature that lets you deploy applications to multiple environments from a single page, regardless of their current state.&#x20;

{% hint style="info" %}
This functionality requires you to [enable Edge Compute](../../../admin/settings/edge.md) features.
{% endhint %}

The Edge Stacks page displays a list of Edge Stacks deployed across your environments and devices and includes their name, the status of the deployment across the relevant environments (acknowledged, images pre-pulled, deployments received and failed, as well as a generic status) and the creation date. You can hover over each of the bars for more detail.

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-list.png" alt=""><figcaption></figcaption></figure>

You can click on an individual stack's name to view the stack's details or edit the stack:

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-edit-stack.png" alt=""><figcaption></figcaption></figure>

You can also view details about the stack's deployment across environments on the **Environments** tab.

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-edit-environment.png" alt=""><figcaption></figcaption></figure>

## Add a new stack

From the menu select **Edge Stacks** then click **Add stack**.

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-add.gif" alt=""><figcaption></figcaption></figure>

Give the stack a descriptive name then select one or more [Edge Groups](../groups.md).

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-add-name.png" alt=""><figcaption></figcaption></figure>

In **Deployment type**, select the type of deployment you are performing.

{% hint style="info" %}
This may be auto-selected by your choice of [Edge Groups](../groups.md).
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-edge-stacks-add-deptype.png" alt=""><figcaption></figcaption></figure>

In the **Build Method**, define how to deploy your app from one of the following options:

| Option     | Overview                                                                        |
| ---------- | ------------------------------------------------------------------------------- |
| Web editor | Use the Portainer web editor to write or paste in your build file.              |
| Upload     | Upload a build file from your computer.                                         |
| Repository | Use a GitHub repo where the build file is stored.                               |
| Template   | Use an Edge stack template. Only available for the **Compose** deployment type. |

{% hint style="info" %}
You can search within the web editor at any time by pressing `Ctrl-F` (or `Cmd-F` on Mac).
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-edge-stacks-add-buildmethod.png" alt=""><figcaption></figcaption></figure>

### Registry

If your stack requires access to images in private registries, you can specify which registry to use as part of the deployment.

<figure><img src="../../../.gitbook/assets/2.15-edge-stacks-add-registry.png" alt=""><figcaption></figcaption></figure>

### Pre-pull images

By default, Docker will start containers within the stack that it already has images for, while at the same time pulling any other images it needs from the upstream registries. In some cases you may want to wait until all of the needed images are pulled to the device before starting the stack. To do this, enable the **Pre-pull images** toggle. This can also help to avoid issues when some images in a stack are unable to be pulled, leading to an incomplete or partial deployment.

<figure><img src="../../../.gitbook/assets/2.18-edge-stacks-prepull.png" alt=""><figcaption></figcaption></figure>

### Retry deployment

If a deployment of an Edge Stack fails (for example if the remote Edge environment is unavailable), by default Portainer will not try and redeploy the stack. If you wish to enable retrying of failed deployments, you can toggle **Retry deployment** to on.

<figure><img src="../../../.gitbook/assets/2.18-edge-stacks-retry.png" alt=""><figcaption></figcaption></figure>

When Retry deployment is enabled for an Edge Stack and the deployment of the Edge Stack fails, Portainer will:

1. Retry the deployment every 10 seconds for the first hour.
2. After the first hour, retry once an hour for 7 days.
3. After 7 days, Portainer will stop retrying and the Edge Stack will be given a "failed" status.

### Update configurations

This section lets you define the method in which your stack updates are deployed across your Edge devices. You can choose to deploy to **All edge devices at once**, or select **Parallel edge device(s)** to specify how many devices to update concurrently.

{% hint style="warning" %}
These settings do **not** apply to the _initial_ provision of your Edge Stack. These only apply to the process that will occur when your stack is updated _after_ deployment.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-updateconfigs.png" alt=""><figcaption></figcaption></figure>

If **Parallel edge device(s)** is selected, you can choose to either deploy in static group sizes or in an exponential rollout strategy. For static group sizes, choose the **Number of device(s)** option and specify your group size.

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-parallel-staticgroups.png" alt=""><figcaption></figcaption></figure>

For an exponential rollout, choose the **Exponential rollout** option and specify how many devices to start with, then select the multiplier to apply to the initial size. For example, selecting a start size of 5 and a multiplier of 2, stack updates would be rolled out to 5 devices, then 10 (5 x 2), then 20 (10 x 2), and so forth.

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-parallel-exponential.png" alt=""><figcaption></figcaption></figure>

When using parallel rollouts, you can also specify the **Timeout** (in minutes) before Portainer considers the update to have failed, as well as the **Update delay** (in minutes) between each group of updates are applied.&#x20;

In addition, you can define the **Update failure action** that will be taken if the update fails:&#x20;

* **Continue** will move on to the next group of devices to update.&#x20;
* **Pause** will halt the update process but will keep the update applied to any devices that have already been deployed to.&#x20;
* **Rollback** will halt the update process and roll back the update on devices already updated.

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-parallel-failureaction.png" alt=""><figcaption></figcaption></figure>

Once the configuration is completed, click **Deploy the stack**.



================================================
FILE: user/edge/stacks/add.md
================================================
# Add a new Edge Stack

From the menu select **Edge Stacks** then click **Add stack**.

<figure><img src="../../../.gitbook/assets/2.20-edge-stacks-add.gif" alt=""><figcaption></figcaption></figure>

Give the stack a descriptive name then select one or more [Edge Groups](../groups.md).

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-add-name.png" alt=""><figcaption></figcaption></figure>

In **Deployment type**, select the type of deployment you are performing.

{% hint style="info" %}
This may be auto-selected based on the environments in your choice of [Edge Groups](../groups.md).
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.20-edge-stacks-add-deploymenttype.png" alt=""><figcaption></figcaption></figure>

In the **Build Method**, define how to deploy your app from one of the following options:

| Option     | Overview                                                                        |
| ---------- | ------------------------------------------------------------------------------- |
| Web editor | Use the Portainer web editor to write or paste in your build file.              |
| Upload     | Upload a build file from your computer.                                         |
| Repository | Use a GitHub repo where the build file is stored.                               |
| Template   | Use an Edge stack template. Only available for the **Compose** deployment type. |

<figure><img src="../../../.gitbook/assets/2.20-edge-stacks-add-buildmethod.png" alt=""><figcaption></figcaption></figure>

## Web editor

Use the web editor to define the services for your deployment.

{% hint style="info" %}
You can search within the web editor at any time by pressing `Ctrl-F` (or `Cmd-F` on Mac).
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-edit-webeditor.png" alt=""><figcaption></figcaption></figure>

## Upload

Click **Select a file** to upload a file from your computer containing your stack definition.

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-add-upload.png" alt=""><figcaption></figcaption></figure>

## Repository

Enter the information about your Git repository to deploy your Edge Stack from Git.

{% hint style="warning" %}
Portainer's Git deployment functionality does not currently support the use of Git submodules. If your repository includes submodules, they will not be pulled as part of the deployment. We [hope to add support](https://github.com/orgs/portainer/discussions/9767) for submodules in a future release.
{% endhint %}

| Field/Option          | Overview                                                                                                                         |
| --------------------- | -------------------------------------------------------------------------------------------------------------------------------- |
| Authentication        | Toggle this on if your Git repository requires authentication.                                                                   |
| Git Credentials       | If the **Authentication** toggle is enabled and you have configured Git credentials, you can select them from this dropdown.     |
| Username              | Enter your Git username.                                                                                                         |
| Personal Access Token | Enter your personal access token or password.                                                                                    |
| Save credential       | Check this option to save the credentials entered above for future use under the name provided in the **credential name** field. |

{% hint style="info" %}
If you have 2FA configured in GitHub, your passcode is your password.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-add-git-auth.png" alt=""><figcaption></figcaption></figure>

| Field/Option                 | Overview                                                                                                                                                                                          |
| ---------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Repository URL               | Enter the repository URL. If you have enabled Authentication above the credentials will be used to access the repository. The below options will be populated by what is found in the repository. |
| Repository reference         | Select the reference to use when deploying the stack (for example, the branch).                                                                                                                   |
| Compose path / manifest path | Enter the path to the Compose or manifest file from the root of the repository.                                                                                                                   |
| Additional paths             | Click **Add file** to add additional files to be parsed by the build (for example, an environment-specific compose or manifest file).                                                             |
| GitOps updates               | Toggle this on to enable GitOps updates (see below).                                                                                                                                              |
| Skip TLS verification        | Toggle this on to skip the verification of TLS certificates used by your repository. This is useful if your repo uses a self-signed certificate.                                                  |

<figure><img src="../../../.gitbook/assets/2.19-stacks-add-git.png" alt=""><figcaption></figcaption></figure>

### GitOps updates

Portainer supports automatically updating your Edge Stacks deployed from Git repositories. To enable this, toggle on **GitOps updates** and configure your settings.

{% hint style="info" %}
For more detail on how automatic updates function under the hood, have a look at [this knowledge base article](https://portal.portainer.io/knowledge/how-do-automatic-updates-for-stacks-applications-work).
{% endhint %}

| Field/Option   | Overview                                                                                                                                                                                                                                                                            |
| -------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Mechanism      | Select the method to use when checking for updates:                                                                                                                                                                                                                                 |
|                | <p><strong>Polling:</strong> Periodically poll the Git repository from Portainer to check for updates to the repository.</p><p><strong>Webhook:</strong> Generate a webhook URL to add to your Git repository to trigger the update on demand (for example via GitHub actions).</p> |
| Fetch interval | If **Polling** is selected, how often Portainer will check the Git repository for updates.                                                                                                                                                                                          |
| Webhook        | When **Webhook** is selected, displays the webhook URL to use in your integration. Click **Copy link** to copy the webhook URL to the clipboard.                                                                                                                                    |

<figure><img src="../../../.gitbook/assets/2.19-stacks-add-git-polling.png" alt=""><figcaption><p>GitOps updates when using polling</p></figcaption></figure>

<figure><img src="../../../.gitbook/assets/2.19-stacks-add-git-webhook.png" alt=""><figcaption><p>GitOps updates when using webhooks</p></figcaption></figure>

|                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Re-pull image      | When **Webhook** is selected, displays the webhook URL to use in your integration. Click **Copy link** to copy the webhook URL to the clipboard.                                                                                                                                                                                                                                                                                                                                                                                                            |
| Force redeployment | <p>Enable this setting to force the redeployment of your stack at the specified interval (or when the webhook is triggered), overwriting any changes that have been made in the local environment, even if there has been no update to the stack in Git. This is useful if you want to ensure that your Git repository is the source of truth for your stacks and are happy with the local stack being replaced.</p><p>If this option is left disabled, automatic updates will only trigger if Portainer detects a change in the remote Git repository.</p> |

<figure><img src="../../../.gitbook/assets/2.19-stacks-add-git-repull-force.png" alt=""><figcaption></figcaption></figure>

### Relative path volumes

When you toggle **Enable relative path volumes** to on, you are able to specify relative path references in your compose files. Portainer will create the required directory structure and populate the directories with the relevant files from your Git repository. This feature is only available for Docker Standalone and Docker Swarm environments.

{% hint style="info" %}
If you have previously enabled [GitOps Edge configurations](add.md#gitops-edge-configurations), the filesystem path set there will be used for the relative path volumes feature as well.
{% endhint %}

On Docker Standalone environments, specify the path at which you want your files to be created on your host filesystem in the **Local filesystem path** field.

{% hint style="warning" %}
Ensure this directory exists on your local filesystem and is writable.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.17-stacks-add-relativepath.png" alt=""><figcaption></figcaption></figure>

On Docker Swarm environments, specify the path at which you want your files to be created in the **Network filesystem path** field.

{% hint style="warning" %}
Ensure that this path is available on all of your Docker Swarm nodes and is writable.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.17-stacks-add-relativepath-swarm.png" alt=""><figcaption></figcaption></figure>

{% hint style="info" %}
For more detail on how this feature works, have a look at [this article](../../../advanced/relative-paths.md).
{% endhint %}

### GitOps Edge configurations

You can also choose to deploy device-specific configurations from your Git repository to the devices your Edge stack will be deployed to. To use this, enable the **GitOps Edge configurations** toggle, enter the **Local** or **Remote filesystem path**, **Directory** (relative to the root of your Git repository) and select the **Device** or **Group matching rule** that corresponds to your configuration.

{% hint style="info" %}
If you have previously enabled [Relative path volumes](add.md#relative-path-volumes), the filesystem path set there will be used for the GitOps Edge configurations feature as well.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.20-edge-stacks-add-git-edgeconfigs.png" alt=""><figcaption></figcaption></figure>

{% hint style="info" %}
If you set both a **Device matching rule** and a **Group matching rule**, the Device matching rule will take precedence. If the Device matching rule cannot be matched (in other words, if a file or folder name matching the device name is then unable to be located), Portainer will fall back to the Group matching rule instead.
{% endhint %}

Within your Git repository at the **Directory** you define, you should have file names or folder names (depending on your **Matching rule** selection) that correspond to the Portainer Edge IDs or Edge Group for the devices you will be deploying the stack to. You can reference this ID in your stack files with the `PORTAINER_EDGE_ID` and `PORTAINER_EDGE_GROUP` environment variables.&#x20;

{% hint style="info" %}
You can find the Edge IDs for your Edge environments under **Environments**, select the environment, and note the **Edge identifier** value in the **Edge information** box. It will look like the following:

`73149964-56f4-473b-81b3-5ecdc397e490`
{% endhint %}

For example, when using folder name matching and a directory of `config` , you can use the following syntax:

```
version: '3'

services:
  myservice:
    image: myimage:latest
    volumes:
      - ./config/${PORTAINER_EDGE_ID}:/my-device-config
```

In this example, each Edge device the stack was deployed to would mount their specific device (based on the Portainer Edge ID) folder from within the `config` directory of the Git repository to the `/my-device-config` folder in the container.

If you deploy your stack to a device that does not have a file or folder with the corresponding Portainer Edge ID in the GitOps Edge configuration directory, the stack will deploy as normal but with no device specific configuration deployed.

## Template

Select an Edge Stack template to deploy from the **Template** dropdown, and make any configuration adjustments as required.

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-add-template.png" alt=""><figcaption></figcaption></figure>

## Additional settings

### Webhooks

For the Web editor, Upload and Template build methods you can choose to enable an Edge Stack webhook. This webhook will allow you to trigger updates to the stack by sending a POST request to a specific URL, instructing Portainer to pull the most up to date version of the associated image and re-deploy the stack.

{% hint style="info" %}
For Git deployed stacks, this functionality is available via [GitOps updates](add.md#gitops-updates).
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-add-webhook.png" alt=""><figcaption></figcaption></figure>

### Environment variables

As an optional step, you can also set environment variables. You can use these to define values in your compose file that would vary between deployments (for example, hostnames, database names, etc).

{% hint style="info" %}
This feature is only available on Docker Standalone and Docker Swarm environments.
{% endhint %}

Environment variables can be set individually within Portainer or you can use **Load variables from .env file** to upload a file containing your environment variables. Environment variables you define (either individually or via a .env file) will be available to use in your compose file using an `environment` definition:

```
environment:
  MY_ENVIRONMENT_VARIABLE: ${MY_ENVIRONMENT_VARIABLE}
```

Alternatively, you can add `stack.env` as an `env_file` definition to add all the environment variables that you have defined individually as well as those included in an uploaded .env file:

```
env_file:
  - stack.env
```

{% hint style="info" %}
Note the compose file is not changed when environment variables are used - this allows variables to be updated within Portainer without editing the compose file itself which would take it out of sync with the Git repository. You will still see the `${MY_ENVIRONMENT_VARIABLE}` style entry in the compose file.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-docker_stack_wed_editor_env_var.png" alt=""><figcaption></figcaption></figure>

### Registry

If your stack requires access to images in private registries, you can specify which registry to use as part of the deployment.

<figure><img src="../../../.gitbook/assets/2.15-edge-stacks-add-registry.png" alt=""><figcaption></figcaption></figure>

### Pre-pull images

By default, Docker will start containers within the stack that it already has images for, while at the same time pulling any other images it needs from the upstream registries. In some cases you may want to wait until all of the needed images are pulled to the device before starting the stack. To do this, enable the **Pre-pull images** toggle. This can also help to avoid issues when some images in a stack are unable to be pulled, leading to an incomplete or partial deployment.

<figure><img src="../../../.gitbook/assets/2.18-edge-stacks-prepull.png" alt=""><figcaption></figcaption></figure>

### Retry deployment

If a deployment of an Edge Stack fails (for example if the remote Edge environment is unavailable), by default Portainer will not try and redeploy the stack. If you wish to enable retrying of failed deployments, you can toggle **Retry deployment** to on and set **Retry for** to the length of time you want Portainer to retry deploying the stack.

<figure><img src="../../../.gitbook/assets/2.25.0-edge-stacks-retry-deployment.png" alt=""><figcaption></figcaption></figure>

When the time selected in **Retry for** is reached, Portainer will stop retrying and the Edge Stack will be given a "failed" status.

### Update configurations

This section lets you define the method in which your stack updates are deployed across your Edge devices. You can choose to deploy to **All edge devices at once**, or select **Parallel edge device(s)** to specify how many devices to update concurrently.

{% hint style="warning" %}
These settings do **not** apply to the _initial_ provision of your Edge Stack. These only apply to the process that will occur when your stack is updated _after_ deployment.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-updateconfigs.png" alt=""><figcaption></figcaption></figure>

If **Parallel edge device(s)** is selected, you can choose to either deploy in static group sizes or in an exponential rollout strategy. For static group sizes, choose the **Number of device(s)** option and specify your group size.

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-parallel-staticgroups.png" alt=""><figcaption></figcaption></figure>

For an exponential rollout, choose the **Exponential rollout** option and specify how many devices to start with, then select the multiplier to apply to the initial size. For example, selecting a start size of 5 and a multiplier of 2, stack updates would be rolled out to 5 devices, then 10 (5 x 2), then 20 (10 x 2), and so forth.

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-parallel-exponential.png" alt=""><figcaption></figcaption></figure>

When using parallel rollouts, you can also specify the **Timeout** (in minutes) before Portainer considers the update to have failed, as well as the **Update delay** (in minutes) between each group of updates are applied.&#x20;

In addition, you can define the **Update failure action** that will be taken if the update fails:&#x20;

* **Continue** will move on to the next group of devices to update.&#x20;
* **Pause** will halt the update process but will keep the update applied to any devices that have already been deployed to.&#x20;
* **Rollback** will halt the update process and roll back the update on devices already updated.

<figure><img src="../../../.gitbook/assets/2.19-edge-stacks-parallel-failureaction.png" alt=""><figcaption></figcaption></figure>

Once the configuration is completed, click **Deploy the stack**.



================================================
FILE: user/edge/templates/README.md
================================================
# Edge Templates

This section lets you configure and deploy workloads from templates to your Edge devices.

{% content-ref url="application.md" %}
[application.md](application.md)
{% endcontent-ref %}

{% content-ref url="custom.md" %}
[custom.md](custom.md)
{% endcontent-ref %}



================================================
FILE: user/edge/templates/application.md
================================================
# Application

This section lists the application templates that are available to be deployed on your Edge devices.

<figure><img src="../../../.gitbook/assets/2.20-edge-templates-application-list.png" alt=""><figcaption></figcaption></figure>

To create an Edge stack from a template, click the template in the list. You will be taken to the [Edge Stack creation page](../stacks/add.md) with the template pre-filled.

If you want to create your own [custom template](../../docker/templates/custom.md) based on an existing application template, click **Copy as Custom**.



================================================
FILE: user/edge/templates/custom.md
================================================
# Custom

This section lists the custom templates that have been created for deploying to your Edge devices.

<figure><img src="../../../.gitbook/assets/2.20-edge-templates-custom-list.png" alt=""><figcaption></figcaption></figure>

To deploy a custom template as an Edge stack, click the template in the list.

## Add a new custom template

To create a new custom template, click the **Add Custom Template** button and fill out the resulting form and stack details.

{% hint style="info" %}
For more detail on custom template creation, refer to the [custom template](../../docker/templates/custom.md#creating-a-new-custom-template) documentation.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.20-edge-templates-custom-add.png" alt=""><figcaption></figcaption></figure>

## Edit an existing template

To edit an existing custom template, click the **Edit** button for the template you want to change.&#x20;

<figure><img src="../../../.gitbook/assets/2.20-edge-templates-custom-edit.png" alt=""><figcaption></figcaption></figure>

## Remove a custom template

To remove a custom template, click the **Delete** button for the template you want to remove. This will not remove any Edge stacks that had been previously created with this template.&#x20;



================================================
FILE: user/home/README.md
================================================
# Home

The **Home** page is the first page you will see after logging into Portainer. This page provides an overview of your environments along with vital statistics about each. You can search and filter your list of environments using the options at the top of the list.

<figure><img src="../../.gitbook/assets/2.25.0-home-environments.png" alt=""><figcaption></figcaption></figure>

Your currently selected environment (if any) will be shown by the **Connected** status on the right. To choose an environment, either click on the tile for the environment or the **Live connect** or **Browse snapshot** button (for [Edge Devices in async mode](snapshot.md)). You can click the pencil icon to edit the environment's connection configuration, and the cog button to go to the environment's settings page (if the environment is directly accessible).

<figure><img src="../../.gitbook/assets/2.17-home-rightoptions.png" alt=""><figcaption></figcaption></figure>

## Build information

You can view the build information for your Portainer installation by clicking on the Portainer version number in the bottom left of the UI. This may be helpful when troubleshooting issues with the Portainer support team.

<figure><img src="../../.gitbook/assets/2.25.0-build-info.png" alt=""><figcaption></figcaption></figure>

In the box that appears you can see the server version, database version, build number and image tag, as well as the versions of the compilation tools, dependencies, and environment variables used to build Portainer.&#x20;

## Getting help

From any page in the Portainer UI, you can click on the **question mark icon** in the top right next to your username to access the related section of this documentation. You can also click the **robot icon** to start a conversation with our [AI chatbot](https://portainer.io/ask-the-ai).&#x20;

<figure><img src="../../.gitbook/assets/2.25.0-icons.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/home/openamt.md
================================================
# OpenAMT

OpenAMT allows you to remotely manage your compatible Edge devices from Portainer, letting you start, stop, restart and access the device console directly from within the Portainer UI.

## Preparation

To associate an Edge device with OpenAMT you must first add a compatible device. To do this, first [deploy the Edge Agent](../../admin/environments/add/) to your device based on the appropriate method for your environment type.

Once the Edge Agent has been set up and deployed on the remote device, the device is ready to be associated with OpenAMT.

## Associate your device

To associate an existing Edge Agent deployment with OpenAMT, from the Home page click the **Associate with OpenAMT** button.&#x20;

<figure><img src="../../.gitbook/assets/2.18-home-openamt-associate-button.png" alt=""><figcaption></figcaption></figure>

Check the box next to the device(s) you want to associate, then click the **Associate Devices** button. The activation process will now begin.

<figure><img src="../../.gitbook/assets/2.18-home-openamt-associate-dialog.png" alt=""><figcaption></figcaption></figure>

Once activation completes you will be returned to the Home page.&#x20;

## Interact with your device

Once an OpenAMT device has been associated with an Edge Device in Portainer, you are able to interact directly with that device. To do so, go to the Home page and use the options on the right hand side of the tile to interact as required.

* **Power ON**: Will power on the device if it is currently switched off.
* **Power OFF**: Will power off the device if it is currently switched on.
* **Restart**: Will initiate a restart of the device.
* **KVM**: Will open a remote KVM (keyboard, video, mouse) session with the device.



================================================
FILE: user/home/snapshot.md
================================================
# Snapshot browsing

Snapshot browsing allows the ability to run remote commands on your Edge devices that are in Async mode. You can browse your device as well as run commands like start, stop, restart, and delete on your containers, stacks and volumes.

To browse your Edge device, on the [home page](./) locate your Edge device and click the **Browse snapshot** button.

<figure><img src="../../.gitbook/assets/2.17-settings-edge-devices-browse.png" alt=""><figcaption></figcaption></figure>

You will be directed to the dashboard for the Edge device, with a **Browsing snapshot** drop down that details the last updated and next updated date, how often the snapshots are taken and the environment status.  You can refer to the [deployment sync options ](../../admin/settings/edge.md#deployment-sync-options)for more details.&#x20;

{% hint style="warning" %}
The information displayed in Portainer for your Edge device is up to date as of the time the latest snapshot (as indicated in the dropdown) was taken. Depending on the [age of the snapshot](../../admin/settings/edge.md#deployment-sync-options) and the environment, this may not be an up to date representation of the current state of the device, so bear this in mind when taking actions on the device.
{% endhint %}

<figure><img src="../../.gitbook/assets/2.16-edge_devices_browse_snaps_dashboard.png" alt=""><figcaption></figcaption></figure>

From here, you can browse the device as you would a regular environment.

<figure><img src="../../.gitbook/assets/2.16-edge_devices_browse_snaps.gif" alt=""><figcaption></figcaption></figure>

a



================================================
FILE: user/kubernetes/README.md
================================================
# Kubernetes

The following sections describe how to manage a Kubernetes environment using menu options available in the Portainer Server.

{% content-ref url="dashboard.md" %}
[dashboard.md](dashboard.md)
{% endcontent-ref %}

{% content-ref url="kubectl.md" %}
[kubectl.md](kubectl.md)
{% endcontent-ref %}

{% content-ref url="kubeconfig.md" %}
[kubeconfig.md](kubeconfig.md)
{% endcontent-ref %}

{% content-ref url="templates/" %}
[templates](templates/)
{% endcontent-ref %}

{% content-ref url="namespaces/" %}
[namespaces](namespaces/)
{% endcontent-ref %}

{% content-ref url="helm.md" %}
[helm.md](helm.md)
{% endcontent-ref %}

{% content-ref url="applications/" %}
[applications](applications/)
{% endcontent-ref %}

{% content-ref url="networking/services.md" %}
[services.md](networking/services.md)
{% endcontent-ref %}

{% content-ref url="networking/ingresses/" %}
[ingresses](networking/ingresses/)
{% endcontent-ref %}

{% content-ref url="configurations/" %}
[configurations](configurations/)
{% endcontent-ref %}

{% content-ref url="volumes/" %}
[volumes](volumes/)
{% endcontent-ref %}

{% content-ref url="cluster/" %}
[cluster](cluster/)
{% endcontent-ref %}




================================================
FILE: user/kubernetes/dashboard.md
================================================
# Dashboard

The Kubernetes dashboard summarizes your Kubernetes environment and shows the components that make up the environment.&#x20;

## Environment info

This section shows the environment name, its URL and port, along with any [tags](../../admin/environments/tags.md#tagging-an-environment).

<figure><img src="../../.gitbook/assets/2.15-kubernetes_env_info.png" alt=""><figcaption></figcaption></figure>

## Summary tiles

The remaining dashboard is made up of tiles showing the number of [namespaces](namespaces/), [applications](applications/), [services](networking/services.md), [ingresses](networking/ingresses/), ConfigMaps, secrets, and [volumes](volumes/) that make up the environment.

<figure><img src="../../.gitbook/assets/2.19-kubernetes-dashboard-tiles.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/kubernetes/helm.md
================================================
# Helm

In version 2.20 and above we moved Helm support into the [Applications](applications/) section alongside the other application creation and management methods for a more streamlined and user-friendly approach.

{% content-ref url="applications/" %}
[applications](applications/)
{% endcontent-ref %}



================================================
FILE: user/kubernetes/kubeconfig.md
================================================
# Kubeconfig

Portainer can act as a proxy for other Kubernetes management tools, providing access to the Kubernetes cluster while still retaining the security and governance that Portainer provides. A user can download their own `kubeconfig` file and use it with their favorite tool to access the Kubernetes cluster with only the permissions afforded to that user.\
\
To generate and download your `kubeconfig` file, from the Home page click the **kubeconfig** button.

{% hint style="info" %}
You must be accessing Portainer via HTTPS for the kubeconfig button to appear. If you are logged in with HTTP, you will not see the option.
{% endhint %}

<figure><img src="../../.gitbook/assets/2.15-k8s-kubeconfig.gif" alt=""><figcaption></figcaption></figure>

You will be asked to select the Kubernetes environments that you would like in your `kubeconfig` file. If you have configured a [kubeconfig expiry](../../admin/settings/#kubeconfig-expiry) value, this will also be shown.&#x20;

<figure><img src="../../.gitbook/assets/2.15-k8s-kubeconfig-confirm.png" alt=""><figcaption></figcaption></figure>

Tick the boxes for the environments you need and click **Download File**.&#x20;

A downloaded `kubeconfig` file will look something like the example below.

{% hint style="info" %}
Note that the server URL is set to the Portainer Server instance, not the Kubernetes cluster.
{% endhint %}

```yaml
apiVersion: v1
clusters:
- cluster:
    insecure-skip-tls-verify: true
    server: https://my-portainer-server:9443/api/endpoints/1/kubernetes
  name: portainer-cluster-kubernetes
contexts:
- context:
    cluster: portainer-cluster-kubernetes
    user: portainer-sa-clusteradmin
  name: portainer-ctx-kubernetes
current-context: portainer-ctx-kubernetes
kind: Config
preferences: {}
users:
- name: portainer-sa-clusteradmin
  user:
    token: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

Each environment in the `kubeconfig` will be accessible via contexts. Access is set based on the specific user that created the `kubeconfig` file.

Unless set to never expire, tokens will expire after the defined period, at which point a new `kubeconfig` file will need to be generated. An administrator can [adjust the token expiry behavior](../../admin/settings/#kubeconfig-expiry) on the **Settings** page.

{% hint style="info" %}
Adjusting the token expiry will not affect previously generated `kubeconfig` files.&#x20;
{% endhint %}




================================================
FILE: user/kubernetes/kubectl.md
================================================
# kubectl shell

Although the Portainer UI provides access to a lot of Kubernetes functionality, sometimes you need to drop into the console. We have provided a shell within the UI that includes `kubectl` and `helm` binaries. The shell is preloaded with a `kubeconfig` for the user's context, restricting access to the permissions defined in Portainer for that user.

To access the shell, select **kubectl shell** from the menu. Once the shell loads, you can run `kubectl` and `helm` commands as needed.

<figure><img src="../../.gitbook/assets/2.20-kubernetes-kubectl.gif" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/kubernetes/applications/README.md
================================================
# Applications

In Kubernetes, an application is a collection of configuration settings and variables required to run your app. This may consist of a single container or multiple containers with complex interoperability.

<figure><img src="../../../.gitbook/assets/2.27-kubernetes-applications-list.png" alt=""><figcaption></figcaption></figure>

You can filter the list of applications by namespace using the **Namespace** dropdown.

Portainer lets you add applications either using a form or through code (for example a manifest or a Helm chart):

{% content-ref url="add.md" %}
[add.md](add.md)
{% endcontent-ref %}

{% content-ref url="manifest.md" %}
[manifest.md](manifest.md)
{% endcontent-ref %}

You can also inspect a running application:

{% content-ref url="inspect.md" %}
[inspect.md](inspect.md)
{% endcontent-ref %}

{% content-ref url="inspect-helm.md" %}
[inspect-helm.md](inspect-helm.md)
{% endcontent-ref %}

Applications can be edited, webhooks can be configured and volumes can be detached:

{% content-ref url="edit.md" %}
[edit.md](edit.md)
{% endcontent-ref %}

{% content-ref url="webhooks.md" %}
[webhooks.md](webhooks.md)
{% endcontent-ref %}

{% content-ref url="detach-volume.md" %}
[detach-volume.md](detach-volume.md)
{% endcontent-ref %}

If you no longer require an application, it can be removed:

{% content-ref url="remove.md" %}
[remove.md](remove.md)
{% endcontent-ref %}



================================================
FILE: user/kubernetes/applications/add.md
================================================
# Add a new application using a form

There are two ways to add a new application: manually by using a form, or automatically by [using code](manifest.md). This article explains how to add an application using a form.

<figure><img src="../../../.gitbook/assets/2.24.0-kubernetes-applications-form-add.gif" alt=""><figcaption></figcaption></figure>

Complete the required information, using the sections below as a guide.

### Base configuration

| Field/Option | Overview                                                                                                                                                                                                      |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Namespace    | Select the namespace where the application will reside.                                                                                                                                                       |
| Name         | Give the application a descriptive name.                                                                                                                                                                      |
| Registry     | Select the registry to pull the image from. If you want to pull from a registry that is not configured with Portainer, click **Advanced mode** then enter the URL and image manually.                         |
| Image        | Enter the name (and optionally the tag) of the image that will be used to deploy the application.                                                                                                             |
| Note         | Enter a note to provide additional details about the application. This field is mandatory if the [Require a note on applications](../../../admin/settings/#deployment-options) toggle is enabled in Settings. |
| Annotations  | You can add annotations to your application as required by clicking **Add annotation** and filling in the **Key** and **Value** fields.                                                                       |
| Stack        | Portainer can automatically bundle multiple applications inside a stack. You can either enter the name of a new stack, select an existing stack from the list, or leave empty to use the application name.    |

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-add-base.png" alt=""><figcaption></figcaption></figure>

### Environment variables

Here you can define any environment variables you wish to be available to your application.

<figure><img src="../../../.gitbook/assets/2.18-k8s-applications-add-envvar.png" alt=""><figcaption></figcaption></figure>

### ConfigMaps

Select any ConfigMaps you have previously created to make them available to the application. Portainer will automatically expose all the keys of a ConfigMap as environment variables. This behavior can be overridden to filesystem mounts for each key via the **Override** button.

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-applications-add-form-configmaps.png" alt=""><figcaption></figcaption></figure>

### Secrets

Select any secrets you have previously created to make them available to the application. Portainer will automatically expose all the keys of a secret as environment variables. This behavior can be overridden to filesystem mounts for each key via the **Override** button.

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-applications-add-form-secrets.png" alt=""><figcaption></figcaption></figure>

### Persisted folders

Define any persistent folders within the application and whether these are new or existing volumes, as well as the size of the volume and storage location.

You can also define the **Data access policy** for your persisted folders:

* **Isolated:** Each instance of the application will use its own data.
* **Shared**: All application instances will use the same data.

<figure><img src="../../../.gitbook/assets/2.18-k8s-applications-add-persisted.png" alt=""><figcaption></figcaption></figure>

### Resource reservations

In this section you can define the amount of **memory** and **CPU** available to the application. If the namespace you have selected has resource quotas set, you must define these values.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-add-resource.png" alt=""><figcaption></figcaption></figure>

### Deployment

This section allows you to choose how you want to deploy the application inside the cluster. Options are:

* **Replicated:** Run one or multiple instances of this container.
* **Global:** Deploy an instance of this container on each cluster node.

You can also define the number of instances of the application to run by setting the **Instance count**.

<figure><img src="../../../.gitbook/assets/2.15-kubernetes_applications_add_form_deployment.png" alt=""><figcaption></figcaption></figure>

Toggle **Enable auto scaling for this application** to enable auto-scaling for the application you are deploying. This requires that the Kubernetes metrics server is installed and [enabled in the cluster setup](../cluster/setup.md#resources-and-metrics).

| Field/Option      | Overview                                                                                                                                                                                |
| ----------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Minimum instances | Enter the minimum number of instances that you want running for this application.                                                                                                       |
| Maximum instances | Enter the maximum number of instances that you want running for this application.                                                                                                       |
| Target CPU usage  | Enter the target CPU percentage for your application. The autoscaler will ensure that enough instances are running to maintain an average CPU usage of this value across all instances. |

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-add-autoscaling.png" alt=""><figcaption></figcaption></figure>

### Placement preferences and constraints

Here you can define which placement rules must be followed by the nodes where the application is deployed to. Placement rules are based on node labels. To create a new rule, click **add rule**.

You can also define the placement policy for the rules you have set. Options are:

* **Mandatory:** The application will only be scheduled on nodes that follow all rules.
* **Preferred**: If possible, the application will be scheduled on nodes that follow all rules.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-add-placementprefs.png" alt=""><figcaption></figcaption></figure>

### Publishing the application

Here you can create the necessary services to expose your application. Select the type of service (ClusterIP, NodePort, or LoadBalancer) from the tabs and click **Create service**. You can then configure each service as required, including adding annotations to the services if required.

{% hint style="info" %}
You can expand the **Explanation** link for more detail on how each service type works.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-applications-add-publishing.png" alt=""><figcaption></figcaption></figure>

When you have finished, click **Deploy application**.



================================================
FILE: user/kubernetes/applications/detach-volume.md
================================================
# Detach a volume from an application

From the menu select **Applications**, select the application then click **Edit this application**.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-edit.gif" alt=""><figcaption></figcaption></figure>

Scroll down to the **Persisting data** section and click the trash can icon to the right of the volume. Scroll down and click **Update application**. When the confirmation message appears, click **Update**.

<figure><img src="../../../.gitbook/assets/2.15-k8s-applications-detach-confirm.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/kubernetes/applications/edit.md
================================================
# Edit an application

From the menu select **Applications**, select the application you want to edit, then click **Edit this application**.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-edit.gif" alt=""><figcaption></figcaption></figure>

Your editing options will depend on how the application was deployed initially.

{% hint style="info" %}
Regardless of the deployment method, you can [edit an application's YAML directly](inspect.md#yaml-tab) through the YAML tab in Portainer Business Edition.
{% endhint %}

## Applications deployed from Git

If the application was [deployed from a Git repository](manifest.md#repository) you can redeploy it from the repository if needed. You will see the repository URL that the application was deployed from, the current version deployed, and the file used for the deployment.

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-applications-edit-git-info.png" alt=""><figcaption></figcaption></figure>

You can reconfigure GitOps updates, the repository reference and authentication here if needed. If a change window is enabled, information on it will appear here as well.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-edit-gitops.png" alt=""><figcaption></figcaption></figure>

If you want to redeploy, click **Pull and update application**. If you're simply updating the repository settings and don't need to redeploy, click **Save settings**.

## Applications deployed from the Web Editor

If the application was deployed from the Web Editor, you will be given the ability to edit the manifest manually.&#x20;

{% hint style="info" %}
You can search within the web editor at any time by pressing `Ctrl-F` (or `Cmd-F` on Mac).
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-edit-webeditor.png" alt=""><figcaption></figcaption></figure>

Make the required changes then click **Update application**.

## Applications deployed from a form or Helm

When editing an application deployed from a form or Helm, you will be able to update the configuration using the same form. Refer to [adding a new application using a form](add.md) for details.




================================================
FILE: user/kubernetes/applications/inspect-helm.md
================================================
# Inspect a Helm application

To view information about Helm applications running in a cluster, from the menu select **Applications** then select the Helm application you want to inspect.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-inspect-helm.gif" alt=""><figcaption></figcaption></figure>

You will be shown details about the Helm application including the name, chart used for the deployment, and the application version.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-inspect-helm-details.png" alt=""><figcaption></figcaption></figure>

To view information about a specific deployment within a Helm application, from the **Applications** page expand the Helm application by clicking the arrow to the left of the application name then click the name of a deployment within the application.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-inspect-helm-deployment.gif" alt=""><figcaption></figcaption></figure>

Here you can view full details of the individual deployment within the Helm application.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-inspect-helm-deployment-details.png" alt=""><figcaption></figcaption></figure>

For more detail on the contents of this page, refer to [Inspect an application](inspect.md).



================================================
FILE: user/kubernetes/applications/inspect.md
================================================
# Inspect an application

To view information about applications running in a cluster, from the menu select **Applications** then select the application you want to inspect.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-inspect.gif" alt=""><figcaption></figcaption></figure>

The **Application details** screen is organized into four sections. The following tables explain all of the information to be found in each.

## Application tab

| Attribute        | Overview                                                                                                                             |
| ---------------- | ------------------------------------------------------------------------------------------------------------------------------------ |
| Name             | The name of the application.                                                                                                         |
| Stack            | The stack that the application belongs to (if any).                                                                                  |
| Namespace        | The namespace that the application is running in.                                                                                    |
| Application Type | The type of application (Pod, Deployment, StatefulSet, DaemonSet, etc).                                                              |
| Status           | Indicates whether or not the application is running. Where applicable, this also shows the replication state and number of replicas. |
| Creation         | Shows when the application was created and by whom, as well as how the application was deployed.                                     |
| Note             | Add a note about the application or edit an existing note.                                                                           |

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-inspect-application.png" alt=""><figcaption></figcaption></figure>

## Placement tab

Here you'll find information about any placement constraints or preferences that have been defined for the application and how they're being applied.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-inspect-placement.png" alt=""><figcaption></figcaption></figure>

## Events tab

Shows information about application-related events.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-inspect-events.png" alt=""><figcaption></figcaption></figure>

## YAML tab

This displays the YAML generated from the application deployment, and lets you edit the YAML for an application directly. Updates to your manifest made here are applied using the Kubernetes `patch` mechanism.&#x20;

{% hint style="info" %}
Editing your YAML through this section is only available in Portainer Business Edition.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-inspect-yaml.png" alt=""><figcaption></figcaption></figure>

Make your edits then click **Apply changes** to update the deployment.

{% hint style="warning" %}
Editing the YAML is not available for resources in namespaces marked as system.
{% endhint %}

## Actions

Depending on how the application was deployed, a number of actions can be performed, including:

* [Editing the application](edit.md).
* Perform a rolling restart of the application (Business Edition only).
* Redeploying the application (terminating all the services and recreating them).
* Rolling the application back to a previous configuration.
* Creating a [template](../templates/) from the application.

{% hint style="info" %}
When using a Git repository, the rolling restart and redeploy options do not re-pull the manifest from the upstream repository. To do this, use the **Pull and update application** button when [editing an application](edit.md#method-1-redeploy-from-git).
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.17-k8s-applications-inspect-actions.png" alt=""><figcaption><p>Some of the potential actions that may appear for your application</p></figcaption></figure>

### Configuration details

| Configuration                                | Overview                                                                                                |
| -------------------------------------------- | ------------------------------------------------------------------------------------------------------- |
| Accessing the application                    | Shows which ports (if any) are published from the container.                                            |
| Auto-scaling                                 | Indicates the application's auto-scaling policy.                                                        |
| Environment variables, ConfigMaps or Secrets | A list of any environment variables, ConfigMaps and secrets that have been defined for the application. |
| Data persistence                             | A list of the persistent folders and their details.                                                     |

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-inspect-configdetails.png" alt=""><figcaption></figcaption></figure>

## Application containers

See which pods run your application, which image is being used, the status, node, and IP address of the pod, and when each pod was created. You can also access the pod stats, console and logs from here.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-inspect-appcontainers.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/kubernetes/applications/manifest.md
================================================
# Add a new application using code

There are two ways to add a new application: [manually by using a form](add.md) or automatically by using code. This article explains how to add an application using code.

{% hint style="info" %}
Creating from code isn't just for applications - you can also deploy namespaces, ingresses, ConfigMaps, secrets, volumes and more using code.
{% endhint %}

First, from the left hand menu select **Applications** then click **Create from code**.

<figure><img src="../../../.gitbook/assets/2.24.0-kubernetes-applications-manifest-add.gif" alt=""><figcaption></figcaption></figure>

Next, select your deployment method from the **Deploy from** section.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-manifest-deployfrom.png" alt=""><figcaption></figcaption></figure>

Then, select the namespace to deploy to and optionally provide a stack name for your deployment in the **Deploy to** section.

{% hint style="info" %}
If you want to use namespaces defined in your manifest, you can leave **Namespace** set to `default` and toggle on the **Use namespace(s) specified from manifest** option. This option is not available for deployments from Helm charts.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-manifest-namespace.png" alt=""><figcaption></figcaption></figure>

Your next options will depend on the deployment method you selected.

## Web editor

Use the Web editor to write or paste in your Kubernetes manifest.&#x20;

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-manifest-webeditor.png" alt=""><figcaption></figcaption></figure>

{% hint style="info" %}
You can search within the web editor at any time by pressing `Ctrl-F` (or `Cmd-F` on Mac).
{% endhint %}

When you're ready, click **Deploy**. &#x20;

## URL

Enter the **URL** to your manifest file in the provided field.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-manifest-url.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Deploy**.

## Repository

Use the provided fields to enter the details of your Git repository containing your Kubernetes manifests.

{% hint style="warning" %}
When an application is deployed from Git, Portainer will clone the entire Git repository as part of the deployment process. Ensure you have enough free space to accommodate this.
{% endhint %}

{% hint style="warning" %}
Portainer's Git deployment functionality does not currently support the use of Git submodules. If your repository includes submodules, they will not be pulled as part of the deployment. We [hope to add support](https://github.com/orgs/portainer/discussions/9767) for submodules in a future release.
{% endhint %}

| Field/Option          | Overview                                                                                                                                                                  |
| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Authentication        | Toggle this on if your repository requires authentication.                                                                                                                |
| Git Credentials       | If the **Authentication** toggle is enabled and you have [configured Git credentials](../../account-settings.md#git-credentials), you can select them from this dropdown. |
| Username              | Enter your Git username.                                                                                                                                                  |
| Personal Access Token | Enter your personal access token or password.                                                                                                                             |
| Save credential       | Check this option to save the credentials entered above for future use under the name provided in the **credential name** field.                                          |

<figure><img src="../../../.gitbook/assets/2.16-stacks-add-gitcreds.png" alt=""><figcaption></figcaption></figure>

| Field/Option          | Overview                                                                                                                                                                                          |
| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Repository URL        | Enter the repository URL. If you have enabled Authentication above the credentials will be used to access the repository. The below options will be populated by what is found in the repository. |
| Skip TLS Verification | Toggle this on to skip the verification of TLS certificates used by your repository. This is useful if your repo uses a self-signed certificate.                                                  |
| Repository reference  | Select the reference to use when deploying the stack (for example, the branch).                                                                                                                   |
| Manifest path         | Enter the path to your manifest file relative to the root of your repository.                                                                                                                     |
| Additional paths      | Click **Add file** to define additional manifests or compose files to process as part of the deployment.                                                                                          |
| GitOps updates        | Toggle this on to enable GitOps updates (see below).                                                                                                                                              |

<figure><img src="../../../.gitbook/assets/2.24.0-kubernetes-applications-manifest-git.png" alt=""><figcaption></figcaption></figure>

### GitOps updates

Enabling GitOps updates gives Portainer the ability to update your application automatically, either by polling the repository at a defined interval for changes or by using a webhook to trigger an update.

{% hint style="info" %}
For more detail on how GitOps updates function under the hood, have a look at [this knowledge base article](https://portal.portainer.io/knowledge/how-do-automatic-updates-for-stacks-applications-work).
{% endhint %}

{% hint style="warning" %}
If your application is configured for GitOps updates and you make changes locally, these changes will be overridden by the application definition in the Git repository. Bear this in mind when making configuration changes.
{% endhint %}

| Field/Option   | Overview                                                                                                                                                                                                                                                    |
| -------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Mechanism      | Choose from **Polling** or **Webhook**.                                                                                                                                                                                                                     |
| Fetch interval | When using the **Polling** method, choose how often you wish to check the Git repository for updates to your application.                                                                                                                                   |
| Webhook        | <p>When using the <strong>Webhook</strong> method, this displays the webhook URL to use. Click <strong>Copy link</strong> to copy the webhook to your clipboard.<br>For more on webhooks, refer to the <a href="webhooks.md">webhook documentation</a>.</p> |

<figure><img src="../../../.gitbook/assets/2.19-stacks-add-git-polling.png" alt=""><figcaption><p>GitOps updates using the polling mechanism</p></figcaption></figure>

<figure><img src="../../../.gitbook/assets/2.19-stacks-add-git-webhook.png" alt=""><figcaption><p>GitOps updates using the webhook mechanism</p></figcaption></figure>

| Field/Option          | Overview                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| --------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Always apply manifest | <p>Enable this setting to force the redeployment of your application (kubectl apply) at the specified interval (or when the webhook is triggered), overwriting any changes that have been made in the local environment, even if there has been no update to the application in Git. This is useful if you want to ensure that your Git repository is the source of truth for your applications and are happy with the local application being replaced.</p><p></p><p>If this option is left disabled, automatic updates will only trigger if Portainer detects a change in the remote Git repository.</p> |

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-ingress-add-manifest-git-alwaysapply.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Deploy**.

## Custom template

From the **Template** dropdown, select the custom template to use. Depending on the template, you may need (or be able) to set template variables that will adjust the deployment configuration. As an optional step, you can edit the template before deploying the application. If you have no custom templates you will be given a link to the [Custom Templates](../templates/) section.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-manifest-customtemplate.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Deploy**.

## Helm chart

Once you have selected a namespace for your Helm deployment you will need to specify a **Name** for your deployment. Then select a chart to use from the list provided. You can search within the list and filter by category.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-manifest-helm-select.png" alt=""><figcaption></figcaption></figure>

Once you have selected a chart, Portainer will import the `values.yaml` file for the chart so you can configure any parameters required for the application. You can click the **Show custom values** option to expand the Web editor to make any changes.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-manifest-helm-webeditor.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Install**.



================================================
FILE: user/kubernetes/applications/remove.md
================================================
# Remove an application

From the menu select **Applications**, tick the checkbox next to the application you want to remove then click **Remove**.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-remove.gif" alt=""><figcaption></figcaption></figure>

When the confirmation message appears, click **Remove**.

<figure><img src="../../../.gitbook/assets/2.15-k8s-applications-remove-confirm.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/kubernetes/applications/webhooks.md
================================================
# Webhooks

A webhook is a POST request sent to a URL. Use webhooks to trigger an action in response to an event such as a repository push.

{% hint style="info" %}
This functionality is only available in [Portainer Business Edition](https://www.portainer.io/business-upsell?from=stack-webhook).
{% endhint %}

{% hint style="info" %}
Webhooks are only available on non-Edge environments (environments running Portainer Server or Portainer Agent, not the Portainer Edge Agent). This is because the tunnel to the Portainer Edge Agent is only opened on-demand, and therefore would mean there is no way to expose a webhook permanently.
{% endhint %}

## Enabling an application webhook

From the menu select **Applications** then select the application that you want to configure the webhook for. Then select the **Edit this application** button.

{% hint style="info" %}
Webhooks are only available for applications deployed from a Git repository.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-applications-webhooks.gif" alt=""><figcaption></figcaption></figure>

Enable **GitOps updates** if it is not already enabled and select `Webhook` as the **Mechanism**. When the URL appears, click **Copy link**. This is the URL used to trigger the webhook.

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-applications-webhooks-git.png" alt=""><figcaption></figcaption></figure>

This example shows how to trigger the webhook:

```
<form action="https://portainer:9443/api/stacks/webhooks/40ac1662-47c3-4a8e-b148-2a34eb52bb42" method="post">
  Redeploy application <input type="submit" />
</form>
```

## Using environment variables with webhooks

When triggering a webhook, environment variables can be passed through the endpoint and referenced within the deployment.

{% hint style="info" %}
Environment variables can not be updated for Pods, only for Deployments.
{% endhint %}

To specify an environment variable on a webhook, add it as a variable to the URL. For example, to pass a `SERVICE_TAG` variable with the value `development`:

```
https://portainer:9443/api/stacks/webhooks/40ac1662-47c3-4a8e-b148-2a34eb52bb42?SERVICE_TAG=development
```

To reference the `SERVICE_TAG` variable in your manifest with a fallback to the value `stable`:

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 2
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
        env:
        - name: SERVICE_TAG 
          value: "stable"
```

{% hint style="warning" %}
Environment variables must already be defined in the manifest - new environment variables cannot be added via the webhook.
{% endhint %}

## Rolling restarts

When using an application's webhook to redeploy your application, you can tell Portainer to perform a rolling restart of the application rather than a "terminate and restart" redeploy.

{% hint style="info" %}
This functionality is only available in Portainer Business Edition.
{% endhint %}

To specify this, use the `rollout-restart` parameter in your webhook call:

```
https://portainer:9443/api/stacks/webhooks/40ac1662-47c3-4a8e-b148-2a34eb52bb42?rollout-restart=all
```

&#x20;Valid options are as below:

| Option                                                          | Overview                                                                                                                                                                                                                                                                                                                                                                    |
| --------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `rollout-restart=all`                                           | All of the application's deployments will be redeployed as a rolling restart.                                                                                                                                                                                                                                                                                               |
| `rollout-restart=deployment/deployment1,deployment/deployment2` | <p>Only the specified deployment(s) will be redeployed as a rolling restart. All other deployments will not be redeployed or restarted. Separate multiple deployments with commas.<br>This option supports Deployments (<code>deployment/deployment1</code>), DaemonSets (<code>daemonset/daemonset1</code>), and StatefulSets (<code>statefulset/statefulset1</code>).</p> |

If the `rollout-restart` parameter is not defined, the webhook will redeploy the application in traditional "terminate and restart" behavior.

{% hint style="warning" %}
If your cluster has a [change window](../cluster/setup.md#change-window-settings) enabled, the rolling restart will only be performed within the change window.
{% endhint %}



================================================
FILE: user/kubernetes/cluster/README.md
================================================
# Cluster

This section provides information and management for your Kubernetes cluster.

{% content-ref url="details.md" %}
[details.md](details.md)
{% endcontent-ref %}

{% content-ref url="node.md" %}
[node.md](node.md)
{% endcontent-ref %}

{% content-ref url="setup.md" %}
[setup.md](setup.md)
{% endcontent-ref %}

{% content-ref url="security.md" %}
[security.md](security.md)
{% endcontent-ref %}

{% content-ref url="registries.md" %}
[registries.md](registries.md)
{% endcontent-ref %}






================================================
FILE: user/kubernetes/cluster/details.md
================================================
# Details

A cluster is a collection of nodes that runs containerized workloads. Portainer lets you keep track of your cluster and its individual nodes, including resource usage and configuration.

From the menu expand the **Cluster** section and select **Details**.&#x20;

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-cluster-details.gif" alt=""><figcaption></figcaption></figure>

The following information is provided:

| Attribute          | Overview                                                                                                                                                    |
| ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Memory reservation | The amount of memory available to the cluster.                                                                                                              |
| Memory used        | The amount of memory used by the cluster. This is only visible if you have [enabled using the metrics API](setup.md#enable-features-using-the-metrics-api). |
| CPU reservation    | The amount of CPU that has been reserved in the cluster.                                                                                                    |
| CPU used           | The amount of CPU used by the cluster. This is only visible if you have [enabled using the metrics API](setup.md#enable-features-using-the-metrics-api).    |

<figure><img src="../../../.gitbook/assets/2.27-kubernetes-cluster-details-resource-reservation.png" alt=""><figcaption></figcaption></figure>

## Omni cluster management

{% hint style="info" %}
This section only appears when the environment is a [Talos Kubernetes cluster provisioned by Portainer through Omni](../../../admin/environments/add/kube-create/omni.md).
{% endhint %}

In this section you can see and update the versions of Kubernetes and Talos on your Talos Kubernetes cluster provisioned by Portainer.

{% hint style="warning" %}
This functionality is in beta and only tested with some configurations.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.26-kubernetes-cluster-details-omni.png" alt=""><figcaption></figcaption></figure>

## MicroK8s cluster management

{% hint style="info" %}
This section only appears when the environment is a MicroK8s cluster provisioned via the [Create a Kubernetes cluster](../../../admin/environments/add/kube-create/microk8s/) functionality.
{% endhint %}

In this section you can see and make changes to the configuration of your MicroK8s cluster provisioned by Portainer.

{% hint style="warning" %}
This functionality is in beta and only tested with some configurations. Refer to our [known issues knowledge base article](https://portal.portainer.io/knowledge/microk8s-known-issues) for caveats when using this feature.
{% endhint %}

| Field/Option                        | Overview                                                                                                                                                                                                                                                                                                                    |
| ----------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Kubernetes version                  | <p>Displays the version of Kubernetes that is running on your cluster.<br>If a newer version of Kubernetes is available, you can click the <strong>Upgrade</strong> button to upgrade your cluster to the version specified. Note that upgrading may cause your cluster to be unavailable while the upgrade processes. </p> |
| Required addons (already installed) | Displays a list of the already installed required addons for your cluster.                                                                                                                                                                                                                                                  |
| Optional addons                     | Displays the optional addons (if any) that are installed on your cluster, as well as any arguments that were used in their configuration. You can adjust the arguments for the addons here, click the **Add addon** button to add additional addons, or click the trash can icon next to an addon to remove it.             |

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-cluster-microk8s.png" alt=""><figcaption></figcaption></figure>

Click the **Apply Changes** button to apply any adjustments you have made to addon configurations, or **Cancel** to revert your changes.

## Nodes

This section lists the nodes in your cluster with information about each node. To view [details of a specific node](node.md), click the name of the node in the list.&#x20;

<figure><img src="../../../.gitbook/assets/2.27-kubernetes-details-nodes-list.png" alt=""><figcaption></figcaption></figure>

The **Conditions** column shows any conditions that are currently active on the node. If no conditions are displayed, this indicates the node is healthy. Any active conditions (DiskPressure, MemoryPressure, PIDPressure, NetworkUnavailable) will be displayed for the particular node.

To view usage stats for a node, click the stats icon to the right of the node.

{% hint style="info" %}
Node stats are only available when you have [enabled using the metrics API](setup.md#enable-features-using-the-metrics-api).
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.17-k8s-cluster-nodestats.png" alt=""><figcaption></figcaption></figure>

On Talos Kubernetes or MicroK8s environments provisioned with the [Create a Kubernetes cluster](../../../admin/environments/add/kube-create/) feature, you will also see buttons to add and remove nodes as well as additional action icons on MicroK8s environments to view the MicroK8s status (for control plane nodes) and to connect to the environment via SSH console.

If you need to adjust elements of your Kubernetes configuration you can do so by selecting **Setup** in the left menu.

{% content-ref url="setup.md" %}
[setup.md](setup.md)
{% endcontent-ref %}

If you would like to define security constraints on the pods in your environment, select **Security constraints**.

{% content-ref url="security.md" %}
[security.md](security.md)
{% endcontent-ref %}




================================================
FILE: user/kubernetes/cluster/node.md
================================================
# Inspect a node

To view details of an individual node in your cluster, from the menu expand **Cluster** and select **Details**, then scroll down and click on the name of the node you want to inspect.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-cluster-node-inspect.gif" alt=""><figcaption></figcaption></figure>

Information about the cluster is separated into two screen tabs.

## Node

The **Node** tab summarizes the following information about the selected node:

| Field/Option    | Overview                                                                               |
| --------------- | -------------------------------------------------------------------------------------- |
| Hostname        | The hostname of the node.                                                              |
| Kubernetes API  | The address and port of the Kubernetes API for this node.                              |
| Role            | The role of the node.                                                                  |
| Kubelet version | The version of kubelet on the node.                                                    |
| Creation date   | The date when this node was created.                                                   |
| Status          | The status of the node.                                                                |
| Availability    | Defines the availability of the node. Options are **Active**, **Pause** and **Drain**. |

<figure><img src="../../../.gitbook/assets/2.15-k8s-cluster-node-details.png" alt=""><figcaption></figcaption></figure>

### Resource reservation

This section provides details about resource reservations assigned on the node as well as the node's resource usage.&#x20;

{% hint style="info" %}
**Memory used** and **CPU used** are only displayed if you have [enabled using the metrics API](setup.md#enable-features-using-metrics-server).
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-k8s-cluster-node-resource.png" alt=""><figcaption></figcaption></figure>

### Labels

This section lists the labels that apply to the node. You can add additional labels if required, as well as edit non-system labels.

<figure><img src="../../../.gitbook/assets/2.15-k8s-cluster-node-labels.png" alt=""><figcaption></figcaption></figure>

### Taints

In this section you can add taints to prevent certain pods being deployed on the node.

<figure><img src="../../../.gitbook/assets/2.15-k8s-cluster-node-taints.png" alt=""><figcaption></figcaption></figure>

## Events

Shows information about node-related events.

<figure><img src="../../../.gitbook/assets/2.15-k8s-cluster-node-events.png" alt=""><figcaption></figcaption></figure>

## Applications running on this node

This section provides information about the applications running on the selected node. Clicking the application name will take you to the application details page for that application.

<figure><img src="../../../.gitbook/assets/2.15-k8s-cluster-node-apps.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/kubernetes/cluster/registries.md
================================================
# Registries

**Registries** lets you manage access to each of the registries that are currently available.

{% hint style="warning" %}
Registry access assigned here only applies to the selected environment. It is not global.
{% endhint %}

## Adding a new registry

From the menu expand **Cluster**, select **Registries** then click **Add registry**. When the global registries page appears, follow [these instructions](../../../admin/registries/add/).

<figure><img src="../../../.gitbook/assets/2.15-k8s-cluster-registries-add.gif" alt=""><figcaption></figcaption></figure>

## Managing access

To configure access to a registry, from the menu expand **Cluster** then select **Registries**.

<figure><img src="../../../.gitbook/assets/2.15-k8s-cluster-registries.gif" alt=""><figcaption></figcaption></figure>

Find the registry you want to manage then select **Manage access**.&#x20;

<figure><img src="../../../.gitbook/assets/2.15-k8s-cluster-registries-manage.png" alt=""><figcaption></figcaption></figure>

From the dropdown, select the namespaces that you would like to have access, then click **Create access**.

<figure><img src="../../../.gitbook/assets/2.15-k8s-cluster-registries-createaccess.png" alt=""><figcaption></figcaption></figure>

You can see a list of the namespaces that have access to the registry or remove a namespace's access to the registry in the **Access** section.

<figure><img src="../../../.gitbook/assets/2.15-k8s-cluster-registries-access.png" alt=""><figcaption></figcaption></figure>

## Browsing a registry

The registry manager extends your container management experience by giving you the ability to browse defined registries and manipulate their content. By using this feature, container users enjoy the benefit of having a single interface to manage any Docker registry deployment, providing a consistent look and feel across any provider.

{% hint style="info" %}
Your registry must support Docker Registry API v2 in order to integrate with Portainer.
{% endhint %}

Select **Browse** next to the registry that you want to browse.

A list of the repositories within a registry, along with the number of tags for each repository appears. Select a repository to view its details.

<figure><img src="../../../.gitbook/assets/2.15-k8s-cluster-registries-browse.png" alt=""><figcaption></figcaption></figure>

The **Repository information** page provides the repository name, tag and image count, as well as a list of all tags. You can retag an image in order to promote it through the deployment lifecycle, or simply add or remove tags to annotate changes or usage.

This page also provides an option to clean up unused legacy images by safely deleting them. You can also remove the entire repository.

{% hint style="info" %}
The actions you can perform on a registry may be limited by the role of your user.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.15-registries-browse-repo-detail.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/kubernetes/cluster/security.md
================================================
# Security constraints

Pod security policies can be used to define under what conditions workloads can run. With Portainer we achieve this by leveraging [Open Policy Agent](https://www.openpolicyagent.org/) via [OPA Gatekeeper](https://github.com/open-policy-agent/gatekeeper).&#x20;

Policies are configured on a per-environment basis. To enable and configure security policies, from the menu select a Kubernetes environment, then expand **Cluster** and click **Security constraints**.

{% hint style="danger" %}
This is advanced functionality and should be applied with caution. If a deployment attempts to create a pod that does not meet defined security constraints it may not be immediately obvious that the constraint is the reason for provision failure.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-cluster-security.gif" alt=""><figcaption></figcaption></figure>

Toggle on **Enable pod security constraints** to enable the functionality, then toggle on the features you require and configure them as needed.

{% hint style="info" %}
Policies are based on the [Kubernetes security policy reference](https://v1-21.docs.kubernetes.io/docs/concepts/policy/pod-security-policy/#policy-reference) - for more detail on each option check the Kubernetes documentation.
{% endhint %}

<table><thead><tr><th width="370">Field/Option</th><th>Overview</th></tr></thead><tbody><tr><td>Restrict running privileged containers</td><td>Set whether any container in a pod can enable privileged mode.</td></tr><tr><td>Restrict host namespace</td><td>Controls whether the pod containers can share the process ID namespace and host IPC namespace.</td></tr><tr><td>Restrict host networking ports</td><td>Define a range of ports that can be used by pods, on a per-network basis.</td></tr><tr><td>Restrict volume types</td><td>Define the types of volumes that may be used. Examples of volume types are <code>configMap</code>, <code>downwardAPI</code>, <code>emptyDir</code>, <code>persistentVolumeClaim</code>, <code>secret</code>, <code>projected</code>, <code>hostPath</code>, <code>flexVolume</code>.</td></tr><tr><td>Restrict host filesystem paths</td><td>Define the host paths that are allowed when using hostPath volumes.</td></tr><tr><td>Restrict drivers</td><td>Define the FlexVolume drivers that can be used.</td></tr><tr><td>Require read-only root filesystem</td><td>Specify that containers must run with a read-only root filesystem.</td></tr><tr><td>Restrict User and group ids</td><td>Controls which user ID or group ID the containers are run with or which group IDs get added. For users, specify <code>MustRunAs</code> to define specific user ID ranges, <code>MustRunAsNonRoot</code> to require non-root users, or <code>RunAsAny</code> to permit running as any user. For groups, specify <code>MustRunAs</code>, <code>MayRunAs</code> or <code>RunAsAny</code>.</td></tr><tr><td>Restrict escalation to root privileges</td><td>Controls the user privileges and prevents files from enabling extra capabilities.</td></tr><tr><td>Restrict Linux capabilities</td><td>Define the capabilities available to the pod. Set allowed capabilities to specify those capabilities that a container can use, and set Required drop capabilities to specify which privileges must be dropped from containers.</td></tr><tr><td>Restrict SELinux security context</td><td>Controls the SELinux context of the container. You can specify the level, role, type and user.</td></tr><tr><td>Restrict Proc Mount types</td><td>Defines the type of <code>/proc</code> mount to use for containers. Select either <code>Default</code> or <code>Unmasked</code>.</td></tr><tr><td>Restrict AppArmor profiles</td><td>Controls the AppArmor profile used by containers. Refer to the <a href="https://v1-21.docs.kubernetes.io/docs/tutorials/clusters/apparmor/#podsecuritypolicy-annotations">AppArmor documentation</a> for more details.</td></tr><tr><td>Restrict seccomp profiles</td><td>Controls the seccomp profile used by containers or pods.</td></tr><tr><td>Restrict sysctl profiles</td><td>Controls the sysctl profile used by containers. Specify the sysctls to forbid from use by pods.</td></tr></tbody></table>

&#x20;Once you have completed your configuration, click **Save settings** to apply your changes.



================================================
FILE: user/kubernetes/cluster/setup.md
================================================
# Setup

You can make changes to your environment's Kubernetes configuration by expanding **Cluster** from the menu then selecting **Setup**.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-cluster-setup.gif" alt=""><figcaption></figcaption></figure>

## Networking - Services

### Allow users to use external load balancer

{% hint style="info" %}
To use this feature, you need to ensure that your cloud provider allows you to create load balancers. Using this feature may incur costs from your cloud provider.
{% endhint %}

Enabling the load balancer feature will allow users to expose applications they deploy over an external IP address assigned by their cloud provider.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-cluster-setup-networking-services.png" alt=""><figcaption></figcaption></figure>

## Networking - Ingresses

Configuring ingress controllers will allow users to expose applications they deploy over a HTTP route.

Portainer auto detects and lists any ingress controllers defined in the cluster and sets them to allowed by default. As an admin you may choose to disable ingress controllers as needed.

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-cluster-setup-ingresses.png" alt=""><figcaption></figcaption></figure>

Enabling **Allow Ingress class to be set to "none"** will let users create ingress objects without specifying any Ingress Class. This is useful for Kubernetes implementations where there is no `IngressClass` defined in the cluster.

Enable the **Configure ingress controller availability per namespace** toggle to be able to control Ingress Class availability further at the namespace level.

Enabling **Only allow admins to deploy ingresses** restricts the deployment of ingresses to cluster administrators only, preventing standard users from creating new ingresses.

## Change Window Settings

This setting allows you to specify a window within which [GitOps updates](../applications/manifest.md#gitops-updates) to your applications can be applied.

{% hint style="warning" %}
If this setting is enabled and an update is made to an application outside of this window, it will not be applied.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-cluster-setup-changewindow.png" alt=""><figcaption></figcaption></figure>

## Deployment Options

This section allows you to override any global deployment options set for Kubernetes environments.

{% hint style="info" %}
This section only appears if the **Allow per environment override** option is enabled in [Settings](../../../admin/settings/#deployment-options).
{% endhint %}

| Field/Option                             | Overview                                                                                                                                                                       |
| ---------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Override global deployment options       | Enable this option to override the global deployment options for this environment.                                                                                             |
| Enforce code-based deployment            | When override is enabled, enable this option to hide the Add with form button when deploying applications and prevent the adding or editing of Kubernetes resources via forms. |
| Allow web editor and custom template use | When code-based deployment is enforced, enable this to allow the use of the web editor and custom templates when deploying an application.                                     |
| Allow specifying of a manifest via a URL | When code-based deployment is enforced, enable this allow the use of the URL option when deploying an application.                                                             |

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-cluster-setup-deployment.png" alt=""><figcaption></figcaption></figure>

## Security

### Restrict access to the default namespace

By default, a Kubernetes cluster will instantiate a default namespace when provisioning the cluster to hold the default set of pods, services, and deployments used by the cluster. If this option is enabled, the only users with the power to run applications in the default namespace are Portainer administrators.

### Restrict secret contents access for non-admins (UI only)

By default, users are able to view and edit Kubernetes secrets within the Portainer UI. Enabling this option disallows all non-admin users from doing so. Note that due to limitations within Kubernetes itself this only applies to the Portainer UI and does not prevent users from doing so through the command line or API.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-cluster-setup-security.png" alt=""><figcaption></figcaption></figure>

## Resources and Metrics

### Allow resource over-commit

Enabling this feature lets you allocate more resources to namespaces than are physically available in the cluster.

{% hint style="warning" %}
**Enable** resource over-commit if you need to assign more resources to namespaces than are physically available in the cluster. This may lead to unexpected deployment failures if there are insufficient resources to meet the demand.

**Disable** resource over-commit (highly recommended) if you are only able to assign resources to namespaces that are less (in aggregate) than the cluster total, minus any system-resource reservation.
{% endhint %}

### Enable features using the metrics API

{% hint style="info" %}
&#x20;Ensure that the Kubernetes [metrics server](https://kubernetes.io/docs/tasks/debug-application-cluster/resource-metrics-pipeline/#metrics-server) or [Prometheus](https://github.com/kubernetes-sigs/prometheus-adapter) is running inside your cluster.
{% endhint %}

Enabling this feature will allow users to use specific features that leverage the metrics API component, such as the memory and CPU usage graphs at the cluster and node level. If Portainer detects you are using a metrics server and is able to connect, this will default to on.

<figure><img src="../../../.gitbook/assets/2.15-k8s-cluster-setup-resources.png" alt=""><figcaption></figcaption></figure>

## Available storage options

Select which storage options will be available for use when deploying applications. Take a look at your storage driver documentation to figure out which access policy to configure, and whether or not the volume-expansion capability is supported. Any storage classes marked as default will be automatically set to on.

<figure><img src="../../../.gitbook/assets/2.15-k8s-cluster-setup-storage.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/kubernetes/configurations/README.md
================================================
# ConfigMaps & Secrets

In Portainer you can create configurations outside of a service's image or running containers. This allows you to keep your images as generic as possible, without the need to bind-mount configuration files into the containers, or to use environment variables.

{% hint style="info" %}
This section was previously known as **Configurations**.
{% endhint %}

This page is split into two tabs - [ConfigMaps](./#configmaps) and [Secrets](./#secrets).

## ConfigMaps

This tab displays the ConfigMaps that exist within your Kubernetes cluster. By default, system resources are hidden. To view them, click the three dot menu on the right hand side and check **Show system resources**.

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-configurations-configmaps-list.png" alt=""><figcaption></figcaption></figure>

You can filter the display of ConfigMaps by namespace by clicking **Filter** and checking the namespaces you want to see.

A ConfigMap with the **external** flag was created outside of Portainer, which means Portainer has limited knowledge on it compared to one created within Portainer. A label of **unused** means that Portainer cannot see any applications that are using this ConfigMap. This label may also appear on **external** resources because of the limited information available.

To add a new ConfigMap via a form, click the **Add with form** button. To add via a manifest, click **Create from manifest**.

{% content-ref url="add.md" %}
[add.md](add.md)
{% endcontent-ref %}

To remove a ConfigMap, check the box next to the ConfigMap you want to remove and click the **Remove** button.

## Secrets

This tab displays the secrets that exist within your Kubernetes cluster. By default, system resources are hidden. To view them, click the three dot menu on the right hand side and check **Show system resources**.

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-configurations-secrets-list.png" alt=""><figcaption></figcaption></figure>

You can filter the display of secrets by namespace by clicking **Filter** and checking the namespaces you want to see.

A secret with the **external** flag was created outside of Portainer, which means Portainer has limited knowledge on it compared to one created within Portainer. A label of **unused** means that Portainer cannot see any applications that are using this secret. This label may also appear on **external** resources because of the limited information available.

To add a new secret via a form, click the **Add with form** button. To add via a manifest, click **Create from manifest**.

{% content-ref url="add-1.md" %}
[add-1.md](add-1.md)
{% endcontent-ref %}

To remove a secret, check the box next to the secret you want to remove and click the **Remove** button.



================================================
FILE: user/kubernetes/configurations/add-1.md
================================================
# Add a Secret

From the menu select **ConfigMaps & Secrets**, ensure the **Secrets** tab is selected, then click **Add with form**.&#x20;

{% hint style="info" %}
Secrets can also be added [using a manifest](../applications/manifest.md) by clicking **Create from manifest**.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-configurations-secrets-add.gif" alt=""><figcaption></figcaption></figure>

Define the secret, using the table below as a guide.

| Field/Option | Overview                                                                                                                            |
| ------------ | ----------------------------------------------------------------------------------------------------------------------------------- |
| Namespace    | Select the namespace where the secret will be saved.                                                                                |
| Name         | Give the secret a descriptive name.                                                                                                 |
| Annotations  | You can add annotations to your secret as required by clicking **Add annotation** and filling in the **Key** and **Value** fields.  |
| Secret Type  | Select from the list of available secret types or select **Custom** to define your own type.                                        |

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-configurations-secrets-add.png" alt=""><figcaption></figcaption></figure>

Data fields change to reflect the type of Data to be entered based on the secret type selection above. In the **Data** section you can enter the details of your secret, in either **Simple mode** or **Advanced mode**. Under simple mode you can add entries in a key and value format, and in advanced mode you can paste in multiple values in YAML format.

<figure><img src="../../../.gitbook/assets/2.16-k8s-secret-data.png" alt=""><figcaption><p>Adding data in Simple mode</p></figcaption></figure>

<figure><img src="../../../.gitbook/assets/2.16-k8s-secret-data-adv.png" alt=""><figcaption><p>Adding data in Advanced mode</p></figcaption></figure>

When you have finished defining the secret, click **Create Secret.**



================================================
FILE: user/kubernetes/configurations/add.md
================================================
# Add a ConfigMap

From the menu select **ConfigMaps & Secrets**, ensure the **ConfigMaps** tab is selected, then click **Add with form**.&#x20;

{% hint style="info" %}
ConfigMaps can also be added [using a manifest](../applications/manifest.md) by clicking **Create from manifest**.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-configurations-configmaps-add.gif" alt=""><figcaption></figcaption></figure>

Define the ConfigMap, using the table below as a guide.

| Field/Option | Overview                                                                                                                               |
| ------------ | -------------------------------------------------------------------------------------------------------------------------------------- |
| Namespace    | Select the namespace where the ConfigMap will be saved.                                                                                |
| Name         | Give the ConfigMap a descriptive name.                                                                                                 |
| Annotations  | You can add annotations to your ConfigMap as required by clicking **Add annotation** and filling in the **Key** and **Value** fields.  |

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-configurations-configmaps-add.png" alt=""><figcaption></figcaption></figure>

In the **Data** section you can enter the details of your ConfgMap, in either **Simple mode** or **Advanced mode**. Under Simple mode you can add entries in a key and value format, and in Advanced mode you can paste in multiple values in YAML format.

<figure><img src="../../../.gitbook/assets/2.15-kubernetes_configmap_add_form_config_data.png" alt=""><figcaption><p>Adding data in Simple mode</p></figcaption></figure>

<figure><img src="../../../.gitbook/assets/2.15-kubernetes_configmap_add_from_config_data_simple.png" alt=""><figcaption><p>Adding data in Advanced mode</p></figcaption></figure>

When you have finished defining the ConfigMap, click **Create ConfigMap.**



================================================
FILE: user/kubernetes/more-resources/README.md
================================================
# More Resources

This section provides access to Kubernetes resources and objects that are not covered by the other menu options.

{% content-ref url="jobs.md" %}
[jobs.md](jobs.md)
{% endcontent-ref %}

{% content-ref url="service-accounts.md" %}
[service-accounts.md](service-accounts.md)
{% endcontent-ref %}

{% content-ref url="cluster-roles.md" %}
[cluster-roles.md](cluster-roles.md)
{% endcontent-ref %}

{% content-ref url="namespace-roles.md" %}
[namespace-roles.md](namespace-roles.md)
{% endcontent-ref %}



================================================
FILE: user/kubernetes/more-resources/cluster-roles.md
================================================
# Cluster Roles

This section lists the Cluster Roles and Cluster Role Bindings on your Kubernetes cluster. New Cluster Roles and Cluster Role Bindings can be created via the **Create from manifest** button.

Select the relevant tab to switch between Cluster Roles and Cluster Role Bindings.

## Cluster Roles

The list of Cluster Roles can be sorted by **Name** or the **Created** date. To remove a Cluster Role, check the box next to the Cluster Role you want to remove then click the **Remove** button.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-more-clusterroles-list.png" alt=""><figcaption></figcaption></figure>

## Cluster Role Bindings

The list of Cluster Role Bindings can be filtered by subject namespace and lists the **Name**, **Role Name**, **Role Kind**, **Subject Kind**, **Subject Name**, **Subject Namespace** and **Created** date. To remove a Cluster Role Binding, check the box next to the Cluster Role Binding you want to remove then click the **Remove** button.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-more-clusterrolebindings-list.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/kubernetes/more-resources/jobs.md
================================================
# Cron Jobs & Jobs

This section lists the Cron Jobs and Kubernetes Jobs on your Kubernetes cluster. New cron jobs and Kubernetes Jobs can be created via the **Create from file** button.

Select the relevant tab to switch between Cron Jobs and Jobs.

## Cron Jobs

The list of cron jobs can be sorted by any of the columns and filtered by Namespace, and can be expanded to view the executions for each cron job where you can see the status, start and finish times, duration, and view the logs for the execution by clicking **Logs**. To remove a cron job, check the box next to the cron job you want to remove then click the **Remove** button.

<figure><img src="../../../.gitbook/assets/2.26-kubernetes-more-resources-jobs-cronjobs.png" alt=""><figcaption></figcaption></figure>

## Jobs

The list of Kubernetes Jobs can be sorted by any of the columns and filtered by namespace, and the logs for Jobs can be listed by clicking **Logs**. To remove a Job, check the box next to the Job you want to remove then click the **Remove** button.

<figure><img src="../../../.gitbook/assets/2.26-kubernetes-more-resources-jobs-jobs.png" alt=""><figcaption></figcaption></figure>




================================================
FILE: user/kubernetes/more-resources/namespace-roles.md
================================================
# Roles

This section lists the Roles and Role Bindings on your Kubernetes cluster. New Roles and Role Bindings can be created via the **Create from manifest** button.

Select the relevant tab to switch between Roles and Role Bindings.

## Roles

The list of Roles can be filtered by namespace. To remove a Role, check the box next to the Role you want to remove then click the **Remove** button.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-more-roles-list.png" alt=""><figcaption></figcaption></figure>

## Role Bindings

The list of Role Bindings can be filtered by subject namespace and lists the **Name**, **Role Kind**, **Role Name**, **Subject Kind**, **Subject Name**, **Subject Namespace** and **Created** date. To remove a Role Binding, check the box next to the Role Binding you want to remove then click the **Remove** button.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-more-rolebindings-list.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/kubernetes/more-resources/service-accounts.md
================================================
# Service Accounts

This section lists the Service Accounts on your Kubernetes cluster. The list can be filtered by namespace. You can create new Service Accounts via manifests by clicking **Create from Manifest**, and you can remove Service Accounts by checking the box next to the Service Account to remove and clicking **Remove**.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-more-serviceaccounts-list.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/kubernetes/namespaces/README.md
================================================
# Namespaces

{% hint style="info" %}
Namespaces used to be called 'resource pools' prior to Portainer CE 2.6.0.
{% endhint %}

In Kubernetes, a single physical cluster can support multiple virtual clusters. These are known as namespaces.&#x20;

<figure><img src="../../../.gitbook/assets/2.24.0-kubernetes-namespaces-list.png" alt=""><figcaption></figcaption></figure>

You can add, remove or manage namespaces in Portainer.

{% content-ref url="add.md" %}
[add.md](add.md)
{% endcontent-ref %}

{% content-ref url="manage.md" %}
[manage.md](manage.md)
{% endcontent-ref %}

{% content-ref url="access.md" %}
[access.md](access.md)
{% endcontent-ref %}

{% content-ref url="remove.md" %}
[remove.md](remove.md)
{% endcontent-ref %}



================================================
FILE: user/kubernetes/namespaces/access.md
================================================
# Manage access to a namespace

{% hint style="info" %}
Kubernetes role-based access control (RBAC) must be enabled and working before access control will work in Portainer.
{% endhint %}

From the menu select **Namespaces** then select **Manage access** on the same row as the namespace you want to manage.

<figure><img src="../../../.gitbook/assets/2.20-namespaces-access.gif" alt=""><figcaption></figcaption></figure>

Select the users/teams who will have access then click **Create access**.

{% hint style="info" %}
Users or groups with cluster-wide roles (such as the Operator role) cannot be assigned to individual namespaces, as their cluster-wide nature applies to all namespaces in the environment.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.20-namespaces-access-create.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/kubernetes/namespaces/add.md
================================================
# Add a new namespace

From the menu select **Namespaces** then click **Add with form**.

{% hint style="info" %}
Namespaces can also be added [using a manifest](../applications/manifest.md) by clicking **Create from manifest**.
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.20-namespaces-add.gif" alt=""><figcaption></figcaption></figure>

Give the namespace a descriptive **name**. As an optional step you can add annotations to your namespace as required by clicking **Add annotation** and filling in the **Key** and **Value** fields.&#x20;

<figure><img src="../../../.gitbook/assets/2.18-k8s-namespaces-add-name.png" alt=""><figcaption></figcaption></figure>

### Resource quota

You can assign a quota by toggling **Resource assignment** on, then setting resource limits like how much memory and CPU will be assigned.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-namespaces-add-resourcequota.png" alt=""><figcaption></figcaption></figure>

### Load balancers

To set a maximum number of external load balancers that can be created inside the namespace, toggle on **Load Balancer quota** and set the **Max Load Balancers** number. If Load Balancer quota is enabled and the Max Load Balancers value is set to `0`, the use of external load balancers is effectively disabled in the namespace.

{% hint style="info" %}
This section is only visible when **Allow users to use external load balancers** is enabled in the [Cluster Setup](../cluster/setup.md#allow-users-to-use-external-load-balancer).
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.18-k8s-namespaces-add-lbquota.png" alt=""><figcaption></figcaption></figure>

### Networking - Ingresses

This section lets you define which ingress controllers are allowed to be used to publish applications within this namespace. Check the boxes next to the ingresses you want to allow and click **Allow selected**, or click **Disallow selected** to disallow their use in this namespace.

{% hint style="info" %}
This section is only visible when **Configure ingress controller availability per namespace** is enabled in the [Cluster Setup](../cluster/setup.md#networking-ingresses).
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.20-namespaces-add-ingress.png" alt=""><figcaption></figcaption></figure>

### Registries

You can define the registries that are available within this namespace in this section. Select the registries from the **Select registries** dropdown to allow access.

<figure><img src="../../../.gitbook/assets/2.18-k8s-namespaces-add-registries.png" alt=""><figcaption></figcaption></figure>

### Storage

Use this section to enable quotas on your storage options for this namespace. To enable the use of quotas on a storage option, toggle **Enable quota** to on and set the **Maximum usage**. A Maximum usage value of `0` effectively prevents the usage of that storage option within the namespace.&#x20;

<figure><img src="../../../.gitbook/assets/2.18-k8s-namespaces-add-storage.png" alt=""><figcaption></figcaption></figure>

### Summary

This section displays a summary of the actions that will be taken when clicking the Add namespace button.&#x20;

<figure><img src="../../../.gitbook/assets/2.18-k8s-namespaces-add-summary.png" alt=""><figcaption></figcaption></figure>

When you're finished, click **Create namespace**.



================================================
FILE: user/kubernetes/namespaces/manage.md
================================================
# Manage a namespace

From the menu select **Namespaces** then select the namespace you want to manage.

<figure><img src="../../../.gitbook/assets/2.20-namespaces-manage.gif" alt=""><figcaption></figcaption></figure>

Here you can view details about the namespace and configure options specific to the namespace.

## Resource Quota

Toggle on **Resource assignment** to enable quotas for this namespace, then define the memory and CPU limits. The current resource reservation and usage for the namespace will be displayed when a limit is set.

<figure><img src="../../../.gitbook/assets/2.25-kubernetes-namespaces-manage-resourcequota.png" alt=""><figcaption></figcaption></figure>

## Load balancers

With this setting you can configure the amount of external load balancers that can be created in this namespace.&#x20;

{% hint style="info" %}
This option only appears when **Allow users to use external load balancer** is enabled in the [cluster setup](../cluster/setup.md#allow-users-to-use-external-load-balancer).
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.17-k8s-namespaces-manage-loadbalancer.png" alt=""><figcaption></figcaption></figure>

## Networking

This section lets you define which ingress controllers are allowed to be used to publish applications within this namespace. Check the boxes next to the ingresses you want to allow and click **Allow selected**, or click **Disallow selected** to disallow their use in this namespace.

{% hint style="info" %}
This section is only visible when **Configure ingress controller availability per namespace** is enabled in the [Cluster Setup](../cluster/setup.md#networking-ingresses).
{% endhint %}

<figure><img src="../../../.gitbook/assets/2.20-namespaces-add-ingress.png" alt=""><figcaption></figcaption></figure>

## Registries

You can define the registries that are available within this namespace in this section. Select the registries from the **Select registries** dropdown to allow access.

<figure><img src="../../../.gitbook/assets/2.18-k8s-namespaces-add-registries.png" alt=""><figcaption></figcaption></figure>

## Storage

For each storage option available in the cluster, you can configure quotas for this namespace to limit usage.

<figure><img src="../../../.gitbook/assets/2.15-kubernetes_namespaces_manage_namespace_storage.png" alt=""><figcaption></figcaption></figure>

## Summary

If you have made changes to the configuration, this section will list those changes.

<figure><img src="../../../.gitbook/assets/2.15-kubernetes_namespaces_manage_namespaces_summary.png" alt=""><figcaption></figcaption></figure>

## Actions

Once you have made the necessary changes, click **Update namespace**. Here you can also flag the namespace as a system namespace by clicking **Mark as system**.

<figure><img src="../../../.gitbook/assets/2.15-kubernetes_namespaces_manage_namespaces_actions.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/kubernetes/namespaces/remove.md
================================================
# Remove a namespace

From the menu select **Namespaces**, tick the checkbox next to the namespace then click **Remove**.

<figure><img src="../../../.gitbook/assets/2.20-namespaces-remove.gif" alt=""><figcaption></figcaption></figure>

When the confirmation message appears, click **Remove**.

<figure><img src="../../../.gitbook/assets/2.15-k8s-namespaces-remove-confirm.png" alt=""><figcaption></figcaption></figure>

If a namespace is stuck in a terminating state, Portainer will ask if you want to force deletion of that namespace.



================================================
FILE: user/kubernetes/networking/README.md
================================================
# Networking

This section allows you to create, configure and manage networking-related objects within your Kubernetes environment.

{% content-ref url="services.md" %}
[services.md](services.md)
{% endcontent-ref %}

{% content-ref url="ingresses/" %}
[ingresses](ingresses/)
{% endcontent-ref %}



================================================
FILE: user/kubernetes/networking/services.md
================================================
# Services

In Kubernetes, a **Service** is an object that is used to expose an application (running in pods) to a network.&#x20;

The Services page lists the services within your cluster, and provides detail on each service. To view the list of services, expand **Networking** and select **Services** from the left hand menu.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-networking-services.gif" alt=""><figcaption></figcaption></figure>

All the services the user has access to are listed on this page.

<figure><img src="../../../.gitbook/assets/2.20-kubernetes-networking-services-list.png" alt=""><figcaption></figcaption></figure>

For each service, the list displays the **name** of the service, the **application** and **namespace** the service belongs to, the **type** of service, the exposed **ports** and **target ports**, the **cluster IP** and **external IP** (if any) and the **creation date** and **user** (if available). Services provisioned externally to Portainer are marked with the **external** label, and system services are marked with the **system** label.&#x20;

{% hint style="info" %}
The display of system services can be toggled under the table settings (click the three dots at the top right of the table and tick **Show system resources**.
{% endhint %}



================================================
FILE: user/kubernetes/networking/ingresses/README.md
================================================
# Ingresses

An **Ingress** in Kubernetes is an API object that provides routing rules to manage external users' access to the services in a Kubernetes cluster, typically via HTTPS/HTTP. With Ingress, you can easily set up rules for routing traffic without creating a bunch of Load Balancers or exposing each service on the node.

To view, edit or create ingresses in your environment, expand **Networking** and select **Ingresses** from the left hand menu.

<figure><img src="../../../../.gitbook/assets/2.20-kubernetes-networking-ingresses.gif" alt=""><figcaption></figcaption></figure>

All the Ingresses that a user has access to are listed on this page.&#x20;

<figure><img src="../../../../.gitbook/assets/2.20-kubernetes-networking-ingresses-list.png" alt=""><figcaption></figcaption></figure>

New Ingress objects can be created either manually or through a manifest:

{% content-ref url="add.md" %}
[add.md](add.md)
{% endcontent-ref %}

{% content-ref url="manifest.md" %}
[manifest.md](manifest.md)
{% endcontent-ref %}

If you no longer require an Ingress, it can be removed:

{% content-ref url="remove-an-ingress.md" %}
[remove-an-ingress.md](remove-an-ingress.md)
{% endcontent-ref %}



================================================
FILE: user/kubernetes/networking/ingresses/add.md
================================================
# Add an Ingress manually

From the menu expand **Networking**, select **Ingresses** then click **Add with form**.

<figure><img src="../../../../.gitbook/assets/2.20-kubernetes-networking-ingresses-add.gif" alt=""><figcaption></figcaption></figure>

Select the **namespace** that the Ingress needs to be created in from the list.

Complete the required information, using the sections below as a guide.

### Base Configuration

<table><thead><tr><th width="213">Field/Option</th><th>Overview</th><th data-hidden></th><th data-hidden></th></tr></thead><tbody><tr><td>Name</td><td>Enter a descriptive name for the ingress.</td><td></td><td></td></tr><tr><td>Ingress class</td><td>Select an Ingress Class object from the list, or select <strong>none</strong> when no <code>IngressClass</code> info is needed in the Ingress specification.</td><td></td><td></td></tr><tr><td>Annotations</td><td>You can add annotations to your ingress as required by clicking <strong>Add annotation</strong> and filling in the <strong>Key</strong> and <strong>Value</strong> fields. Depending on your selected ingress class you may also be able to add rewrite annotations and/or regular expression annotations.</td><td></td><td></td></tr></tbody></table>

<figure><img src="../../../../.gitbook/assets/2.18-k8s-ingresses-add-name.png" alt=""><figcaption></figcaption></figure>

{% hint style="info" %}
**Note for Google Cloud users**

Google Cloud ingress controller (gce or GKE Ingress) continues to use the deprecated `kubernetes.io/ingress.class` annotation on ingresses, whereas most other ingress controllers use the `IngressClass` resource that was introduced in Kubernetes 1.18.

Portainer targets the `IngressClass` resource means of specifying ingress classes, but you can still use the Google Cloud ingress controllers by turning on the **Allow ingress class to be set to "none"** toggle in [Cluster setup](../../cluster/setup.md#ingress-controllers) and setting them up as custom with `none` selected as their **Ingress class**. Then when adding an ingress based on this, set an annotation with the **key** `kubernetes.io/ingress.class` and **value** `gce.`
{% endhint %}

### Ingress Rule

Here you can define the specifics for the Ingress rule:

<table><thead><tr><th width="201">Field/Option</th><th>Overview</th><th data-hidden></th></tr></thead><tbody><tr><td>Hostname</td><td>Enter the FQDN that the application should be accessed with<br>eg: <code>myapp.mydomain.com</code>.</td><td></td></tr><tr><td>TLS Secret</td><td>Select the TLS secret that holds the SSL certificate information for the hostname entered above. Optionally, create a new <a href="../../configurations/add-1.md">TLS Secret</a> by clicking on the <strong>Create secret</strong> link (opens in a new tab). Once secret is created click on the reload button next to the TLS secret dropdown and select the new secret.</td><td></td></tr><tr><td>Service</td><td>Select a service that you want to expose from the list.</td><td></td></tr><tr><td>Service port</td><td>Select the port that needs to be exposed from the list.</td><td></td></tr><tr><td>Path type</td><td>Select the relevant path type. The default is <code>Prefix</code>.</td><td></td></tr><tr><td>Path</td><td>Enter the path to expose the application on. To expose on the root of the domain use <code>/</code>.</td><td></td></tr></tbody></table>

You can expose other services using a different path by clicking on **Add path**.

<figure><img src="../../../../.gitbook/assets/2.19-kubernetes-ingress-create-rules.png" alt=""><figcaption></figcaption></figure>

Add more rules by clicking on **Add new host** or a fallback rule by **Add fallback rule**.

{% hint style="info" %}
A fallback rule has no host specified. This rule only applies when an inbound request has a hostname that does not match with any of your other rules.
{% endhint %}

When you're ready, click **Create**.



================================================
FILE: user/kubernetes/networking/ingresses/manifest.md
================================================
# Add an Ingress using a manifest

There are two ways to add a new ingress: [manually by using a form](add.md) or automatically by using a manifest. This article explains how to add an ingress using a manifest.

{% hint style="info" %}
Manifests aren't just for Ingresses - you can also deploy namespaces, ConfigMaps, secrets and volumes using a manifest.
{% endhint %}

From the menu expand **Networking**, select **Ingresses** then click **Create from manifest**.

<figure><img src="../../../../.gitbook/assets/2.20-kubernetes-networking-ingresses-manifest.gif" alt=""><figcaption></figcaption></figure>

From here you can follow the instructions for adding from a manifest.

{% content-ref url="../../applications/manifest.md" %}
[manifest.md](../../applications/manifest.md)
{% endcontent-ref %}



================================================
FILE: user/kubernetes/networking/ingresses/remove-an-ingress.md
================================================
# Remove an Ingress

From the menu expand **Networking** and select **Ingress**, tick the checkbox next to the Ingress you want to remove then click **Remove**. Click **Remove** again to confirm.

<figure><img src="../../../../.gitbook/assets/2.20-kubernetes-networking-ingresses-remove.gif" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/kubernetes/templates/README.md
================================================
# Custom Templates

Portainer BE 2.10 added custom template support for Kubernetes environments, allowing you to create templates based on Kubernetes manifests for future deployment.

From the menu select **Custom Templates** to view a list of custom templates you've already created.

<figure><img src="../../../.gitbook/assets/2.15-k8s_kubernetes_custom_templates.gif" alt=""><figcaption></figcaption></figure>

You can create a new template.

{% content-ref url="add.md" %}
[add.md](add.md)
{% endcontent-ref %}

You can also edit an existing template.

{% content-ref url="edit.md" %}
[edit.md](edit.md)
{% endcontent-ref %}

And, if you no longer need a custom template, you can simply remove it.

{% content-ref url="remove.md" %}
[remove.md](remove.md)
{% endcontent-ref %}



================================================
FILE: user/kubernetes/templates/add.md
================================================
# Add a new custom template

## Creating the template

From the menu select **Custom Templates** then click **Add Custom Template**.

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-templates-add.gif" alt=""><figcaption></figcaption></figure>

Complete the form, using the table below as a guide.

| Field/Option | Overview                                                                                         |
| ------------ | ------------------------------------------------------------------------------------------------ |
| Title        | Enter a title for your custom template. This is how the template will appear when it's deployed. |
| Description  | Enter a description of the template.                                                             |
| Note         | As an optional step, record some extra information about the template.                           |
| Icon URL     | Optionally, enter the URL to an image to use as an icon for the template.                        |

<figure><img src="../../../.gitbook/assets/2.15-kubernetes_create_custom_template.png" alt=""><figcaption></figcaption></figure>

Next, select the **Build method**.

## Selecting the build method

### Method 1: Web editor

Define or paste the contents of your manifest file into the web editor. When deploying an application using a custom template you will be given an opportunity to edit the manifest before deployment.

{% hint style="info" %}
You can search within the web editor at any time by pressing `Ctrl-F` (or `Cmd-F` on Mac).
{% endhint %}



<figure><img src="../../../.gitbook/assets/2.19-kubernetes-templates-add-web.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Create custom template**.

### Method 2: Upload

If you have a manifest file locally, you can upload it directly to Portainer. Click **Select file** to browse to the file.



<figure><img src="../../../.gitbook/assets/2.19-kubernetes-templates-add-upload.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Create custom template**.

### Method 3: Repository

If you have a template in a Git repository, you can add it to your custom templates. Enter the required details for access to your Git repository.

| Field/Option          | Overview                                                                                                                                  |
| --------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- |
| Authentication        | Toggle this option on if your repository requires authentication.                                                                         |
| Git credentials       | If you have credentials configured you can select the set to use from this dropdown.                                                      |
| Username              | Enter your Git username.                                                                                                                  |
| Personal access token | Enter your personal access token or password.                                                                                             |
| Repository URL        | Enter the URL to your Git repository.                                                                                                     |
| Repository reference  | Select the reference to use from your repository. This will be auto populated with available references from your repository.             |
| Manifest path         | Enter the path and filename of the manifest within your repository.                                                                       |
| Skip TLS Verification | Toggle this option on to skip TLS verification for the repository. This is useful if you are using self-signed certificates on your repo. |

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-templates-add-git.png" alt=""><figcaption></figcaption></figure>

When you're ready, click **Create custom template**.

## Variables in templates

Custom templates support the use of variables to provide further customization of the deployed stack. A stack can define a variable that can then be adjusted by the user at deployment.

{% hint style="info" %}
This feature is only available in Portainer Business Edition.
{% endhint %}

Variables are identified in stacks with `{{ }}`. For example, the following stack provides a `REPLICA_COUNT` variable:

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-templates-add-variables.png" alt=""><figcaption></figcaption></figure>

When a variable is defined, options appear to customize how the variable appears when deploying the stack. You can set the **label**, **description** and **default value**.

When a template is deployed, any variables that have been configured are editable:

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-templates-add-variables-deploy.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/kubernetes/templates/edit.md
================================================
# Edit a custom template

From the menu select **Custom Templates** then click **Edit** next to the template you want to edit.

<figure><img src="../../../.gitbook/assets/2.15-k8s_kubernetes_edit_custom_templates.gif" alt=""><figcaption></figcaption></figure>

{% hint style="info" %}
You can search within the web editor at any time by pressing `Ctrl-F` (or `Cmd-F` on Mac).
{% endhint %}

If your template is deployed from a Git repository, you will have the option to edit the Git settings if required. You can also click **Reload custom template** to update the template from the remote repository.

<figure><img src="../../../.gitbook/assets/2.19-kubernetes-templates-edit-git.png" alt=""><figcaption></figcaption></figure>

Make the required changes to the template then click **Update the template**.



================================================
FILE: user/kubernetes/templates/remove.md
================================================
# Remove a custom template

{% hint style="info" %}
Removing a custom template will not remove any deployments created using the template.
{% endhint %}

From the menu select **Custom Templates** then click **Delete** next to the template you want to remove.

<figure><img src="../../../.gitbook/assets/2.15-k8s_kubernetes_delete_custom_templates.gif" alt=""><figcaption></figcaption></figure>

When the confirmation message appears, click **Remove**.

<figure><img src="../../../.gitbook/assets/2.15-k8s-templates-remove-confirm.png" alt=""><figcaption></figcaption></figure>




================================================
FILE: user/kubernetes/volumes/README.md
================================================
# Volumes

In Kubernetes, a volume is an abstraction of a file system that is available to applications. In Portainer you can manage the volumes that have been deployed by your applications within your cluster.

{% hint style="info" %}
Volumes can also be added [using a manifest](../applications/manifest.md) by clicking **Create from manifest**.
{% endhint %}

{% content-ref url="inspect.md" %}
[inspect.md](inspect.md)
{% endcontent-ref %}

{% content-ref url="../../docker/volumes/remove.md" %}
[remove.md](../../docker/volumes/remove.md)
{% endcontent-ref %}

## Volumes tab

Lets you view information about the volumes that exist within the cluster, including:

* The namespace that each volume is a part of.
* Which applications use each volume.
* The storage class each volume belongs to.
* The size of each volume.
* When the volumes were created and by whom.
* A volume with the **external** flag was created outside of Portainer, which means Portainer has limited knowledge on it compared to one created within Portainer. A label of **unused** means that Portainer cannot see any applications that are using this volume. This label may also appear on **external** resources because of the limited information available.

<figure><img src="../../../.gitbook/assets/2.15-kubernetes_volumes_voulme_list.png" alt=""><figcaption></figcaption></figure>

## Storage tab

The storage tab lists the storage classes available within your infrastructure along with the disk space used by each volume. Each storage class can be expanded to list the volumes contained within.

<figure><img src="../../../.gitbook/assets/2.15-kubernetes_volumes_storage_list.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/kubernetes/volumes/inspect.md
================================================
# Inspect a volume

From the menu select **Volumes** then select the volume you want to inspect.

<figure><img src="../../../.gitbook/assets/2.15-k8s_kubernetes_volume_inspect.gif" alt=""><figcaption></figcaption></figure>

When you select a volume, the screen will divide into three sections, each described below.

## Volume section

Summarizes key information about the volume.

| Attribute            | Overview                                                                                                                                             |
| -------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                 | The name of the volume.                                                                                                                              |
| Namespace            | The namespace that the volume belongs to.                                                                                                            |
| Storage              | The storage object that the volume uses.                                                                                                             |
| Shared Access Policy | The access policy configured for the volume.                                                                                                         |
| Provisioner          | The storage provisioner that provisions the volume.                                                                                                  |
| Creation date        | When the volume was created.                                                                                                                         |
| Size                 | The size of the volume. You can grow a volume by clicking the **Increase size** button and adjusting the value. Shrinking a volume is not supported. |

<figure><img src="../../../.gitbook/assets/2.15-kubernetes_volumes_volume_section.png" alt=""><figcaption></figcaption></figure>

## Events section

Shows information about volume-related events.

<figure><img src="../../../.gitbook/assets/2.15-k8s-volumes-inspect-events.png" alt=""><figcaption></figcaption></figure>

## YAML section

This displays the YAML generated from the volume deployment. Use it to create backups of the configuration.

<figure><img src="../../../.gitbook/assets/2.15-kubernetes_volume_volume_yaml.png" alt=""><figcaption></figcaption></figure>



================================================
FILE: user/kubernetes/volumes/remove.md
================================================
# Remove a volume

{% hint style="warning" %}
You can only remove a volume that is free and has been [detached from any applications that use it](../applications/detach-volume.md).
{% endhint %}

From the menu select **Volumes**, tick the checkbox next to the volume you want to remove then click **Remove**.

<figure><img src="../../../.gitbook/assets/2.15-k8s-volumes-remove.gif" alt=""><figcaption></figcaption></figure>

When the confirmation message appears, click **Remove**.

<figure><img src="../../../.gitbook/assets/2.15-k8s-volumes-remove-confirm.png" alt=""><figcaption></figcaption></figure>


